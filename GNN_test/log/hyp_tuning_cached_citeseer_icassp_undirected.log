nohup: ignoring input
wandb: Agent Starting Run: r2l6t893 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Currently logged in as: jamesli-wks (jamesli-wks-johns-hopkins-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211403-r2l6t893
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r2l6t893
Create sweep with ID: dmkp0e91
Sweep URL: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:00<01:01,  3.25it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:02, 78.13it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 127.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 157.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 179.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 195.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 207.96it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 216.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 219.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.29
wandb:  sub_train_acc 0.2648
wandb: sub_train_loss 1.0675
wandb:       test_acc 0.321
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run twilight-sweep-1 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r2l6t893
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211403-r2l6t893/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: amrynshe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211421-amrynshe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/amrynshe
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 228.58it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 230.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 229.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 230.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 231.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 232.11it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 232.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 231.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 231.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.26781
wandb: sub_train_loss 1.06885
wandb:       test_acc 0.321
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run whole-sweep-2 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/amrynshe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211421-amrynshe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ioyd929a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211435-ioyd929a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ioyd929a
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.67it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 214.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 211.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 213.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 216.26it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 219.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 220.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 219.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.366
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.31079
wandb: sub_train_loss 1.149
wandb:       test_acc 0.368
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run colorful-sweep-3 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ioyd929a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211435-ioyd929a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1156vztw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211451-1156vztw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1156vztw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 228.25it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 230.97it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 233.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 235.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 233.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 224.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 219.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 203.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 214.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.358
wandb: best_valid_acc 0.404
wandb:  sub_train_acc 0.30237
wandb: sub_train_loss 1.14907
wandb:       test_acc 0.356
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run misunderstood-sweep-4 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1156vztw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211451-1156vztw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gbuheub1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211507-gbuheub1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gbuheub1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.76it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 197.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 208.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 218.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 224.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 228.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 230.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 231.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 223.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.372
wandb: best_valid_acc 0.36
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1.17219
wandb:       test_acc 0.321
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run drawn-sweep-5 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gbuheub1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211507-gbuheub1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g1dbgiuh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211522-g1dbgiuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g1dbgiuh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 221.19it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 214.71it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 210.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 213.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 217.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 218.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 216.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 212.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 212.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.327
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.31049
wandb: sub_train_loss 1.17143
wandb:       test_acc 0.32
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run vocal-sweep-6 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g1dbgiuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211522-g1dbgiuh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 14nleg11 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211538-14nleg11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/14nleg11
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 220.45it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 225.35it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 222.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 220.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 222.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 225.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 226.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 227.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 224.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.262
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.17583
wandb: sub_train_loss 1.16496
wandb:       test_acc 0.171
wandb:      valid_acc 0.15
wandb: 
wandb: üöÄ View run solar-sweep-7 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/14nleg11
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211538-14nleg11/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gezzaq0w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211559-gezzaq0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gezzaq0w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 214.01it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 215.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 215.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 215.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 214.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 213.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 215.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 218.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.17613
wandb: sub_train_loss 1.16423
wandb:       test_acc 0.173
wandb:      valid_acc 0.154
wandb: 
wandb: üöÄ View run fallen-sweep-8 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gezzaq0w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211559-gezzaq0w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 057onum3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211614-057onum3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/057onum3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 210.71it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 214.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 215.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 212.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 204.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 198.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 196.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 198.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 203.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.532
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.46138
wandb: sub_train_loss 1.20789
wandb:       test_acc 0.514
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run robust-sweep-9 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/057onum3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211614-057onum3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lg0h06tz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211629-lg0h06tz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lg0h06tz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.49it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 220.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 222.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 224.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 223.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 219.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 212.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 209.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 214.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.35317
wandb: sub_train_loss 1.20775
wandb:       test_acc 0.396
wandb:      valid_acc 0.36
wandb: 
wandb: üöÄ View run wobbly-sweep-10 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lg0h06tz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211629-lg0h06tz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wi2vqkam with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211651-wi2vqkam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wi2vqkam
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 190.95it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 198.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 205.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 208.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 209.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 206.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 204.62it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 204.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 203.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.235
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.22873
wandb: sub_train_loss 1.22427
wandb:       test_acc 0.248
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run silver-sweep-11 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wi2vqkam
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211651-wi2vqkam/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8kcssljg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211702-8kcssljg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8kcssljg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.34it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.51it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 191.22it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 193.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 192.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 194.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 195.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 200.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 204.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.4
wandb: best_valid_acc 0.368
wandb:  sub_train_acc 0.33874
wandb: sub_train_loss 1.22287
wandb:       test_acc 0.4
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run hardy-sweep-12 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8kcssljg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211702-8kcssljg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e4ipngnm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211717-e4ipngnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e4ipngnm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.36it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 185.71it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 187.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 188.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 188.11it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 187.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 188.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 189.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 181.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 181.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.488
wandb: best_valid_acc 0.498
wandb:  sub_train_acc 0.46859
wandb: sub_train_loss 1.22712
wandb:       test_acc 0.488
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run vital-sweep-13 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e4ipngnm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211717-e4ipngnm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0k9a77o5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211731-0k9a77o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0k9a77o5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 198.15it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 201.45it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 200.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 201.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 202.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 201.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 199.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 197.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 197.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 199.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.543
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.50736
wandb: sub_train_loss 1.22649
wandb:       test_acc 0.543
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run winter-sweep-14 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0k9a77o5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211731-0k9a77o5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s1t01fu4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211747-s1t01fu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s1t01fu4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.30it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 170.20it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 168.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 169.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 179.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 184.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 188.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 191.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 192.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.622
wandb:  sub_train_acc 0.58852
wandb: sub_train_loss 1.25016
wandb:       test_acc 0.587
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run efficient-sweep-15 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s1t01fu4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211747-s1t01fu4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4pvoa48x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211803-4pvoa48x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4pvoa48x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 149.71it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 144.03it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 142.81it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 139.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 142.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 138.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 142.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 145.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 154.46it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 164.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 167.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 173.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 155.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.597
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.55756
wandb: sub_train_loss 1.25018
wandb:       test_acc 0.533
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run polished-sweep-16 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4pvoa48x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211803-4pvoa48x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7p7qcm22 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211818-7p7qcm22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7p7qcm22
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.75it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.19it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.99it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 160.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 164.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 171.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 178.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 183.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 185.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 184.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.275
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.25458
wandb: sub_train_loss 0.00662
wandb:       test_acc 0.275
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run likely-sweep-17 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7p7qcm22
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211818-7p7qcm22/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: he3apm8u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211834-he3apm8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/he3apm8u
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 177.29it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.03it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 179.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 175.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 172.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 170.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 170.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 177.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 180.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 186.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.301
wandb: best_valid_acc 0.29
wandb:  sub_train_acc 0.24436
wandb: sub_train_loss 0.0129
wandb:       test_acc 0.257
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run balmy-sweep-18 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/he3apm8u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211834-he3apm8u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q5mbvz9j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211849-q5mbvz9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q5mbvz9j
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.74it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.71it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 170.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 180.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 187.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 190.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 190.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 191.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 190.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 190.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.324
wandb: best_valid_acc 0.37
wandb:  sub_train_acc 0.29907
wandb: sub_train_loss 0.01197
wandb:       test_acc 0.324
wandb:      valid_acc 0.37
wandb: 
wandb: üöÄ View run jumping-sweep-19 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q5mbvz9j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211849-q5mbvz9j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a878gn3w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211904-a878gn3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a878gn3w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.06it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 158.36it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 149.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 138.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 145.62it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 155.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 159.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 172.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 182.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 189.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 193.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.454
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.33063
wandb: sub_train_loss 0.00567
wandb:       test_acc 0.463
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run drawn-sweep-20 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a878gn3w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211904-a878gn3w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: adnptk3p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211920-adnptk3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/adnptk3p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.29it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 183.78it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 185.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 185.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 185.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 186.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 185.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 185.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 185.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 184.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.443
wandb: best_valid_acc 0.452
wandb:  sub_train_acc 0.41479
wandb: sub_train_loss 0.01255
wandb:       test_acc 0.451
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run exalted-sweep-21 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/adnptk3p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211920-adnptk3p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p3qcpclm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211935-p3qcpclm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p3qcpclm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.22it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 183.42it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 188.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 188.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 187.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 186.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 171.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 168.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 169.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 171.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.408
wandb:  sub_train_acc 0.40186
wandb: sub_train_loss 0.00845
wandb:       test_acc 0.413
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run dashing-sweep-22 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p3qcpclm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211935-p3qcpclm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 25rrfsfe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211950-25rrfsfe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/25rrfsfe
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.48it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.69it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 170.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 172.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 174.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 168.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 176.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 181.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 186.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 188.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.477
wandb: best_valid_acc 0.496
wandb:  sub_train_acc 0.38834
wandb: sub_train_loss 0.00763
wandb:       test_acc 0.441
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run rosy-sweep-23 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/25rrfsfe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211950-25rrfsfe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b6rfkbau with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212005-b6rfkbau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b6rfkbau
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.49it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.46it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 157.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 163.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 164.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 170.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 172.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 164.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 159.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 162.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.476
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.42681
wandb: sub_train_loss 0.0077
wandb:       test_acc 0.485
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run ancient-sweep-24 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b6rfkbau
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212005-b6rfkbau/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kokmph3d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212021-kokmph3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kokmph3d
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.71it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.73it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.17it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 166.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 170.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 174.55it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 172.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 167.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 159.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 152.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 151.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.4208
wandb: sub_train_loss 0.00843
wandb:       test_acc 0.57
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run swept-sweep-25 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kokmph3d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212021-kokmph3d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j4n7oq2g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212036-j4n7oq2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j4n7oq2g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.59it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 161.77it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 161.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 165.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 168.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 173.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 176.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 177.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 180.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 184.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.483
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.40667
wandb: sub_train_loss 0.00988
wandb:       test_acc 0.472
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run tough-sweep-26 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j4n7oq2g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212036-j4n7oq2g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6xy431q7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212051-6xy431q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6xy431q7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.20it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.10it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 171.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 174.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 175.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 175.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 175.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 177.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 181.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 184.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.568
wandb: best_valid_acc 0.584
wandb:  sub_train_acc 0.46889
wandb: sub_train_loss 0.01387
wandb:       test_acc 0.567
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run zany-sweep-27 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6xy431q7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212051-6xy431q7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: msm4f7vs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212112-msm4f7vs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/msm4f7vs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.29it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 162.34it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 162.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 161.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 159.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 159.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 159.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 158.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 158.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 162.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 168.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.562
wandb: best_valid_acc 0.59
wandb:  sub_train_acc 0.48843
wandb: sub_train_loss 0.0135
wandb:       test_acc 0.572
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run celestial-sweep-28 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/msm4f7vs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212112-msm4f7vs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a0ucx9ia with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212128-a0ucx9ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a0ucx9ia
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.37it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 178.57it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 179.34it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 176.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 171.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 170.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 169.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 170.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 170.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 170.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 169.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.626
wandb: best_valid_acc 0.608
wandb:  sub_train_acc 0.54884
wandb: sub_train_loss 0.00374
wandb:       test_acc 0.59
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run icy-sweep-29 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a0ucx9ia
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212128-a0ucx9ia/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 91m9hq5t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212142-91m9hq5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/91m9hq5t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.31it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.93it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 149.60it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 144.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 141.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 138.91it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 140.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 148.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 155.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 158.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 159.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 160.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.612
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.58191
wandb: sub_train_loss 0.00389
wandb:       test_acc 0.612
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run robust-sweep-30 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/91m9hq5t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212142-91m9hq5t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6afz6ch7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212203-6afz6ch7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6afz6ch7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.24it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.40it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 156.75it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 159.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 161.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 161.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 160.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 159.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 158.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 156.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 155.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 153.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.598
wandb: best_valid_acc 0.626
wandb:  sub_train_acc 0.60956
wandb: sub_train_loss 0.00418
wandb:       test_acc 0.587
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run fresh-sweep-31 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6afz6ch7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212203-6afz6ch7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xoltjd51 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212224-xoltjd51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xoltjd51
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.03it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 142.60it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 140.39it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 142.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 145.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 147.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 148.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 150.32it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 150.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 153.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 156.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 159.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.659
wandb: best_valid_acc 0.672
wandb:  sub_train_acc 0.65404
wandb: sub_train_loss 0.00247
wandb:       test_acc 0.648
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run misunderstood-sweep-32 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xoltjd51
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212224-xoltjd51/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a2ptq432 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212238-a2ptq432
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a2ptq432
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.14it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.14it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 141.49it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 145.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 148.48it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 148.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 153.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 154.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 147.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 146.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.339
wandb: best_valid_acc 0.302
wandb:  sub_train_acc 0.18936
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.181
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run lively-sweep-33 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a2ptq432
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212238-a2ptq432/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pmwfjumj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212254-pmwfjumj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pmwfjumj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.80it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.07it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 141.26it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 136.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 134.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 137.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 137.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 139.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 141.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 143.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 143.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 143.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 142.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.336
wandb: best_valid_acc 0.294
wandb:  sub_train_acc 0.23384
wandb: sub_train_loss 0.00059
wandb:       test_acc 0.267
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run still-sweep-34 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pmwfjumj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212254-pmwfjumj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wsgfwqvo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212310-wsgfwqvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wsgfwqvo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.12it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.34it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 121.04it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 121.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 124.95it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 128.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 134.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 140.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 147.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 154.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 160.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 164.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 167.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.366
wandb: best_valid_acc 0.436
wandb:  sub_train_acc 0.23234
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.204
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run clean-sweep-35 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wsgfwqvo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212310-wsgfwqvo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a0onxqd9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212324-a0onxqd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a0onxqd9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.28it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.52it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 176.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 175.57it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 174.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 176.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 176.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 177.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 177.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 176.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.302
wandb: best_valid_acc 0.356
wandb:  sub_train_acc 0.32191
wandb: sub_train_loss 0.0
wandb:       test_acc 0.192
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run soft-sweep-36 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a0onxqd9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212324-a0onxqd9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yldb300f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212336-yldb300f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yldb300f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.88it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.85it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.48it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 150.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 147.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 146.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 147.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 147.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 150.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 149.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 145.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 143.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.428
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.315
wandb: sub_train_loss 0.00243
wandb:       test_acc 0.294
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run easy-sweep-37 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yldb300f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212336-yldb300f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w1cgg7eq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212351-w1cgg7eq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w1cgg7eq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.56it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 174.10it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 171.99it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 169.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 169.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 170.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 169.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 168.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 168.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 167.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 166.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.289
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.30568
wandb: sub_train_loss 0.00278
wandb:       test_acc 0.289
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run laced-sweep-38 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w1cgg7eq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212351-w1cgg7eq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fvf84b7q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212413-fvf84b7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvf84b7q
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.17it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.22it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.64it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 140.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 139.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 143.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 148.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 151.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 152.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 154.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 156.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.462
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.35648
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.365
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run silvery-sweep-39 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvf84b7q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212413-fvf84b7q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yj318bj6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212428-yj318bj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yj318bj6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.13it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 147.04it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 144.99it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 144.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 138.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 136.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 140.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 149.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 156.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 160.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 161.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 165.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.546
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.34476
wandb: sub_train_loss 8e-05
wandb:       test_acc 0.482
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run rare-sweep-40 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yj318bj6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212428-yj318bj6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: spp3rct5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212443-spp3rct5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/spp3rct5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.67it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.91it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 146.74it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 148.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 147.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 147.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 148.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 151.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 148.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 148.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 149.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.565
wandb: best_valid_acc 0.608
wandb:  sub_train_acc 0.39285
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.346
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run feasible-sweep-41 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/spp3rct5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212443-spp3rct5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rv3zsjow with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212458-rv3zsjow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rv3zsjow
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.61it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.86it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 159.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 160.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 158.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 155.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 154.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 149.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 147.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 147.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.57
wandb:  sub_train_acc 0.46589
wandb: sub_train_loss 0.01487
wandb:       test_acc 0.555
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run revived-sweep-42 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rv3zsjow
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212458-rv3zsjow/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vndgkufa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212510-vndgkufa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vndgkufa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.43it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 139.09it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 135.32it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 132.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 135.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 139.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 128.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 132.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 133.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 133.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 130.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 129.33it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 131.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.63
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.45506
wandb: sub_train_loss 0.0019
wandb:       test_acc 0.545
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run zesty-sweep-43 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vndgkufa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212510-vndgkufa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ix3cwknd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212525-ix3cwknd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ix3cwknd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.07it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.09it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.42it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 151.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 150.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 153.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 145.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 143.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 138.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 136.59it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 141.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 140.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.555
wandb: best_valid_acc 0.582
wandb:  sub_train_acc 0.48091
wandb: sub_train_loss 0.04612
wandb:       test_acc 0.497
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run sparkling-sweep-44 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ix3cwknd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212525-ix3cwknd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sqbvjpl9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212539-sqbvjpl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqbvjpl9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.58it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.75it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 154.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 145.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 138.46it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 138.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 141.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 144.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 151.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 157.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 160.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.643
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.50586
wandb: sub_train_loss 0.01273
wandb:       test_acc 0.544
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run decent-sweep-45 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqbvjpl9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212539-sqbvjpl9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r78j7294 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212556-r78j7294
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r78j7294
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.20it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.76it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 159.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 162.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 164.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 165.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 166.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 166.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 166.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 161.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.621
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.52269
wandb: sub_train_loss 0.0
wandb:       test_acc 0.572
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run balmy-sweep-46 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r78j7294
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212556-r78j7294/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i9rijrrd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212610-i9rijrrd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i9rijrrd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.43it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 123.70it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 128.08it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 129.71it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 131.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 133.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 136.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 139.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 140.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 148.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 152.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 155.93it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 158.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.668
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.64232
wandb: sub_train_loss 0.00037
wandb:       test_acc 0.642
wandb:      valid_acc 0.648
wandb: 
wandb: üöÄ View run grateful-sweep-47 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i9rijrrd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212610-i9rijrrd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qspp5yh7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212626-qspp5yh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qspp5yh7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.05it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 146.86it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 147.41it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 146.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 144.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 142.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 138.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 135.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 135.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 139.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 140.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 141.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 139.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.682
wandb: best_valid_acc 0.684
wandb:  sub_train_acc 0.58341
wandb: sub_train_loss 0.0
wandb:       test_acc 0.569
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run usual-sweep-48 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qspp5yh7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212626-qspp5yh7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7acx6gq0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212642-7acx6gq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7acx6gq0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 219.10it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 212.63it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 205.40it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 209.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 211.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 209.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 206.85it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 212.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 220.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 226.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 228.75it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 231.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 233.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.298
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.24016
wandb: sub_train_loss 0.79441
wandb:       test_acc 0.298
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run leafy-sweep-49 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7acx6gq0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212642-7acx6gq0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zc7hjqf6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212702-zc7hjqf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zc7hjqf6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 213.54it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 218.18it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 223.02it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 218.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 211.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 211.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 210.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 211.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 213.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 214.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 213.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 207.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 204.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 210.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.315
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.24947
wandb: sub_train_loss 0.79671
wandb:       test_acc 0.313
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run fiery-sweep-50 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zc7hjqf6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212702-zc7hjqf6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e06y5qmv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212717-e06y5qmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e06y5qmv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 205.18it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 211.47it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 218.81it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 223.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 225.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 226.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 227.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 227.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 227.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 228.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 228.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 228.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 229.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 226.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.365
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.28825
wandb: sub_train_loss 0.8771
wandb:       test_acc 0.368
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run fancy-sweep-51 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e06y5qmv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212717-e06y5qmv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2985nzlx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212732-2985nzlx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2985nzlx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.12it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 204.20it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 216.49it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 223.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 228.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 229.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 231.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 234.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 234.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 235.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 235.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 236.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 230.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.381
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.28825
wandb: sub_train_loss 0.87621
wandb:       test_acc 0.364
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run swift-sweep-52 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2985nzlx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212732-2985nzlx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vn2h8jfq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212753-vn2h8jfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vn2h8jfq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 195.61it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.57it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 201.96it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 210.12it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 213.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 215.20it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 213.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 213.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 207.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 210.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 214.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 217.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 220.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 213.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.414
wandb: best_valid_acc 0.386
wandb:  sub_train_acc 0.3679
wandb: sub_train_loss 0.9018
wandb:       test_acc 0.414
wandb:      valid_acc 0.386
wandb: 
wandb: üöÄ View run dauntless-sweep-53 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vn2h8jfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212753-vn2h8jfq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qgiq8rni with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212809-qgiq8rni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qgiq8rni
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 219.87it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 218.99it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 219.42it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 220.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 223.31it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 224.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 224.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 221.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 223.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 228.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 231.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 229.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 225.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.392
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.34325
wandb: sub_train_loss 0.90148
wandb:       test_acc 0.393
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run fresh-sweep-54 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qgiq8rni
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212809-qgiq8rni/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fqiwwoab with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212824-fqiwwoab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fqiwwoab
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 221.86it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 222.34it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 223.50it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 222.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 223.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 225.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 227.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 227.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 227.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 228.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 228.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 226.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 225.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.22723
wandb: sub_train_loss 0.88902
wandb:       test_acc 0.264
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run ethereal-sweep-55 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fqiwwoab
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212824-fqiwwoab/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tt2ntyan with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212839-tt2ntyan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tt2ntyan
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 211.37it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 213.60it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 218.31it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 222.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 216.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 216.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 220.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 222.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 222.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 224.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 225.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 224.02it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 221.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.272
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.23565
wandb: sub_train_loss 0.88862
wandb:       test_acc 0.272
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run daily-sweep-56 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tt2ntyan
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212839-tt2ntyan/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t6zync1g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212854-t6zync1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t6zync1g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.52it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 192.90it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 193.71it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 193.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 195.42it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 196.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 192.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 193.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 195.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 199.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 200.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 203.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 205.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 208.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 200.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.545
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.3706
wandb: sub_train_loss 0.94201
wandb:       test_acc 0.407
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run usual-sweep-57 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t6zync1g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212854-t6zync1g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o2skq2um with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212910-o2skq2um
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o2skq2um
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 214.41it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 215.61it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 210.54it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 209.43it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 207.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 210.52it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 212.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 216.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 218.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 219.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 218.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 216.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 219.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.539
wandb: best_valid_acc 0.498
wandb:  sub_train_acc 0.40577
wandb: sub_train_loss 0.94245
wandb:       test_acc 0.456
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run celestial-sweep-58 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o2skq2um
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212910-o2skq2um/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f3t8nqao with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212926-f3t8nqao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f3t8nqao
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 206.09it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 199.73it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 203.55it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 200.57it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 195.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 191.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 191.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 189.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 187.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 188.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 189.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 191.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 192.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 185.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.529
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.48001
wandb: sub_train_loss 0.96468
wandb:       test_acc 0.528
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run northern-sweep-59 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f3t8nqao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212926-f3t8nqao/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wt45fn8z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212942-wt45fn8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wt45fn8z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.45it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.54it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 180.49it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 183.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 189.15it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 190.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 192.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 191.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 189.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 192.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 193.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 194.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 197.95it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 200.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 199.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.50827
wandb: sub_train_loss 0.96499
wandb:       test_acc 0.555
wandb:      valid_acc 0.556
wandb: 
wandb: üöÄ View run feasible-sweep-60 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wt45fn8z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212942-wt45fn8z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dllyy24e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212957-dllyy24e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dllyy24e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 195.17it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 193.81it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 198.25it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 200.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 200.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 201.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 202.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 200.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 198.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 199.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 198.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 198.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 197.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 197.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 198.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.59
wandb: best_valid_acc 0.582
wandb:  sub_train_acc 0.52029
wandb: sub_train_loss 0.96696
wandb:       test_acc 0.554
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run fancy-sweep-61 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dllyy24e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212957-dllyy24e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cxcbxa5t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213012-cxcbxa5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cxcbxa5t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.37it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 198.96it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 200.51it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 200.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 199.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 200.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 198.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 199.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 198.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 200.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 201.63it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 202.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 203.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 203.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 200.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.564
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.53562
wandb: sub_train_loss 0.96618
wandb:       test_acc 0.564
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run colorful-sweep-62 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cxcbxa5t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213012-cxcbxa5t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b0d3ox7v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213028-b0d3ox7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b0d3ox7v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.01it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.85it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.82it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 187.87it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 188.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 189.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 190.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 188.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 185.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 183.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 183.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 184.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 184.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 186.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.609
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.55275
wandb: sub_train_loss 0.99759
wandb:       test_acc 0.526
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run cosmic-sweep-63 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b0d3ox7v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213028-b0d3ox7v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rz5v63yw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213042-rz5v63yw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rz5v63yw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.02it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 195.87it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 197.10it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 197.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 189.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 183.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 179.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 175.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 173.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 175.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 177.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 179.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 181.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 181.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 183.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.611
wandb: best_valid_acc 0.618
wandb:  sub_train_acc 0.5801
wandb: sub_train_loss 0.99753
wandb:       test_acc 0.566
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run wise-sweep-64 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rz5v63yw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213042-rz5v63yw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 39opcsuq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213058-39opcsuq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/39opcsuq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 183.74it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 188.02it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 188.33it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 183.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 186.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 190.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 191.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 190.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 188.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 188.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 188.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 187.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 187.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 187.27it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 186.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.318
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.24497
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.291
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run polished-sweep-65 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/39opcsuq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213058-39opcsuq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x2xiszjo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213114-x2xiszjo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x2xiszjo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.89it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 177.50it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 174.72it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 176.46it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 177.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 178.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 179.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 180.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 179.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 181.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 183.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 184.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 181.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 178.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 176.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 169.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.312
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.21972
wandb: sub_train_loss 8e-05
wandb:       test_acc 0.268
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run frosty-sweep-66 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x2xiszjo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213114-x2xiszjo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6lb07usz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213129-6lb07usz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6lb07usz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.52it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 170.87it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 166.50it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 168.02it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 169.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 172.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 180.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 186.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 186.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 190.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 188.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 191.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 193.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 196.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 197.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.323
wandb: best_valid_acc 0.388
wandb:  sub_train_acc 0.31169
wandb: sub_train_loss 0.00012
wandb:       test_acc 0.257
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run glad-sweep-67 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6lb07usz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213129-6lb07usz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qc84wscp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213144-qc84wscp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qc84wscp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.96it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 170.97it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 172.75it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 177.12it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 180.90it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 180.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 180.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 178.56it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 175.87it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 179.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 182.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 185.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 188.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 190.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 191.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.404
wandb: best_valid_acc 0.45
wandb:  sub_train_acc 0.35437
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.391
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run skilled-sweep-68 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qc84wscp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213144-qc84wscp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6figmlik with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213159-6figmlik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6figmlik
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.59it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.75it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.88it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 178.05it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 179.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 174.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 168.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 162.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 162.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 168.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 172.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 172.13it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 173.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 177.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 180.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 185.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.381
wandb: best_valid_acc 0.348
wandb:  sub_train_acc 0.35197
wandb: sub_train_loss 0.00011
wandb:       test_acc 0.345
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run earthy-sweep-69 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6figmlik
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213159-6figmlik/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7hcmwwi0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213221-7hcmwwi0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7hcmwwi0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.21it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 167.84it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 163.01it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 161.46it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 159.71it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 160.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 161.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 165.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 169.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 175.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 175.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 167.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 160.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 160.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 158.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 158.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 159.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.399
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.39104
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.361
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run frosty-sweep-70 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7hcmwwi0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213221-7hcmwwi0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e2hlhge1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213242-e2hlhge1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2hlhge1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.41it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 148.82it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 149.22it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.83it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 157.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 163.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 169.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 172.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 175.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 176.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 176.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 176.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 173.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 174.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 173.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 176.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.39285
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.473
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run clean-sweep-71 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2hlhge1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213242-e2hlhge1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yej05ck2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213256-yej05ck2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yej05ck2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.71it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 178.61it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 182.46it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 184.14it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 186.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 186.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 181.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 172.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 167.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 170.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 171.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 172.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 172.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 175.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 175.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 176.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.518
wandb:  sub_train_acc 0.38112
wandb: sub_train_loss 7e-05
wandb:       test_acc 0.502
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run deft-sweep-72 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yej05ck2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213256-yej05ck2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2jgp8g8h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213312-2jgp8g8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2jgp8g8h
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.41it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.58it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.50it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 155.47it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 157.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 160.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 164.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 170.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 175.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 179.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 182.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 185.24it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 187.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 187.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 179.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.43823
wandb: sub_train_loss 0.0001
wandb:       test_acc 0.516
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run stilted-sweep-73 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2jgp8g8h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213312-2jgp8g8h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i68h6xgp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213328-i68h6xgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i68h6xgp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.09it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.48it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.54it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.95it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 173.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 169.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 166.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 163.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 159.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 161.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 168.15it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 176.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 179.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 181.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 182.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 182.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.491
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.37601
wandb: sub_train_loss 0.00013
wandb:       test_acc 0.4
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run resilient-sweep-74 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i68h6xgp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213328-i68h6xgp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzuplz0w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213343-nzuplz0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzuplz0w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.85it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 157.21it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 153.44it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 152.34it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 152.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 156.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 159.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 157.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 155.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 141.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 138.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 140.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 137.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 137.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 137.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 141.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 144.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 144.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 141.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.582
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.45416
wandb: sub_train_loss 0.00032
wandb:       test_acc 0.586
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run jolly-sweep-75 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzuplz0w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213343-nzuplz0w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vpbxkmq2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213359-vpbxkmq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vpbxkmq2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.52it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.90it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 176.93it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 182.38it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 180.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 180.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 182.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 184.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 184.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 186.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 187.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 171.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 158.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 151.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 145.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 141.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.43042
wandb: sub_train_loss 8e-05
wandb:       test_acc 0.464
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run visionary-sweep-76 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vpbxkmq2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213359-vpbxkmq2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oh9l4qvq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213413-oh9l4qvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oh9l4qvq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.41it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.04it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.98it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 160.57it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 165.64it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 168.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 166.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 171.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 175.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 177.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 179.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 178.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 175.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 175.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 175.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 174.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.617
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.49835
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.574
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run fiery-sweep-77 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oh9l4qvq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213413-oh9l4qvq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t7n6c1lf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213429-t7n6c1lf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t7n6c1lf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.45it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.09it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.82it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.63it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 170.82it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 170.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 170.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 167.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 165.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 163.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 156.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 155.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 161.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 163.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 158.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 160.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 162.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.601
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.53502
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.575
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run daily-sweep-78 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t7n6c1lf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213429-t7n6c1lf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2kef7gjo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213445-2kef7gjo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2kef7gjo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.90it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 154.12it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.58it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 156.09it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 154.31it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 157.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 157.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 158.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 158.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 159.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 157.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 150.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 149.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 155.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 154.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 155.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 151.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.66066
wandb: sub_train_loss 7e-05
wandb:       test_acc 0.654
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run spring-sweep-79 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2kef7gjo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213445-2kef7gjo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9vkyn1z7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213459-9vkyn1z7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9vkyn1z7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.60it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.12it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 140.70it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 142.09it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 143.70it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 149.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 149.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 149.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 147.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 148.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 155.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 159.42it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 154.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 153.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 151.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 151.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 144.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 136.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 131.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.655
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.65555
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.653
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run smart-sweep-80 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9vkyn1z7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213459-9vkyn1z7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g7m270ya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213515-g7m270ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g7m270ya
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.78it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.52it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 158.68it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 156.11it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 156.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 160.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 163.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 164.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 166.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 167.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 168.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 164.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 158.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 161.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 158.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 154.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.343
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.21701
wandb: sub_train_loss 0.0
wandb:       test_acc 0.221
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run glamorous-sweep-81 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g7m270ya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213515-g7m270ya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fcldrwp8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213526-fcldrwp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fcldrwp8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.09it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 138.36it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 142.87it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 145.08it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 152.43it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 157.59it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 160.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 161.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 160.57it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 157.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 160.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 161.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 161.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 161.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 162.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 162.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 155.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 152.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.284
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.22423
wandb: sub_train_loss 0.0
wandb:       test_acc 0.187
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run fresh-sweep-82 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fcldrwp8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213526-fcldrwp8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ot1dqkxt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213541-ot1dqkxt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ot1dqkxt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.01it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.75it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.65it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 151.61it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 149.14it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 144.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 145.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 141.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 139.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 142.16it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 147.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 151.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 155.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 158.28it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 159.93it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 160.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 161.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 162.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.293
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.28825
wandb: sub_train_loss 0.0
wandb:       test_acc 0.213
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run treasured-sweep-83 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ot1dqkxt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213541-ot1dqkxt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: invzqpri with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213556-invzqpri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/invzqpri
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.21it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.47it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 169.73it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 172.11it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 172.85it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 174.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 174.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 175.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 175.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 176.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 175.43it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 165.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 160.02it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 157.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 157.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 157.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 158.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.296
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.23805
wandb: sub_train_loss 0.0
wandb:       test_acc 0.271
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run soft-sweep-84 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/invzqpri
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213556-invzqpri/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 46irq45k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213612-46irq45k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/46irq45k
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.54it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.44it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 134.48it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.88it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 137.98it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 138.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 140.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 140.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 141.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 142.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 142.17it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 143.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 144.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 146.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 147.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 149.49it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 156.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 162.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 166.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.398
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.17613
wandb: sub_train_loss 0.0
wandb:       test_acc 0.177
wandb:      valid_acc 0.142
wandb: 
wandb: üöÄ View run sleek-sweep-85 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/46irq45k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213612-46irq45k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: faw7wu4z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213632-faw7wu4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/faw7wu4z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.71it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 181.11it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 180.12it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 174.19it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 164.25it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 164.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 145.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 145.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 146.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 145.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 142.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 142.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 149.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 152.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 155.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 158.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 153.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.459
wandb: best_valid_acc 0.466
wandb:  sub_train_acc 0.32071
wandb: sub_train_loss 0.0
wandb:       test_acc 0.315
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run volcanic-sweep-86 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/faw7wu4z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213632-faw7wu4z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nea4pcpa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213647-nea4pcpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nea4pcpa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.21it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 155.94it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.17it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 164.36it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 167.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 167.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 169.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 167.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 167.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 170.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 172.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 175.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 176.15it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 153.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 156.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 159.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 162.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.396
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.2128
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.2
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run eternal-sweep-87 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nea4pcpa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213647-nea4pcpa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: icqbgsmc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213658-icqbgsmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/icqbgsmc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.38it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 173.04it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.29it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 172.68it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 171.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 171.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 170.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 171.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 171.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 171.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 172.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 172.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 171.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 170.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 170.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 171.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.487
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.24316
wandb: sub_train_loss 0.0
wandb:       test_acc 0.145
wandb:      valid_acc 0.134
wandb: 
wandb: üöÄ View run rich-sweep-88 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/icqbgsmc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213658-icqbgsmc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7e3cs4ex with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213723-7e3cs4ex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7e3cs4ex
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.09it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.62it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.73it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 162.03it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 160.32it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 161.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 165.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 167.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 168.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 170.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 166.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 161.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 159.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 156.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 157.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 157.76it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 157.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 161.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.522
wandb:  sub_train_acc 0.40036
wandb: sub_train_loss 0.0
wandb:       test_acc 0.451
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run confused-sweep-89 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7e3cs4ex
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213723-7e3cs4ex/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tiz20kvy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213738-tiz20kvy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tiz20kvy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.00it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 145.81it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 142.39it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 144.51it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 147.40it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 141.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 141.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 143.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 142.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 144.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 147.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 149.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 151.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 151.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 148.81it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 147.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 148.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 153.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 157.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.537
wandb: best_valid_acc 0.566
wandb:  sub_train_acc 0.34325
wandb: sub_train_loss 0.0
wandb:       test_acc 0.425
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run decent-sweep-90 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tiz20kvy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213738-tiz20kvy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zyocehrc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213753-zyocehrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zyocehrc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.02it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.70it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 146.40it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 143.43it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 142.82it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 143.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 145.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 147.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 151.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 156.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 154.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 147.76it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 142.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 142.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 147.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 152.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 155.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 159.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.543
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.37451
wandb: sub_train_loss 0.0
wandb:       test_acc 0.426
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run earnest-sweep-91 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zyocehrc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213753-zyocehrc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9xiwenvb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213809-9xiwenvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9xiwenvb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.65it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.13it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 162.51it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 160.79it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 161.84it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 163.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 164.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 165.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 166.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 169.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 169.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 169.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 169.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 167.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 167.75it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 167.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 167.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.61
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.49925
wandb: sub_train_loss 0.0
wandb:       test_acc 0.564
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run vibrant-sweep-92 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9xiwenvb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213809-9xiwenvb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5rp9bhq2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213824-5rp9bhq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5rp9bhq2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.79it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.89it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.60it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 160.44it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 161.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 163.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 154.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 154.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 153.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 158.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 161.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 164.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 166.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 168.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 169.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 170.53it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 171.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.583
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.5248
wandb: sub_train_loss 0.124
wandb:       test_acc 0.55
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run likely-sweep-93 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5rp9bhq2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213824-5rp9bhq2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d4klgoll with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213839-d4klgoll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4klgoll
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.20it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.75it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.43it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.40it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 142.81it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 142.11it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 140.25it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 145.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 150.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 149.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 152.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 153.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 150.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 145.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 144.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 143.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 143.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 143.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.592
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.46558
wandb: sub_train_loss 0.56123
wandb:       test_acc 0.467
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run snowy-sweep-94 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4klgoll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213839-d4klgoll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yaupzxnf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213855-yaupzxnf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yaupzxnf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.85it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.42it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 140.21it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 137.70it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 137.05it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 133.12it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 132.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 129.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 128.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 131.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 132.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 133.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 132.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 133.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 134.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 135.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 136.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 138.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 142.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 144.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.619
wandb: best_valid_acc 0.648
wandb:  sub_train_acc 0.47881
wandb: sub_train_loss 0.10068
wandb:       test_acc 0.463
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run glorious-sweep-95 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yaupzxnf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213855-yaupzxnf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4lopfztr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213910-4lopfztr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4lopfztr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.87it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.49it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.51it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 156.56it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 157.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 157.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 158.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 158.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 158.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 158.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 161.06it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 162.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 162.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 162.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 161.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 161.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 161.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 161.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.638
wandb: best_valid_acc 0.654
wandb:  sub_train_acc 0.44755
wandb: sub_train_loss 8e-05
wandb:       test_acc 0.401
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run pleasant-sweep-96 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4lopfztr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213910-4lopfztr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4g0v8hjl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213925-4g0v8hjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4g0v8hjl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 202.21it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 222.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 245.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 259.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 268.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 274.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 273.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 262.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.299
wandb: best_valid_acc 0.272
wandb:  sub_train_acc 0.26631
wandb: sub_train_loss 1.25458
wandb:       test_acc 0.309
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run ethereal-sweep-97 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4g0v8hjl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213925-4g0v8hjl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ufgiqt2k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213936-ufgiqt2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ufgiqt2k
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 264.69it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 277.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 294.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 290.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 283.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 277.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 279.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.308
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.2642
wandb: sub_train_loss 1.25325
wandb:       test_acc 0.314
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run smooth-sweep-98 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ufgiqt2k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213936-ufgiqt2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d4xpbkm7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213951-d4xpbkm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4xpbkm7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 235.77it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 244.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 251.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 259.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 253.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 258.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 266.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 260.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.373
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.33033
wandb: sub_train_loss 1.37734
wandb:       test_acc 0.338
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run crimson-sweep-99 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4xpbkm7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213951-d4xpbkm7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0y5ltqah with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214012-0y5ltqah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0y5ltqah
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 235.64it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 263.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 283.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 294.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 300.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 303.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 294.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.37
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.32582
wandb: sub_train_loss 1.37675
wandb:       test_acc 0.336
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run earthy-sweep-100 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0y5ltqah
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214012-0y5ltqah/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8fyc9gqh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214027-8fyc9gqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8fyc9gqh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 253.59it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 262.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 265.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 269.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 273.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 277.72it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 271.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.466
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.29155
wandb: sub_train_loss 1.44646
wandb:       test_acc 0.32
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run rosy-sweep-101 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8fyc9gqh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214027-8fyc9gqh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: af9734p9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214043-af9734p9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/af9734p9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 260.86it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 277.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 282.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 284.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 283.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 283.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 283.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.395
wandb: best_valid_acc 0.444
wandb:  sub_train_acc 0.28855
wandb: sub_train_loss 1.44648
wandb:       test_acc 0.321
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run whole-sweep-102 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/af9734p9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214043-af9734p9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9cmws1vc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214058-9cmws1vc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9cmws1vc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 282.75it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 286.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 293.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 295.33it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 296.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 300.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 298.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.255
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.1605
wandb: sub_train_loss 1.48282
wandb:       test_acc 0.161
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run ancient-sweep-103 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9cmws1vc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214058-9cmws1vc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8zsmgykr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214118-8zsmgykr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zsmgykr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 261.61it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 272.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 278.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 282.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 279.10it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 271.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 274.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.252
wandb:  sub_train_acc 0.1605
wandb: sub_train_loss 1.48331
wandb:       test_acc 0.161
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run major-sweep-104 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zsmgykr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214118-8zsmgykr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7synixcn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214139-7synixcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7synixcn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 277.81it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 245.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 237.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 238.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 210.48it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 207.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 205.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 206.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 217.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.584
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.4734
wandb: sub_train_loss 1.50354
wandb:       test_acc 0.488
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run wandering-sweep-105 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7synixcn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214139-7synixcn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0sihr2aw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214153-0sihr2aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0sihr2aw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 238.88it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 240.86it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 256.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 262.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 266.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 270.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 274.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 266.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.58
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.48332
wandb: sub_train_loss 1.50397
wandb:       test_acc 0.507
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run light-sweep-106 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0sihr2aw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214153-0sihr2aw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 59k335ds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214209-59k335ds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59k335ds
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 307.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 317.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 308.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 304.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 303.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 301.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 303.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.235
wandb: best_valid_acc 0.222
wandb:  sub_train_acc 0.14518
wandb: sub_train_loss 1.52661
wandb:       test_acc 0.115
wandb:      valid_acc 0.092
wandb: 
wandb: üöÄ View run bright-sweep-107 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59k335ds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214209-59k335ds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ss2jv87z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214225-ss2jv87z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ss2jv87z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 249.38it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 263.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 241.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 264.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 274.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 282.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.22
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.14698
wandb: sub_train_loss 1.5268
wandb:       test_acc 0.112
wandb:      valid_acc 0.096
wandb: 
wandb: üöÄ View run noble-sweep-108 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ss2jv87z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214225-ss2jv87z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5t7k096v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214239-5t7k096v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5t7k096v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 207.51it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 208.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 238.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 267.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 284.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 292.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 295.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 274.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.483
wandb: best_valid_acc 0.474
wandb:  sub_train_acc 0.4746
wandb: sub_train_loss 1.5418
wandb:       test_acc 0.483
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run dainty-sweep-109 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5t7k096v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214239-5t7k096v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: or7sasyo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214255-or7sasyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/or7sasyo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 232.83it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 248.34it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 251.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 250.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 252.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 255.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 254.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 250.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.473
wandb: best_valid_acc 0.474
wandb:  sub_train_acc 0.474
wandb: sub_train_loss 1.54136
wandb:       test_acc 0.473
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run feasible-sweep-110 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/or7sasyo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214255-or7sasyo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3i3mc6w8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214316-3i3mc6w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3i3mc6w8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.94it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 209.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 221.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 217.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 221.14it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 217.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 213.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 215.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 216.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.5801
wandb: sub_train_loss 1.55856
wandb:       test_acc 0.587
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run classic-sweep-111 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3i3mc6w8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214316-3i3mc6w8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lasj463y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214331-lasj463y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lasj463y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 314.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 310.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 304.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 300.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 300.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 300.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 302.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.604
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.45957
wandb: sub_train_loss 1.55862
wandb:       test_acc 0.423
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run smooth-sweep-112 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lasj463y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214331-lasj463y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: te22v0r5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214346-te22v0r5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/te22v0r5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.87it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 149.93it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 159.89it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 161.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 141.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 139.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 158.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 171.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 181.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 187.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.296
wandb:  sub_train_acc 0.28013
wandb: sub_train_loss 0.01443
wandb:       test_acc 0.318
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run sparkling-sweep-113 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/te22v0r5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214346-te22v0r5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zl23cooz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214402-zl23cooz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zl23cooz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.82it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 181.79it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 180.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 178.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 177.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 176.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 175.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 174.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 173.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 175.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.24316
wandb: sub_train_loss 0.00631
wandb:       test_acc 0.293
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run azure-sweep-114 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zl23cooz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214402-zl23cooz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 87rjnc6p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214416-87rjnc6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/87rjnc6p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.21it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.86it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 166.01it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 164.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 162.31it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 169.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 178.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 182.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 183.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 185.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.473
wandb: best_valid_acc 0.5
wandb:  sub_train_acc 0.33243
wandb: sub_train_loss 0.03497
wandb:       test_acc 0.375
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run electric-sweep-115 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/87rjnc6p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214416-87rjnc6p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b8eowsbs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214432-b8eowsbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b8eowsbs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 162.37it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.84it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 170.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 170.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 172.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 174.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 176.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 174.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 175.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 177.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 174.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.377
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.28344
wandb: sub_train_loss 0.04227
wandb:       test_acc 0.291
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run cool-sweep-116 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b8eowsbs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214432-b8eowsbs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hbaj079m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214447-hbaj079m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hbaj079m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.60it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.56it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 184.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 177.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 179.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 172.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 132.91it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 125.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 130.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 135.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 140.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.433
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.34926
wandb: sub_train_loss 0.0967
wandb:       test_acc 0.378
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run olive-sweep-117 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hbaj079m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214447-hbaj079m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6ju9jnvj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214502-6ju9jnvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6ju9jnvj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.40it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 153.15it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 153.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.72it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.19it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 151.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 154.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 164.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 174.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.472
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.38112
wandb: sub_train_loss 0.09475
wandb:       test_acc 0.449
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run fine-sweep-118 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6ju9jnvj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214502-6ju9jnvj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iw0b0vqc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214518-iw0b0vqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iw0b0vqc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.32it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 190.02it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 182.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 186.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 188.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 189.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 190.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 192.26it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 189.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 186.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.014 MB of 0.023 MB uploadedwandb: / 0.014 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.4725
wandb: sub_train_loss 0.12686
wandb:       test_acc 0.494
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run zany-sweep-119 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iw0b0vqc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214518-iw0b0vqc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s3apxwse with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214533-s3apxwse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s3apxwse
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.37it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.86it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 181.51it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 178.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 182.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 182.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 181.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 180.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 180.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 173.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.453
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.43222
wandb: sub_train_loss 0.11577
wandb:       test_acc 0.433
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run floral-sweep-120 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s3apxwse
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214533-s3apxwse/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ju2grn6w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214549-ju2grn6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-121
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ju2grn6w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.89it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.58it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 158.79it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 159.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 160.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 157.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 155.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 157.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 159.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 159.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 160.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.582
wandb: best_valid_acc 0.604
wandb:  sub_train_acc 0.49203
wandb: sub_train_loss 0.12812
wandb:       test_acc 0.522
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run iconic-sweep-121 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ju2grn6w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214549-ju2grn6w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kqizw7ob with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214603-kqizw7ob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-122
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kqizw7ob
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.24it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 172.13it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 176.99it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 179.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 181.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 187.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 189.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 189.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 192.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.618
wandb:  sub_train_acc 0.50286
wandb: sub_train_loss 0.13773
wandb:       test_acc 0.513
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run tough-sweep-122 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kqizw7ob
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214603-kqizw7ob/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 61b30gde with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214619-61b30gde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/61b30gde
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.79it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.73it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 183.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 190.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 193.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 196.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 193.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 192.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 192.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 191.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.633
wandb: best_valid_acc 0.654
wandb:  sub_train_acc 0.58852
wandb: sub_train_loss 0.17795
wandb:       test_acc 0.619
wandb:      valid_acc 0.634
wandb: 
wandb: üöÄ View run quiet-sweep-123 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/61b30gde
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214619-61b30gde/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v15j35eu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214631-v15j35eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-124
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v15j35eu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.28it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.24it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 173.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 170.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 172.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 175.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 179.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 181.03it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 182.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 187.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.615
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.58702
wandb: sub_train_loss 0.19166
wandb:       test_acc 0.616
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run wandering-sweep-124 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v15j35eu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214631-v15j35eu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8u5251zy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214646-8u5251zy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-125
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8u5251zy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 167.17it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 157.52it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 156.21it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 156.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 159.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 165.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 161.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 156.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 158.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 163.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 135.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.669
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.63511
wandb: sub_train_loss 0.21347
wandb:       test_acc 0.655
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run confused-sweep-125 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8u5251zy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214646-8u5251zy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5bk9cihc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214701-5bk9cihc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-126
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5bk9cihc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.03it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 172.06it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 161.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 155.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 155.89it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 151.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 151.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 151.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 143.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 147.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 156.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.651
wandb: best_valid_acc 0.684
wandb:  sub_train_acc 0.62639
wandb: sub_train_loss 0.19602
wandb:       test_acc 0.64
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run desert-sweep-126 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5bk9cihc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214701-5bk9cihc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ri8hyf8p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214713-ri8hyf8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ri8hyf8p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.76it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.80it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.16it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 159.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 162.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 167.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 168.21it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 167.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 169.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 173.98it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 176.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.689
wandb: best_valid_acc 0.708
wandb:  sub_train_acc 0.65404
wandb: sub_train_loss 0.26762
wandb:       test_acc 0.638
wandb:      valid_acc 0.678
wandb: 
wandb: üöÄ View run royal-sweep-127 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ri8hyf8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214713-ri8hyf8p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9mhqyqhf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214727-9mhqyqhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-128
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9mhqyqhf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.90it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.88it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 182.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 188.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 191.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 186.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 184.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 184.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 183.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 182.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.691
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.682
wandb: sub_train_loss 0.25683
wandb:       test_acc 0.689
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run ethereal-sweep-128 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9mhqyqhf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214727-9mhqyqhf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0a8gfmp9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214739-0a8gfmp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-129
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0a8gfmp9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.25it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.07it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.20it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 128.95it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 127.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 127.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 130.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 132.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 132.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 131.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 131.32it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 131.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 129.90it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 129.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.18215
wandb: sub_train_loss 0.00028
wandb:       test_acc 0.184
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run curious-sweep-129 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0a8gfmp9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214739-0a8gfmp9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hxotq6b2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214752-hxotq6b2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hxotq6b2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.70it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.93it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 143.19it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 144.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 144.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 144.49it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 144.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 145.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 142.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 140.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 138.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.022 MB of 0.023 MB uploadedwandb: / 0.022 MB of 0.023 MB uploadedwandb: - 0.022 MB of 0.023 MB uploadedwandb: \ 0.022 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.335
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.20709
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.209
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run peach-sweep-130 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hxotq6b2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214752-hxotq6b2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: agxc4mfu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214808-agxc4mfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/agxc4mfu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.37it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 135.86it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 132.01it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 134.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 133.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 134.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 136.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 138.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 137.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 137.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 134.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 131.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 130.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 130.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.21671
wandb: sub_train_loss 0.06397
wandb:       test_acc 0.192
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run golden-sweep-131 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/agxc4mfu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214808-agxc4mfu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m62vd74p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214823-m62vd74p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-132
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m62vd74p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.50it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 130.37it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 133.00it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 127.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 120.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 115.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 112.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 117.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 122.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 125.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 124.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 121.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 119.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 121.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 122.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.357
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.29967
wandb: sub_train_loss 0.08563
wandb:       test_acc 0.393
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run dazzling-sweep-132 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m62vd74p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214823-m62vd74p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mtjqu0ks with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214838-mtjqu0ks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-133
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mtjqu0ks
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.80it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 132.18it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 130.78it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 127.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 123.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 122.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 122.19it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 122.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 120.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 121.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 122.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 119.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 121.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 122.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 122.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.528
wandb:  sub_train_acc 0.27743
wandb: sub_train_loss 0.33709
wandb:       test_acc 0.265
wandb:      valid_acc 0.216
wandb: 
wandb: üöÄ View run treasured-sweep-133 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mtjqu0ks
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214838-mtjqu0ks/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a22uxo51 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214853-a22uxo51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-134
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a22uxo51
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.94it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.46it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.12it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 126.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 128.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 130.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 130.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 130.27it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 130.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 129.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 127.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 131.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 133.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 134.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.30328
wandb: sub_train_loss 0.31258
wandb:       test_acc 0.272
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run ancient-sweep-134 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a22uxo51
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214853-a22uxo51/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2ybxy6wd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214908-2ybxy6wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-135
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2ybxy6wd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.58it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.50it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 136.22it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 135.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 130.98it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 133.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 133.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 133.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 134.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 135.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 133.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 130.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 132.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.461
wandb: best_valid_acc 0.466
wandb:  sub_train_acc 0.3685
wandb: sub_train_loss 0.25396
wandb:       test_acc 0.36
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run hardy-sweep-135 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2ybxy6wd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214908-2ybxy6wd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l7w8vvp4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214920-l7w8vvp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-136
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l7w8vvp4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.13it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 134.84it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.28it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 134.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 133.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 128.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 131.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 132.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 130.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 127.33it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 124.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 124.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 122.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.566
wandb:  sub_train_acc 0.46168
wandb: sub_train_loss 0.31876
wandb:       test_acc 0.471
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run prime-sweep-136 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l7w8vvp4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214920-l7w8vvp4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l6jsmywz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214934-l6jsmywz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6jsmywz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.92it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.73it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.91it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 109.14it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 107.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 106.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 102.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 104.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 105.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 108.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 107.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 106.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 106.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 105.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 106.20it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 109.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 116.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.616
wandb: best_valid_acc 0.636
wandb:  sub_train_acc 0.50676
wandb: sub_train_loss 0.1602
wandb:       test_acc 0.539
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run radiant-sweep-137 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6jsmywz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214934-l6jsmywz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mzakcak7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214950-mzakcak7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-138
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mzakcak7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.85it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.09it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.29it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 120.29it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 120.69it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 123.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 125.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 124.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 124.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 125.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 124.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 125.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 125.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 125.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 124.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.614
wandb:  sub_train_acc 0.50496
wandb: sub_train_loss 0.0578
wandb:       test_acc 0.566
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run charmed-sweep-138 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mzakcak7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214950-mzakcak7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: grqpp9sc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215005-grqpp9sc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-139
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/grqpp9sc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.09it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 146.57it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 139.26it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 137.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 135.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 134.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 134.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 133.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 133.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 138.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 141.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 143.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 144.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.596
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.34415
wandb: sub_train_loss 0.16194
wandb:       test_acc 0.327
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run vocal-sweep-139 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/grqpp9sc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215005-grqpp9sc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: brmaempi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215020-brmaempi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-140
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/brmaempi
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.18it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 123.49it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 127.51it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 133.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 135.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 136.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 137.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 138.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 140.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 142.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 140.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 138.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.538
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.48302
wandb: sub_train_loss 0.22484
wandb:       test_acc 0.449
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run cosmic-sweep-140 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/brmaempi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215020-brmaempi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1fz45xg3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215035-1fz45xg3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-141
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1fz45xg3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.93it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 127.45it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 128.91it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 131.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 132.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 133.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 133.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 134.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 132.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 132.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 132.90it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 131.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 131.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 132.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.631
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.32041
wandb: sub_train_loss 0.55342
wandb:       test_acc 0.304
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run morning-sweep-141 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1fz45xg3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215035-1fz45xg3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ovgwohak with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215051-ovgwohak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ovgwohak
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.82it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 124.30it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 131.36it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 136.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 137.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 134.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 131.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 131.96it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 131.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 133.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 133.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 132.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 132.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 132.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.43102
wandb: sub_train_loss 0.23688
wandb:       test_acc 0.367
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run zesty-sweep-142 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ovgwohak
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215051-ovgwohak/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j2fd28cv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215107-j2fd28cv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-143
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j2fd28cv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.04it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 117.92it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 114.84it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 114.56it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 117.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 119.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 122.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 127.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 129.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 130.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 130.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 132.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 127.77it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 127.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.66
wandb: best_valid_acc 0.694
wandb:  sub_train_acc 0.578
wandb: sub_train_loss 0.28529
wandb:       test_acc 0.565
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run deft-sweep-143 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j2fd28cv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215107-j2fd28cv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 080bp31a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215122-080bp31a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-144
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/080bp31a
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.15it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.48it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 129.59it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 130.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 129.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 126.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 123.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 122.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 128.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 132.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 134.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 137.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 139.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 136.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.673
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.55636
wandb: sub_train_loss 0.85744
wandb:       test_acc 0.555
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run fancy-sweep-144 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/080bp31a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215122-080bp31a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 59iomnkt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215138-59iomnkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-145
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59iomnkt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 242.33it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 226.71it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 232.00it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 242.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 251.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 255.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 258.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 262.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:00<00:00, 261.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 266.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 269.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 257.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.2633
wandb: sub_train_loss 1.03018
wandb:       test_acc 0.308
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run polished-sweep-145 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59iomnkt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215138-59iomnkt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9kahiqfk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215153-9kahiqfk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-146
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9kahiqfk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 280.42it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 279.63it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 282.89it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 283.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 285.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 288.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 288.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 289.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 287.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 289.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.2606
wandb: sub_train_loss 1.02938
wandb:       test_acc 0.306
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run swept-sweep-146 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9kahiqfk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215153-9kahiqfk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iktjsjrq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215209-iktjsjrq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iktjsjrq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.50it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 270.67it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 274.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 277.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 236.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 214.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 213.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:00<00:00, 223.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 232.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 237.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 239.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 238.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.347
wandb: best_valid_acc 0.414
wandb:  sub_train_acc 0.29216
wandb: sub_train_loss 1.18341
wandb:       test_acc 0.275
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run upbeat-sweep-147 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iktjsjrq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215209-iktjsjrq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rov4sron with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215224-rov4sron
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-148
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rov4sron
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 239.31it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 255.47it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 259.65it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 244.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 245.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 261.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 263.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:00<00:00, 260.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 255.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 255.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 255.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 255.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.364
wandb: best_valid_acc 0.41
wandb:  sub_train_acc 0.29456
wandb: sub_train_loss 1.18314
wandb:       test_acc 0.277
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run good-sweep-148 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rov4sron
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215224-rov4sron/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d9f35xwb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215239-d9f35xwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-149
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d9f35xwb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 288.71it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 293.76it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 299.79it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 303.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 306.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 307.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 305.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 306.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:00<00:00, 301.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 303.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.439
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.28945
wandb: sub_train_loss 1.27833
wandb:       test_acc 0.31
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run blooming-sweep-149 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d9f35xwb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215239-d9f35xwb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sqf1y2u7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215256-sqf1y2u7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-150
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqf1y2u7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 283.49it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 295.33it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 301.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 300.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 303.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 305.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 304.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 292.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:00<00:00, 296.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 299.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.28855
wandb: sub_train_loss 1.2775
wandb:       test_acc 0.309
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run golden-sweep-150 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqf1y2u7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215256-sqf1y2u7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8s1rqq69 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215317-8s1rqq69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-151
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8s1rqq69
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 275.27it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 276.25it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 281.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 280.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 281.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 281.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 273.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 276.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 279.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 288.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 282.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.266
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.18665
wandb: sub_train_loss 1.32931
wandb:       test_acc 0.174
wandb:      valid_acc 0.152
wandb: 
wandb: üöÄ View run legendary-sweep-151 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8s1rqq69
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215317-8s1rqq69/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d4gu3yi2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215332-d4gu3yi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4gu3yi2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 302.28it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 302.67it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 299.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 297.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 294.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 289.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 286.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 282.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:00<00:00, 290.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 291.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.253
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.18726
wandb: sub_train_loss 1.32948
wandb:       test_acc 0.175
wandb:      valid_acc 0.15
wandb: 
wandb: üöÄ View run desert-sweep-152 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d4gu3yi2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215332-d4gu3yi2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dmfxijll with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215347-dmfxijll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-153
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dmfxijll
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 289.35it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 263.81it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 257.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 262.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 261.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 262.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 261.33it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 261.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:00<00:00, 260.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 269.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 264.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.58
wandb: best_valid_acc 0.574
wandb:  sub_train_acc 0.35528
wandb: sub_train_loss 1.3569
wandb:       test_acc 0.348
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run feasible-sweep-153 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dmfxijll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215347-dmfxijll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a4n9kba6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215403-a4n9kba6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-154
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a4n9kba6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 217.75it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 226.84it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 230.32it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 233.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 238.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 237.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 254.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 261.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 260.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 262.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 262.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 251.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.33965
wandb: sub_train_loss 1.35667
wandb:       test_acc 0.317
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run whole-sweep-154 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a4n9kba6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215403-a4n9kba6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yd09gcne with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215417-yd09gcne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-155
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yd09gcne
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 241.97it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 248.29it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 236.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 247.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 256.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 269.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 277.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 283.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 281.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 270.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.536
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.50286
wandb: sub_train_loss 1.39219
wandb:       test_acc 0.528
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run silver-sweep-155 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yd09gcne
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215417-yd09gcne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wyr7acj5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215433-wyr7acj5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-156
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wyr7acj5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 264.23it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 272.77it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 274.61it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 271.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 273.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 274.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 274.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 278.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:00<00:00, 276.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 276.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 275.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.49474
wandb: sub_train_loss 1.39207
wandb:       test_acc 0.515
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run lunar-sweep-156 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wyr7acj5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215433-wyr7acj5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sm0xg5lw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215448-sm0xg5lw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-157
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sm0xg5lw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 272.96it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:00, 280.91it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 283.31it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 282.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 287.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 286.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 292.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 296.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:00<00:00, 291.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 288.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 288.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.544
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.49083
wandb: sub_train_loss 1.41323
wandb:       test_acc 0.497
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run astral-sweep-157 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sm0xg5lw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215448-sm0xg5lw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cebszakg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215509-cebszakg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cebszakg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 267.76it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:00, 283.70it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 291.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 300.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 302.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 295.92it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 291.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 288.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:00<00:00, 284.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 289.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.020 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.521
wandb: best_valid_acc 0.528
wandb:  sub_train_acc 0.48783
wandb: sub_train_loss 1.41258
wandb:       test_acc 0.494
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run whole-sweep-158 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cebszakg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215509-cebszakg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e78u19mw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215525-e78u19mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-159
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e78u19mw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 232.32it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 232.47it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 237.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:00, 244.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 248.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 258.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 265.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 274.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 284.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 285.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 285.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.566
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.55455
wandb: sub_train_loss 1.43785
wandb:       test_acc 0.568
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run charmed-sweep-159 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e78u19mw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215525-e78u19mw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5qdyp0hf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215539-5qdyp0hf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-160
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5qdyp0hf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.57it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 286.02it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 289.57it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 294.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 294.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 294.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 295.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:00<00:00, 292.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 294.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 294.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 293.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.574
wandb:  sub_train_acc 0.51728
wandb: sub_train_loss 1.43795
wandb:       test_acc 0.488
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run major-sweep-160 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5qdyp0hf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215539-5qdyp0hf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jnzu7tqa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215555-jnzu7tqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-161
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jnzu7tqa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 179.45it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.13it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 186.70it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 187.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 184.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 181.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 180.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 183.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 184.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 182.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 178.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 178.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 177.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 177.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 177.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.317
wandb: best_valid_acc 0.29
wandb:  sub_train_acc 0.24857
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.297
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run exalted-sweep-161 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jnzu7tqa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215555-jnzu7tqa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o69kbo3e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215611-o69kbo3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-162
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o69kbo3e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.33it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 184.16it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 183.47it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 182.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 183.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 185.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 182.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 180.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 177.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 177.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 176.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 175.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 176.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 179.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 179.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.32
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.27322
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.329
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run avid-sweep-162 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o69kbo3e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215611-o69kbo3e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: biohy1xm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215626-biohy1xm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/biohy1xm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.47it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.20it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 180.39it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 182.99it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 179.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 178.35it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 176.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 176.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 173.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 173.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 171.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 168.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 167.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 166.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 166.45it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 169.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.443
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.32402
wandb: sub_train_loss 0.00425
wandb:       test_acc 0.347
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run restful-sweep-163 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/biohy1xm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215626-biohy1xm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 12cxd0ty with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215641-12cxd0ty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-164
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/12cxd0ty
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.68it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 193.59it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 191.08it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 190.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 185.96it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 162.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 159.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 159.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 163.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 163.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 164.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 165.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 168.14it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 166.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 166.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 167.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.461
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.33393
wandb: sub_train_loss 0.0107
wandb:       test_acc 0.37
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run fresh-sweep-164 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/12cxd0ty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215641-12cxd0ty/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o0bmxgal with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215657-o0bmxgal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-165
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o0bmxgal
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.18it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 167.18it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 169.52it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 169.48it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 165.39it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 168.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 174.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 178.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 180.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 181.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 179.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 174.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 170.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 168.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 172.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 174.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.472
wandb: best_valid_acc 0.502
wandb:  sub_train_acc 0.40938
wandb: sub_train_loss 0.02797
wandb:       test_acc 0.439
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run apricot-sweep-165 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o0bmxgal
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215657-o0bmxgal/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 34p4t1a2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215712-34p4t1a2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/34p4t1a2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.68it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.57it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 166.05it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 162.31it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 161.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 166.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 167.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 170.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 169.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 169.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 170.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 174.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 177.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 177.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 177.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 178.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.521
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.40998
wandb: sub_train_loss 0.02885
wandb:       test_acc 0.44
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run fresh-sweep-166 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/34p4t1a2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215712-34p4t1a2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rosd9ki3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215727-rosd9ki3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rosd9ki3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.90it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.01it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.06it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 155.15it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 157.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 159.71it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 161.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 166.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 171.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 173.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 175.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 176.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 176.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 176.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 175.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 176.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 171.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.488
wandb: best_valid_acc 0.514
wandb:  sub_train_acc 0.42891
wandb: sub_train_loss 0.01742
wandb:       test_acc 0.443
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run earthy-sweep-167 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rosd9ki3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215727-rosd9ki3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s70gdhkj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215742-s70gdhkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s70gdhkj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 159.66it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 167.65it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.35it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 166.40it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 164.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 161.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 162.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 165.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 168.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 172.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 177.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 178.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 175.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 172.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 171.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 170.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.518
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.45567
wandb: sub_train_loss 0.01655
wandb:       test_acc 0.489
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run devoted-sweep-168 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s70gdhkj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215742-s70gdhkj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wl1u3u1s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215758-wl1u3u1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-169
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wl1u3u1s
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.24it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 133.82it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 142.45it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 145.01it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 152.91it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 160.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 164.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 165.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 168.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 174.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 177.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 177.83it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 177.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 177.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 179.32it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 178.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 172.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.574
wandb: best_valid_acc 0.578
wandb:  sub_train_acc 0.44725
wandb: sub_train_loss 0.01928
wandb:       test_acc 0.454
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run clean-sweep-169 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wl1u3u1s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215758-wl1u3u1s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bd3cpmd0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215812-bd3cpmd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-170
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bd3cpmd0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.69it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.34it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 167.67it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 172.22it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 175.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 179.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 180.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 179.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 179.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 180.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 179.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 180.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 181.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 182.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 182.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 183.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.594
wandb: best_valid_acc 0.612
wandb:  sub_train_acc 0.49684
wandb: sub_train_loss 0.02133
wandb:       test_acc 0.529
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run leafy-sweep-170 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bd3cpmd0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215812-bd3cpmd0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w7y4vuys with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215824-w7y4vuys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-171
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w7y4vuys
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.96it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.61it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 161.37it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 152.36it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 142.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 141.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 149.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 160.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 168.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 172.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 176.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 176.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 178.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 181.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 181.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 181.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.607
wandb: best_valid_acc 0.636
wandb:  sub_train_acc 0.55666
wandb: sub_train_loss 0.03421
wandb:       test_acc 0.564
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run jumping-sweep-171 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w7y4vuys
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215824-w7y4vuys/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bntn9nc1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215839-bntn9nc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-172
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bntn9nc1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.62it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 149.72it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 165.78it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 177.24it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 179.65it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 176.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 180.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 185.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 188.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 188.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 187.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 186.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 184.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 182.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 182.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 179.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.609
wandb: best_valid_acc 0.654
wandb:  sub_train_acc 0.51428
wandb: sub_train_loss 0.03288
wandb:       test_acc 0.529
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run major-sweep-172 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bntn9nc1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215839-bntn9nc1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tri8ce13 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215854-tri8ce13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tri8ce13
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.97it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 184.80it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 185.05it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 184.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 187.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 189.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 190.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 192.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 194.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 195.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 196.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 194.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 195.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 195.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 195.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.651
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.58732
wandb: sub_train_loss 0.04522
wandb:       test_acc 0.604
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run fallen-sweep-173 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tri8ce13
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215854-tri8ce13/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b3xm4xfy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215914-b3xm4xfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-174
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b3xm4xfy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.17it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.96it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 182.64it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 185.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 186.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 186.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 189.85it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 192.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 193.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 194.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 193.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 187.23it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 183.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 182.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.665
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.59182
wandb: sub_train_loss 0.04324
wandb:       test_acc 0.607
wandb:      valid_acc 0.622
wandb: 
wandb: üöÄ View run generous-sweep-174 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b3xm4xfy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215914-b3xm4xfy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: szsx2r6n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215929-szsx2r6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-175
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/szsx2r6n
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.59it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 183.97it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 188.80it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 189.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 191.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 193.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 195.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 193.88it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 188.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 190.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 192.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 193.29it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 190.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 189.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 188.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.65855
wandb: sub_train_loss 0.0576
wandb:       test_acc 0.654
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run vibrant-sweep-175 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/szsx2r6n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215929-szsx2r6n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: okcpkrzl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215941-okcpkrzl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-176
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/okcpkrzl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.99it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.78it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 168.54it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 174.87it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 178.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 179.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 181.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 182.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 178.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 183.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 185.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 187.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 189.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 192.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 194.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.69
wandb: best_valid_acc 0.708
wandb:  sub_train_acc 0.62399
wandb: sub_train_loss 0.06724
wandb:       test_acc 0.604
wandb:      valid_acc 0.612
wandb: 
wandb: üöÄ View run youthful-sweep-176 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/okcpkrzl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215941-okcpkrzl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kfbkgsvb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215955-kfbkgsvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-177
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kfbkgsvb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.04it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.71it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 140.23it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 138.66it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 137.27it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 136.38it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 135.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 135.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 132.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 130.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 128.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 126.85it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 125.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 125.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 126.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 131.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 132.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 130.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 128.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 126.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 125.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.343
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.18185
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.187
wandb:      valid_acc 0.17
wandb: 
wandb: üöÄ View run generous-sweep-177 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kfbkgsvb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215955-kfbkgsvb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9v1472qa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220010-9v1472qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9v1472qa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.12it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 134.65it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.59it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 142.83it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 144.18it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 144.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 143.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 144.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 143.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 144.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 145.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 145.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 145.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 146.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 146.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 145.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 140.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 129.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 115.26it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 114.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.299
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.20589
wandb: sub_train_loss 0.0
wandb:       test_acc 0.222
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run celestial-sweep-178 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9v1472qa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220010-9v1472qa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j3qijgos with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220030-j3qijgos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-179
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j3qijgos
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 113.27it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 117.42it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 118.47it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 119.29it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 117.77it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 117.84it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 117.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 116.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 114.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 114.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 116.83it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 119.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 120.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 121.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 122.81it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 121.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 121.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 122.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 115.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 117.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 120.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 120.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 117.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.10069
wandb: sub_train_loss 0.97878
wandb:       test_acc 0.082
wandb:      valid_acc 0.062
wandb: 
wandb: üöÄ View run lunar-sweep-179 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j3qijgos
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220030-j3qijgos/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: csv0sfru with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220046-csv0sfru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-180
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/csv0sfru
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.32it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.01it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.27it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 136.47it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 134.60it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 133.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 133.59it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 127.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 124.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 127.48it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 130.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 133.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 134.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 134.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 135.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 136.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 137.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 130.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 133.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 138.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.402
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.35588
wandb: sub_train_loss 1.19046
wandb:       test_acc 0.377
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run major-sweep-180 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/csv0sfru
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220046-csv0sfru/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x8yas59f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220102-x8yas59f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-181
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x8yas59f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.03it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.39it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 118.04it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 121.66it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 123.30it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 121.34it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 119.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 117.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 115.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 115.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 114.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 112.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 110.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 110.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 112.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 116.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 121.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 126.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 129.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 131.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 132.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 137.54it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 140.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.537
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.26029
wandb: sub_train_loss 0.90271
wandb:       test_acc 0.238
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run solar-sweep-181 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x8yas59f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220102-x8yas59f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z5scdflh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220117-z5scdflh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-182
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z5scdflh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.50it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.82it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 134.07it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 131.92it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.56it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 136.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 138.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 141.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 142.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 143.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 143.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 141.55it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 142.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 144.20it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 144.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 143.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 138.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 137.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 132.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 132.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.453
wandb: best_valid_acc 0.518
wandb:  sub_train_acc 0.29546
wandb: sub_train_loss 0.86755
wandb:       test_acc 0.314
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run light-sweep-182 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z5scdflh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220117-z5scdflh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 605jpwej with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220132-605jpwej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/605jpwej
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.93it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 122.67it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 123.65it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 122.83it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 124.86it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 124.21it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 120.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 119.73it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 120.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 116.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 115.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 114.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 113.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 113.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 113.26it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 113.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 115.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 120.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 123.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 126.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 125.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 122.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 118.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.557
wandb: best_valid_acc 0.59
wandb:  sub_train_acc 0.4214
wandb: sub_train_loss 0.19928
wandb:       test_acc 0.457
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run silvery-sweep-183 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/605jpwej
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220132-605jpwej/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lt0m0rpa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220147-lt0m0rpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-184
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lt0m0rpa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.15it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.46it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 142.56it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 143.67it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 144.24it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 142.39it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 140.67it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 139.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 140.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 142.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 141.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 140.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 139.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 139.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 139.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 139.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 139.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 139.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 139.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 139.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.508
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.38653
wandb: sub_train_loss 0.39345
wandb:       test_acc 0.355
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run ethereal-sweep-184 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lt0m0rpa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220147-lt0m0rpa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s04opmby with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220203-s04opmby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-185
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s04opmby
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.38it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 108.53it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 90.16it/s]  15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 88.76it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 95.36it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 102.34it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 107.72it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 111.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 116.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 121.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 123.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 123.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 122.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 117.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 105.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:01, 105.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 105.31it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 104.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 105.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 106.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 107.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 111.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 116.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 120.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.588
wandb: best_valid_acc 0.604
wandb:  sub_train_acc 0.33514
wandb: sub_train_loss 1.59221
wandb:       test_acc 0.316
wandb:      valid_acc 0.362
wandb: 
wandb: üöÄ View run ancient-sweep-185 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s04opmby
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220203-s04opmby/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6o1uoquc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220219-6o1uoquc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-186
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6o1uoquc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.55it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.86it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 137.03it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.16it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.30it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 132.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 130.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 130.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 130.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 130.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 128.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 128.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 126.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 126.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 126.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 126.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 123.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 122.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 121.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 121.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 120.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 124.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.47
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.35077
wandb: sub_train_loss 0.09938
wandb:       test_acc 0.33
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run stoic-sweep-186 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6o1uoquc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220219-6o1uoquc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p8727kw8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220233-p8727kw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-187
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p8727kw8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.84it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 120.95it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 125.24it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 125.10it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 132.88it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 137.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 141.12it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 143.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 142.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 144.17it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 144.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 144.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 144.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 145.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 145.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 145.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 145.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 145.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 145.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 145.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.608
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.3661
wandb: sub_train_loss 0.4724
wandb:       test_acc 0.33
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run worldly-sweep-187 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p8727kw8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220233-p8727kw8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sal9ri6k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220249-sal9ri6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sal9ri6k
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.93it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.09it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.21it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.61it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.84it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 134.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 134.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 135.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 134.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 135.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 134.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 134.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 129.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 129.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 129.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 130.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 129.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 129.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 131.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 132.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 133.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.612
wandb: best_valid_acc 0.65
wandb:  sub_train_acc 0.48873
wandb: sub_train_loss 0.28621
wandb:       test_acc 0.502
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run dutiful-sweep-188 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sal9ri6k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220249-sal9ri6k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b1hbw8ia with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220305-b1hbw8ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-189
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b1hbw8ia
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.11it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 138.84it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 139.40it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 133.99it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 130.55it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 128.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 131.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 132.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 131.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 129.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 129.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 129.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 128.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 125.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 124.02it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 123.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 123.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 127.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 130.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 131.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 131.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.622
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.43372
wandb: sub_train_loss 0.88602
wandb:       test_acc 0.408
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run electric-sweep-189 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b1hbw8ia
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220305-b1hbw8ia/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pxboiace with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220321-pxboiace
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-190
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pxboiace
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.41it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 98.80it/s] 10%|‚ñà         | 31/300 [00:00<00:02, 102.38it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 106.40it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 112.60it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 111.12it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 113.63it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 117.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 118.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 121.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 122.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 122.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 109.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 96.21it/s]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 97.36it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:01, 102.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 108.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 112.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 114.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 114.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 117.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 118.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 114.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 115.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.663
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.50075
wandb: sub_train_loss 0.10442
wandb:       test_acc 0.491
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run playful-sweep-190 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pxboiace
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220321-pxboiace/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pu841nr4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220338-pu841nr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-191
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pu841nr4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.49it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 116.81it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 113.68it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 115.88it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 104.16it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 111.91it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 117.33it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 125.53it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 130.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 133.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 130.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 128.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 125.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 125.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 125.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 127.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 128.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 129.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 126.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 122.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 124.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 125.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.697
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.60986
wandb: sub_train_loss 0.12755
wandb:       test_acc 0.595
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run divine-sweep-191 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pu841nr4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220338-pu841nr4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0lfx4yok with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220352-0lfx4yok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-192
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0lfx4yok
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.03it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 105.29it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 107.32it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 107.14it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 108.89it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 111.15it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 112.24it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 114.29it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 115.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 117.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 115.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 124.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 128.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 131.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 132.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 132.96it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 129.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 129.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 130.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 130.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 132.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 131.84it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 127.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.50406
wandb: sub_train_loss 0.87163
wandb:       test_acc 0.511
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run vocal-sweep-192 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0lfx4yok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220352-0lfx4yok/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0p4f3uy3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220408-0p4f3uy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0p4f3uy3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 204.15it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 202.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 205.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 216.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 222.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 223.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 226.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 225.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 220.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.161
wandb: best_valid_acc 0.186
wandb:  sub_train_acc 0.15479
wandb: sub_train_loss 1.70559
wandb:       test_acc 0.16
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run drawn-sweep-193 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0p4f3uy3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220408-0p4f3uy3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s3azbn3d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220424-s3azbn3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-194
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s3azbn3d
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.58it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.89it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 181.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 182.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 182.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 189.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 203.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 216.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 217.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 202.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.298
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.2657
wandb: sub_train_loss 1.70253
wandb:       test_acc 0.297
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run jumping-sweep-194 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s3azbn3d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220424-s3azbn3d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8zhct76l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220444-8zhct76l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-195
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zhct76l
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 215.69it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 219.49it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 213.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 222.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 229.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 234.15it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 237.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 238.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 231.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.259
wandb: best_valid_acc 0.304
wandb:  sub_train_acc 0.24527
wandb: sub_train_loss 1.71639
wandb:       test_acc 0.257
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run dark-sweep-195 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zhct76l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220444-8zhct76l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eje28rjq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220459-eje28rjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-196
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eje28rjq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 222.35it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 226.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 226.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 225.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 225.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 224.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 222.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 225.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 225.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.281
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.23715
wandb: sub_train_loss 1.71721
wandb:       test_acc 0.282
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run wild-sweep-196 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eje28rjq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220459-eje28rjq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f2grb8mu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220514-f2grb8mu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-197
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f2grb8mu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.03it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 206.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 205.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 198.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 197.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 199.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 199.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 195.29it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 190.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.325
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.30358
wandb: sub_train_loss 1.7211
wandb:       test_acc 0.325
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run dandy-sweep-197 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f2grb8mu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220514-f2grb8mu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tzxp81ya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220530-tzxp81ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tzxp81ya
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 229.01it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 230.48it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 231.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 232.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 233.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 230.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 229.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 228.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 230.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.324
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.30087
wandb: sub_train_loss 1.72059
wandb:       test_acc 0.324
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run magic-sweep-198 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tzxp81ya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220530-tzxp81ya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hcun50xl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220546-hcun50xl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hcun50xl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 213.74it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 204.69it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 200.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 200.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 196.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 194.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 196.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 198.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 201.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 199.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.186
wandb: best_valid_acc 0.214
wandb:  sub_train_acc 0.21821
wandb: sub_train_loss 1.72035
wandb:       test_acc 0.233
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run eager-sweep-199 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hcun50xl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220546-hcun50xl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sblw2nwh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220600-sblw2nwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sblw2nwh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.07it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 206.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 203.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 204.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 204.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 204.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 206.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 206.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 205.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 205.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.252
wandb: best_valid_acc 0.238
wandb:  sub_train_acc 0.24767
wandb: sub_train_loss 1.72072
wandb:       test_acc 0.26
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run spring-sweep-200 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sblw2nwh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220600-sblw2nwh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y3o8rior with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220622-y3o8rior
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y3o8rior
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.92it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 213.23it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 212.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 216.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 216.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 217.60it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 217.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 219.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 217.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.27562
wandb: sub_train_loss 1.72735
wandb:       test_acc 0.278
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run firm-sweep-201 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y3o8rior
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220622-y3o8rior/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hn0fuogq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220637-hn0fuogq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-202
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hn0fuogq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 217.17it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 215.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 214.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 215.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 217.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 219.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 221.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 220.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 218.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.181
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.21701
wandb: sub_train_loss 1.72782
wandb:       test_acc 0.223
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run legendary-sweep-202 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hn0fuogq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220637-hn0fuogq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 11d02192 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220653-11d02192
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/11d02192
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 200.98it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 202.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 202.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 202.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 201.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 200.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 198.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 190.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 198.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 199.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.187
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.19387
wandb: sub_train_loss 1.7294
wandb:       test_acc 0.192
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run vivid-sweep-203 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/11d02192
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220653-11d02192/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kntgge3y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220708-kntgge3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-204
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kntgge3y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.36it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 168.04it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 172.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 180.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 186.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 191.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 195.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 195.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 194.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 197.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.39
wandb:  sub_train_acc 0.2648
wandb: sub_train_loss 1.72927
wandb:       test_acc 0.26
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run ruby-sweep-204 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kntgge3y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220708-kntgge3y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nmxmggv5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220723-nmxmggv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-205
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nmxmggv5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.09it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.36it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 164.59it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 175.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 177.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 175.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 173.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 170.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 166.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 161.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 161.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.331
wandb: best_valid_acc 0.354
wandb:  sub_train_acc 0.33363
wandb: sub_train_loss 1.73012
wandb:       test_acc 0.341
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run drawn-sweep-205 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nmxmggv5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220723-nmxmggv5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vq4wb9jb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220739-vq4wb9jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-206
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vq4wb9jb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 203.24it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 202.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 202.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 201.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 202.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 199.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 201.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 203.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 204.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.23505
wandb: sub_train_loss 1.7293
wandb:       test_acc 0.247
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run deft-sweep-206 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vq4wb9jb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220739-vq4wb9jb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rtgu58nm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220759-rtgu58nm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-207
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rtgu58nm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.66it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.58it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.48it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 167.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 175.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 179.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 185.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 186.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 189.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.537
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.53321
wandb: sub_train_loss 1.73305
wandb:       test_acc 0.516
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run ethereal-sweep-207 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rtgu58nm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220759-rtgu58nm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zk293s4h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220821-zk293s4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-208
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zk293s4h
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.07it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 181.19it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 177.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 174.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 174.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 181.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 182.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 182.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 184.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 184.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 181.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.531
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.55095
wandb: sub_train_loss 1.73335
wandb:       test_acc 0.534
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run apricot-sweep-208 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zk293s4h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220821-zk293s4h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vzy5a8hp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220837-vzy5a8hp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-209
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vzy5a8hp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.28it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 193.00it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 196.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 194.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 192.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 187.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 184.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 181.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 184.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 189.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.328
wandb: best_valid_acc 0.32
wandb:  sub_train_acc 0.26691
wandb: sub_train_loss 1.55322
wandb:       test_acc 0.295
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run stilted-sweep-209 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vzy5a8hp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220837-vzy5a8hp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 841zfx9b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220852-841zfx9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-210
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/841zfx9b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.19it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 153.92it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 161.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 167.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 171.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 176.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 180.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 182.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 183.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 184.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.24
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.08536
wandb: sub_train_loss 1.51308
wandb:       test_acc 0.24
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run expert-sweep-210 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/841zfx9b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220852-841zfx9b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u1dtje5d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220908-u1dtje5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-211
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1dtje5d
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.39it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 170.02it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 158.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 156.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 155.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 158.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 155.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 151.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 144.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 137.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 138.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.181
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.20739
wandb: sub_train_loss 1.59292
wandb:       test_acc 0.181
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run olive-sweep-211 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1dtje5d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220908-u1dtje5d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p7ciwiqr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220923-p7ciwiqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-212
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p7ciwiqr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.24it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 163.42it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 170.44it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 174.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 179.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 173.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 181.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 186.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 191.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 193.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.342
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.22272
wandb: sub_train_loss 1.59854
wandb:       test_acc 0.296
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run iconic-sweep-212 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p7ciwiqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220923-p7ciwiqr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dbusk456 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220935-dbusk456
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-213
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dbusk456
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.61it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.37it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 166.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 168.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 169.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 169.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 175.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 182.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 183.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 184.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.265
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.24947
wandb: sub_train_loss 1.59885
wandb:       test_acc 0.258
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run fast-sweep-213 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dbusk456
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220935-dbusk456/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0puo00ta with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220949-0puo00ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-214
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0puo00ta
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.22it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.16it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 175.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 176.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 180.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 184.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 187.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 189.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 190.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 193.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.371
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.25518
wandb: sub_train_loss 1.57849
wandb:       test_acc 0.246
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run laced-sweep-214 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0puo00ta
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220949-0puo00ta/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zw48td2g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221000-zw48td2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-215
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zw48td2g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.66it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 192.07it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 185.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 184.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 185.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 185.76it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 188.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 190.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 188.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 186.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.229
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.21942
wandb: sub_train_loss 1.5985
wandb:       test_acc 0.236
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run solar-sweep-215 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zw48td2g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221000-zw48td2g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iah8xrei with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221015-iah8xrei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-216
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iah8xrei
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.60it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.23it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 171.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 173.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 175.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 172.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 169.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 166.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 166.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 167.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.39
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.29486
wandb: sub_train_loss 1.60632
wandb:       test_acc 0.382
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run jolly-sweep-216 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iah8xrei
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221015-iah8xrei/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ttzjer5f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221030-ttzjer5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-217
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ttzjer5f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.77it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 193.20it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 195.21it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 197.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 198.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 198.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 198.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 197.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 198.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.32
wandb: best_valid_acc 0.296
wandb:  sub_train_acc 0.28194
wandb: sub_train_loss 1.61157
wandb:       test_acc 0.319
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run earthy-sweep-217 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ttzjer5f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221030-ttzjer5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y7bu0ofp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221040-y7bu0ofp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y7bu0ofp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.66it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 130.31it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 125.03it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 129.03it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 133.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 138.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 144.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 149.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 154.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 158.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 160.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 163.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.016 MB of 0.023 MB uploadedwandb: - 0.016 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.183
wandb: best_valid_acc 0.176
wandb:  sub_train_acc 0.16742
wandb: sub_train_loss 1.62719
wandb:       test_acc 0.183
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run wobbly-sweep-218 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y7bu0ofp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221040-y7bu0ofp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d0t05va2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221056-d0t05va2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-219
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d0t05va2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.28it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 172.07it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 175.11it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 177.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 179.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 178.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 175.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 174.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 171.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 169.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 172.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.456
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.34295
wandb: sub_train_loss 1.60479
wandb:       test_acc 0.335
wandb:      valid_acc 0.362
wandb: 
wandb: üöÄ View run winter-sweep-219 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d0t05va2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221056-d0t05va2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4xvxh85b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221111-4xvxh85b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-220
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4xvxh85b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.73it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.11it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 163.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 168.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 172.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 173.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 174.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 172.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 171.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 173.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 170.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.361
wandb: best_valid_acc 0.34
wandb:  sub_train_acc 0.31951
wandb: sub_train_loss 1.62846
wandb:       test_acc 0.361
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run clear-sweep-220 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4xvxh85b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221111-4xvxh85b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nno0tfau with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221127-nno0tfau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-221
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nno0tfau
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.35it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.06it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 163.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 168.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 174.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 177.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 164.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 165.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 164.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 159.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 166.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.553
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.49624
wandb: sub_train_loss 1.6089
wandb:       test_acc 0.553
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run likely-sweep-221 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nno0tfau
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221127-nno0tfau/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e1r60z70 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221141-e1r60z70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e1r60z70
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.01it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.89it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 178.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 179.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 178.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 177.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 175.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 176.03it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 173.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 173.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.42
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.41419
wandb: sub_train_loss 1.58547
wandb:       test_acc 0.422
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run fast-sweep-222 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e1r60z70
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221141-e1r60z70/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lvvpnhfr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221157-lvvpnhfr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-223
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lvvpnhfr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 162.60it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.76it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 169.78it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 172.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 174.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 174.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 148.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 136.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 138.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 140.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 139.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.387
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.42621
wandb: sub_train_loss 1.62748
wandb:       test_acc 0.388
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run worldly-sweep-223 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lvvpnhfr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221157-lvvpnhfr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8nwdrqvt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221212-8nwdrqvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-224
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8nwdrqvt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.63it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.49it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 166.35it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 166.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 164.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 165.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 166.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 168.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 169.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 170.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 160.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.548
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.54373
wandb: sub_train_loss 1.63068
wandb:       test_acc 0.548
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run trim-sweep-224 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8nwdrqvt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221212-8nwdrqvt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: clbhbjb2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221228-clbhbjb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-225
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/clbhbjb2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.94it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.51it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.15it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 150.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 153.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 154.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 151.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 150.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 149.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 150.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 146.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 144.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.231
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.211
wandb: sub_train_loss 1.51142
wandb:       test_acc 0.231
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run quiet-sweep-225 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/clbhbjb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221228-clbhbjb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jdarplyf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221243-jdarplyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-226
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jdarplyf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.89it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 167.76it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 170.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 170.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 170.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 168.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 166.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 165.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 157.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 162.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 165.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.15479
wandb: sub_train_loss 1.57745
wandb:       test_acc 0.283
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run cerulean-sweep-226 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jdarplyf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221243-jdarplyf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u28y8mfm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221258-u28y8mfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-227
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u28y8mfm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 170.69it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 167.87it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 169.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 170.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 170.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 170.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 172.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 171.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 169.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 167.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 167.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.186
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.23414
wandb: sub_train_loss 1.60542
wandb:       test_acc 0.183
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run worldly-sweep-227 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u28y8mfm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221258-u28y8mfm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ja16rcgj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221314-ja16rcgj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-228
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ja16rcgj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.12it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.29it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 149.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 150.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 152.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 149.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 148.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 147.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 148.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 154.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 157.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 159.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.181
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.21701
wandb: sub_train_loss 1.5808
wandb:       test_acc 0.181
wandb:      valid_acc 0.232
wandb: 
wandb: üöÄ View run drawn-sweep-228 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ja16rcgj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221314-ja16rcgj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wmfg4clz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221328-wmfg4clz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-229
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wmfg4clz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.03it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.03it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 160.58it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 163.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 163.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 163.80it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 161.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 157.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 157.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 157.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 156.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.333
wandb: best_valid_acc 0.32
wandb:  sub_train_acc 0.23354
wandb: sub_train_loss 1.64046
wandb:       test_acc 0.187
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run lucky-sweep-229 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wmfg4clz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221328-wmfg4clz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xmwekxso with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221340-xmwekxso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-230
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xmwekxso
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.70it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 160.69it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 160.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 162.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 163.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 162.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 159.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 158.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 160.93it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 164.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 165.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.177
wandb: best_valid_acc 0.164
wandb:  sub_train_acc 0.16261
wandb: sub_train_loss 1.57668
wandb:       test_acc 0.17
wandb:      valid_acc 0.154
wandb: 
wandb: üöÄ View run royal-sweep-230 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xmwekxso
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221340-xmwekxso/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0h63t9j0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221355-0h63t9j0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-231
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0h63t9j0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.70it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.85it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 160.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 163.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 162.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 163.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 163.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 163.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 163.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 163.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 164.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.16
wandb: best_valid_acc 0.138
wandb:  sub_train_acc 0.15269
wandb: sub_train_loss 1.58972
wandb:       test_acc 0.16
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run sandy-sweep-231 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0h63t9j0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221355-0h63t9j0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5otb9bwc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221415-5otb9bwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-232
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5otb9bwc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.22it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.07it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 152.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 147.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 145.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 145.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 145.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 145.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 144.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 146.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 143.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.273
wandb: best_valid_acc 0.262
wandb:  sub_train_acc 0.16501
wandb: sub_train_loss 1.58546
wandb:       test_acc 0.17
wandb:      valid_acc 0.144
wandb: 
wandb: üöÄ View run quiet-sweep-232 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5otb9bwc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221415-5otb9bwc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xd7iaf94 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221430-xd7iaf94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-233
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xd7iaf94
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.15it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.18it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 164.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 168.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 164.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 161.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 162.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 163.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 165.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 165.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.293
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.23414
wandb: sub_train_loss 1.60743
wandb:       test_acc 0.246
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run radiant-sweep-233 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xd7iaf94
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221430-xd7iaf94/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 173y69ot with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221446-173y69ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-234
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/173y69ot
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.91it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.89it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 176.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 176.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 174.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 175.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 175.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 176.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 175.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 173.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 174.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.253
wandb: best_valid_acc 0.292
wandb:  sub_train_acc 0.20439
wandb: sub_train_loss 1.55381
wandb:       test_acc 0.304
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run dulcet-sweep-234 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/173y69ot
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221446-173y69ot/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mtuwpspv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221506-mtuwpspv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-235
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mtuwpspv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.56it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 152.10it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.51it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 155.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 156.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 158.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 160.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 161.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 161.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 160.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.207
wandb: best_valid_acc 0.2
wandb:  sub_train_acc 0.18665
wandb: sub_train_loss 1.64701
wandb:       test_acc 0.212
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run ethereal-sweep-235 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mtuwpspv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221506-mtuwpspv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: au94llcv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221521-au94llcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-236
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/au94llcv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.38it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.33it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 158.42it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 157.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 154.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 155.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 156.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 158.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 162.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 160.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 158.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 158.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.13045
wandb: sub_train_loss 1.5835
wandb:       test_acc 0.131
wandb:      valid_acc 0.112
wandb: 
wandb: üöÄ View run swept-sweep-236 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/au94llcv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221521-au94llcv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 64w1cm2p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221537-64w1cm2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-237
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/64w1cm2p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.00it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.52it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 150.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 150.64it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 150.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 146.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 148.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 155.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 156.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 158.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 159.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.467
wandb: best_valid_acc 0.464
wandb:  sub_train_acc 0.27081
wandb: sub_train_loss 1.63477
wandb:       test_acc 0.271
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run fanciful-sweep-237 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/64w1cm2p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221537-64w1cm2p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1uliz5si with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221552-1uliz5si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-238
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1uliz5si
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.59it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.57it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 157.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 159.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 160.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 159.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 158.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 158.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 159.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 159.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.322
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.27142
wandb: sub_train_loss 1.60913
wandb:       test_acc 0.221
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run fearless-sweep-238 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1uliz5si
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221552-1uliz5si/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: afje1ua7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221607-afje1ua7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-239
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/afje1ua7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.84it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 141.73it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 137.95it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 140.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 137.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 134.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 135.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 136.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 138.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 140.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 142.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 144.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 145.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.643
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.65164
wandb: sub_train_loss 1.57017
wandb:       test_acc 0.652
wandb:      valid_acc 0.662
wandb: 
wandb: üöÄ View run peach-sweep-239 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/afje1ua7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221607-afje1ua7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 45ems16n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221623-45ems16n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-240
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/45ems16n
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.55it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.50it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 149.61it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 149.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 147.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 143.57it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 142.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 140.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 142.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 144.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 144.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 145.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 148.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.559
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.49083
wandb: sub_train_loss 1.57532
wandb:       test_acc 0.453
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run proud-sweep-240 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/45ems16n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221623-45ems16n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7vc11pj0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221639-7vc11pj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-241
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7vc11pj0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.42it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 194.36it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 208.10it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 208.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 211.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 212.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 214.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 216.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 217.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 219.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 215.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 210.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 208.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 211.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.286
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.23956
wandb: sub_train_loss 1.66201
wandb:       test_acc 0.286
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run firm-sweep-241 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7vc11pj0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221639-7vc11pj0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rlupmvrc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221653-rlupmvrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-242
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rlupmvrc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 224.22it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 230.94it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 231.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 232.99it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 232.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 231.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 232.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 234.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 235.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 235.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 235.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 236.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 234.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.23174
wandb: sub_train_loss 1.65496
wandb:       test_acc 0.294
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run worthy-sweep-242 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rlupmvrc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221653-rlupmvrc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ukwow664 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221709-ukwow664
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-243
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ukwow664
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 229.74it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 234.82it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 235.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 235.56it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 234.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 235.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 233.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 237.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 236.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 239.25it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 240.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 241.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 237.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.347
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.3153
wandb: sub_train_loss 1.67694
wandb:       test_acc 0.349
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run eager-sweep-243 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ukwow664
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221709-ukwow664/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mj7x07ok with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221726-mj7x07ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-244
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mj7x07ok
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 195.25it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 199.40it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 203.97it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 207.24it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 206.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 205.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 208.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 212.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 217.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 221.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 222.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 224.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 224.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.296
wandb: best_valid_acc 0.304
wandb:  sub_train_acc 0.23685
wandb: sub_train_loss 1.67821
wandb:       test_acc 0.296
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run volcanic-sweep-244 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mj7x07ok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221726-mj7x07ok/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hk5jtexy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221741-hk5jtexy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-245
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hk5jtexy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 214.52it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.05it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 222.11it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 223.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 220.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 220.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 215.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 213.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 216.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 216.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 220.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 223.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 223.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 219.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.368
wandb: best_valid_acc 0.41
wandb:  sub_train_acc 0.38173
wandb: sub_train_loss 1.6828
wandb:       test_acc 0.368
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run drawn-sweep-245 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hk5jtexy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221741-hk5jtexy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vxd7f0gh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221757-vxd7f0gh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-246
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vxd7f0gh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 226.65it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 225.71it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 223.68it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 223.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 224.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 226.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 228.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 229.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 228.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 229.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 231.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 233.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 229.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.302
wandb:  sub_train_acc 0.27081
wandb: sub_train_loss 1.68327
wandb:       test_acc 0.295
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run confused-sweep-246 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vxd7f0gh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221757-vxd7f0gh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yzdko3s0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221815-yzdko3s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-247
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yzdko3s0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.25it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 227.85it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 208.26it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 207.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 214.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 221.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 224.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 223.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 223.62it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 224.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 224.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 224.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 221.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.182
wandb:  sub_train_acc 0.19237
wandb: sub_train_loss 1.6815
wandb:       test_acc 0.211
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run trim-sweep-247 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yzdko3s0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221815-yzdko3s0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aanuk73b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221827-aanuk73b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-248
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/aanuk73b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.34it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 202.42it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 209.71it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 213.56it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 216.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 214.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 214.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 209.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 207.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 210.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 213.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 209.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 211.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 209.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.189
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.18786
wandb: sub_train_loss 1.68196
wandb:       test_acc 0.206
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run divine-sweep-248 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/aanuk73b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221827-aanuk73b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uey7g14w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221842-uey7g14w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uey7g14w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.19it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 207.62it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 209.12it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 207.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 205.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 202.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 208.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 211.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 213.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 214.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 215.57it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 215.33it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 215.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 212.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.288
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.28434
wandb: sub_train_loss 1.6931
wandb:       test_acc 0.282
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run trim-sweep-249 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uey7g14w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221842-uey7g14w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qj4tdi0x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221854-qj4tdi0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-250
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qj4tdi0x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 213.46it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 218.66it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 219.36it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 219.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 220.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 220.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 219.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 220.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 215.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 212.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 213.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 214.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 216.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 216.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.287
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.27923
wandb: sub_train_loss 1.69299
wandb:       test_acc 0.281
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run stilted-sweep-250 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qj4tdi0x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221854-qj4tdi0x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fg5fbq5h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221909-fg5fbq5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-251
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fg5fbq5h
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 203.32it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 204.98it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 204.02it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 205.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 204.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 206.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 209.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 207.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 202.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 201.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 201.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 202.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 202.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 203.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 204.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.121
wandb: best_valid_acc 0.114
wandb:  sub_train_acc 0.13556
wandb: sub_train_loss 1.69466
wandb:       test_acc 0.122
wandb:      valid_acc 0.112
wandb: 
wandb: üöÄ View run flowing-sweep-251 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fg5fbq5h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221909-fg5fbq5h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 551dcwk2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221924-551dcwk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-252
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/551dcwk2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.60it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.92it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.51it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 166.07it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 176.14it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 175.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 174.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 177.31it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 179.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 182.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 184.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 188.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 186.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 177.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 178.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 178.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.326
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.1602
wandb: sub_train_loss 1.69541
wandb:       test_acc 0.148
wandb:      valid_acc 0.136
wandb: 
wandb: üöÄ View run lunar-sweep-252 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/551dcwk2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221924-551dcwk2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p9s0xkkq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221939-p9s0xkkq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-253
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p9s0xkkq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.32it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 159.56it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 163.44it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 163.96it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 165.77it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 167.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 177.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 184.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 189.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 194.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 196.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 198.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 199.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 200.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 201.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.337
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.26961
wandb: sub_train_loss 1.69563
wandb:       test_acc 0.26
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run young-sweep-253 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p9s0xkkq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221939-p9s0xkkq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: z71vh7dq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222000-z71vh7dq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-254
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z71vh7dq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.98it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 188.12it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 194.24it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 196.52it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 195.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 196.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 199.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 202.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 201.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 200.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 202.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 203.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 204.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 204.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 200.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.322
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.29216
wandb: sub_train_loss 1.69587
wandb:       test_acc 0.293
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run comfy-sweep-254 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z71vh7dq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222000-z71vh7dq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3frzrp6r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222014-3frzrp6r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-255
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3frzrp6r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.04it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 189.39it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 190.53it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 193.41it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 193.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 193.27it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 192.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 191.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 190.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 192.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 191.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 191.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 190.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 190.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.618
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.578
wandb: sub_train_loss 1.70135
wandb:       test_acc 0.552
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run sleek-sweep-255 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3frzrp6r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222014-3frzrp6r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3o26c8i0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222026-3o26c8i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-256
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3o26c8i0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.79it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 179.86it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 184.77it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 187.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 190.00it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 192.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 189.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 190.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 189.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 189.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 187.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 185.11it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 183.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 181.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 181.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.59243
wandb: sub_train_loss 1.70109
wandb:       test_acc 0.596
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run bumbling-sweep-256 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3o26c8i0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222026-3o26c8i0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gzch974y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222040-gzch974y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gzch974y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.22it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 180.40it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 181.74it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 181.66it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 180.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 179.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 178.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 178.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 177.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 174.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 171.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 171.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 162.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 140.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 140.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 144.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.265
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.24286
wandb: sub_train_loss 1.34024
wandb:       test_acc 0.245
wandb:      valid_acc 0.216
wandb: 
wandb: üöÄ View run firm-sweep-257 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gzch974y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222040-gzch974y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 81davc2m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222056-81davc2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-258
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/81davc2m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.68it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 172.99it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.33it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 176.35it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 179.38it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 180.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 178.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 174.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 172.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 172.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 174.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 176.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 164.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 171.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 175.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 177.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.237
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.22783
wandb: sub_train_loss 1.32826
wandb:       test_acc 0.232
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run fresh-sweep-258 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/81davc2m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222056-81davc2m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 25zccztl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222111-25zccztl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-259
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/25zccztl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.60it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.26it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 179.93it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 180.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 179.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 178.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 177.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 176.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 177.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 178.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 177.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 180.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 183.71it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 183.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 177.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 176.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.279
wandb: best_valid_acc 0.304
wandb:  sub_train_acc 0.24977
wandb: sub_train_loss 1.45205
wandb:       test_acc 0.281
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run legendary-sweep-259 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/25zccztl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222111-25zccztl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 38fmawf8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222126-38fmawf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/38fmawf8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.84it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 177.62it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 180.44it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 180.41it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 179.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 185.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 187.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 180.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 173.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 168.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 171.51it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 171.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 165.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 158.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 153.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 152.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.181
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.30688
wandb: sub_train_loss 1.40635
wandb:       test_acc 0.184
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run polar-sweep-260 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/38fmawf8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222126-38fmawf8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 529ak9xn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222142-529ak9xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-261
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/529ak9xn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.65it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.70it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.27it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 178.65it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 179.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 179.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 181.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 177.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 174.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 176.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 172.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 168.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 167.62it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 166.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 166.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 166.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.373
wandb: best_valid_acc 0.382
wandb:  sub_train_acc 0.27262
wandb: sub_train_loss 1.46518
wandb:       test_acc 0.359
wandb:      valid_acc 0.364
wandb: 
wandb: üöÄ View run hardy-sweep-261 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/529ak9xn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222142-529ak9xn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wezdjg5g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222158-wezdjg5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-262
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wezdjg5g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.58it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 149.32it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.77it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.78it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 163.00it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 166.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 166.33it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 169.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 171.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 173.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 175.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 172.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 171.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 170.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 169.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 167.97it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 170.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.44
wandb: best_valid_acc 0.47
wandb:  sub_train_acc 0.40878
wandb: sub_train_loss 1.3925
wandb:       test_acc 0.388
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run warm-sweep-262 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wezdjg5g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222158-wezdjg5g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f8dvqzcr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222221-f8dvqzcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-263
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f8dvqzcr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.53it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.14it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 186.30it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 189.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 191.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 191.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 194.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 194.14it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 192.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 191.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 193.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 194.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 195.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 195.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 192.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.174
wandb: best_valid_acc 0.152
wandb:  sub_train_acc 0.17794
wandb: sub_train_loss 1.43415
wandb:       test_acc 0.174
wandb:      valid_acc 0.152
wandb: 
wandb: üöÄ View run bumbling-sweep-263 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f8dvqzcr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222221-f8dvqzcr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: idqh35zv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222232-idqh35zv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-264
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/idqh35zv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.03it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.46it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 169.25it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 170.26it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 173.52it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 178.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 180.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 179.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 178.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 179.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 181.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 184.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 184.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 182.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 186.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.359
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.3168
wandb: sub_train_loss 1.40181
wandb:       test_acc 0.308
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run robust-sweep-264 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/idqh35zv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222232-idqh35zv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xydpuhiw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222253-xydpuhiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-265
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xydpuhiw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.46it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 168.64it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.27it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.68it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 173.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 173.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 173.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 171.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 168.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 173.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 176.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 177.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 179.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 179.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 183.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 181.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.334
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.32913
wandb: sub_train_loss 1.44484
wandb:       test_acc 0.301
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run eager-sweep-265 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xydpuhiw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222253-xydpuhiw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 652d8y49 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222307-652d8y49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-266
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/652d8y49
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.61it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.97it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.77it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 177.63it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 178.16it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 174.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 174.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 176.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 180.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 184.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 186.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 187.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 187.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 187.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 178.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.248
wandb: best_valid_acc 0.268
wandb:  sub_train_acc 0.2119
wandb: sub_train_loss 1.42726
wandb:       test_acc 0.252
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run deep-sweep-266 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/652d8y49
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222307-652d8y49/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i16b894t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222323-i16b894t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-267
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i16b894t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.12it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 159.88it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 158.53it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 159.50it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 156.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 159.07it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 160.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 160.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 162.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 162.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 163.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 163.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 159.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 157.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 158.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 157.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 151.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.15
wandb: best_valid_acc 0.138
wandb:  sub_train_acc 0.16351
wandb: sub_train_loss 1.43715
wandb:       test_acc 0.151
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run serene-sweep-267 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i16b894t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222323-i16b894t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mt1s8ox3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222344-mt1s8ox3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-268
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mt1s8ox3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.49it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 161.00it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.23it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 162.69it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 162.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 158.28it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 154.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 153.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 153.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 154.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 157.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 158.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 158.63it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 160.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 157.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 158.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 159.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.466
wandb:  sub_train_acc 0.3177
wandb: sub_train_loss 1.48014
wandb:       test_acc 0.285
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run rose-sweep-268 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mt1s8ox3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222344-mt1s8ox3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l8qiy815 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222358-l8qiy815
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-269
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l8qiy815
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.42it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.55it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.41it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 171.49it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 175.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 178.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 179.10it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 179.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 179.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 177.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 176.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 174.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 174.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 174.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 171.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 168.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.443
wandb: best_valid_acc 0.452
wandb:  sub_train_acc 0.39285
wandb: sub_train_loss 1.48426
wandb:       test_acc 0.448
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run eternal-sweep-269 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l8qiy815
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222358-l8qiy815/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7c9h2tie with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222410-7c9h2tie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-270
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7c9h2tie
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.43it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 160.03it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.21it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 162.24it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 162.07it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 161.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 164.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 166.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 169.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 169.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 167.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 167.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 169.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 157.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 158.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 164.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 168.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.253
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.23084
wandb: sub_train_loss 1.45588
wandb:       test_acc 0.211
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run dashing-sweep-270 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7c9h2tie
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222410-7c9h2tie/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yyxq6hj9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222424-yyxq6hj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-271
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yyxq6hj9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.87it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.10it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 167.44it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 167.28it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 166.91it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 167.15it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 169.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 169.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 167.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 165.60it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 165.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 162.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 159.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 155.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 144.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 136.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 136.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 136.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.296
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.31861
wandb: sub_train_loss 1.47205
wandb:       test_acc 0.305
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run gentle-sweep-271 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yyxq6hj9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222424-yyxq6hj9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ujns81uw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222440-ujns81uw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-272
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ujns81uw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.97it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.12it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 134.75it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 136.80it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 134.22it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 142.17it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 150.51it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 152.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 155.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 153.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 153.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 153.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 154.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 157.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 159.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 162.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 163.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 166.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.54644
wandb: sub_train_loss 1.44122
wandb:       test_acc 0.524
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run hearty-sweep-272 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ujns81uw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222440-ujns81uw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7uvm5d4f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222457-7uvm5d4f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-273
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7uvm5d4f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.95it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.03it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.56it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 175.28it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 177.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 177.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 172.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 172.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 172.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 172.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 172.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 172.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 173.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 173.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 173.46it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 173.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.18
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.15449
wandb: sub_train_loss 1.08963
wandb:       test_acc 0.161
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run fresh-sweep-273 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7uvm5d4f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222457-7uvm5d4f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k4p6p2if with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222512-k4p6p2if
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-274
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k4p6p2if
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.75it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.50it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 169.41it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 169.05it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 169.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 168.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 170.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 173.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 175.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 177.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 178.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 177.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 177.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 178.40it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 178.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 176.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.229
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.2116
wandb: sub_train_loss 1.14907
wandb:       test_acc 0.231
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run sage-sweep-274 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k4p6p2if
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222512-k4p6p2if/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wbi8h90n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222527-wbi8h90n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-275
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wbi8h90n
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.90it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.36it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.74it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 158.59it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 156.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 158.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 159.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 160.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 160.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 161.04it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 159.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 159.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 158.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 154.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 155.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 157.34it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 158.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 149.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.256
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.2086
wandb: sub_train_loss 1.36984
wandb:       test_acc 0.079
wandb:      valid_acc 0.07
wandb: 
wandb: üöÄ View run silvery-sweep-275 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wbi8h90n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222527-wbi8h90n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p0jb67ov with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222543-p0jb67ov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-276
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p0jb67ov
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.38it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.52it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.86it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 167.62it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 172.30it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 175.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 176.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 178.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 178.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 178.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 178.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 177.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 175.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 175.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 175.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 175.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.194
wandb: best_valid_acc 0.252
wandb:  sub_train_acc 0.2092
wandb: sub_train_loss 1.36242
wandb:       test_acc 0.084
wandb:      valid_acc 0.07
wandb: 
wandb: üöÄ View run wobbly-sweep-276 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p0jb67ov
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222543-p0jb67ov/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gw8l1xum with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222557-gw8l1xum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-277
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gw8l1xum
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.78it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 166.73it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 167.38it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 160.30it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 160.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 161.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 160.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 160.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 160.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 159.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 159.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 158.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 157.92it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 156.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 156.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 157.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 157.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.18
wandb:  sub_train_acc 0.27292
wandb: sub_train_loss 1.26045
wandb:       test_acc 0.201
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run dazzling-sweep-277 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gw8l1xum
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222557-gw8l1xum/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c0jkwtn4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222613-c0jkwtn4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-278
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/c0jkwtn4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.96it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 160.03it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 164.85it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 165.91it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 168.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 171.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 172.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 173.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 172.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 173.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 174.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 174.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 173.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 174.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 174.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 173.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.2
wandb:  sub_train_acc 0.23565
wandb: sub_train_loss 1.35826
wandb:       test_acc 0.228
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run prime-sweep-278 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/c0jkwtn4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222613-c0jkwtn4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 239j12b5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222635-239j12b5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-279
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/239j12b5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.15it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.78it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.37it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 171.39it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 171.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 172.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 173.53it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 170.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 165.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 161.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 163.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 164.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 167.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 167.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 167.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 168.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 167.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.289
wandb: best_valid_acc 0.326
wandb:  sub_train_acc 0.18365
wandb: sub_train_loss 1.36893
wandb:       test_acc 0.219
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run fresh-sweep-279 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/239j12b5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222635-239j12b5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9xi0zi6o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222651-9xi0zi6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-280
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9xi0zi6o
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.97it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.59it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 168.29it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 170.23it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 169.33it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 169.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 170.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 168.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 167.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 161.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 162.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 158.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 159.27it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 157.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 156.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 152.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 149.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.195
wandb: best_valid_acc 0.178
wandb:  sub_train_acc 0.18124
wandb: sub_train_loss 1.2809
wandb:       test_acc 0.195
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run leafy-sweep-280 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9xi0zi6o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222651-9xi0zi6o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q2mizg4t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222711-q2mizg4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-281
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q2mizg4t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.65it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.95it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.95it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.08it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 159.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 164.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 166.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 165.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 165.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 165.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 165.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 164.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 163.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 161.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 158.71it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 157.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.366
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.32612
wandb: sub_train_loss 1.22804
wandb:       test_acc 0.366
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run northern-sweep-281 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q2mizg4t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222711-q2mizg4t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0qiw90hy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222726-0qiw90hy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-282
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0qiw90hy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.65it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.99it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 161.80it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 167.44it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 168.69it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 169.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 169.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 167.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 167.80it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 170.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 171.94it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 173.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 169.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 166.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 165.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 166.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 168.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.318
wandb:  sub_train_acc 0.28915
wandb: sub_train_loss 1.21957
wandb:       test_acc 0.311
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run dainty-sweep-282 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0qiw90hy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222726-0qiw90hy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: co5l0jrg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222743-co5l0jrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-283
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/co5l0jrg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.56it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 168.62it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 167.92it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 167.30it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 168.10it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 168.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 167.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 167.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 167.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 166.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 165.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 165.31it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 164.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 164.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 155.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 158.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 160.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.326
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.27322
wandb: sub_train_loss 1.28471
wandb:       test_acc 0.326
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run peachy-sweep-283 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/co5l0jrg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222743-co5l0jrg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: reygqzqi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222757-reygqzqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-284
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/reygqzqi
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 159.76it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 164.40it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 164.23it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 166.54it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 166.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 166.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 167.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 167.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 165.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 165.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 164.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 164.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 165.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 163.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 163.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 161.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 163.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.242
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.22753
wandb: sub_train_loss 1.28907
wandb:       test_acc 0.242
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run swift-sweep-284 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/reygqzqi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222757-reygqzqi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6s8sywyc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222812-6s8sywyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-285
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6s8sywyc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.60it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.29it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.67it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 156.75it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 159.51it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 159.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 160.30it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 160.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 161.82it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 163.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 164.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 163.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 163.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 164.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 166.21it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 166.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 166.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.466
wandb: best_valid_acc 0.466
wandb:  sub_train_acc 0.44244
wandb: sub_train_loss 1.25645
wandb:       test_acc 0.461
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run radiant-sweep-285 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6s8sywyc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222812-6s8sywyc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wcviwcr5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222824-wcviwcr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-286
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wcviwcr5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.89it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.52it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 153.99it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 155.69it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 154.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 155.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 151.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 150.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 150.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 151.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 152.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 152.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 152.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 156.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 159.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 160.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 156.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.437
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.41268
wandb: sub_train_loss 1.2301
wandb:       test_acc 0.437
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run rare-sweep-286 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wcviwcr5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222824-wcviwcr5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: juozanft with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222838-juozanft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-287
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/juozanft
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 119.92it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.15it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.36it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 126.86it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 129.26it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 131.07it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 132.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 127.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 129.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 132.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 124.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 124.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 127.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 128.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 130.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 132.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 131.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 131.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 130.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 131.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 132.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.562
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.55095
wandb: sub_train_loss 1.28144
wandb:       test_acc 0.52
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run divine-sweep-287 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/juozanft
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222838-juozanft/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9i6xt7j2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222853-9i6xt7j2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-288
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9i6xt7j2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.88it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.75it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 126.80it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 124.61it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 123.62it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 122.52it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 121.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 122.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 126.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 133.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 130.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 127.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 130.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 134.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 136.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 138.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 141.10it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 143.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 144.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 145.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 134.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.573
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.58371
wandb: sub_train_loss 1.22621
wandb:       test_acc 0.578
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run solar-sweep-288 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9i6xt7j2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222853-9i6xt7j2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fvedc3sb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222909-fvedc3sb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-289
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvedc3sb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 285.65it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 257.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 260.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 262.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 259.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 244.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 245.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 252.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.25188
wandb: sub_train_loss 1.7283
wandb:       test_acc 0.285
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run gentle-sweep-289 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvedc3sb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222909-fvedc3sb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 78nfkvax with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222924-78nfkvax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-290
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/78nfkvax
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 307.01it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 304.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 299.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 298.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 297.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 295.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 294.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.298
wandb: best_valid_acc 0.258
wandb:  sub_train_acc 0.24406
wandb: sub_train_loss 1.73015
wandb:       test_acc 0.298
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run glamorous-sweep-290 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/78nfkvax
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222924-78nfkvax/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6wxxw5vg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222940-6wxxw5vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-291
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6wxxw5vg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.70it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 278.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 279.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 269.94it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 275.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 274.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 282.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 277.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.338
wandb: best_valid_acc 0.354
wandb:  sub_train_acc 0.30117
wandb: sub_train_loss 1.74547
wandb:       test_acc 0.341
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run jumping-sweep-291 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6wxxw5vg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222940-6wxxw5vg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l8622asl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222954-l8622asl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-292
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l8622asl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 289.06it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 286.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 281.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 280.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 281.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 281.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 282.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.347
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.3159
wandb: sub_train_loss 1.74489
wandb:       test_acc 0.356
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run sparkling-sweep-292 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l8622asl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222954-l8622asl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ztt2fts0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223006-ztt2fts0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-293
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ztt2fts0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 229.36it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 251.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 234.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 233.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 236.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 235.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 235.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 234.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 235.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.39
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.37601
wandb: sub_train_loss 1.75297
wandb:       test_acc 0.395
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run iconic-sweep-293 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ztt2fts0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223006-ztt2fts0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m2zwjmz1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223021-m2zwjmz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-294
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m2zwjmz1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 263.08it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 221.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 219.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 218.09it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 211.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 211.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 214.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 218.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 217.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.367
wandb: best_valid_acc 0.436
wandb:  sub_train_acc 0.35317
wandb: sub_train_loss 1.75299
wandb:       test_acc 0.367
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run smart-sweep-294 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m2zwjmz1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223021-m2zwjmz1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yjxiu4xe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223036-yjxiu4xe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yjxiu4xe
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 304.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 311.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 315.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 286.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 257.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 253.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 266.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.263
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.24647
wandb: sub_train_loss 1.75727
wandb:       test_acc 0.262
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run divine-sweep-295 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yjxiu4xe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223036-yjxiu4xe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s7997khg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223051-s7997khg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-296
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s7997khg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 259.34it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 266.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 262.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 263.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 261.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 260.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 264.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 263.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.219
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.24226
wandb: sub_train_loss 1.75642
wandb:       test_acc 0.256
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run ruby-sweep-296 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s7997khg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223051-s7997khg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: do2mxth0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223107-do2mxth0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-297
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/do2mxth0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 255.88it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 260.03it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 256.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 262.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 269.32it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 275.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 276.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.192
wandb: best_valid_acc 0.18
wandb:  sub_train_acc 0.19176
wandb: sub_train_loss 1.7608
wandb:       test_acc 0.196
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run toasty-sweep-297 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/do2mxth0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223107-do2mxth0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ukxt3ld0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223128-ukxt3ld0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-298
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ukxt3ld0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 290.13it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 288.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 284.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 284.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 282.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 279.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 282.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.2
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.2128
wandb: sub_train_loss 1.76089
wandb:       test_acc 0.213
wandb:      valid_acc 0.186
wandb: 
wandb: üöÄ View run soft-sweep-298 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ukxt3ld0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223128-ukxt3ld0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jsc3wabr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223142-jsc3wabr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-299
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jsc3wabr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 269.71it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 280.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 262.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 257.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 259.72it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 261.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 248.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 255.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.244
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.14728
wandb: sub_train_loss 1.76291
wandb:       test_acc 0.13
wandb:      valid_acc 0.094
wandb: 
wandb: üöÄ View run fragrant-sweep-299 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jsc3wabr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223142-jsc3wabr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8upuhuxr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223158-8upuhuxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-300
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8upuhuxr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 286.42it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 278.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 270.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 278.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 280.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 282.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 280.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.205
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.14668
wandb: sub_train_loss 1.76364
wandb:       test_acc 0.131
wandb:      valid_acc 0.112
wandb: 
wandb: üöÄ View run deep-sweep-300 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8upuhuxr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223158-8upuhuxr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 63vtnot1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223214-63vtnot1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-301
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/63vtnot1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 299.30it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 277.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 268.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 266.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 260.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 257.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 253.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.344
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.3168
wandb: sub_train_loss 1.76524
wandb:       test_acc 0.321
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run deft-sweep-301 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/63vtnot1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223214-63vtnot1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m22c1x0r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223229-m22c1x0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-302
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m22c1x0r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 272.98it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 276.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 281.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 278.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 277.10it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 276.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 278.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 278.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.295
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.28945
wandb: sub_train_loss 1.76486
wandb:       test_acc 0.294
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run jumping-sweep-302 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m22c1x0r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223229-m22c1x0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: di3jfb4j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223245-di3jfb4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-303
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/di3jfb4j
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 223.75it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 197.99it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 216.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 248.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 261.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 271.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 278.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 258.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.55756
wandb: sub_train_loss 1.76786
wandb:       test_acc 0.564
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run crimson-sweep-303 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/di3jfb4j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223245-di3jfb4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wkuoo9nd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223259-wkuoo9nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-304
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wkuoo9nd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 259.12it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 281.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 285.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 290.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 292.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 294.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.559
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.53953
wandb: sub_train_loss 1.76779
wandb:       test_acc 0.559
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run stellar-sweep-304 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wkuoo9nd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223259-wkuoo9nd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ubp8p542 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223321-ubp8p542
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-305
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ubp8p542
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.34it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 172.32it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 179.14it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 182.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 179.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 179.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 174.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 173.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 176.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 174.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.324
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.27502
wandb: sub_train_loss 1.55356
wandb:       test_acc 0.323
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run prime-sweep-305 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ubp8p542
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223321-ubp8p542/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t31jy9qa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223334-t31jy9qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-306
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t31jy9qa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.77it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 145.69it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 152.21it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 153.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 149.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 157.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 166.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 164.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 161.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 159.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 165.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 161.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.169
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.2119
wandb: sub_train_loss 1.5383
wandb:       test_acc 0.213
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run bumbling-sweep-306 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t31jy9qa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223334-t31jy9qa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b0l60hyv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223349-b0l60hyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-307
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b0l60hyv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.00it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 180.99it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 175.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 186.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 189.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 194.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 197.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 199.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 200.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.326
wandb: best_valid_acc 0.394
wandb:  sub_train_acc 0.32672
wandb: sub_train_loss 1.56854
wandb:       test_acc 0.325
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run kind-sweep-307 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b0l60hyv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223349-b0l60hyv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lwfygtfi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223400-lwfygtfi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-308
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lwfygtfi
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.68it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 190.77it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 189.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 193.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 194.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 188.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 178.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 170.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 167.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 164.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.239
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.24797
wandb: sub_train_loss 1.565
wandb:       test_acc 0.211
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run lively-sweep-308 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lwfygtfi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223400-lwfygtfi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pfzyxbvs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223416-pfzyxbvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pfzyxbvs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.86it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.44it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 136.50it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 128.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 127.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 125.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 122.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 121.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 123.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 126.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 130.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 129.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 133.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 130.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.376
wandb: best_valid_acc 0.41
wandb:  sub_train_acc 0.35618
wandb: sub_train_loss 1.60546
wandb:       test_acc 0.387
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run pretty-sweep-309 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pfzyxbvs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223416-pfzyxbvs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sfpsajjq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223432-sfpsajjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-310
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfpsajjq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.46it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 182.68it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 169.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 167.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 163.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 159.25it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 160.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 165.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 164.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 163.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 162.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.313
wandb: best_valid_acc 0.296
wandb:  sub_train_acc 0.28765
wandb: sub_train_loss 1.60767
wandb:       test_acc 0.305
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run laced-sweep-310 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfpsajjq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223432-sfpsajjq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sbvk4kxk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223447-sbvk4kxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-311
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sbvk4kxk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.25it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 111.32it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 117.91it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 141.33it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 155.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 163.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 163.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 170.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 174.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 176.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 174.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.302
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.32071
wandb: sub_train_loss 1.63579
wandb:       test_acc 0.305
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run misty-sweep-311 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sbvk4kxk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223447-sbvk4kxk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cpfnaut3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223503-cpfnaut3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-312
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cpfnaut3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.30it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.89it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.65it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 134.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 133.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 132.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 141.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 154.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 155.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 164.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 169.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 175.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.382
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.40186
wandb: sub_train_loss 1.63145
wandb:       test_acc 0.383
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run wandering-sweep-312 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cpfnaut3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223503-cpfnaut3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6yg8jfw8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223518-6yg8jfw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-313
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6yg8jfw8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.94it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 188.73it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 186.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 183.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 184.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 182.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 179.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 182.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 183.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 184.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.308
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.33484
wandb: sub_train_loss 1.64288
wandb:       test_acc 0.309
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run soft-sweep-313 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6yg8jfw8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223518-6yg8jfw8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: moipvz65 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223533-moipvz65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-314
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/moipvz65
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.16it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 157.60it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 162.52it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 165.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 160.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 158.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 158.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 155.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 158.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 163.34it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 165.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.20it/s]
wandb: - 0.000 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.264
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.28945
wandb: sub_train_loss 1.65071
wandb:       test_acc 0.264
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run firm-sweep-314 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/moipvz65
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223533-moipvz65/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6yxprl29 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223548-6yxprl29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-315
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6yxprl29
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 179.71it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.46it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 147.77it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 150.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 152.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 151.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 140.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 144.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 146.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 144.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 146.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.163
wandb: best_valid_acc 0.154
wandb:  sub_train_acc 0.16772
wandb: sub_train_loss 1.66526
wandb:       test_acc 0.128
wandb:      valid_acc 0.114
wandb: 
wandb: üöÄ View run autumn-sweep-315 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6yxprl29
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223548-6yxprl29/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bmv4ydj5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223609-bmv4ydj5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-316
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bmv4ydj5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.84it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 153.12it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 148.02it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 142.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 137.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 137.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 136.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 136.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 135.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 137.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 138.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 138.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 149.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.304
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.34175
wandb: sub_train_loss 1.65819
wandb:       test_acc 0.306
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run golden-sweep-316 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bmv4ydj5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223609-bmv4ydj5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6pvzlkzc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223625-6pvzlkzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-317
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6pvzlkzc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 177.21it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 169.36it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 164.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 165.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 172.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 179.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 180.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 181.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 181.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 182.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.374
wandb:  sub_train_acc 0.41689
wandb: sub_train_loss 1.66716
wandb:       test_acc 0.413
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run hearty-sweep-317 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6pvzlkzc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223625-6pvzlkzc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jjs6hj0k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223639-jjs6hj0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-318
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jjs6hj0k
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.56it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 203.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 199.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 196.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 194.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 193.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 193.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 191.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 190.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.56it/s]
wandb: - 0.000 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.332
wandb: best_valid_acc 0.33
wandb:  sub_train_acc 0.34626
wandb: sub_train_loss 1.67259
wandb:       test_acc 0.332
wandb:      valid_acc 0.33
wandb: 
wandb: üöÄ View run icy-sweep-318 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jjs6hj0k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223639-jjs6hj0k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mwcoepxj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223655-mwcoepxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-319
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mwcoepxj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.01it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.99it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 190.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 192.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 194.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 195.09it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 196.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 193.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 183.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 176.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.014 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.631
wandb: best_valid_acc 0.658
wandb:  sub_train_acc 0.63
wandb: sub_train_loss 1.67179
wandb:       test_acc 0.634
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run clean-sweep-319 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mwcoepxj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223655-mwcoepxj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k2km2md3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223715-k2km2md3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-320
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k2km2md3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 179.70it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 178.59it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 175.47it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 172.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 173.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 176.28it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 175.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 178.03it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 181.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 183.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.658
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.66066
wandb: sub_train_loss 1.67884
wandb:       test_acc 0.658
wandb:      valid_acc 0.698
wandb: 
wandb: üöÄ View run genial-sweep-320 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k2km2md3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223715-k2km2md3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s5ps3lcq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223731-s5ps3lcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-321
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5ps3lcq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.34it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 127.20it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 128.31it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 129.03it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 129.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 129.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 128.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 129.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 129.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 131.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 134.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 137.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 141.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 143.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.159
wandb: best_valid_acc 0.156
wandb:  sub_train_acc 0.16441
wandb: sub_train_loss 1.37804
wandb:       test_acc 0.161
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run dry-sweep-321 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5ps3lcq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223731-s5ps3lcq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1uo5ytur with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223746-1uo5ytur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-322
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1uo5ytur
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.89it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 117.80it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 119.77it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 127.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 129.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 131.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 132.15it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 132.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 137.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 139.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 142.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 141.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 139.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.205
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.1554
wandb: sub_train_loss 1.38852
wandb:       test_acc 0.16
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run trim-sweep-322 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1uo5ytur
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223746-1uo5ytur/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 28pe67or with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223807-28pe67or
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-323
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/28pe67or
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.93it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 122.41it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 128.91it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 127.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 127.64it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 127.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 127.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 127.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 126.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 126.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 125.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 125.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 124.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 122.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 121.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.234
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.22964
wandb: sub_train_loss 1.47337
wandb:       test_acc 0.233
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run azure-sweep-323 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/28pe67or
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223807-28pe67or/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8vyu997m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223821-8vyu997m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-324
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8vyu997m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.25it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.63it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 139.59it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 133.88it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 131.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 127.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 129.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 132.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 120.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 117.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 116.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 116.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 123.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 128.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.254
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.25909
wandb: sub_train_loss 1.49307
wandb:       test_acc 0.256
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run fanciful-sweep-324 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8vyu997m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223821-8vyu997m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 24l1scwm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223837-24l1scwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-325
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/24l1scwm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.88it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.77it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 140.73it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 139.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 138.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 135.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 137.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 140.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 141.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 141.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 141.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 127.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 113.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.363
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.35948
wandb: sub_train_loss 1.51741
wandb:       test_acc 0.363
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run ancient-sweep-325 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/24l1scwm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223837-24l1scwm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eq5lmi42 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223853-eq5lmi42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-326
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eq5lmi42
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.66it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.26it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 121.54it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 123.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 125.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 126.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 127.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 126.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 126.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 126.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 126.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 116.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 118.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 123.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 127.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.32041
wandb: sub_train_loss 1.52081
wandb:       test_acc 0.317
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run fresh-sweep-326 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eq5lmi42
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223853-eq5lmi42/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p8a1ts9y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223909-p8a1ts9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-327
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p8a1ts9y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.68it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.96it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 142.38it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 141.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 142.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 140.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 138.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 135.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 131.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 130.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 130.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 126.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 127.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.491
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.46047
wandb: sub_train_loss 1.58047
wandb:       test_acc 0.496
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run copper-sweep-327 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p8a1ts9y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223909-p8a1ts9y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n65dd9lt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223929-n65dd9lt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-328
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n65dd9lt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.19it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.61it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.73it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.68it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 123.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 125.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 126.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 122.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 121.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 119.21it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 118.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 120.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 124.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 127.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 129.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.30839
wandb: sub_train_loss 1.54331
wandb:       test_acc 0.259
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run deft-sweep-328 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n65dd9lt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223929-n65dd9lt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 11z4h5ih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223951-11z4h5ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-329
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/11z4h5ih
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.85it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 123.32it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 121.92it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 120.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 124.18it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 125.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 125.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 124.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 129.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 129.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 133.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 132.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 133.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 132.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.11
wandb: best_valid_acc 0.088
wandb:  sub_train_acc 0.15179
wandb: sub_train_loss 1.56414
wandb:       test_acc 0.115
wandb:      valid_acc 0.088
wandb: 
wandb: üöÄ View run snowy-sweep-329 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/11z4h5ih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223951-11z4h5ih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cfmtgfvq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224003-cfmtgfvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-330
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cfmtgfvq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.22it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 140.73it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 140.50it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 141.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 143.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 142.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 140.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 139.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 138.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 134.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.243
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.30117
wandb: sub_train_loss 1.57673
wandb:       test_acc 0.25
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run electric-sweep-330 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cfmtgfvq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224003-cfmtgfvq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h24hhhq2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224017-h24hhhq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-331
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h24hhhq2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.69it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.95it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 121.77it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.76it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 129.81it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 131.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 133.29it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 134.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 133.02it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 133.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 134.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 134.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 134.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 136.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.147
wandb: best_valid_acc 0.118
wandb:  sub_train_acc 0.18154
wandb: sub_train_loss 1.61871
wandb:       test_acc 0.149
wandb:      valid_acc 0.114
wandb: 
wandb: üöÄ View run drawn-sweep-331 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h24hhhq2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224017-h24hhhq2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7gkv86a6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224033-7gkv86a6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-332
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7gkv86a6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.62it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.24it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 115.15it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 117.85it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 119.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 125.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 130.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 134.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 133.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 135.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 135.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 136.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 137.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 135.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.352
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.37752
wandb: sub_train_loss 1.59543
wandb:       test_acc 0.352
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run divine-sweep-332 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7gkv86a6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224033-7gkv86a6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3d8bdzrt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224048-3d8bdzrt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-333
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3d8bdzrt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.77it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.58it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.20it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 121.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 114.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 113.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 113.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 113.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 114.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 113.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 115.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 117.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 117.39it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 116.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 116.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.243
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.24497
wandb: sub_train_loss 1.62448
wandb:       test_acc 0.25
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run classic-sweep-333 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3d8bdzrt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224048-3d8bdzrt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v2ixgurl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224103-v2ixgurl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-334
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v2ixgurl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.07it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.04it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 123.01it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.57it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 128.86it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 131.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 135.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 137.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 139.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 139.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 138.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 136.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 120.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 113.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.46
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.45627
wandb: sub_train_loss 1.61934
wandb:       test_acc 0.46
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run royal-sweep-334 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v2ixgurl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224103-v2ixgurl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m0is1men with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224119-m0is1men
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-335
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m0is1men
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.23it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 111.77it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 108.20it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 109.33it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 117.58it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 121.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 119.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 117.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 115.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 116.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 118.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 120.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 121.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 125.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 129.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.567
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.55455
wandb: sub_train_loss 1.6368
wandb:       test_acc 0.566
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run olive-sweep-335 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m0is1men
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224119-m0is1men/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhva1eus with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224140-hhva1eus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-336
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hhva1eus
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.01it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.97it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.03it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 135.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 137.83it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 136.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 135.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 135.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 139.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 141.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 141.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 140.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.575
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.56177
wandb: sub_train_loss 1.63537
wandb:       test_acc 0.561
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run stellar-sweep-336 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hhva1eus
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224140-hhva1eus/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0naukm2m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224155-0naukm2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-337
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0naukm2m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 272.59it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 259.66it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 255.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 259.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 260.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 262.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 268.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 275.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:00<00:00, 279.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 276.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 269.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.295
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.25398
wandb: sub_train_loss 1.69766
wandb:       test_acc 0.296
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run earnest-sweep-337 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0naukm2m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224155-0naukm2m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r0fcn6vb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224214-r0fcn6vb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-338
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r0fcn6vb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 201.98it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 215.86it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 233.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 244.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 256.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 265.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 267.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 266.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 264.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 261.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 261.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 256.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.315
wandb: best_valid_acc 0.294
wandb:  sub_train_acc 0.26961
wandb: sub_train_loss 1.69623
wandb:       test_acc 0.317
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run faithful-sweep-338 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r0fcn6vb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224214-r0fcn6vb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pr7abh6a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224230-pr7abh6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-339
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pr7abh6a
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 248.59it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 269.73it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 286.16it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 295.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 299.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 288.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 281.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 283.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 284.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 281.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 282.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.365
wandb: best_valid_acc 0.386
wandb:  sub_train_acc 0.32552
wandb: sub_train_loss 1.71869
wandb:       test_acc 0.365
wandb:      valid_acc 0.386
wandb: 
wandb: üöÄ View run stellar-sweep-339 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pr7abh6a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224230-pr7abh6a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f0ig8o7r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224251-f0ig8o7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-340
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f0ig8o7r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 271.80it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 272.09it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 277.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 234.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 223.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 207.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 219.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 213.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 216.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 230.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 238.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 233.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.364
wandb: best_valid_acc 0.404
wandb:  sub_train_acc 0.33333
wandb: sub_train_loss 1.71887
wandb:       test_acc 0.372
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run eternal-sweep-340 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f0ig8o7r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224251-f0ig8o7r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5itvwz0v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224312-5itvwz0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-341
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5itvwz0v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 234.66it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 245.39it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:00, 262.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 278.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 287.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 293.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 299.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 300.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:00<00:00, 299.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 299.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 289.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.362
wandb: best_valid_acc 0.394
wandb:  sub_train_acc 0.37121
wandb: sub_train_loss 1.73221
wandb:       test_acc 0.391
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run ruby-sweep-341 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5itvwz0v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224312-5itvwz0v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 771ovc0q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224330-771ovc0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-342
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/771ovc0q
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 246.08it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 252.78it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 252.24it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 252.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 237.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 217.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 224.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 229.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 245.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 257.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 267.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.379
wandb: best_valid_acc 0.396
wandb:  sub_train_acc 0.36159
wandb: sub_train_loss 1.73276
wandb:       test_acc 0.387
wandb:      valid_acc 0.378
wandb: 
wandb: üöÄ View run winter-sweep-342 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/771ovc0q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224330-771ovc0q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vbe2zjfs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224352-vbe2zjfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-343
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vbe2zjfs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 241.12it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 239.04it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 241.21it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 246.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 250.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 254.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 257.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 261.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 263.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 261.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 252.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 252.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.24316
wandb: sub_train_loss 1.73884
wandb:       test_acc 0.258
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run visionary-sweep-343 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vbe2zjfs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224352-vbe2zjfs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sfhhcbj2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224407-sfhhcbj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-344
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfhhcbj2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 235.44it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 226.64it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 226.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 238.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 243.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 245.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 249.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 250.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 251.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 252.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 253.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 247.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.266
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.24617
wandb: sub_train_loss 1.73942
wandb:       test_acc 0.264
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run sparkling-sweep-344 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfhhcbj2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224407-sfhhcbj2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nd6xr7b1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224423-nd6xr7b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-345
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nd6xr7b1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 265.57it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 246.81it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:00, 236.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 233.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 247.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 260.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 268.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 277.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 284.29it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 277.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 265.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.17
wandb: best_valid_acc 0.196
wandb:  sub_train_acc 0.2083
wandb: sub_train_loss 1.74432
wandb:       test_acc 0.208
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run breezy-sweep-345 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nd6xr7b1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224423-nd6xr7b1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 20gtx01t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224438-20gtx01t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-346
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/20gtx01t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 273.01it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 276.03it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 269.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 272.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 275.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 274.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 263.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 259.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 265.39it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 269.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 267.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.224
wandb: best_valid_acc 0.214
wandb:  sub_train_acc 0.22393
wandb: sub_train_loss 1.74515
wandb:       test_acc 0.221
wandb:      valid_acc 0.214
wandb: 
wandb: üöÄ View run iconic-sweep-346 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/20gtx01t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224438-20gtx01t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: duxalqnj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224453-duxalqnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-347
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/duxalqnj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.79it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 268.72it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 265.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 255.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 246.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 238.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 237.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 240.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 230.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 231.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 214.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 230.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.188
wandb:  sub_train_acc 0.08867
wandb: sub_train_loss 1.74764
wandb:       test_acc 0.08
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run fanciful-sweep-347 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/duxalqnj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224453-duxalqnj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mqws3w5f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224514-mqws3w5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-348
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mqws3w5f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 239.76it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 201.61it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 201.00it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 205.67it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 204.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 203.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 202.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 207.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 218.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 226.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 238.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 250.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.188
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.09258
wandb: sub_train_loss 1.74815
wandb:       test_acc 0.082
wandb:      valid_acc 0.064
wandb: 
wandb: üöÄ View run wild-sweep-348 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mqws3w5f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224514-mqws3w5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gdwfirim with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224529-gdwfirim
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-349
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gdwfirim
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 285.14it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 289.46it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 292.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 298.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 301.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 296.94it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 295.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 297.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:00<00:00, 299.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 296.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.25458
wandb: sub_train_loss 1.7505
wandb:       test_acc 0.242
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run glorious-sweep-349 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gdwfirim
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224529-gdwfirim/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: drwsme10 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224540-drwsme10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-350
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/drwsme10
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 284.76it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 285.11it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 288.09it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 294.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 300.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 305.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 308.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 310.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:00<00:00, 308.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 299.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.344
wandb: best_valid_acc 0.352
wandb:  sub_train_acc 0.25609
wandb: sub_train_loss 1.75027
wandb:       test_acc 0.254
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run astral-sweep-350 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/drwsme10
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224540-drwsme10/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rco9vo5b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224555-rco9vo5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-351
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rco9vo5b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 304.34it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 296.54it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 279.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 270.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 268.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 266.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 276.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 281.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 277.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 273.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 275.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.564
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.50255
wandb: sub_train_loss 1.75458
wandb:       test_acc 0.48
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run jolly-sweep-351 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rco9vo5b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224555-rco9vo5b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uvn2nztu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224611-uvn2nztu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-352
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uvn2nztu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 315.51it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 188.02it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 203.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 216.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 227.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 236.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 242.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 245.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 258.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 267.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 245.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.583
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.51428
wandb: sub_train_loss 1.75423
wandb:       test_acc 0.508
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run dainty-sweep-352 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uvn2nztu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224611-uvn2nztu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mwtdz496 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224631-mwtdz496
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-353
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mwtdz496
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.67it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 159.58it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 154.07it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 151.79it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 138.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 126.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 132.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 137.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 145.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 151.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 155.32it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 159.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 164.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 168.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 173.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 173.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 172.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.302
wandb: best_valid_acc 0.268
wandb:  sub_train_acc 0.23384
wandb: sub_train_loss 1.34039
wandb:       test_acc 0.257
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run fine-sweep-353 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mwtdz496
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224631-mwtdz496/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8fswagb1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224646-8fswagb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-354
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8fswagb1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.49it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 171.58it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.85it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 164.39it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 159.68it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 157.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 158.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 160.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 153.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 153.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 149.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 157.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 163.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 164.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 167.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 168.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 168.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.328
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.26781
wandb: sub_train_loss 1.34188
wandb:       test_acc 0.296
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run apricot-sweep-354 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8fswagb1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224646-8fswagb1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sz7zrwb5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224657-sz7zrwb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-355
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sz7zrwb5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.09it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.97it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.86it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 172.29it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 177.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 180.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 183.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 184.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 183.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 183.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 179.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 176.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 178.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 180.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 180.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 153.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.358
wandb: best_valid_acc 0.356
wandb:  sub_train_acc 0.31199
wandb: sub_train_loss 1.42342
wandb:       test_acc 0.358
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run giddy-sweep-355 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sz7zrwb5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224657-sz7zrwb5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7zbnurc3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224712-7zbnurc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-356
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7zbnurc3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.93it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.06it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.20it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 161.33it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 169.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 167.89it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 172.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 177.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 184.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 190.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 192.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 194.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 192.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 187.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 181.62it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 176.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.3
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.29726
wandb: sub_train_loss 1.41129
wandb:       test_acc 0.304
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run fresh-sweep-356 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7zbnurc3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224712-7zbnurc3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: goxgvy7b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224727-goxgvy7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-357
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/goxgvy7b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.63it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 188.80it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 191.69it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 190.47it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 192.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 191.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 186.18it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 178.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 175.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 170.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 159.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 157.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 163.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 166.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.5
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.43102
wandb: sub_train_loss 1.4741
wandb:       test_acc 0.498
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run jolly-sweep-357 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/goxgvy7b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224727-goxgvy7b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nmbag6qe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224749-nmbag6qe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-358
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nmbag6qe
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.07it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.78it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.32it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 173.89it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 176.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 174.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 172.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 169.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 168.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 167.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 166.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 167.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 167.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 168.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 167.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 169.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.422
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.38173
wandb: sub_train_loss 1.4702
wandb:       test_acc 0.407
wandb:      valid_acc 0.406
wandb: 
wandb: üöÄ View run effortless-sweep-358 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nmbag6qe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224749-nmbag6qe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2hovkz95 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224801-2hovkz95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-359
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2hovkz95
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.57it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.29it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.42it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 171.33it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 170.16it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 176.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 184.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 189.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 191.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 192.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 186.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 185.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 184.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 184.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 183.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.165
wandb: best_valid_acc 0.154
wandb:  sub_train_acc 0.18515
wandb: sub_train_loss 1.511
wandb:       test_acc 0.17
wandb:      valid_acc 0.146
wandb: 
wandb: üöÄ View run happy-sweep-359 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2hovkz95
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224801-2hovkz95/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0wruckly with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224816-0wruckly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-360
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0wruckly
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.03it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.44it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 180.62it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 184.46it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 182.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 179.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 174.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 178.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 177.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 177.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 177.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 177.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 177.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 177.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 180.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 181.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.394
wandb: best_valid_acc 0.368
wandb:  sub_train_acc 0.38293
wandb: sub_train_loss 1.51862
wandb:       test_acc 0.4
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run floral-sweep-360 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0wruckly
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224816-0wruckly/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tvw33o1v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224838-tvw33o1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-361
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tvw33o1v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.52it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.67it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 168.84it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 168.24it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 169.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 171.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 171.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 170.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 169.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 166.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 163.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 157.89it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 158.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 160.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 162.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 162.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 163.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.314
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.33454
wandb: sub_train_loss 1.53746
wandb:       test_acc 0.316
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run lively-sweep-361 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tvw33o1v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224838-tvw33o1v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a4pkmbt3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224852-a4pkmbt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-362
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a4pkmbt3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.50it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.81it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 163.58it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 169.47it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 173.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 174.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 177.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 182.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 185.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 185.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 183.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 180.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 180.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 181.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 182.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 182.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.34
wandb: best_valid_acc 0.34
wandb:  sub_train_acc 0.3688
wandb: sub_train_loss 1.53082
wandb:       test_acc 0.34
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run upbeat-sweep-362 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a4pkmbt3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224852-a4pkmbt3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ae64ca3r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224908-ae64ca3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-363
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ae64ca3r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.72it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.98it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 180.71it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 178.39it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 178.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 151.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 148.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 144.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 146.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 156.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 162.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 162.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 161.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 161.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 164.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 161.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.229
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.2642
wandb: sub_train_loss 1.57061
wandb:       test_acc 0.227
wandb:      valid_acc 0.214
wandb: 
wandb: üöÄ View run genial-sweep-363 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ae64ca3r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224908-ae64ca3r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: durf4cje with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224923-durf4cje
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-364
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/durf4cje
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.97it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 192.68it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 191.48it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 189.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 187.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 188.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 190.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 190.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 190.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 193.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 193.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 193.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 193.34it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 194.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 191.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.339
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.36369
wandb: sub_train_loss 1.55573
wandb:       test_acc 0.339
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run fine-sweep-364 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/durf4cje
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224923-durf4cje/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ycw14w9c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224938-ycw14w9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ycw14w9c
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.08it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 176.91it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 174.79it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 170.13it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 168.71it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 168.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 170.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 172.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 172.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 173.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 176.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 178.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 179.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 180.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 180.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 181.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.405
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.4214
wandb: sub_train_loss 1.57034
wandb:       test_acc 0.417
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run prime-sweep-365 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ycw14w9c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224938-ycw14w9c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nvdfbrpv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224954-nvdfbrpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nvdfbrpv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.08it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.41it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.72it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 174.93it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 177.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 176.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 172.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 174.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 173.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 174.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 178.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 181.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 181.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 182.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 182.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 182.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.388
wandb: best_valid_acc 0.366
wandb:  sub_train_acc 0.38894
wandb: sub_train_loss 1.57678
wandb:       test_acc 0.388
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run kind-sweep-366 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nvdfbrpv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224954-nvdfbrpv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 50hdvbtw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225005-50hdvbtw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-367
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/50hdvbtw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 158.33it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.28it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 144.72it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 144.10it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 146.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 150.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 162.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 170.52it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 175.11it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 179.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 180.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 181.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 179.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 181.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 182.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 183.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.671
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.67238
wandb: sub_train_loss 1.59075
wandb:       test_acc 0.673
wandb:      valid_acc 0.684
wandb: 
wandb: üöÄ View run splendid-sweep-367 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/50hdvbtw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225005-50hdvbtw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oebbo6d8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225019-oebbo6d8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-368
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oebbo6d8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.98it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.51it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 167.40it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 170.50it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 173.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 173.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 171.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 174.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 176.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 177.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 177.30it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 176.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 175.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 176.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 176.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 176.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.681
wandb: best_valid_acc 0.694
wandb:  sub_train_acc 0.67448
wandb: sub_train_loss 1.58945
wandb:       test_acc 0.676
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run resilient-sweep-368 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oebbo6d8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225019-oebbo6d8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j8x41oaz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225035-j8x41oaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-369
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j8x41oaz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.82it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.49it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.18it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.69it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 121.35it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 116.85it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 120.13it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 121.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 120.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 121.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 119.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 118.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 119.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 121.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 121.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 119.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 122.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 123.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 127.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 128.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 131.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 132.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.282
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.26601
wandb: sub_train_loss 1.05497
wandb:       test_acc 0.282
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run iconic-sweep-369 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j8x41oaz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225035-j8x41oaz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0pzk6710 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225050-0pzk6710
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-370
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0pzk6710
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.16it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 113.54it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 115.93it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 121.60it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 122.05it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 120.82it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 121.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 121.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 124.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 124.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 121.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 121.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 122.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 118.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 107.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 108.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 110.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 115.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 119.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 119.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 118.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 117.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 117.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.201
wandb: best_valid_acc 0.182
wandb:  sub_train_acc 0.15479
wandb: sub_train_loss 1.07047
wandb:       test_acc 0.162
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run worldly-sweep-370 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0pzk6710
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225050-0pzk6710/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xyscayj7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225106-xyscayj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-371
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xyscayj7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.02it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.49it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 141.29it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 140.28it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 140.37it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 140.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 139.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 139.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 138.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 138.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 139.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 135.55it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 129.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 122.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 112.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 113.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 110.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 104.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 104.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 101.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 98.21it/s]  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 96.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.27502
wandb: sub_train_loss 1.14546
wandb:       test_acc 0.305
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run warm-sweep-371 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xyscayj7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225106-xyscayj7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1tet5qu9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225121-1tet5qu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-372
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1tet5qu9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.37it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 123.44it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.63it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 127.32it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 126.94it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 127.56it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 121.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 122.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 122.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 124.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 125.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 125.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 126.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 130.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 132.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 134.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 135.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 136.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 136.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 136.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 134.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 133.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.24
wandb: best_valid_acc 0.268
wandb:  sub_train_acc 0.27713
wandb: sub_train_loss 1.20213
wandb:       test_acc 0.224
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run lemon-sweep-372 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1tet5qu9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225121-1tet5qu9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eix4mqu8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225137-eix4mqu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-373
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eix4mqu8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 112.94it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 102.07it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 104.25it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 104.95it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 106.67it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 104.88it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 109.09it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 114.06it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 116.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 110.35it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 113.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 109.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 110.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 111.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 112.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 113.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 113.45it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 114.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 116.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 116.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 117.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 116.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 115.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 114.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 115.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.42
wandb: best_valid_acc 0.39
wandb:  sub_train_acc 0.34566
wandb: sub_train_loss 1.23387
wandb:       test_acc 0.35
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run gentle-sweep-373 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eix4mqu8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225137-eix4mqu8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r9dt4b4d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225153-r9dt4b4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-374
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r9dt4b4d
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.63it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 119.92it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 122.57it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 126.42it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 124.34it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 125.34it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 124.36it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 123.92it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 123.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 121.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 119.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 119.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 118.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 119.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 117.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 116.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 114.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 115.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 120.25it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 124.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 123.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 122.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 122.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.327
wandb: best_valid_acc 0.362
wandb:  sub_train_acc 0.35918
wandb: sub_train_loss 1.23815
wandb:       test_acc 0.338
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run pious-sweep-374 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r9dt4b4d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225153-r9dt4b4d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zwzhdqt5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225207-zwzhdqt5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-375
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zwzhdqt5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.21it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 130.99it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 135.30it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 139.83it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 141.01it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 143.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 138.64it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 133.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 133.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 130.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 129.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 128.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 128.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 130.74it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 132.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 134.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 123.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 123.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 123.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 122.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 122.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.557
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.49895
wandb: sub_train_loss 1.31957
wandb:       test_acc 0.558
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run pleasant-sweep-375 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zwzhdqt5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225207-zwzhdqt5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zfk8i8q7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225223-zfk8i8q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-376
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zfk8i8q7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.40it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.34it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.62it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 136.22it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 137.38it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 137.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 137.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 137.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 138.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 138.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 138.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 138.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 137.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 137.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 137.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 136.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 136.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 134.32it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 132.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 130.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 129.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.28043
wandb: sub_train_loss 1.3158
wandb:       test_acc 0.23
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run fresh-sweep-376 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zfk8i8q7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225223-zfk8i8q7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dk9he30v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225238-dk9he30v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-377
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dk9he30v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 88.27it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 88.85it/s]  9%|‚ñâ         | 28/300 [00:00<00:03, 88.92it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:03, 87.09it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 86.46it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 87.10it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 90.06it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 94.34it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 103.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:01, 117.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 126.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 132.83it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 135.29it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 131.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 129.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 132.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 135.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 132.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 131.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 132.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 131.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 126.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 122.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.326
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.36549
wandb: sub_train_loss 1.33753
wandb:       test_acc 0.326
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run morning-sweep-377 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dk9he30v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225238-dk9he30v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iolhviya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225253-iolhviya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-378
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iolhviya
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 104.75it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 129.74it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 133.62it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 135.89it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 139.69it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 141.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 141.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 139.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 138.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 136.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 133.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 130.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 128.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 127.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 128.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 131.85it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 133.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 132.69it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 131.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 130.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 128.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.374
wandb: best_valid_acc 0.388
wandb:  sub_train_acc 0.40697
wandb: sub_train_loss 1.33637
wandb:       test_acc 0.374
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run apricot-sweep-378 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/iolhviya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225253-iolhviya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzt53xyd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225309-nzt53xyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-379
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzt53xyd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.98it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 128.48it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 130.70it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 130.97it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 133.14it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 130.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 130.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 130.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 131.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 130.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 130.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 129.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 126.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 122.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 119.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 119.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 119.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 120.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 121.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 121.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 121.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 122.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 125.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.392
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.39826
wandb: sub_train_loss 1.38025
wandb:       test_acc 0.394
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run faithful-sweep-379 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzt53xyd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225309-nzt53xyd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nsuskpvo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225324-nsuskpvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-380
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nsuskpvo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.41it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 129.75it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.69it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 129.70it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 130.82it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 132.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 134.54it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 135.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 135.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 136.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 137.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 136.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 133.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 132.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 131.22it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 132.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 131.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 132.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 135.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 133.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 132.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.169
wandb: best_valid_acc 0.16
wandb:  sub_train_acc 0.22723
wandb: sub_train_loss 1.39953
wandb:       test_acc 0.175
wandb:      valid_acc 0.16
wandb: 
wandb: üöÄ View run ethereal-sweep-380 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nsuskpvo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225324-nsuskpvo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 59xl4217 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225340-59xl4217
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-381
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59xl4217
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.97it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.41it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.11it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 139.69it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 141.97it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 142.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 142.39it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 143.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 142.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 140.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 141.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 142.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 143.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 142.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 142.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 142.33it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 142.27it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 141.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 141.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 141.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.537
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.52359
wandb: sub_train_loss 1.41339
wandb:       test_acc 0.537
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run silver-sweep-381 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59xl4217
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225340-59xl4217/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gz5z9wjh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225355-gz5z9wjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-382
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gz5z9wjh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.22it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.15it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 121.44it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 125.19it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 127.97it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 128.78it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 127.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 127.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 129.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 129.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 130.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 130.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 130.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 130.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 128.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 124.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 124.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 125.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 127.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 128.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 129.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 130.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.343
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.35137
wandb: sub_train_loss 1.38799
wandb:       test_acc 0.345
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run chocolate-sweep-382 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gz5z9wjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225355-gz5z9wjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jxfzobwa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225411-jxfzobwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-383
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jxfzobwa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 100.00it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 105.19it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 104.02it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 107.75it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 111.64it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 115.07it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 119.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 120.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 121.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 121.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 119.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 113.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 113.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 109.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 112.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 112.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 114.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 118.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 119.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 119.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 116.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 112.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 109.29it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 107.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.676
wandb: best_valid_acc 0.704
wandb:  sub_train_acc 0.66967
wandb: sub_train_loss 1.42235
wandb:       test_acc 0.672
wandb:      valid_acc 0.684
wandb: 
wandb: üöÄ View run rural-sweep-383 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jxfzobwa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225411-jxfzobwa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ehrg184f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225426-ehrg184f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ehrg184f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.93it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.41it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.09it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.84it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.59it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 132.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 131.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 125.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 120.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 120.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 121.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 121.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 124.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 127.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 131.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 133.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 132.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 134.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 136.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 135.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 136.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.613
wandb: best_valid_acc 0.626
wandb:  sub_train_acc 0.62369
wandb: sub_train_loss 1.45952
wandb:       test_acc 0.632
wandb:      valid_acc 0.62
wandb: 
wandb: üöÄ View run cosmic-sweep-384 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ehrg184f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225426-ehrg184f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 42wxh3xf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225441-42wxh3xf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-385
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/42wxh3xf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 217.00it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 218.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 212.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 213.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 216.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 217.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 220.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 220.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 218.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.272
wandb:  sub_train_acc 0.24977
wandb: sub_train_loss 1.06883
wandb:       test_acc 0.307
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run devoted-sweep-385 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/42wxh3xf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225441-42wxh3xf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kdyy7r42 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225457-kdyy7r42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-386
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kdyy7r42
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 230.75it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 228.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 220.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 220.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 223.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 223.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 223.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 225.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 224.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.2606
wandb: sub_train_loss 1.06728
wandb:       test_acc 0.314
wandb:      valid_acc 0.276
wandb: 
wandb: üöÄ View run happy-sweep-386 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kdyy7r42
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225457-kdyy7r42/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j1kvlpzk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225512-j1kvlpzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-387
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j1kvlpzk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.21it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 226.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 230.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 233.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 235.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 235.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 237.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 237.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.363
wandb: best_valid_acc 0.414
wandb:  sub_train_acc 0.3162
wandb: sub_train_loss 1.14928
wandb:       test_acc 0.363
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run brisk-sweep-387 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j1kvlpzk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225512-j1kvlpzk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hsnj23r1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225527-hsnj23r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-388
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hsnj23r1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.06it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 207.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 207.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 208.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 209.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 206.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 196.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 204.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 213.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 208.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.36
wandb: best_valid_acc 0.406
wandb:  sub_train_acc 0.3138
wandb: sub_train_loss 1.14946
wandb:       test_acc 0.364
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run devoted-sweep-388 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hsnj23r1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225527-hsnj23r1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uy2mivhj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225543-uy2mivhj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-389
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uy2mivhj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 179.93it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.96it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 187.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 201.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 208.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 205.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 204.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 204.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 205.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 202.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.30989
wandb: sub_train_loss 1.17168
wandb:       test_acc 0.341
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run honest-sweep-389 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uy2mivhj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225543-uy2mivhj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m6rgs1mb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225557-m6rgs1mb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-390
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m6rgs1mb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.45it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 206.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 208.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 210.86it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 203.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 211.80it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 216.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 216.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 221.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 214.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.331
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.29486
wandb: sub_train_loss 1.17167
wandb:       test_acc 0.31
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run good-sweep-390 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m6rgs1mb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225557-m6rgs1mb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7s9blicm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225619-7s9blicm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-391
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7s9blicm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.48it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 202.14it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 205.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 209.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 210.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 211.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 212.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 215.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 214.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 211.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.172
wandb:  sub_train_acc 0.17704
wandb: sub_train_loss 1.16502
wandb:       test_acc 0.174
wandb:      valid_acc 0.156
wandb: 
wandb: üöÄ View run likely-sweep-391 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7s9blicm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225619-7s9blicm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fm6u8qbt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225639-fm6u8qbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-392
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fm6u8qbt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 198.25it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 203.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 210.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 210.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 210.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 216.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 220.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 224.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 218.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.226
wandb:  sub_train_acc 0.17644
wandb: sub_train_loss 1.16417
wandb:       test_acc 0.172
wandb:      valid_acc 0.154
wandb: 
wandb: üöÄ View run sage-sweep-392 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fm6u8qbt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225639-fm6u8qbt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t6yo5zt6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225655-t6yo5zt6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-393
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t6yo5zt6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 199.28it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 202.27it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 203.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 200.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 189.56it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 185.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 183.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 190.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 193.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.547
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.45056
wandb: sub_train_loss 1.20839
wandb:       test_acc 0.502
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run dutiful-sweep-393 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t6yo5zt6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225655-t6yo5zt6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r4zofppd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225710-r4zofppd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-394
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r4zofppd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.98it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 208.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 212.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 213.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 211.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 207.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 209.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 203.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 199.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 205.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.539
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.44575
wandb: sub_train_loss 1.2074
wandb:       test_acc 0.489
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run peach-sweep-394 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r4zofppd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225710-r4zofppd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2wi4chyb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225725-2wi4chyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-395
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2wi4chyb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.77it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 172.85it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 177.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 186.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 191.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 195.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 197.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 196.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 196.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 196.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.338
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.27292
wandb: sub_train_loss 1.22313
wandb:       test_acc 0.338
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run genial-sweep-395 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2wi4chyb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225725-2wi4chyb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sd4bc35q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225741-sd4bc35q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-396
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sd4bc35q
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.45it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 191.38it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 193.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 195.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 194.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 189.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 191.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 192.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 195.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 195.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.308
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.26631
wandb: sub_train_loss 1.22396
wandb:       test_acc 0.308
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run upbeat-sweep-396 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sd4bc35q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225741-sd4bc35q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rg7dk1wo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225757-rg7dk1wo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-397
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rg7dk1wo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.34it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 191.31it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 190.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 192.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 194.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 195.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 196.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 196.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 195.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 195.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.52
wandb:  sub_train_acc 0.49354
wandb: sub_train_loss 1.22706
wandb:       test_acc 0.524
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run daily-sweep-397 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rg7dk1wo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225757-rg7dk1wo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: edkeoae2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225812-edkeoae2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-398
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/edkeoae2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 199.50it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 203.72it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 203.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 204.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 204.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 205.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 204.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 203.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 202.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.512
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.48632
wandb: sub_train_loss 1.22701
wandb:       test_acc 0.524
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run rich-sweep-398 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/edkeoae2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225812-edkeoae2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3e9s9mv7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225827-3e9s9mv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-399
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3e9s9mv7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.09it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 180.45it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 171.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 168.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 167.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 175.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 178.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 181.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 182.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 186.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.602
wandb:  sub_train_acc 0.581
wandb: sub_train_loss 1.24986
wandb:       test_acc 0.581
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run valiant-sweep-399 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3e9s9mv7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225827-3e9s9mv7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g996emsv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225838-g996emsv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-400
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g996emsv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.59it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 183.77it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 187.58it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 189.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 191.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 192.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 192.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 193.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 192.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 188.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.604
wandb:  sub_train_acc 0.57259
wandb: sub_train_loss 1.2495
wandb:       test_acc 0.576
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run pleasant-sweep-400 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g996emsv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225838-g996emsv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dlwr6gyx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225853-dlwr6gyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-401
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dlwr6gyx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.29it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.50it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 171.66it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 175.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 172.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 168.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 166.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 171.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 174.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 176.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.322
wandb: best_valid_acc 0.292
wandb:  sub_train_acc 0.24166
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.289
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run sparkling-sweep-401 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dlwr6gyx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225853-dlwr6gyx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2928rioz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225908-2928rioz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-402
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2928rioz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.13it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 171.08it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 168.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 167.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 165.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 160.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 155.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 160.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 164.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 166.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 161.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.313
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.22934
wandb: sub_train_loss 0.00019
wandb:       test_acc 0.315
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run comfy-sweep-402 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2928rioz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225908-2928rioz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jyfc3461 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225924-jyfc3461
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-403
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jyfc3461
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.73it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 170.34it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 178.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 182.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 186.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 189.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 185.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 187.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 188.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 188.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.347
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.30328
wandb: sub_train_loss 0.00011
wandb:       test_acc 0.372
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run misty-sweep-403 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jyfc3461
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225924-jyfc3461/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pccpsp8a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225939-pccpsp8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-404
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pccpsp8a
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.20it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 178.36it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 172.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 166.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 163.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 158.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 162.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 163.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 166.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 168.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 170.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.405
wandb: best_valid_acc 0.472
wandb:  sub_train_acc 0.33784
wandb: sub_train_loss 0.00012
wandb:       test_acc 0.406
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run stoic-sweep-404 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pccpsp8a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225939-pccpsp8a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xyq6nchu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225951-xyq6nchu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-405
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xyq6nchu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.69it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.77it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 179.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 184.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 187.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 187.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 187.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 188.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 190.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 193.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.443
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.40577
wandb: sub_train_loss 0.00043
wandb:       test_acc 0.448
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run comfy-sweep-405 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xyq6nchu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225951-xyq6nchu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qsus81w1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230005-qsus81w1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-406
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qsus81w1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.44it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 171.07it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 169.73it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 168.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 166.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 159.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 162.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 162.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 154.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 147.64it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 153.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.444
wandb: best_valid_acc 0.464
wandb:  sub_train_acc 0.4196
wandb: sub_train_loss 0.00031
wandb:       test_acc 0.442
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run twilight-sweep-406 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qsus81w1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230005-qsus81w1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u1ef84v4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230020-u1ef84v4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-407
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1ef84v4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.43it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.99it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 166.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 169.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 171.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 175.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 176.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 179.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 181.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.521
wandb: best_valid_acc 0.518
wandb:  sub_train_acc 0.38714
wandb: sub_train_loss 0.00039
wandb:       test_acc 0.429
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run quiet-sweep-407 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1ef84v4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230020-u1ef84v4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ddriopsx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230035-ddriopsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-408
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ddriopsx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 180.55it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 180.12it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 182.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 186.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 185.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 184.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 183.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 182.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 183.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 184.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.512
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.40487
wandb: sub_train_loss 0.00015
wandb:       test_acc 0.481
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run ethereal-sweep-408 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ddriopsx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230035-ddriopsx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hquch4eu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230051-hquch4eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-409
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hquch4eu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.62it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 167.74it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 171.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 173.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 175.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 176.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 180.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 182.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 182.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 184.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.56
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.43853
wandb: sub_train_loss 0.00043
wandb:       test_acc 0.558
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run electric-sweep-409 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hquch4eu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230051-hquch4eu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9c9psg0r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230106-9c9psg0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-410
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9c9psg0r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.51it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 175.24it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 178.72it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 181.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 183.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 185.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 183.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 182.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 181.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 180.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.42982
wandb: sub_train_loss 0.00034
wandb:       test_acc 0.536
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run noble-sweep-410 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9c9psg0r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230106-9c9psg0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 934ju590 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230122-934ju590
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-411
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/934ju590
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.10it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.51it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 160.57it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 164.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 166.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 167.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 168.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 168.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 168.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 168.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 164.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.598
wandb:  sub_train_acc 0.48392
wandb: sub_train_loss 0.00038
wandb:       test_acc 0.524
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run cool-sweep-411 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/934ju590
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230122-934ju590/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: quzwv8gn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230138-quzwv8gn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-412
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/quzwv8gn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.24it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.27it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 161.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 164.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 164.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 165.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 166.21it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 163.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 166.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 169.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 171.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.582
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.43613
wandb: sub_train_loss 0.00037
wandb:       test_acc 0.518
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run good-sweep-412 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/quzwv8gn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230138-quzwv8gn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rms1eq5m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230153-rms1eq5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-413
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rms1eq5m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.31it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.72it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 161.74it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 165.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 162.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 159.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 160.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 162.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 162.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 164.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 164.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.605
wandb: best_valid_acc 0.622
wandb:  sub_train_acc 0.56658
wandb: sub_train_loss 0.00013
wandb:       test_acc 0.61
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run lyric-sweep-413 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rms1eq5m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230153-rms1eq5m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gfttyzkv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230204-gfttyzkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-414
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gfttyzkv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.82it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 139.19it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 133.23it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 133.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 140.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 139.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 138.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 142.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 144.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 145.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 146.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 148.88it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 155.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.626
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.54554
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.613
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run avid-sweep-414 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gfttyzkv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230204-gfttyzkv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ksl0lyg1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230218-ksl0lyg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-415
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ksl0lyg1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.44it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.46it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 151.78it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 149.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 148.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 148.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 148.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 147.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 148.13it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 150.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 151.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.655
wandb: best_valid_acc 0.684
wandb:  sub_train_acc 0.66697
wandb: sub_train_loss 7e-05
wandb:       test_acc 0.666
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run efficient-sweep-415 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ksl0lyg1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230218-ksl0lyg1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 61nykqom with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230234-61nykqom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-416
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/61nykqom
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.92it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.35it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.96it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 150.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 152.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 152.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 152.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 153.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 152.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 157.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 161.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 163.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 155.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.65404
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.652
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run dashing-sweep-416 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/61nykqom
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230234-61nykqom/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s5v3jdb6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230251-s5v3jdb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-417
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5v3jdb6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.95it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 134.42it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 126.74it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 124.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 129.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 135.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 144.46it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 152.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 157.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 162.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 143.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 141.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.344
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.24466
wandb: sub_train_loss 0.0
wandb:       test_acc 0.341
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run colorful-sweep-417 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5v3jdb6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230251-s5v3jdb6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zfbxap7w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230306-zfbxap7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-418
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zfbxap7w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.61it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.90it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 134.02it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 136.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 137.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 140.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 145.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 148.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 150.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 152.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 154.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 154.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 154.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.342
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.17884
wandb: sub_train_loss 0.0
wandb:       test_acc 0.203
wandb:      valid_acc 0.188
wandb: 
wandb: üöÄ View run dark-sweep-418 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zfbxap7w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230306-zfbxap7w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ew8njds6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230321-ew8njds6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-419
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ew8njds6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.88it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.02it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 159.94it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 157.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 152.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 150.43it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 145.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 144.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 142.64it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 146.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 149.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 154.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.37
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.27112
wandb: sub_train_loss 0.0
wandb:       test_acc 0.349
wandb:      valid_acc 0.358
wandb: 
wandb: üöÄ View run autumn-sweep-419 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ew8njds6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230321-ew8njds6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bo4kyy05 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230338-bo4kyy05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-420
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bo4kyy05
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.05it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.04it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 115.47it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 113.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 112.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 115.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 115.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 116.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 122.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 128.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 131.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 131.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 135.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 137.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.341
wandb: best_valid_acc 0.384
wandb:  sub_train_acc 0.24707
wandb: sub_train_loss 0.0
wandb:       test_acc 0.187
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run upbeat-sweep-420 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bo4kyy05
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230338-bo4kyy05/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zjnjlxbl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230353-zjnjlxbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-421
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zjnjlxbl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.03it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.07it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 148.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 141.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 140.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 139.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 135.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 133.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 123.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 121.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 120.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 122.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.392
wandb: best_valid_acc 0.398
wandb:  sub_train_acc 0.2095
wandb: sub_train_loss 0.0
wandb:       test_acc 0.25
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run lyric-sweep-421 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zjnjlxbl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230353-zjnjlxbl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l25ojdv0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230409-l25ojdv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-422
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l25ojdv0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.84it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 125.45it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 123.66it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 131.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 121.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 134.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 143.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 147.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 153.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 157.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 143.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 141.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.377
wandb: best_valid_acc 0.352
wandb:  sub_train_acc 0.27292
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.158
wandb:      valid_acc 0.156
wandb: 
wandb: üöÄ View run chocolate-sweep-422 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l25ojdv0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230409-l25ojdv0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kkb3wre9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230424-kkb3wre9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-423
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kkb3wre9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.50it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 158.94it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 154.19it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 158.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 162.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 165.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 164.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 166.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 167.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.43
wandb: best_valid_acc 0.45
wandb:  sub_train_acc 0.34476
wandb: sub_train_loss 0.0
wandb:       test_acc 0.392
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run stilted-sweep-423 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kkb3wre9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230424-kkb3wre9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1kihw3c2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230435-1kihw3c2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-424
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1kihw3c2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.67it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.91it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 129.74it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 128.91it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 131.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 134.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 135.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 144.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 149.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 153.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 154.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 151.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 151.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.448
wandb: best_valid_acc 0.452
wandb:  sub_train_acc 0.32041
wandb: sub_train_loss 0.0
wandb:       test_acc 0.302
wandb:      valid_acc 0.322
wandb: 
wandb: üöÄ View run wobbly-sweep-424 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1kihw3c2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230435-1kihw3c2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 84z55f9b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230450-84z55f9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-425
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/84z55f9b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 159.93it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 137.57it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 133.09it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 137.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 136.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 138.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 142.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 149.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 153.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 153.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 148.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 143.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.014 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.591
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.25368
wandb: sub_train_loss 0.0
wandb:       test_acc 0.29
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run exalted-sweep-425 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/84z55f9b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230450-84z55f9b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hsh8yieg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230505-hsh8yieg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-426
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hsh8yieg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.75it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.06it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 157.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 158.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 147.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 138.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 131.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 121.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 114.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 118.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.6
wandb: best_valid_acc 0.62
wandb:  sub_train_acc 0.42471
wandb: sub_train_loss 0.0
wandb:       test_acc 0.517
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run sweet-sweep-426 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hsh8yieg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230505-hsh8yieg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: osb82hrb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230522-osb82hrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-427
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/osb82hrb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.65it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 147.89it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 110.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 98.42it/s]  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 100.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 105.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 119.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 133.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 144.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 151.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 155.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.2645
wandb: sub_train_loss 0.00995
wandb:       test_acc 0.284
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run floral-sweep-427 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/osb82hrb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230522-osb82hrb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eu2s71o9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230537-eu2s71o9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-428
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eu2s71o9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.91it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 158.20it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 160.51it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 157.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 160.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 160.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 160.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 158.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 160.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 151.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 152.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.616
wandb: best_valid_acc 0.638
wandb:  sub_train_acc 0.49384
wandb: sub_train_loss 0.66001
wandb:       test_acc 0.441
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run bright-sweep-428 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eu2s71o9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230537-eu2s71o9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5wumfus3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230552-5wumfus3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-429
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5wumfus3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.72it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.15it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.11it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 148.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 148.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 138.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 142.57it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 144.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 147.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 149.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 148.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 147.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.659
wandb: best_valid_acc 0.674
wandb:  sub_train_acc 0.48813
wandb: sub_train_loss 0.55168
wandb:       test_acc 0.523
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run warm-sweep-429 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5wumfus3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230552-5wumfus3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5elnbidx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230607-5elnbidx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-430
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5elnbidx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.20it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.81it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 137.92it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 137.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 139.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 138.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 138.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 139.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 140.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 142.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 141.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 141.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 142.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.604
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.52089
wandb: sub_train_loss 0.0
wandb:       test_acc 0.566
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run swift-sweep-430 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5elnbidx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230607-5elnbidx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fu1vf2zn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230623-fu1vf2zn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-431
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fu1vf2zn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.73it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 130.04it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 130.08it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 129.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 132.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 136.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 136.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 134.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 133.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 133.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 135.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 135.09it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 132.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 131.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.666
wandb: best_valid_acc 0.678
wandb:  sub_train_acc 0.62008
wandb: sub_train_loss 0.00048
wandb:       test_acc 0.612
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run driven-sweep-431 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fu1vf2zn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230623-fu1vf2zn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: euapwcr3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230638-euapwcr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-432
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/euapwcr3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.49it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.11it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 143.90it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 144.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 145.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 143.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 143.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 146.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 148.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 149.21it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 150.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 151.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.621
wandb: best_valid_acc 0.648
wandb:  sub_train_acc 0.36099
wandb: sub_train_loss 0.25201
wandb:       test_acc 0.327
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run desert-sweep-432 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/euapwcr3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230638-euapwcr3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0uwfqfxv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230654-0uwfqfxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-433
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0uwfqfxv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 207.94it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 209.94it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 212.69it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 215.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 217.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 214.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 213.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 212.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:00<00:00, 213.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 212.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 214.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 217.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 219.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.24917
wandb: sub_train_loss 0.79503
wandb:       test_acc 0.312
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run warm-sweep-433 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0uwfqfxv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230654-0uwfqfxv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q40q0mgr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230709-q40q0mgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-434
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q40q0mgr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 226.65it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 230.79it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 233.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 233.99it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 235.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 232.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 228.60it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 228.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 229.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 230.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 231.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 232.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 231.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.26691
wandb: sub_train_loss 0.79451
wandb:       test_acc 0.315
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run gentle-sweep-434 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q40q0mgr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230709-q40q0mgr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dqc2fb81 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230726-dqc2fb81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-435
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dqc2fb81
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 222.96it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 226.67it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 229.43it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 231.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 231.25it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 232.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 232.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 231.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 228.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 227.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 227.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 224.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 228.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.369
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.28855
wandb: sub_train_loss 0.87724
wandb:       test_acc 0.365
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run splendid-sweep-435 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dqc2fb81
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230726-dqc2fb81/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t9bgjcuh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230742-t9bgjcuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-436
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t9bgjcuh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.63it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 231.39it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 226.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 228.62it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 229.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 228.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 226.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 223.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 219.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 222.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 223.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 223.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.364
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.28584
wandb: sub_train_loss 0.87707
wandb:       test_acc 0.361
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run stellar-sweep-436 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t9bgjcuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230742-t9bgjcuh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k56dmqt3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230757-k56dmqt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-437
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k56dmqt3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 222.29it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 224.08it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 227.43it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 229.52it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 228.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 225.91it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 223.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 222.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 211.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 212.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 211.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 209.61it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 204.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.4
wandb: best_valid_acc 0.378
wandb:  sub_train_acc 0.35798
wandb: sub_train_loss 0.90143
wandb:       test_acc 0.4
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run lunar-sweep-437 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k56dmqt3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230757-k56dmqt3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6wml7rc8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230812-6wml7rc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-438
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6wml7rc8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.44it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 209.86it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 208.54it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 214.92it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 215.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 212.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 210.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 208.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 206.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 205.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 204.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 202.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 203.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 207.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.348
wandb: best_valid_acc 0.386
wandb:  sub_train_acc 0.36309
wandb: sub_train_loss 0.90137
wandb:       test_acc 0.41
wandb:      valid_acc 0.378
wandb: 
wandb: üöÄ View run major-sweep-438 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6wml7rc8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230812-6wml7rc8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9qvrlw1x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230828-9qvrlw1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-439
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9qvrlw1x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 215.12it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 212.19it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 214.19it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 212.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 213.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 209.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 208.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 207.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 205.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 207.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 212.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 214.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 209.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 209.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.272
wandb:  sub_train_acc 0.23925
wandb: sub_train_loss 0.88897
wandb:       test_acc 0.276
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run lemon-sweep-439 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9qvrlw1x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230828-9qvrlw1x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s82zrtby with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230843-s82zrtby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s82zrtby
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 196.59it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.39it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 196.38it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 201.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 202.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 200.50it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 203.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 204.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 202.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 202.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 202.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 203.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 204.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 204.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 202.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.31
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.26601
wandb: sub_train_loss 0.88862
wandb:       test_acc 0.31
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run valiant-sweep-440 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s82zrtby
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230843-s82zrtby/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rkeobzpk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230904-rkeobzpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-441
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rkeobzpk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 207.36it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 208.75it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 207.31it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 208.59it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 206.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 200.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 201.36it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 205.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 207.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 207.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 206.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 206.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 207.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 209.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 206.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.581
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.35077
wandb: sub_train_loss 0.94282
wandb:       test_acc 0.402
wandb:      valid_acc 0.378
wandb: 
wandb: üöÄ View run decent-sweep-441 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rkeobzpk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230904-rkeobzpk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gdjctyt8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230920-gdjctyt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-442
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gdjctyt8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 217.48it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.37it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 215.46it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 215.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 214.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 213.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 212.94it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 213.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:00<00:00, 214.37it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 205.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 202.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 206.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 211.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 212.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.484
wandb: best_valid_acc 0.512
wandb:  sub_train_acc 0.41028
wandb: sub_train_loss 0.94192
wandb:       test_acc 0.454
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run dutiful-sweep-442 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gdjctyt8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230920-gdjctyt8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qni5mcnj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230935-qni5mcnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-443
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qni5mcnj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.38it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 182.56it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 184.12it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 189.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 190.21it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 192.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 192.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 195.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 196.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 199.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 201.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 200.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 201.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 202.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 196.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.547
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.51067
wandb: sub_train_loss 0.96495
wandb:       test_acc 0.548
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run snowy-sweep-443 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qni5mcnj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230935-qni5mcnj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0awkysk9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230950-0awkysk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-444
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0awkysk9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 183.84it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 185.02it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 192.53it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 195.41it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 196.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 199.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 201.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 202.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 197.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 197.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 194.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 196.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 197.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 193.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 196.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.528
wandb:  sub_train_acc 0.47099
wandb: sub_train_loss 0.96455
wandb:       test_acc 0.503
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run resilient-sweep-444 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0awkysk9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230950-0awkysk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o23hljr8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231005-o23hljr8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-445
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o23hljr8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.74it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 196.05it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 201.27it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 203.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 204.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 204.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 201.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 201.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 203.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 203.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 202.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 203.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 204.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 205.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 203.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.556
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.51127
wandb: sub_train_loss 0.96669
wandb:       test_acc 0.53
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run pleasant-sweep-445 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o23hljr8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231005-o23hljr8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l6j9ip8s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231020-l6j9ip8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-446
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6j9ip8s
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.53it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.13it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 173.20it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 175.37it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 173.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 170.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 172.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 176.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 174.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 174.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 175.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 175.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 173.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 175.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 176.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 179.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.49775
wandb: sub_train_loss 0.9668
wandb:       test_acc 0.53
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run floral-sweep-446 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6j9ip8s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231020-l6j9ip8s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 38byj5j3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231037-38byj5j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-447
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/38byj5j3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.94it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 186.02it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 189.79it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 192.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 187.74it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 179.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 178.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 177.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 177.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 180.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 186.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 185.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 180.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 177.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 176.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.611
wandb: best_valid_acc 0.626
wandb:  sub_train_acc 0.55996
wandb: sub_train_loss 0.99776
wandb:       test_acc 0.534
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run rare-sweep-447 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/38byj5j3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231037-38byj5j3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o2ipb21p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231053-o2ipb21p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-448
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o2ipb21p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.68it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.85it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 174.64it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 174.08it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 174.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 172.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 169.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 174.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 178.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 180.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 184.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 188.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 191.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 193.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 195.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.653
wandb: best_valid_acc 0.64
wandb:  sub_train_acc 0.59243
wandb: sub_train_loss 0.9973
wandb:       test_acc 0.577
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run deep-sweep-448 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o2ipb21p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231053-o2ipb21p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sqrmrqb7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231108-sqrmrqb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-449
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqrmrqb7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.80it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.60it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.20it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 167.86it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 165.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 166.20it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 159.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 163.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 170.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 175.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 178.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 181.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 184.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 187.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 188.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 189.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.289
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.19868
wandb: sub_train_loss 0.0
wandb:       test_acc 0.292
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run gentle-sweep-449 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sqrmrqb7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231108-sqrmrqb7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cm1w54vc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231123-cm1w54vc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-450
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cm1w54vc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.41it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.70it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 162.84it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 164.27it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 165.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 166.97it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 177.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 184.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 186.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 190.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 191.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 191.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 188.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 187.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 188.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 188.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.238
wandb:  sub_train_acc 0.19627
wandb: sub_train_loss 0.0
wandb:       test_acc 0.268
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run fresh-sweep-450 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cm1w54vc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231123-cm1w54vc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8o310cxf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231135-8o310cxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-451
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8o310cxf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.70it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.32it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 169.85it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 167.13it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 162.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 164.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 167.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 168.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 167.77it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 167.22it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 170.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 170.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 171.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 172.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 174.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 176.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.383
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.38623
wandb: sub_train_loss 0.0
wandb:       test_acc 0.389
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run stellar-sweep-451 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8o310cxf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231135-8o310cxf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d29ph5lz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231149-d29ph5lz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-452
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d29ph5lz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.40it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 143.04it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 159.68it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 166.60it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 170.46it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 166.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 168.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 165.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 160.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 157.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 156.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 159.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 151.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 148.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 151.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 161.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 168.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 161.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.37
wandb:  sub_train_acc 0.33303
wandb: sub_train_loss 0.0
wandb:       test_acc 0.302
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run rose-sweep-452 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d29ph5lz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231149-d29ph5lz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8qg1a69r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231205-8qg1a69r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-453
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8qg1a69r
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.41it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 154.72it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.17it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 158.59it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 148.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 150.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 154.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 157.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 164.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 171.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 169.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 167.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 172.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 175.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 175.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 176.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 169.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.385
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.39826
wandb: sub_train_loss 0.0
wandb:       test_acc 0.374
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run revived-sweep-453 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8qg1a69r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231205-8qg1a69r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 00m6whil with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231221-00m6whil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-454
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/00m6whil
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.27it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.37it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.92it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 162.65it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 163.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 157.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 162.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 162.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 165.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 169.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 172.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 174.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 172.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 176.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 180.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 183.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.423
wandb: best_valid_acc 0.436
wandb:  sub_train_acc 0.40096
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run honest-sweep-454 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/00m6whil
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231221-00m6whil/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nqq8dcr4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231235-nqq8dcr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-455
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nqq8dcr4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.63it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 143.68it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 132.86it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 134.12it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 124.47it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 133.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 143.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 149.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 154.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 156.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 164.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 168.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 169.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 169.57it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 169.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 169.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 168.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.414
wandb: best_valid_acc 0.442
wandb:  sub_train_acc 0.37932
wandb: sub_train_loss 0.0
wandb:       test_acc 0.318
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run lyric-sweep-455 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nqq8dcr4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231235-nqq8dcr4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ewz3a1np with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231251-ewz3a1np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-456
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ewz3a1np
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.66it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 123.16it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 124.67it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 124.07it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 123.47it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 130.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 140.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 141.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 142.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 142.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 149.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 155.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 157.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 160.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 161.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 161.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 160.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 167.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.53
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.41689
wandb: sub_train_loss 0.0
wandb:       test_acc 0.485
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run worldly-sweep-456 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ewz3a1np
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231251-ewz3a1np/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9mpqxmjs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231309-9mpqxmjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-457
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9mpqxmjs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.29it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.51it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.59it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 175.11it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 176.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 178.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 180.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 179.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 176.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 176.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 177.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 175.28it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 172.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 172.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 169.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 163.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.568
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.45386
wandb: sub_train_loss 0.0
wandb:       test_acc 0.552
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run legendary-sweep-457 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9mpqxmjs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231309-9mpqxmjs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 56vfw8e9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231322-56vfw8e9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-458
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/56vfw8e9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.50it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.99it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 163.81it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 163.61it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 150.90it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 143.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 141.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 142.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:01, 141.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 140.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 139.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 141.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 144.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 149.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 155.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 163.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 167.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 167.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.516
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.41749
wandb: sub_train_loss 0.0
wandb:       test_acc 0.517
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run warm-sweep-458 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/56vfw8e9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231322-56vfw8e9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ge6fssc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231340-1ge6fssc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-459
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ge6fssc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.32it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 156.60it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 157.47it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 159.46it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 160.37it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 161.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 161.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 161.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 161.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 163.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 164.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 165.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 166.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 167.09it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 166.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 166.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 164.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.44995
wandb: sub_train_loss 0.0
wandb:       test_acc 0.575
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run splendid-sweep-459 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ge6fssc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231340-1ge6fssc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 07gh5ouv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231357-07gh5ouv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-460
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/07gh5ouv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.82it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 138.79it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 139.29it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 143.30it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 155.91it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 163.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 170.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 173.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 176.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 178.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 180.76it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 181.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 181.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 180.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 179.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 179.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.50406
wandb: sub_train_loss 0.0
wandb:       test_acc 0.563
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run fine-sweep-460 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/07gh5ouv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231357-07gh5ouv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6f6rcr83 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231413-6f6rcr83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-461
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6f6rcr83
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.81it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 160.06it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 155.54it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 139.78it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 128.53it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 127.07it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 126.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 129.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 133.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 132.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 131.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 129.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 134.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 140.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 143.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 146.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 151.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 156.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 160.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.605
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.55035
wandb: sub_train_loss 0.0
wandb:       test_acc 0.598
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run zany-sweep-461 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6f6rcr83
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231413-6f6rcr83/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rctrny2l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231428-rctrny2l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-462
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rctrny2l
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.99it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.98it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 137.17it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 136.87it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 137.86it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 134.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 137.33it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 140.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 134.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 133.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 136.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 138.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 142.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 138.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 134.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 127.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 127.33it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 125.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 127.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 129.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.632
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.56057
wandb: sub_train_loss 0.0
wandb:       test_acc 0.616
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run cosmic-sweep-462 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rctrny2l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231428-rctrny2l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uosvst78 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231444-uosvst78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-463
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uosvst78
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.17it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.65it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 141.35it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 141.51it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 144.92it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 148.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 146.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 150.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 153.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 155.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 157.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 155.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 157.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 158.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 160.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 162.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 161.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 161.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.67899
wandb: sub_train_loss 0.0
wandb:       test_acc 0.678
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run rich-sweep-463 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uosvst78
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231444-uosvst78/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ovkxep2u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231459-ovkxep2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-464
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ovkxep2u
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.86it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 151.77it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 154.97it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.84it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 158.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 159.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 161.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 164.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 166.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 168.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 169.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 170.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 170.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 170.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 169.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 164.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 160.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.64743
wandb: sub_train_loss 0.0
wandb:       test_acc 0.649
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run confused-sweep-464 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ovkxep2u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231459-ovkxep2u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eapfxr14 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231514-eapfxr14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-465
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eapfxr14
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.19it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.86it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 146.37it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 150.76it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 153.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 154.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 156.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 150.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 149.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 149.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 144.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 147.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 150.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 152.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 157.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 158.93it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 160.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.33
wandb: best_valid_acc 0.288
wandb:  sub_train_acc 0.15509
wandb: sub_train_loss 0.0
wandb:       test_acc 0.163
wandb:      valid_acc 0.144
wandb: 
wandb: üöÄ View run decent-sweep-465 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/eapfxr14
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231514-eapfxr14/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qs5ly5ao with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231530-qs5ly5ao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-466
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qs5ly5ao
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.55it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.23it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.12it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 147.70it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 154.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 158.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 154.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 148.57it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 147.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 139.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 134.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 130.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 128.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 129.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 131.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 131.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 137.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 139.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 137.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.332
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.18515
wandb: sub_train_loss 0.0
wandb:       test_acc 0.084
wandb:      valid_acc 0.098
wandb: 
wandb: üöÄ View run fragrant-sweep-466 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qs5ly5ao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231530-qs5ly5ao/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kh5lchsq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231545-kh5lchsq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-467
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kh5lchsq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.89it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 127.11it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 126.52it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 130.67it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 132.05it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 134.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 141.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 145.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 149.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 146.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 144.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 142.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 143.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 146.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 148.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 150.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 157.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 160.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 163.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.397
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.20349
wandb: sub_train_loss 0.0
wandb:       test_acc 0.21
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run copper-sweep-467 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kh5lchsq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231545-kh5lchsq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a70jbzwc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231600-a70jbzwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-468
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a70jbzwc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.34it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 163.70it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 167.05it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 168.05it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 166.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 165.18it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 163.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 163.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 162.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 163.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 163.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 163.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 164.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 165.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 164.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 164.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 165.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.453
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.22062
wandb: sub_train_loss 0.0
wandb:       test_acc 0.196
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run treasured-sweep-468 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/a70jbzwc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231600-a70jbzwc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wquhdnks with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231616-wquhdnks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-469
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wquhdnks
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.35it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.88it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.14it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 146.35it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 150.22it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 153.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 154.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 154.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 155.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 157.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 156.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 158.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 159.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 160.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 161.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 162.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 162.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 162.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.366
wandb: best_valid_acc 0.368
wandb:  sub_train_acc 0.34596
wandb: sub_train_loss 0.0
wandb:       test_acc 0.284
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run rose-sweep-469 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wquhdnks
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231616-wquhdnks/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qkoe1rrx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231636-qkoe1rrx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-470
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qkoe1rrx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.96it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 142.44it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 141.50it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 142.92it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 144.42it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 145.15it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 145.17it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 142.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 141.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 142.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 141.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 142.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 142.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 141.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 143.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 144.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 145.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 147.37it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 149.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.383
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.34656
wandb: sub_train_loss 0.0
wandb:       test_acc 0.204
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run comic-sweep-470 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qkoe1rrx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231636-qkoe1rrx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rq999se4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231652-rq999se4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-471
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rq999se4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.50it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 142.16it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 139.62it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 137.79it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 138.75it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 142.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 150.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 153.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 157.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 159.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 159.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 162.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 163.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 164.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 163.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 163.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 164.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 164.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.418
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.27172
wandb: sub_train_loss 0.0
wandb:       test_acc 0.351
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run rural-sweep-471 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rq999se4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231652-rq999se4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l6a9b31v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231707-l6a9b31v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-472
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6a9b31v
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.00it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.45it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.70it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 156.11it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 159.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 161.37it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 162.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 164.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 164.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 165.87it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 165.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 164.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 162.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 160.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 158.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 158.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 159.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.526
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.35948
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run peachy-sweep-472 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l6a9b31v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231707-l6a9b31v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y145klm2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231723-y145klm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-473
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y145klm2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.99it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.52it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 163.16it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 165.19it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 168.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 167.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 168.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 170.29it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 170.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 170.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 170.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 168.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 168.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 167.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 166.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 165.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 165.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.29937
wandb: sub_train_loss 0.00422
wandb:       test_acc 0.25
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run decent-sweep-473 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y145klm2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231723-y145klm2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ucs6kv16 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231738-ucs6kv16
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-474
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ucs6kv16
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.32it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.36it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.81it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 147.11it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 146.20it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 149.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 152.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 152.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 148.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 147.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 147.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 148.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 150.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 154.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 158.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 160.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 163.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 165.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.522
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.2654
wandb: sub_train_loss 0.02689
wandb:       test_acc 0.28
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run amber-sweep-474 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ucs6kv16
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231738-ucs6kv16/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6h7kiu4j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231753-6h7kiu4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-475
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6h7kiu4j
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.67it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.11it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.53it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 155.80it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 156.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 157.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 159.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 159.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 159.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 156.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 149.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 142.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 141.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 143.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 144.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 147.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 149.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 150.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.566
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.31169
wandb: sub_train_loss 0.09663
wandb:       test_acc 0.311
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run denim-sweep-475 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6h7kiu4j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231753-6h7kiu4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8ga8vbut with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231809-8ga8vbut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-476
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8ga8vbut
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.31it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.45it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.37it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 145.52it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 144.51it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 147.22it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 152.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 156.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 157.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 159.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 157.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 151.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 151.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 151.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 151.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 150.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 147.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.574
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.42531
wandb: sub_train_loss 0.0
wandb:       test_acc 0.438
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run fresh-sweep-476 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8ga8vbut
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231809-8ga8vbut/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bgv2zdji with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231824-bgv2zdji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-477
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bgv2zdji
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.18it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.79it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 149.70it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 149.38it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 153.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 157.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 159.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 161.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 162.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 163.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 163.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 164.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 164.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 164.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 164.40it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 163.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 162.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.617
wandb: best_valid_acc 0.612
wandb:  sub_train_acc 0.25068
wandb: sub_train_loss 0.03555
wandb:       test_acc 0.272
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run sweet-sweep-477 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bgv2zdji
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231824-bgv2zdji/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2v1qiuwo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231839-2v1qiuwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-478
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2v1qiuwo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.47it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.24it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.72it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 148.55it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 148.96it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.68it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 147.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 147.01it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 147.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:00, 149.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 150.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 151.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 149.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 143.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 139.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 137.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 135.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 135.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 135.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 133.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.671
wandb: best_valid_acc 0.67
wandb:  sub_train_acc 0.51097
wandb: sub_train_loss 4e-05
wandb:       test_acc 0.525
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run blooming-sweep-478 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2v1qiuwo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231839-2v1qiuwo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 07m0zvk6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231855-07m0zvk6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-479
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/07m0zvk6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.72it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.61it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.27it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.57it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.02it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 135.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 139.10it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 144.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 142.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 122.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 119.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 118.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 117.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 116.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 118.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 119.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 118.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 121.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 130.43it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 137.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 142.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.635
wandb: best_valid_acc 0.67
wandb:  sub_train_acc 0.51067
wandb: sub_train_loss 0.08658
wandb:       test_acc 0.506
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run effortless-sweep-479 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/07m0zvk6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231855-07m0zvk6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dm9eerbt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231910-dm9eerbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-480
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dm9eerbt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.96it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.28it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.51it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.19it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 129.80it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 131.73it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 133.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 135.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 136.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 138.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 143.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 147.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 149.13it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 150.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 152.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 153.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 154.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 150.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 149.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.663
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.37571
wandb: sub_train_loss 0.1548
wandb:       test_acc 0.344
wandb:      valid_acc 0.36
wandb: 
wandb: üöÄ View run dry-sweep-480 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dm9eerbt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231910-dm9eerbt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z2n72rsw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231926-z2n72rsw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-481
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z2n72rsw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 211.02it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 252.23it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 275.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 286.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 285.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 295.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 285.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.2633
wandb: sub_train_loss 1.25326
wandb:       test_acc 0.311
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run daily-sweep-481 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z2n72rsw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231926-z2n72rsw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fvm7tzcn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231942-fvm7tzcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-482
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvm7tzcn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 285.48it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 287.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 283.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 281.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 286.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 287.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 286.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.3
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.2624
wandb: sub_train_loss 1.25299
wandb:       test_acc 0.309
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run dry-sweep-482 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fvm7tzcn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231942-fvm7tzcn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vxilrkwe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231956-vxilrkwe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-483
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vxilrkwe
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 279.57it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 279.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 281.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 283.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 271.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 268.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 269.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 273.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.358
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.32882
wandb: sub_train_loss 1.37662
wandb:       test_acc 0.336
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run generous-sweep-483 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vxilrkwe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231956-vxilrkwe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hvgqypsq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232012-hvgqypsq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-484
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hvgqypsq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 266.52it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 260.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 253.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 247.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 242.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 239.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 241.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 246.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.379
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.32702
wandb: sub_train_loss 1.37673
wandb:       test_acc 0.335
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run floral-sweep-484 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hvgqypsq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232012-hvgqypsq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mggfgkng with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232028-mggfgkng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-485
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mggfgkng
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.63it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 261.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 282.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 284.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 286.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 279.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 273.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 276.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.402
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.28795
wandb: sub_train_loss 1.44617
wandb:       test_acc 0.316
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run dutiful-sweep-485 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mggfgkng
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232028-mggfgkng/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fli2ykf0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232042-fli2ykf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-486
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fli2ykf0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 288.50it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 299.78it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 303.27it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 304.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 299.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 295.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 296.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.405
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.28915
wandb: sub_train_loss 1.44578
wandb:       test_acc 0.319
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run exalted-sweep-486 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fli2ykf0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232042-fli2ykf0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l5hfzefv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232058-l5hfzefv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-487
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l5hfzefv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 254.53it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 245.44it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 246.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 245.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 243.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 246.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 250.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 249.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.272
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.1605
wandb: sub_train_loss 1.48251
wandb:       test_acc 0.161
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run vivid-sweep-487 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l5hfzefv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232058-l5hfzefv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1cl219ab with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232114-1cl219ab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-488
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1cl219ab
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 215.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 236.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 249.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 255.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 227.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 193.76it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 186.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 190.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 206.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.252
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.1602
wandb: sub_train_loss 1.48258
wandb:       test_acc 0.161
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run treasured-sweep-488 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1cl219ab
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232114-1cl219ab/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ivyqfodt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232128-ivyqfodt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-489
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ivyqfodt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 303.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 308.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 284.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 276.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 275.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 276.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 279.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.59
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.46318
wandb: sub_train_loss 1.50384
wandb:       test_acc 0.475
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run dashing-sweep-489 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ivyqfodt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232128-ivyqfodt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jzg6r71p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232152-jzg6r71p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-490
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jzg6r71p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 249.33it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 245.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 242.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 237.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 239.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 240.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 242.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 243.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.59
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.45867
wandb: sub_train_loss 1.504
wandb:       test_acc 0.478
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run fast-sweep-490 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jzg6r71p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232152-jzg6r71p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w4vvttry with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232205-w4vvttry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-491
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w4vvttry
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 247.65it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 255.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 263.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 263.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 256.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 258.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 262.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.179
wandb: best_valid_acc 0.168
wandb:  sub_train_acc 0.15479
wandb: sub_train_loss 1.52671
wandb:       test_acc 0.12
wandb:      valid_acc 0.1
wandb: 
wandb: üöÄ View run dauntless-sweep-491 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w4vvttry
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232205-w4vvttry/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9ha25mwv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232220-9ha25mwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-492
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9ha25mwv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 239.21it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 246.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 251.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 252.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 263.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 262.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 268.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 262.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.216
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.15209
wandb: sub_train_loss 1.52669
wandb:       test_acc 0.121
wandb:      valid_acc 0.096
wandb: 
wandb: üöÄ View run astral-sweep-492 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9ha25mwv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232220-9ha25mwv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ydt08xx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232239-1ydt08xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-493
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ydt08xx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 243.71it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 235.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 237.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 234.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 238.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 242.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 238.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 238.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 238.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.452
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.45747
wandb: sub_train_loss 1.54214
wandb:       test_acc 0.452
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run woven-sweep-493 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ydt08xx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232239-1ydt08xx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bx9how1c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232256-bx9how1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-494
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bx9how1c
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.82it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 235.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 256.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 267.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 275.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 284.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 283.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 272.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.452
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.44815
wandb: sub_train_loss 1.54151
wandb:       test_acc 0.452
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run trim-sweep-494 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bx9how1c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232256-bx9how1c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dzo4wllw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232317-dzo4wllw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-495
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dzo4wllw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 249.18it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 286.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 297.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 304.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 308.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 307.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 302.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.552
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.54013
wandb: sub_train_loss 1.55857
wandb:       test_acc 0.531
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run rich-sweep-495 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dzo4wllw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232317-dzo4wllw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gi4h4vfb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232333-gi4h4vfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-496
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gi4h4vfb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 257.81it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 272.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 274.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 277.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 280.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 282.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 284.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 279.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.53411
wandb: sub_train_loss 1.55812
wandb:       test_acc 0.543
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run graceful-sweep-496 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gi4h4vfb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232333-gi4h4vfb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 81k5prxc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232347-81k5prxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-497
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/81k5prxc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.01it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.32it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 157.96it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 150.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 153.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 157.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 163.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 165.44it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 171.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 175.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 181.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.32
wandb: best_valid_acc 0.296
wandb:  sub_train_acc 0.26751
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.327
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run electric-sweep-497 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/81k5prxc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232347-81k5prxc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jap71yv6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232402-jap71yv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-498
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jap71yv6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.58it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 193.76it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 193.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 192.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 190.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 188.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 189.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 189.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 190.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 191.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.315
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.25609
wandb: sub_train_loss 0.00013
wandb:       test_acc 0.313
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run visionary-sweep-498 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/jap71yv6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232402-jap71yv6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mmnjug0c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232418-mmnjug0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-499
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mmnjug0c
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.53it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.32it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 163.07it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 163.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 165.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 167.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 170.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 172.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 170.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 169.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.449
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.32161
wandb: sub_train_loss 0.00772
wandb:       test_acc 0.38
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run sleek-sweep-499 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mmnjug0c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232418-mmnjug0c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lpq1fccz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232438-lpq1fccz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-500
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lpq1fccz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.65it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 165.50it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 158.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 156.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 157.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 158.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 161.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 162.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 164.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 164.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 154.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.434
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.32071
wandb: sub_train_loss 0.00927
wandb:       test_acc 0.351
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run leafy-sweep-500 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lpq1fccz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232438-lpq1fccz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: st12ixnb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232459-st12ixnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-501
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/st12ixnb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.00it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.56it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 133.10it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 124.89it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 119.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 121.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 121.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 128.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 131.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 134.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 131.19it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 120.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 117.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 115.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.528
wandb: best_valid_acc 0.514
wandb:  sub_train_acc 0.41238
wandb: sub_train_loss 0.03509
wandb:       test_acc 0.467
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run rosy-sweep-501 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/st12ixnb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232459-st12ixnb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ifsxliei with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232522-ifsxliei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-502
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ifsxliei
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.50it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 169.86it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 171.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 172.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 173.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 176.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 176.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 175.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 174.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 169.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 170.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.496
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.44064
wandb: sub_train_loss 0.0358
wandb:       test_acc 0.5
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run dry-sweep-502 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ifsxliei
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232522-ifsxliei/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zcb0xuo1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232536-zcb0xuo1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-503
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zcb0xuo1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.78it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 163.52it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 173.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 176.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 179.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 159.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 163.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 158.59it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 159.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.492
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.44965
wandb: sub_train_loss 0.0317
wandb:       test_acc 0.461
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run peachy-sweep-503 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zcb0xuo1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232536-zcb0xuo1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j3or976y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232553-j3or976y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-504
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j3or976y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.52it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.58it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 157.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 157.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 158.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 158.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 161.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 166.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 170.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 172.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.43974
wandb: sub_train_loss 0.03
wandb:       test_acc 0.463
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run legendary-sweep-504 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/j3or976y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232553-j3or976y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 79oxb3nd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232607-79oxb3nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-505
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/79oxb3nd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.03it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.93it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.24it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 145.78it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 159.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 160.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 154.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 166.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 171.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 171.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 176.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.595
wandb: best_valid_acc 0.622
wandb:  sub_train_acc 0.43312
wandb: sub_train_loss 0.03786
wandb:       test_acc 0.437
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run fallen-sweep-505 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/79oxb3nd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232607-79oxb3nd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nuhx246x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232623-nuhx246x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-506
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nuhx246x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.79it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.75it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 145.64it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 150.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 157.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 169.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 176.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 181.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 174.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 175.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 165.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.581
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.44995
wandb: sub_train_loss 0.03277
wandb:       test_acc 0.454
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run misty-sweep-506 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nuhx246x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232623-nuhx246x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fn6ap97w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232635-fn6ap97w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-507
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fn6ap97w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.41it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 191.28it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 189.59it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 188.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 188.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 188.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 188.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 188.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 185.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 181.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.632
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.46619
wandb: sub_train_loss 0.06773
wandb:       test_acc 0.47
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run icy-sweep-507 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fn6ap97w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232635-fn6ap97w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: egaopz9x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232649-egaopz9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-508
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/egaopz9x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.35it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 197.48it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 196.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 197.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 197.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 196.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 180.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 183.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 173.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 155.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.64
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.42411
wandb: sub_train_loss 0.07437
wandb:       test_acc 0.423
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run dutiful-sweep-508 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/egaopz9x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232649-egaopz9x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kp3j5wmy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232704-kp3j5wmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-509
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kp3j5wmy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.02it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.53it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 166.40it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 158.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 153.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 156.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 165.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 169.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 173.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 176.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 179.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.663
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.62759
wandb: sub_train_loss 0.06792
wandb:       test_acc 0.618
wandb:      valid_acc 0.664
wandb: 
wandb: üöÄ View run decent-sweep-509 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kp3j5wmy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232704-kp3j5wmy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u5c13bn5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232719-u5c13bn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-510
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u5c13bn5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.79it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.15it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 183.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 182.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 179.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 180.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 181.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 182.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 182.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 185.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.659
wandb: best_valid_acc 0.694
wandb:  sub_train_acc 0.59122
wandb: sub_train_loss 0.06486
wandb:       test_acc 0.607
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run electric-sweep-510 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u5c13bn5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232719-u5c13bn5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ralg4ot with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232735-3ralg4ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-511
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3ralg4ot
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.06it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 171.81it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.16it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 184.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 189.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 193.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 192.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 192.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 191.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 184.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.714
wandb:  sub_train_acc 0.61767
wandb: sub_train_loss 0.1038
wandb:       test_acc 0.615
wandb:      valid_acc 0.612
wandb: 
wandb: üöÄ View run bright-sweep-511 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3ralg4ot
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232735-3ralg4ot/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uszig0ew with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232751-uszig0ew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-512
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uszig0ew
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.12it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.90it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 187.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 185.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 181.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 182.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 182.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 182.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 182.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 180.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.66426
wandb: sub_train_loss 0.08669
wandb:       test_acc 0.655
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run wandering-sweep-512 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uszig0ew
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232751-uszig0ew/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cmctui3i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232811-cmctui3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-513
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cmctui3i
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.36it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 124.87it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 131.22it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 133.71it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 131.39it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 129.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 129.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 131.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 132.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 133.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 136.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 136.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 135.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 136.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.18305
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.183
wandb:      valid_acc 0.17
wandb: 
wandb: üöÄ View run visionary-sweep-513 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cmctui3i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232811-cmctui3i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: awi6ajdc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232827-awi6ajdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-514
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/awi6ajdc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.72it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 114.19it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 119.12it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 124.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 128.04it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 134.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 139.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 141.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 141.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 142.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 143.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 143.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 144.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 143.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.328
wandb: best_valid_acc 0.32
wandb:  sub_train_acc 0.18154
wandb: sub_train_loss 0.0
wandb:       test_acc 0.183
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run bright-sweep-514 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/awi6ajdc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232827-awi6ajdc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5qauvbag with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232842-5qauvbag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-515
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5qauvbag
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.32it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 108.94it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 106.05it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 108.01it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 109.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 110.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 113.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 111.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 110.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 111.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 115.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 120.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 124.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 124.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 124.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 117.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.462
wandb: best_valid_acc 0.512
wandb:  sub_train_acc 0.21551
wandb: sub_train_loss 0.6957
wandb:       test_acc 0.193
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run morning-sweep-515 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5qauvbag
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232842-5qauvbag/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0fwrxist with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232857-0fwrxist
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-516
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0fwrxist
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.13it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 116.50it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 111.03it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 113.28it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 112.25it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 113.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 117.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 118.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 119.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 111.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 111.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 116.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 118.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 123.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 129.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.505
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.17223
wandb: sub_train_loss 0.20912
wandb:       test_acc 0.184
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run wandering-sweep-516 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0fwrxist
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232857-0fwrxist/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ffuwmln with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232913-1ffuwmln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-517
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ffuwmln
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.17it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 100.04it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 98.00it/s]  22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 97.47it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 99.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 99.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 99.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 99.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 96.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 95.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 98.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 100.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 104.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 108.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 113.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 114.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 114.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 104.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá
wandb:       test_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.535
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.41749
wandb: sub_train_loss 1.54145
wandb:       test_acc 0.441
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run winter-sweep-517 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ffuwmln
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232913-1ffuwmln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rc9k108d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232928-rc9k108d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-518
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rc9k108d
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.63it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.72it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 138.41it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 137.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 138.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 136.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 134.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 130.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 108.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 104.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 108.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 111.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 112.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 112.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 113.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.41479
wandb: sub_train_loss 0.82746
wandb:       test_acc 0.419
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run curious-sweep-518 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rc9k108d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232928-rc9k108d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x0i45ln6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232943-x0i45ln6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-519
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x0i45ln6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.63it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.33it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 122.40it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 127.24it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 128.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 126.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 126.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 125.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 126.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 128.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 128.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 127.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 122.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 111.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 106.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.528
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.38744
wandb: sub_train_loss 1.00719
wandb:       test_acc 0.388
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run quiet-sweep-519 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x0i45ln6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232943-x0i45ln6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h88taqr4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233000-h88taqr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-520
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h88taqr4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.19it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 112.58it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 108.58it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 113.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 114.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 115.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 116.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 120.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 124.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 128.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 131.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 131.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 133.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 130.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 127.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.552
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.28254
wandb: sub_train_loss 0.82937
wandb:       test_acc 0.227
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run magic-sweep-520 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h88taqr4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233000-h88taqr4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zhb8pub7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233015-zhb8pub7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-521
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zhb8pub7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.33it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 109.90it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 115.72it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 121.13it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 121.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 122.33it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 125.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 118.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 122.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 121.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 119.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 118.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 117.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 118.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 116.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.64
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.49294
wandb: sub_train_loss 0.52209
wandb:       test_acc 0.496
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run pious-sweep-521 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zhb8pub7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233015-zhb8pub7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lt9hypid with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233030-lt9hypid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-522
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lt9hypid
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.92it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.53it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 121.01it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 118.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 117.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 117.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 118.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 113.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 118.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 115.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 115.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 116.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 115.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 109.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 108.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 110.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.615
wandb: best_valid_acc 0.636
wandb:  sub_train_acc 0.2131
wandb: sub_train_loss 1.21453
wandb:       test_acc 0.151
wandb:      valid_acc 0.126
wandb: 
wandb: üöÄ View run fragrant-sweep-522 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lt9hypid
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233030-lt9hypid/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6l1o674m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233045-6l1o674m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-523
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6l1o674m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.14it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 106.53it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 106.49it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 107.37it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 106.07it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 108.10it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 110.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 115.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 116.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 114.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 114.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 105.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 108.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 112.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 115.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 114.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 111.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.643
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.28554
wandb: sub_train_loss 0.34185
wandb:       test_acc 0.267
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run olive-sweep-523 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/6l1o674m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233045-6l1o674m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wugu2cfd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233101-wugu2cfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-524
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wugu2cfd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.54it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 109.53it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 109.36it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 107.36it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 109.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 110.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 112.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 119.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 124.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 128.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 128.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 132.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 134.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 137.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 140.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.639
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.51368
wandb: sub_train_loss 0.86775
wandb:       test_acc 0.528
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run honest-sweep-524 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wugu2cfd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233101-wugu2cfd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kwdu6v3m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233116-kwdu6v3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-525
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kwdu6v3m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.50it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 131.54it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.37it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 129.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 132.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 132.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 132.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 131.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 131.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 131.45it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 129.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 119.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 108.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 111.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñá
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.66
wandb: best_valid_acc 0.678
wandb:  sub_train_acc 0.48662
wandb: sub_train_loss 1.43257
wandb:       test_acc 0.51
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run morning-sweep-525 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kwdu6v3m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233116-kwdu6v3m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: middtf4l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233128-middtf4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-526
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/middtf4l
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.41it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.79it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.00it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.73it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 127.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 126.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 127.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 128.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 128.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 128.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 121.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 123.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 130.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 132.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.676
wandb: best_valid_acc 0.674
wandb:  sub_train_acc 0.48422
wandb: sub_train_loss 0.18621
wandb:       test_acc 0.456
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run dauntless-sweep-526 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/middtf4l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233128-middtf4l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dhq0f20x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233142-dhq0f20x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-527
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dhq0f20x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.19it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 122.59it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 123.16it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 125.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 124.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 124.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 121.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 123.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 130.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 135.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 138.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 140.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 137.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.35618
wandb: sub_train_loss 0.81852
wandb:       test_acc 0.327
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run proud-sweep-527 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dhq0f20x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233142-dhq0f20x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 23cvxp34 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233157-23cvxp34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-528
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/23cvxp34
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.11it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.55it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 114.14it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 117.32it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 118.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 120.30it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 121.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 122.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 122.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 122.94it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 117.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 121.54it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 127.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 129.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 131.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñà
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.651
wandb: best_valid_acc 0.672
wandb:  sub_train_acc 0.40307
wandb: sub_train_loss 1.86806
wandb:       test_acc 0.349
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run jumping-sweep-528 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/23cvxp34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233157-23cvxp34/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4beq61yn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233213-4beq61yn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-529
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4beq61yn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 266.36it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 222.70it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 210.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 229.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 241.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 248.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 247.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 244.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:00<00:00, 245.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 249.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 249.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 241.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.263
wandb: sub_train_loss 1.03015
wandb:       test_acc 0.308
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run glowing-sweep-529 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4beq61yn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233213-4beq61yn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: czrv7aie with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233227-czrv7aie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-530
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/czrv7aie
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 311.36it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 315.31it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 319.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 321.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 322.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 323.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 318.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 319.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:00<00:00, 316.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 318.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.31
wandb: best_valid_acc 0.272
wandb:  sub_train_acc 0.26029
wandb: sub_train_loss 1.02887
wandb:       test_acc 0.308
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run olive-sweep-530 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/czrv7aie
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233227-czrv7aie/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w6xxghg2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233249-w6xxghg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-531
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w6xxghg2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 227.53it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 239.78it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 250.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 256.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 261.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 265.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 269.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 272.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 268.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 268.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 270.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 264.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.355
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.29426
wandb: sub_train_loss 1.18334
wandb:       test_acc 0.276
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run different-sweep-531 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w6xxghg2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233249-w6xxghg2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: atnmm7nj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233304-atnmm7nj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-532
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/atnmm7nj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 271.30it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 272.53it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 275.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 266.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 256.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 250.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 247.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 247.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 249.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 247.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 257.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 256.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.376
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.29426
wandb: sub_train_loss 1.18395
wandb:       test_acc 0.276
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run glad-sweep-532 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/atnmm7nj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233304-atnmm7nj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: an0ou41b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233320-an0ou41b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-533
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/an0ou41b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 271.45it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 231.50it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 208.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 213.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 227.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 238.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 232.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 237.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 234.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 234.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 242.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 235.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.414
wandb: best_valid_acc 0.442
wandb:  sub_train_acc 0.28885
wandb: sub_train_loss 1.27851
wandb:       test_acc 0.309
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run morning-sweep-533 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/an0ou41b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233320-an0ou41b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 654l7k53 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233335-654l7k53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-534
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/654l7k53
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 244.86it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 244.96it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 247.92it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 248.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 250.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 257.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 270.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 282.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 287.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 288.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 271.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.47
wandb:  sub_train_acc 0.29035
wandb: sub_train_loss 1.2779
wandb:       test_acc 0.314
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run astral-sweep-534 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/654l7k53
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233335-654l7k53/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nd7l9sol with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233346-nd7l9sol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-535
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nd7l9sol
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 267.94it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 292.31it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 307.04it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 314.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 318.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 320.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 322.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 323.57it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:00<00:00, 321.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 316.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.277
wandb: best_valid_acc 0.252
wandb:  sub_train_acc 0.18756
wandb: sub_train_loss 1.32921
wandb:       test_acc 0.175
wandb:      valid_acc 0.15
wandb: 
wandb: üöÄ View run fragrant-sweep-535 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nd7l9sol
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233346-nd7l9sol/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i77m804w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233401-i77m804w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-536
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i77m804w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 245.55it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 248.50it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 255.66it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 260.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 267.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 271.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 274.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 274.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 274.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 275.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.255
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.18696
wandb: sub_train_loss 1.32872
wandb:       test_acc 0.174
wandb:      valid_acc 0.15
wandb: 
wandb: üöÄ View run swept-sweep-536 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i77m804w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233401-i77m804w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2yqjxwfk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233413-2yqjxwfk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-537
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2yqjxwfk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 277.58it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 288.14it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 276.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 253.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 244.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 220.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 228.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 236.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 253.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 261.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 253.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.35167
wandb: sub_train_loss 1.35707
wandb:       test_acc 0.326
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run legendary-sweep-537 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2yqjxwfk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233413-2yqjxwfk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 50jib71u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233427-50jib71u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-538
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/50jib71u
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 252.11it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 260.15it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 256.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 273.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 284.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 291.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 292.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 278.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 268.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 259.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 271.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.014 MB of 0.023 MB uploadedwandb: / 0.014 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.583
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.36189
wandb: sub_train_loss 1.35621
wandb:       test_acc 0.352
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run twilight-sweep-538 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/50jib71u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233427-50jib71u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x66elrtk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233442-x66elrtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-539
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x66elrtk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.77it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 249.77it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 252.82it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 254.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 253.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 248.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 244.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 243.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 248.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 258.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 265.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 255.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.528
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.46198
wandb: sub_train_loss 1.39228
wandb:       test_acc 0.451
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run fresh-sweep-539 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x66elrtk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233442-x66elrtk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fnau3mvw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233457-fnau3mvw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-540
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fnau3mvw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 247.85it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 250.62it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 256.94it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 256.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 260.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 267.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 275.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 282.22it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:00<00:00, 282.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 288.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.508
wandb: best_valid_acc 0.496
wandb:  sub_train_acc 0.46919
wandb: sub_train_loss 1.39148
wandb:       test_acc 0.463
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run devoted-sweep-540 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fnau3mvw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233457-fnau3mvw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7qluht76 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233513-7qluht76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-541
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7qluht76
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 242.38it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 267.57it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 278.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 265.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 263.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 266.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 270.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 280.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 285.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 289.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 277.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.513
wandb: best_valid_acc 0.518
wandb:  sub_train_acc 0.48813
wandb: sub_train_loss 1.41266
wandb:       test_acc 0.495
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run wild-sweep-541 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7qluht76
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233513-7qluht76/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9pnt61yr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233529-9pnt61yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-542
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9pnt61yr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 276.40it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 250.11it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:00, 246.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 255.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 251.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 250.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 250.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 257.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 262.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 272.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 262.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.528
wandb: best_valid_acc 0.52
wandb:  sub_train_acc 0.48873
wandb: sub_train_loss 1.41321
wandb:       test_acc 0.491
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run laced-sweep-542 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9pnt61yr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233529-9pnt61yr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e7yq4yvd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233544-e7yq4yvd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-543
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e7yq4yvd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 281.84it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 289.38it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 295.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 297.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 297.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 292.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 292.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 294.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:00<00:00, 295.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 294.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.625
wandb: best_valid_acc 0.62
wandb:  sub_train_acc 0.54584
wandb: sub_train_loss 1.43809
wandb:       test_acc 0.517
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run charmed-sweep-543 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e7yq4yvd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233544-e7yq4yvd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hfsyfuwa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233600-hfsyfuwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-544
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hfsyfuwa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 257.49it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 264.53it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 271.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 276.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 275.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 281.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 280.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 283.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 277.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 261.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 265.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.625
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.474
wandb: sub_train_loss 1.43826
wandb:       test_acc 0.471
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run fresh-sweep-544 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hfsyfuwa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233600-hfsyfuwa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z6klu7gq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233615-z6klu7gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-545
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z6klu7gq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.96it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.45it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 179.12it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 179.01it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 182.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 181.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 183.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 182.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 180.46it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 179.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 175.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 175.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 178.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 180.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 180.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.331
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.26871
wandb: sub_train_loss 0.0
wandb:       test_acc 0.333
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run zany-sweep-545 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z6klu7gq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233615-z6klu7gq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1exhl3c0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233631-1exhl3c0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-546
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1exhl3c0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.50it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 173.90it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.97it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 177.77it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 179.77it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 176.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 171.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 166.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 167.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 175.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 183.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 189.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 193.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 196.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 185.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.308
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.21701
wandb: sub_train_loss 0.0
wandb:       test_acc 0.222
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run dainty-sweep-546 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1exhl3c0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233631-1exhl3c0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzkszrhw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233647-nzkszrhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-547
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzkszrhw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.18it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 160.39it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 158.89it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 153.71it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 153.04it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 164.38it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 171.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 177.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 180.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 182.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 180.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 171.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 165.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 162.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 164.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 163.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.43
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.32402
wandb: sub_train_loss 0.0003
wandb:       test_acc 0.334
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run jumping-sweep-547 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzkszrhw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233647-nzkszrhw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q8uu37d6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233658-q8uu37d6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-548
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q8uu37d6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.19it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.33it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 162.85it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 158.63it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 155.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 150.27it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 152.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 153.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 160.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 164.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 166.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 167.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 169.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 168.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 168.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 170.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 171.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.31199
wandb: sub_train_loss 0.00023
wandb:       test_acc 0.322
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run avid-sweep-548 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q8uu37d6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233658-q8uu37d6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xbxs89sz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233713-xbxs89sz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-549
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xbxs89sz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 169.04it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 165.58it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 166.09it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 170.48it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 172.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 167.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 171.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 166.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 165.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 166.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 166.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 166.44it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 160.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 160.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 158.45it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 157.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 157.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.516
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.34295
wandb: sub_train_loss 0.01592
wandb:       test_acc 0.342
wandb:      valid_acc 0.344
wandb: 
wandb: üöÄ View run lunar-sweep-549 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xbxs89sz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233713-xbxs89sz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 24dxvlx8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233729-24dxvlx8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-550
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/24dxvlx8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.58it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 188.13it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 188.06it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 188.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 189.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 187.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 187.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 187.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 186.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 186.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 185.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 181.90it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 179.39it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 180.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 180.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.464
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.30027
wandb: sub_train_loss 0.01342
wandb:       test_acc 0.299
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run charmed-sweep-550 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/24dxvlx8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233729-24dxvlx8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: svtmglpx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233750-svtmglpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-551
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/svtmglpx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.19it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 194.34it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 194.27it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 194.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 195.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 195.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 194.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 188.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 188.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 190.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 191.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 193.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 194.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 191.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 186.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.481
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.42952
wandb: sub_train_loss 0.00279
wandb:       test_acc 0.441
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run upbeat-sweep-551 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/svtmglpx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233750-svtmglpx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9fpvmret with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233807-9fpvmret
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-552
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9fpvmret
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.82it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.68it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 161.57it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 162.87it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 166.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 172.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 179.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 182.91it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 183.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 183.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 180.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 178.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 179.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 179.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 178.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 176.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.498
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.41719
wandb: sub_train_loss 0.00236
wandb:       test_acc 0.433
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run bumbling-sweep-552 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9fpvmret
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233807-9fpvmret/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: is9g0tly with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233819-is9g0tly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-553
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/is9g0tly
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.85it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 142.48it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 158.95it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 160.82it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 161.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 162.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 161.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 160.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:01, 139.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 142.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 144.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 146.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 145.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 142.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 146.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 144.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 143.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 145.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.588
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.42922
wandb: sub_train_loss 0.00689
wandb:       test_acc 0.451
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run cerulean-sweep-553 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/is9g0tly
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233819-is9g0tly/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o38d8rbl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233833-o38d8rbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-554
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o38d8rbl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.57it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 113.65it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.06it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 151.72it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 164.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 170.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 166.91it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 165.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 163.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 159.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 159.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 157.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 154.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 159.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 164.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 173.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 181.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.47731
wandb: sub_train_loss 0.00283
wandb:       test_acc 0.488
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run smart-sweep-554 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o38d8rbl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233833-o38d8rbl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nsfpezo5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233852-nsfpezo5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-555
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nsfpezo5
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.39it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.83it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 157.45it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 161.23it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 165.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 169.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 171.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 171.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 168.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 166.33it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 161.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 150.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 150.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 158.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 167.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 167.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 164.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.613
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.54373
wandb: sub_train_loss 0.005
wandb:       test_acc 0.565
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run dainty-sweep-555 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nsfpezo5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233852-nsfpezo5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rgt51oos with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233914-rgt51oos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-556
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rgt51oos
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.74it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 158.48it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.68it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 164.09it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 167.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 170.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 174.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 175.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 175.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 177.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 177.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 179.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 181.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 181.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 180.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 182.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.605
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.53772
wandb: sub_train_loss 0.01169
wandb:       test_acc 0.556
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run colorful-sweep-556 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rgt51oos
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233914-rgt51oos/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t5mi7ni7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233928-t5mi7ni7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-557
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t5mi7ni7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.13it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.44it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.57it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 154.10it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 159.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 163.59it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 169.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 172.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 176.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 182.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 185.57it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 182.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 178.81it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 180.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 179.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 178.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.673
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.60866
wandb: sub_train_loss 0.01279
wandb:       test_acc 0.64
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run copper-sweep-557 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/t5mi7ni7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233928-t5mi7ni7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7j5j1h1y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233949-7j5j1h1y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-558
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7j5j1h1y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.25it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.46it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 186.31it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 186.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 188.54it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 189.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 178.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 171.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 167.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 163.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 159.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 161.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 161.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 159.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 167.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 175.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.57349
wandb: sub_train_loss 0.00949
wandb:       test_acc 0.577
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run major-sweep-558 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7j5j1h1y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233949-7j5j1h1y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 982823l1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234006-982823l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-559
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/982823l1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.30it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 159.14it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 157.37it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.49it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 157.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 151.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 156.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 161.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 166.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 168.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 168.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 168.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 168.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 167.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 169.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 170.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 169.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.66035
wandb: sub_train_loss 0.01128
wandb:       test_acc 0.661
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run major-sweep-559 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/982823l1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234006-982823l1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vgs4hucx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234022-vgs4hucx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-560
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vgs4hucx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.73it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 181.40it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 182.13it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 177.00it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 174.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 174.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 174.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 175.56it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 177.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 178.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 178.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 179.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 179.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 182.02it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 183.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 185.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.718
wandb:  sub_train_acc 0.58882
wandb: sub_train_loss 0.02094
wandb:       test_acc 0.583
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run genial-sweep-560 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vgs4hucx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234022-vgs4hucx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1vykb5am with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234038-1vykb5am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-561
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1vykb5am
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.15it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.66it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 131.44it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 137.85it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 141.73it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 132.27it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 137.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 140.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 142.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 144.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 143.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 140.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 138.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 137.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 135.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 135.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 136.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 138.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 141.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 142.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.336
wandb: best_valid_acc 0.314
wandb:  sub_train_acc 0.18124
wandb: sub_train_loss 0.0
wandb:       test_acc 0.183
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run splendid-sweep-561 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1vykb5am
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234038-1vykb5am/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sxh200h6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234053-sxh200h6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-562
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sxh200h6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 105.47it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 108.52it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 99.01it/s]  16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 112.01it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 118.53it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 121.21it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 125.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 125.96it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 128.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 124.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 123.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 121.17it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 119.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 121.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 122.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 124.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 124.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 122.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 123.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 121.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 123.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 124.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 126.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.337
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.19267
wandb: sub_train_loss 0.0
wandb:       test_acc 0.213
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run grateful-sweep-562 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sxh200h6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234053-sxh200h6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q86fkxcd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234109-q86fkxcd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-563
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q86fkxcd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.56it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 108.12it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.57it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 113.32it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 113.37it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 117.61it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 120.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 124.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 128.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 124.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 116.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 110.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 107.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 106.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 107.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 110.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 116.64it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 122.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 127.49it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 125.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 114.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 109.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 108.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.474
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.35137
wandb: sub_train_loss 0.30494
wandb:       test_acc 0.397
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run rare-sweep-563 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q86fkxcd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234109-q86fkxcd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ctdkoal with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234127-1ctdkoal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-564
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ctdkoal
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.03it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.52it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.62it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.07it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 126.20it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 128.74it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 128.43it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 127.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 125.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 126.08it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 122.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 119.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 119.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 121.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 122.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 121.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 121.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 122.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 122.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 122.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 121.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 122.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 124.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.482
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.22693
wandb: sub_train_loss 0.57005
wandb:       test_acc 0.179
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run vital-sweep-564 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1ctdkoal
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234127-1ctdkoal/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wn6hybeh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234145-wn6hybeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-565
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wn6hybeh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.94it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.41it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 127.58it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 127.24it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 127.92it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 129.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 130.26it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 131.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 130.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 129.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 128.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 128.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 128.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 130.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 133.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 135.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 136.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 138.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 138.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 138.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 137.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.12654
wandb: sub_train_loss 0.76037
wandb:       test_acc 0.108
wandb:      valid_acc 0.076
wandb: 
wandb: üöÄ View run stellar-sweep-565 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wn6hybeh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234145-wn6hybeh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7z6v8vci with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234158-7z6v8vci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-566
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7z6v8vci
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.99it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 123.96it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.79it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 119.57it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 119.13it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 117.97it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 118.98it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 119.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 118.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 118.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 121.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 120.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 117.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 116.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 113.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 116.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 122.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 127.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 131.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 132.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 131.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 124.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 118.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.54
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.2107
wandb: sub_train_loss 0.343
wandb:       test_acc 0.182
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run treasured-sweep-566 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7z6v8vci
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234158-7z6v8vci/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bb8u3l0t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234221-bb8u3l0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-567
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bb8u3l0t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.76it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.81it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.10it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 132.48it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 136.58it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 137.06it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 137.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 136.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 132.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 130.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 127.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 127.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 124.75it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 124.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 124.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 124.50it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 128.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 131.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 135.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 134.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 132.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.545
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.33574
wandb: sub_train_loss 1.23362
wandb:       test_acc 0.358
wandb:      valid_acc 0.362
wandb: 
wandb: üöÄ View run drawn-sweep-567 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bb8u3l0t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234221-bb8u3l0t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zovj0xco with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234237-zovj0xco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-568
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zovj0xco
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.76it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 118.97it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 119.34it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 121.59it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 123.42it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 125.42it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 119.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 119.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 121.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 121.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 122.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 124.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 125.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 126.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 127.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 129.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 133.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 134.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 133.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 132.44it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 135.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 135.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.541
wandb: best_valid_acc 0.584
wandb:  sub_train_acc 0.34986
wandb: sub_train_loss 0.24618
wandb:       test_acc 0.321
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run amber-sweep-568 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zovj0xco
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234237-zovj0xco/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w1t508ve with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234302-w1t508ve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-569
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w1t508ve
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.71it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 126.02it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.27it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.96it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 125.50it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 122.68it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 122.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 125.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 128.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 129.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 128.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 133.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 136.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 140.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 143.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 144.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 145.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 146.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 147.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 148.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 149.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.603
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.40186
wandb: sub_train_loss 0.40102
wandb:       test_acc 0.412
wandb:      valid_acc 0.378
wandb: 
wandb: üöÄ View run hardy-sweep-569 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w1t508ve
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234302-w1t508ve/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: raqb61s0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234318-raqb61s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-570
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/raqb61s0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.00it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.22it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 122.76it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 129.20it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 128.47it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 128.55it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 129.66it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 132.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 135.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 136.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 135.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 135.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 134.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 134.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 134.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 126.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 130.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 133.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 137.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 137.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 139.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.616
wandb: best_valid_acc 0.636
wandb:  sub_train_acc 0.35708
wandb: sub_train_loss 0.12282
wandb:       test_acc 0.335
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run vague-sweep-570 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/raqb61s0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234318-raqb61s0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uceo9xz2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234334-uceo9xz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-571
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uceo9xz2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.15it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.54it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.20it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 131.83it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 129.44it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 126.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 116.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 116.38it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 116.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 116.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 116.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 117.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 118.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 121.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 124.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 127.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 127.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 127.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 124.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 119.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 120.55it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 124.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.648
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.56988
wandb: sub_train_loss 0.37223
wandb:       test_acc 0.612
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run legendary-sweep-571 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uceo9xz2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234334-uceo9xz2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8r79loot with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234349-8r79loot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-572
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8r79loot
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.30it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 120.47it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 117.34it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 118.10it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 112.28it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 92.73it/s]  29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 81.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 76.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:02, 75.26it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 88.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 100.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 104.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 105.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 104.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 106.99it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 110.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 112.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 116.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 121.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 126.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 129.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 131.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 132.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 133.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.633
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.2645
wandb: sub_train_loss 0.86285
wandb:       test_acc 0.238
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run jumping-sweep-572 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8r79loot
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234349-8r79loot/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n4kvfr90 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234405-n4kvfr90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-573
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n4kvfr90
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.98it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.26it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 130.94it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 128.33it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 130.33it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 116.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 120.12it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 120.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 115.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 116.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 116.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 119.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 126.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 133.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 138.20it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 140.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 141.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 141.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 142.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 144.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 144.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.624
wandb:  sub_train_acc 0.38593
wandb: sub_train_loss 0.34915
wandb:       test_acc 0.359
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run noble-sweep-573 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n4kvfr90
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234405-n4kvfr90/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yjlvdz3k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234420-yjlvdz3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-574
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yjlvdz3k
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 109.04it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 119.29it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 116.11it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.41it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 115.05it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 115.34it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 117.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 120.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 122.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 124.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 128.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 132.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 134.38it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 136.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 138.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 131.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 120.35it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 118.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 115.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 112.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 114.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 120.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.649
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.34836
wandb: sub_train_loss 1.06622
wandb:       test_acc 0.313
wandb:      valid_acc 0.348
wandb: 
wandb: üöÄ View run curious-sweep-574 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yjlvdz3k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234420-yjlvdz3k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gqnk4au1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234435-gqnk4au1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-575
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gqnk4au1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.40it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.59it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.65it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 147.42it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.59it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 145.57it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 146.15it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 147.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 146.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 143.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 136.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 132.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 128.89it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 127.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 126.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 124.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 121.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 120.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 123.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 134.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.681
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.50797
wandb: sub_train_loss 0.29501
wandb:       test_acc 0.505
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run fresh-sweep-575 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gqnk4au1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234435-gqnk4au1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3awpwxna with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234450-3awpwxna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-576
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3awpwxna
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.52it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.18it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 125.30it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 121.82it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 128.33it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 130.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 128.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 127.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 127.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 130.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 133.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 133.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 135.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 136.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 136.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 138.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 135.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 133.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 133.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 134.55it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 134.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.36339
wandb: sub_train_loss 0.94418
wandb:       test_acc 0.356
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run frosty-sweep-576 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3awpwxna
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234450-3awpwxna/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m16l8r9p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234505-m16l8r9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-577
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m16l8r9p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 239.79it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 240.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 237.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 232.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 223.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 217.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 214.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 211.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 219.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.209
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.15509
wandb: sub_train_loss 1.70852
wandb:       test_acc 0.173
wandb:      valid_acc 0.144
wandb: 
wandb: üöÄ View run rich-sweep-577 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m16l8r9p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234505-m16l8r9p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r6j2xwga with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234521-r6j2xwga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-578
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r6j2xwga
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.69it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 200.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 206.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 214.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 219.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 217.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 208.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 194.76it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 187.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 199.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.165
wandb: best_valid_acc 0.196
wandb:  sub_train_acc 0.09919
wandb: sub_train_loss 1.7089
wandb:       test_acc 0.184
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run elated-sweep-578 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r6j2xwga
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234521-r6j2xwga/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xosur7sv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234537-xosur7sv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-579
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xosur7sv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 226.56it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 230.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 225.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 222.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 222.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 222.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 222.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 221.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 223.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.2101
wandb: sub_train_loss 1.71831
wandb:       test_acc 0.212
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run kind-sweep-579 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xosur7sv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234537-xosur7sv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7yhk6bya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234553-7yhk6bya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-580
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7yhk6bya
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 225.51it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 231.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 229.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 229.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 228.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 229.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 228.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 223.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 226.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.25368
wandb: sub_train_loss 1.71799
wandb:       test_acc 0.245
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run sweepy-sweep-580 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7yhk6bya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234553-7yhk6bya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mki7fip8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234608-mki7fip8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-581
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mki7fip8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.62it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 191.56it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 198.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 197.31it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 200.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 202.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 205.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 209.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 211.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 205.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.415
wandb: best_valid_acc 0.41
wandb:  sub_train_acc 0.37571
wandb: sub_train_loss 1.71993
wandb:       test_acc 0.415
wandb:      valid_acc 0.41
wandb: 
wandb: üöÄ View run fallen-sweep-581 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mki7fip8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234608-mki7fip8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ib4im536 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234627-ib4im536
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-582
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ib4im536
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.62it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 221.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 221.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 224.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 224.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 223.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 226.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 226.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 225.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.396
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.35497
wandb: sub_train_loss 1.72194
wandb:       test_acc 0.396
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run misty-sweep-582 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ib4im536
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234627-ib4im536/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ituvf4ti with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234642-ituvf4ti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-583
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ituvf4ti
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 222.50it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 224.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 226.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 227.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 229.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 229.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 229.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 228.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 227.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.275
wandb: best_valid_acc 0.302
wandb:  sub_train_acc 0.2116
wandb: sub_train_loss 1.72056
wandb:       test_acc 0.237
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run volcanic-sweep-583 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ituvf4ti
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234642-ituvf4ti/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f0yl3jzz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234657-f0yl3jzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-584
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f0yl3jzz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 213.05it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 218.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 219.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 217.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 219.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 220.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 222.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 223.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 221.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.213
wandb: best_valid_acc 0.258
wandb:  sub_train_acc 0.25518
wandb: sub_train_loss 1.72133
wandb:       test_acc 0.28
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run bright-sweep-584 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f0yl3jzz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234657-f0yl3jzz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qtgjgcq0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234718-qtgjgcq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-585
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qtgjgcq0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 207.94it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 205.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 204.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 202.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 202.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 199.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 202.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 204.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 204.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.165
wandb: best_valid_acc 0.178
wandb:  sub_train_acc 0.12594
wandb: sub_train_loss 1.72758
wandb:       test_acc 0.118
wandb:      valid_acc 0.094
wandb: 
wandb: üöÄ View run magic-sweep-585 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qtgjgcq0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234718-qtgjgcq0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kngeyu85 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234733-kngeyu85
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-586
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kngeyu85
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 197.24it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 198.16it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 199.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 201.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 200.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 200.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 199.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 201.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 206.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.371
wandb: best_valid_acc 0.354
wandb:  sub_train_acc 0.25098
wandb: sub_train_loss 1.72688
wandb:       test_acc 0.242
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run cosmic-sweep-586 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kngeyu85
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234733-kngeyu85/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qhpznpt9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234744-qhpznpt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-587
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qhpznpt9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 197.05it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 188.37it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 193.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 199.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 203.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 205.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 206.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 207.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 207.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.22182
wandb: sub_train_loss 1.72939
wandb:       test_acc 0.221
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run graceful-sweep-587 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/qhpznpt9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234744-qhpznpt9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pksc7k8z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234758-pksc7k8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-588
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pksc7k8z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 198.65it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 200.52it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 200.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 204.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 205.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 205.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 206.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 206.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 204.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.361
wandb: best_valid_acc 0.398
wandb:  sub_train_acc 0.29306
wandb: sub_train_loss 1.72969
wandb:       test_acc 0.28
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run vivid-sweep-588 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pksc7k8z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234758-pksc7k8z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fqwc7njy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234820-fqwc7njy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-589
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fqwc7njy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.64it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 196.16it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 197.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 200.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 200.96it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 200.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 200.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 199.67it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 195.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.219
wandb: best_valid_acc 0.2
wandb:  sub_train_acc 0.21641
wandb: sub_train_loss 1.72924
wandb:       test_acc 0.225
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run magic-sweep-589 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fqwc7njy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234820-fqwc7njy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nv37xiha with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234832-nv37xiha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-590
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nv37xiha
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.89it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 186.52it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 190.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 192.17it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 193.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 195.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 196.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 196.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 196.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 196.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.39
wandb: best_valid_acc 0.388
wandb:  sub_train_acc 0.39375
wandb: sub_train_loss 1.72958
wandb:       test_acc 0.389
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run comic-sweep-590 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nv37xiha
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234832-nv37xiha/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b3ua2i6u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234858-b3ua2i6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-591
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b3ua2i6u
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.59it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 173.09it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 180.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 186.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 187.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 189.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 192.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 195.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 195.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 197.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 191.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.588
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.51488
wandb: sub_train_loss 1.73319
wandb:       test_acc 0.525
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run jolly-sweep-591 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b3ua2i6u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234858-b3ua2i6u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7k5d7se4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234918-7k5d7se4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-592
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7k5d7se4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.78it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.76it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 172.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 174.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 176.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 177.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 171.30it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 169.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 171.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 177.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.602
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.59122
wandb: sub_train_loss 1.73324
wandb:       test_acc 0.604
wandb:      valid_acc 0.594
wandb: 
wandb: üöÄ View run cerulean-sweep-592 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7k5d7se4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234918-7k5d7se4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 58g1to78 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234933-58g1to78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-593
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/58g1to78
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.38it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.59it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 192.15it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 192.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 193.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 189.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 186.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 184.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 172.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 174.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.178
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.09017
wandb: sub_train_loss 1.46232
wandb:       test_acc 0.243
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run fast-sweep-593 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/58g1to78
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234933-58g1to78/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hzuu5nds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234945-hzuu5nds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-594
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hzuu5nds
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.33it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 168.54it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 167.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 164.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 159.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 158.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 160.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 164.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 165.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 167.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 167.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.08506
wandb: sub_train_loss 1.4428
wandb:       test_acc 0.234
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run upbeat-sweep-594 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hzuu5nds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234945-hzuu5nds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wfs4771m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234959-wfs4771m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-595
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wfs4771m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.06it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.33it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 169.92it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 174.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 180.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 184.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 185.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 189.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 191.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 192.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.36
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.25158
wandb: sub_train_loss 1.45842
wandb:       test_acc 0.346
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run usual-sweep-595 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wfs4771m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234959-wfs4771m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: auyvzymz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235014-auyvzymz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-596
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/auyvzymz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.43it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 193.53it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 187.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 184.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 181.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 185.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 185.29it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 183.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 177.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 169.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.23505
wandb: sub_train_loss 1.45674
wandb:       test_acc 0.233
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run twilight-sweep-596 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/auyvzymz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235014-auyvzymz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e9epwwgp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235026-e9epwwgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-597
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e9epwwgp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.53it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.83it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 191.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 193.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 194.46it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 193.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 194.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 193.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 191.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 192.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.29366
wandb: sub_train_loss 1.45926
wandb:       test_acc 0.166
wandb:      valid_acc 0.156
wandb: 
wandb: üöÄ View run glad-sweep-597 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e9epwwgp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235026-e9epwwgp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: trc4nuf7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235040-trc4nuf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-598
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/trc4nuf7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.79it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.92it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 179.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 179.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 178.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 177.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 175.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 173.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 174.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 176.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.404
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.32792
wandb: sub_train_loss 1.49339
wandb:       test_acc 0.258
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run silver-sweep-598 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/trc4nuf7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235040-trc4nuf7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lx6kke2b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235055-lx6kke2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-599
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lx6kke2b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.11it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 190.64it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 192.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 190.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 187.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 189.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 189.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 190.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 189.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 191.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.371
wandb: best_valid_acc 0.408
wandb:  sub_train_acc 0.29276
wandb: sub_train_loss 1.49055
wandb:       test_acc 0.23
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run still-sweep-599 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lx6kke2b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235055-lx6kke2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7tmfoybo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235110-7tmfoybo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-600
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7tmfoybo
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.63it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 178.67it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 181.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 181.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 183.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 185.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 186.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 187.33it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 188.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 190.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.316
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.26721
wandb: sub_train_loss 1.48543
wandb:       test_acc 0.293
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run amber-sweep-600 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7tmfoybo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235110-7tmfoybo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1nwo6nq8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235126-1nwo6nq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-601
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1nwo6nq8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.32it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 185.98it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 186.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 185.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 184.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 183.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 183.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 182.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 182.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 183.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.31
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.28554
wandb: sub_train_loss 1.49844
wandb:       test_acc 0.316
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run playful-sweep-601 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1nwo6nq8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235126-1nwo6nq8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fg5llg67 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235142-fg5llg67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-602
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fg5llg67
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.64it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.52it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 159.40it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 158.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 154.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 149.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 152.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 158.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 164.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 165.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 166.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.438
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.36129
wandb: sub_train_loss 1.5086
wandb:       test_acc 0.286
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run laced-sweep-602 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fg5llg67
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235142-fg5llg67/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ian8u4oq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235153-ian8u4oq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-603
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ian8u4oq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.37it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 168.42it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 169.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 168.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 169.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 171.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 173.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 174.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 173.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.284
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.25398
wandb: sub_train_loss 1.48314
wandb:       test_acc 0.284
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run ethereal-sweep-603 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ian8u4oq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235153-ian8u4oq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4tjnv8wn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235207-4tjnv8wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-604
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4tjnv8wn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.66it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.22it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 151.82it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 144.78it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 146.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 148.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 148.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 148.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 145.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 146.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 154.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 156.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.166
wandb: best_valid_acc 0.148
wandb:  sub_train_acc 0.16832
wandb: sub_train_loss 1.47223
wandb:       test_acc 0.166
wandb:      valid_acc 0.148
wandb: 
wandb: üöÄ View run generous-sweep-604 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4tjnv8wn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235207-4tjnv8wn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kds96da2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235223-kds96da2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-605
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kds96da2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.85it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 156.80it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 153.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 151.59it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 153.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 153.97it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 154.67it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 157.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 161.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 166.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 167.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.433
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.39315
wandb: sub_train_loss 1.51004
wandb:       test_acc 0.433
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run radiant-sweep-605 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kds96da2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235223-kds96da2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bvzpksib with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235234-bvzpksib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-606
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bvzpksib
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.63it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.96it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.28it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 158.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 159.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 160.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 161.67it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 163.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 162.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 164.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 166.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.46979
wandb: sub_train_loss 1.50075
wandb:       test_acc 0.511
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run lyric-sweep-606 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bvzpksib
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235234-bvzpksib/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xzh1o2vk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235249-xzh1o2vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-607
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xzh1o2vk
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.37it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.32it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 147.87it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 145.19it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 144.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 144.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 144.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 147.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 148.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 149.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 150.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.621
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.62549
wandb: sub_train_loss 1.51776
wandb:       test_acc 0.623
wandb:      valid_acc 0.634
wandb: 
wandb: üöÄ View run unique-sweep-607 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xzh1o2vk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235249-xzh1o2vk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ii87p3j3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235303-ii87p3j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-608
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ii87p3j3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.62it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 149.58it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 148.75it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 145.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 142.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 144.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 147.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 149.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 152.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 150.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 149.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 148.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.65224
wandb: sub_train_loss 1.50256
wandb:       test_acc 0.654
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run electric-sweep-608 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ii87p3j3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235303-ii87p3j3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4v21k3wf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235319-4v21k3wf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-609
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4v21k3wf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.00it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.11it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 143.77it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 145.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 144.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 149.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 136.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 138.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 142.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 143.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 145.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 146.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 147.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.246
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.24707
wandb: sub_train_loss 1.22675
wandb:       test_acc 0.232
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run denim-sweep-609 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4v21k3wf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235319-4v21k3wf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rnlsjvss with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235335-rnlsjvss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-610
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rnlsjvss
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.40it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.19it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 150.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 151.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 153.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 157.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 132.75it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 131.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 130.77it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 121.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 118.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.316
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.2131
wandb: sub_train_loss 1.23266
wandb:       test_acc 0.231
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run lyric-sweep-610 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rnlsjvss
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235335-rnlsjvss/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rf9amdx4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235350-rf9amdx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-611
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rf9amdx4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.83it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.17it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.78it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 128.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 125.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 128.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 132.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 139.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 146.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 151.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 154.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 156.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.308
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.20409
wandb: sub_train_loss 1.36405
wandb:       test_acc 0.189
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run celestial-sweep-611 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rf9amdx4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235350-rf9amdx4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: libb3nex with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235406-libb3nex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-612
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/libb3nex
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.01it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.29it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 169.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 171.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 173.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 174.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 174.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 172.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 166.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 162.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 158.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.183
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.23384
wandb: sub_train_loss 1.30633
wandb:       test_acc 0.186
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run sparkling-sweep-612 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/libb3nex
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235406-libb3nex/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uo51wiil with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235422-uo51wiil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-613
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uo51wiil
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.25it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 161.39it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 152.28it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 138.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 136.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 136.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 136.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 137.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 136.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 136.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 136.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 138.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 145.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.16
wandb: best_valid_acc 0.14
wandb:  sub_train_acc 0.22483
wandb: sub_train_loss 1.37546
wandb:       test_acc 0.163
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run gentle-sweep-613 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uo51wiil
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235422-uo51wiil/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0bm90tgz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235436-0bm90tgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-614
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0bm90tgz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.75it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 163.78it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 162.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 163.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 165.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 166.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 164.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 165.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 165.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 165.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.161
wandb: best_valid_acc 0.14
wandb:  sub_train_acc 0.1581
wandb: sub_train_loss 1.34182
wandb:       test_acc 0.16
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run fluent-sweep-614 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0bm90tgz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235436-0bm90tgz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dezb8io3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235452-dezb8io3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-615
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dezb8io3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.68it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 163.87it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 163.17it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 161.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 166.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 169.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 171.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 173.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 172.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 174.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 173.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.263
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.16982
wandb: sub_train_loss 1.31814
wandb:       test_acc 0.174
wandb:      valid_acc 0.148
wandb: 
wandb: üöÄ View run bumbling-sweep-615 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dezb8io3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235452-dezb8io3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s8sy79bw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235507-s8sy79bw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-616
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s8sy79bw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.16it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.03it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 170.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 171.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 170.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 163.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 143.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 133.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 135.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 135.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 133.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 133.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.255
wandb: best_valid_acc 0.222
wandb:  sub_train_acc 0.17403
wandb: sub_train_loss 1.3222
wandb:       test_acc 0.177
wandb:      valid_acc 0.15
wandb: 
wandb: üöÄ View run wise-sweep-616 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s8sy79bw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235507-s8sy79bw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wz80kz14 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235525-wz80kz14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-617
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wz80kz14
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.58it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 140.68it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 142.59it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 146.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 147.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 145.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 145.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 145.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 145.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 150.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 153.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 153.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.317
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.32612
wandb: sub_train_loss 1.28117
wandb:       test_acc 0.318
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run olive-sweep-617 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wz80kz14
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235525-wz80kz14/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ur8bpyb7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235537-ur8bpyb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-618
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ur8bpyb7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.24it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.13it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 147.75it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 149.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 153.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 155.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 157.15it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 157.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 157.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 157.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 157.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 155.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.30237
wandb: sub_train_loss 1.34299
wandb:       test_acc 0.317
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run light-sweep-618 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ur8bpyb7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235537-ur8bpyb7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w5jzht3h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235553-w5jzht3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-619
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w5jzht3h
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.73it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 154.00it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 156.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 157.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 161.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 163.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 162.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 162.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 161.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 161.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 160.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 160.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.348
wandb: best_valid_acc 0.352
wandb:  sub_train_acc 0.30237
wandb: sub_train_loss 1.38978
wandb:       test_acc 0.358
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run honest-sweep-619 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/w5jzht3h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235553-w5jzht3h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o0dy2wyx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235614-o0dy2wyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-620
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o0dy2wyx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.65it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 152.65it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 153.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 155.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 142.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 140.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 143.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 145.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 145.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 146.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 148.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 153.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.327
wandb: best_valid_acc 0.326
wandb:  sub_train_acc 0.27262
wandb: sub_train_loss 1.35821
wandb:       test_acc 0.328
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run firm-sweep-620 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o0dy2wyx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235614-o0dy2wyx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wj3xyqo7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235630-wj3xyqo7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-621
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wj3xyqo7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.19it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.19it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.32it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 152.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 155.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 157.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 158.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 160.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 161.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 162.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 162.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 162.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.519
wandb: best_valid_acc 0.5
wandb:  sub_train_acc 0.4758
wandb: sub_train_loss 1.35365
wandb:       test_acc 0.519
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run dry-sweep-621 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wj3xyqo7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235630-wj3xyqo7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5lmpx0rl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235644-5lmpx0rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-622
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5lmpx0rl
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.76it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 137.42it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 137.56it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 139.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 139.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 141.31it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 140.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 141.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 140.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 134.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 135.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 132.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 131.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.466
wandb: best_valid_acc 0.442
wandb:  sub_train_acc 0.43793
wandb: sub_train_loss 1.35537
wandb:       test_acc 0.466
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run light-sweep-622 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5lmpx0rl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235644-5lmpx0rl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ti6535ii with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235700-ti6535ii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-623
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ti6535ii
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.04it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 141.33it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 143.45it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 144.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 145.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 145.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 145.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 144.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 146.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 148.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 146.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 145.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 147.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.643
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.65434
wandb: sub_train_loss 1.34057
wandb:       test_acc 0.645
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run breezy-sweep-623 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ti6535ii
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235700-ti6535ii/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gpuyf8p3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235715-gpuyf8p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-624
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gpuyf8p3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.41it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.72it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.17it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 144.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 140.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 143.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 145.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 146.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 140.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 134.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 136.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 139.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 143.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.644
wandb: best_valid_acc 0.65
wandb:  sub_train_acc 0.6306
wandb: sub_train_loss 1.33713
wandb:       test_acc 0.615
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run lucky-sweep-624 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gpuyf8p3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235715-gpuyf8p3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: frwounfp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235730-frwounfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-625
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/frwounfp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.38it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 206.24it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 214.15it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 218.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 224.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 228.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 231.40it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 230.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 225.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 229.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 228.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 226.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.246
wandb: best_valid_acc 0.194
wandb:  sub_train_acc 0.12684
wandb: sub_train_loss 1.66478
wandb:       test_acc 0.246
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run crisp-sweep-625 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/frwounfp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235730-frwounfp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r9s3wgkg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235742-r9s3wgkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-626
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r9s3wgkg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 230.19it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 232.65it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 232.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 233.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 231.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 231.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 229.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 228.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 225.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 225.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 226.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 224.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 227.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.261
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.22573
wandb: sub_train_loss 1.66092
wandb:       test_acc 0.265
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run clean-sweep-626 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/r9s3wgkg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235742-r9s3wgkg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7kieujac with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235756-7kieujac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-627
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7kieujac
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 207.08it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.81it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 219.49it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 221.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 223.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 228.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 229.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 227.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 227.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 224.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 221.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 218.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 217.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 221.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.281
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.25068
wandb: sub_train_loss 1.678
wandb:       test_acc 0.281
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run swift-sweep-627 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/7kieujac
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235756-7kieujac/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vrfttl3o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235812-vrfttl3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-628
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vrfttl3o
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 232.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 234.83it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 233.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 222.67it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 217.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 215.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 214.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 214.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 217.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 221.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 224.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 227.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 223.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.277
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.24076
wandb: sub_train_loss 1.67786
wandb:       test_acc 0.278
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run genial-sweep-628 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/vrfttl3o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235812-vrfttl3o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kv4t7g81 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235826-kv4t7g81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-629
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kv4t7g81
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 218.84it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 222.07it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 219.09it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 202.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 196.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 199.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 195.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 201.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 204.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 208.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 210.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 214.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 215.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 209.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.37722
wandb: sub_train_loss 1.68326
wandb:       test_acc 0.419
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run copper-sweep-629 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/kv4t7g81
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235826-kv4t7g81/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzzwdw5e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235842-nzzwdw5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-630
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzzwdw5e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.32it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.60it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 198.53it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 206.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 213.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 218.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 217.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 220.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 219.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 219.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 215.67it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 204.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 206.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 210.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.403
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.35317
wandb: sub_train_loss 1.68357
wandb:       test_acc 0.379
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run eager-sweep-630 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzzwdw5e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235842-nzzwdw5e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ds8jue1q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235858-ds8jue1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-631
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ds8jue1q
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 207.22it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 199.72it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 199.02it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 205.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 215.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 220.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 223.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 225.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 222.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 225.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 224.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 226.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 227.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.23
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.21371
wandb: sub_train_loss 1.68219
wandb:       test_acc 0.23
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run lively-sweep-631 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ds8jue1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235858-ds8jue1q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gok8f9ui with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235919-gok8f9ui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-632
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gok8f9ui
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 196.95it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 208.85it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 214.94it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 215.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 218.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 210.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 209.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 216.44it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 219.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 221.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 223.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 224.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 224.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 218.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.258
wandb:  sub_train_acc 0.24737
wandb: sub_train_loss 1.68323
wandb:       test_acc 0.276
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run earthy-sweep-632 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gok8f9ui
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235919-gok8f9ui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 08s6mik8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235933-08s6mik8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-633
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/08s6mik8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 207.76it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 209.78it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 210.54it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 211.10it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 210.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 209.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 210.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 213.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 214.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 216.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 217.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 218.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 220.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.215
wandb: best_valid_acc 0.184
wandb:  sub_train_acc 0.21551
wandb: sub_train_loss 1.69252
wandb:       test_acc 0.219
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run solar-sweep-633 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/08s6mik8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235933-08s6mik8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oxmfdpsz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235949-oxmfdpsz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-634
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oxmfdpsz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 213.18it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.21it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 218.85it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 219.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 219.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 218.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 217.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 217.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 219.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 220.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 221.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 222.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 223.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.253
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.26661
wandb: sub_train_loss 1.69282
wandb:       test_acc 0.26
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run desert-sweep-634 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/oxmfdpsz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235949-oxmfdpsz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ojorew94 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000005-ojorew94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-635
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ojorew94
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.43it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 203.28it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 203.54it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 205.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 203.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 204.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 204.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 207.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 207.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 209.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 209.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 208.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 207.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 207.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 206.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.113
wandb: best_valid_acc 0.1
wandb:  sub_train_acc 0.12684
wandb: sub_train_loss 1.69467
wandb:       test_acc 0.105
wandb:      valid_acc 0.09
wandb: 
wandb: üöÄ View run unique-sweep-635 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ojorew94
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000005-ojorew94/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y5kc5eyb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000025-y5kc5eyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-636
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y5kc5eyb
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 194.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 188.30it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 188.42it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 194.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 196.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 191.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 188.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 190.67it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 193.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 194.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 198.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 203.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 205.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.194
wandb: best_valid_acc 0.204
wandb:  sub_train_acc 0.12864
wandb: sub_train_loss 1.69501
wandb:       test_acc 0.105
wandb:      valid_acc 0.098
wandb: 
wandb: üöÄ View run skilled-sweep-636 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/y5kc5eyb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000025-y5kc5eyb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: whg8sd6w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000040-whg8sd6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-637
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/whg8sd6w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.82it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.62it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 186.33it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 188.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 188.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 194.12it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 199.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 202.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 202.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 198.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 195.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 194.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 193.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 192.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.28
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.29726
wandb: sub_train_loss 1.69593
wandb:       test_acc 0.303
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run feasible-sweep-637 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/whg8sd6w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000040-whg8sd6w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h3gkfkll with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000052-h3gkfkll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-638
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h3gkfkll
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.33it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.86it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 185.31it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 187.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 190.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 191.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 193.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 195.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 194.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 194.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 193.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 193.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 190.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 186.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 182.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.289
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.27592
wandb: sub_train_loss 1.69569
wandb:       test_acc 0.291
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run solar-sweep-638 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h3gkfkll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000052-h3gkfkll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o5newrbn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000106-o5newrbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-639
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o5newrbn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.17it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 188.14it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 187.52it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 185.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 186.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 187.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 189.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 189.64it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 191.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 192.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 192.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 193.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 193.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 193.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.597
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.59152
wandb: sub_train_loss 1.7014
wandb:       test_acc 0.597
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run divine-sweep-639 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o5newrbn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000106-o5newrbn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5u2jvt9g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000121-5u2jvt9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-640
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5u2jvt9g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 196.76it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 196.22it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 195.19it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 189.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 181.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 177.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 173.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 172.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 172.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 174.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 174.40it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 172.67it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 165.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 165.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 168.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 169.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.61
wandb: best_valid_acc 0.612
wandb:  sub_train_acc 0.61317
wandb: sub_train_loss 1.70136
wandb:       test_acc 0.618
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run leafy-sweep-640 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5u2jvt9g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000121-5u2jvt9g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zovtyqd0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000142-zovtyqd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-641
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zovtyqd0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.44it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.69it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 182.36it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 175.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 181.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 183.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 186.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 189.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 189.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 188.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 190.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 190.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 188.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 189.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 191.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.263
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.21371
wandb: sub_train_loss 1.18959
wandb:       test_acc 0.232
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run kind-sweep-641 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zovtyqd0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000142-zovtyqd0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 48dsy569 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000158-48dsy569
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-642
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/48dsy569
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.25it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 177.16it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 176.12it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 179.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 184.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 185.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 186.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 189.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 189.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 186.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 181.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 178.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 176.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 174.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 172.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.274
wandb:  sub_train_acc 0.19808
wandb: sub_train_loss 1.06299
wandb:       test_acc 0.234
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run dry-sweep-642 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/48dsy569
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000158-48dsy569/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 332nqjvh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000214-332nqjvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-643
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/332nqjvh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 183.39it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.46it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.16it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 184.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 185.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 186.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 187.08it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 187.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 188.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 189.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 186.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 185.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 186.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 186.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.195
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.22723
wandb: sub_train_loss 1.24091
wandb:       test_acc 0.195
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run rural-sweep-643 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/332nqjvh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000214-332nqjvh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ykn54y92 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000228-ykn54y92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-644
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ykn54y92
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.81it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.75it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 193.40it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 194.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 194.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 193.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 190.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 190.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 188.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 190.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 189.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 186.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 185.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 180.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 172.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.206
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.23354
wandb: sub_train_loss 1.24186
wandb:       test_acc 0.208
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run lunar-sweep-644 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ykn54y92
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000228-ykn54y92/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v4ygntjh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000249-v4ygntjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-645
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v4ygntjh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.41it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.29it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 188.61it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 189.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 187.61it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 189.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 191.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 192.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 187.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 185.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 187.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 189.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 191.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 191.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 190.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.28
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.25398
wandb: sub_train_loss 1.20936
wandb:       test_acc 0.29
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run exalted-sweep-645 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v4ygntjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000249-v4ygntjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8dxvffe1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000307-8dxvffe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-646
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8dxvffe1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.65it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 152.20it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 151.07it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 147.37it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 147.57it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 148.54it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 155.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 157.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 162.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 166.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 165.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 162.62it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 162.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 162.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 159.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 156.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 157.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.342
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.33784
wandb: sub_train_loss 1.15823
wandb:       test_acc 0.222
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run smooth-sweep-646 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8dxvffe1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000307-8dxvffe1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1m6mma9e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000322-1m6mma9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-647
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1m6mma9e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.64it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.78it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.01it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 171.87it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 168.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 170.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 176.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 173.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 169.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 158.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 157.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 156.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 154.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 145.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 150.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 155.97it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 160.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.198
wandb: best_valid_acc 0.194
wandb:  sub_train_acc 0.19928
wandb: sub_train_loss 1.13598
wandb:       test_acc 0.198
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run lilac-sweep-647 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/1m6mma9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000322-1m6mma9e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zk5ctagd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000338-zk5ctagd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-648
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zk5ctagd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.69it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 160.03it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 162.38it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 166.22it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 165.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 159.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 147.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 144.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:01, 143.01it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 141.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 141.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 150.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 155.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 160.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 158.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 155.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 154.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 156.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.188
wandb: best_valid_acc 0.178
wandb:  sub_train_acc 0.22543
wandb: sub_train_loss 1.1782
wandb:       test_acc 0.188
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run zesty-sweep-648 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zk5ctagd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000338-zk5ctagd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: djhk2pxw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000353-djhk2pxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-649
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/djhk2pxw
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.89it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 170.59it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 166.65it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 165.99it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 163.70it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 164.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 166.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 168.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 158.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 151.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 146.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 151.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 154.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 157.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 160.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 160.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 164.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 161.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.442
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.40667
wandb: sub_train_loss 1.21213
wandb:       test_acc 0.439
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run eager-sweep-649 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/djhk2pxw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000353-djhk2pxw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f5qh5663 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000408-f5qh5663
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-650
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f5qh5663
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.96it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 157.77it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 159.60it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 160.47it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 159.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 160.33it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 162.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 169.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 172.88it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 173.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 169.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 173.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 174.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 175.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 174.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 172.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.314
wandb:  sub_train_acc 0.28975
wandb: sub_train_loss 1.17069
wandb:       test_acc 0.305
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run rural-sweep-650 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f5qh5663
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000408-f5qh5663/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: houy37mu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000427-houy37mu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-651
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/houy37mu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.58it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 158.58it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 157.89it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 157.21it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 159.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 162.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 166.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 170.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 174.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 177.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 180.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 181.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 182.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 183.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 184.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 185.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.457
wandb: best_valid_acc 0.44
wandb:  sub_train_acc 0.2633
wandb: sub_train_loss 1.25469
wandb:       test_acc 0.26
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run bumbling-sweep-651 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/houy37mu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000427-houy37mu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sfjaj010 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000442-sfjaj010
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-652
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfjaj010
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.17it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 166.90it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 166.99it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 169.96it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 172.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 171.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 172.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 165.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 161.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 158.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 158.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 155.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 153.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 153.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 152.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 156.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 156.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.389
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.30899
wandb: sub_train_loss 1.24623
wandb:       test_acc 0.389
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run olive-sweep-652 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/sfjaj010
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000442-sfjaj010/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2r7qki6m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000457-2r7qki6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-653
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2r7qki6m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.62it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 144.68it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 130.88it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 137.14it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 143.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 146.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 149.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 153.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 153.97it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 154.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 156.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 156.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 154.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 153.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 153.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 152.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 152.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.494
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.4734
wandb: sub_train_loss 1.21752
wandb:       test_acc 0.496
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run unique-sweep-653 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2r7qki6m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000457-2r7qki6m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 23oaentg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000513-23oaentg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-654
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/23oaentg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.67it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 171.36it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.01it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 170.41it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 171.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 170.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 168.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 167.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 168.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 169.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 170.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 169.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 169.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 170.09it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 170.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 171.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.552
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.51247
wandb: sub_train_loss 1.2323
wandb:       test_acc 0.552
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run fallen-sweep-654 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/23oaentg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000513-23oaentg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p3q090xd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000528-p3q090xd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-655
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p3q090xd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.29it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.40it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.97it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 150.92it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 153.69it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 155.16it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 156.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 155.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 155.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 155.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 155.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 157.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 158.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 158.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 159.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 159.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 157.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 156.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.678
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.61797
wandb: sub_train_loss 1.21648
wandb:       test_acc 0.623
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run logical-sweep-655 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p3q090xd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000528-p3q090xd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bu2lpspp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000543-bu2lpspp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-656
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bu2lpspp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.74it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.89it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.09it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.29it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 152.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 153.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 156.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 154.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 152.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 152.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 153.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 154.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 159.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 163.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 165.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 167.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 168.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.625
wandb: best_valid_acc 0.65
wandb:  sub_train_acc 0.64022
wandb: sub_train_loss 1.24146
wandb:       test_acc 0.625
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run hopeful-sweep-656 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bu2lpspp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000543-bu2lpspp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lcgbftbt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000559-lcgbftbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-657
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lcgbftbt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.22it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.04it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.05it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 156.88it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 160.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 157.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 151.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 145.30it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:01, 142.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 141.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 141.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 139.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 140.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 142.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 146.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 147.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 146.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 145.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 143.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.33
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.15449
wandb: sub_train_loss 0.69671
wandb:       test_acc 0.261
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run volcanic-sweep-657 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lcgbftbt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000559-lcgbftbt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c1hv1o52 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000614-c1hv1o52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-658
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/c1hv1o52
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.06it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 161.57it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 158.76it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 154.28it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 154.98it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 157.14it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 158.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 159.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 158.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 155.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 156.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 158.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 159.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 158.03it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 156.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 158.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 159.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 160.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.231
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.15299
wandb: sub_train_loss 0.71875
wandb:       test_acc 0.232
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run legendary-sweep-658 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/c1hv1o52
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000614-c1hv1o52/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q231i1za with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000629-q231i1za
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-659
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q231i1za
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.27it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 151.76it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 152.87it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 151.34it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 149.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 151.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 158.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 163.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 167.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 169.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 169.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 169.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 169.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 169.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 170.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 171.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.191
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.2119
wandb: sub_train_loss 0.90306
wandb:       test_acc 0.082
wandb:      valid_acc 0.064
wandb: 
wandb: üöÄ View run stellar-sweep-659 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/q231i1za
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000629-q231i1za/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9yf2ypo0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000645-9yf2ypo0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-660
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9yf2ypo0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.08it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.64it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 159.09it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 158.05it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 157.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 154.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 145.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 146.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 144.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 144.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 143.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 145.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 147.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 146.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 148.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 148.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 149.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 144.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 142.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.386
wandb:  sub_train_acc 0.21731
wandb: sub_train_loss 0.88181
wandb:       test_acc 0.099
wandb:      valid_acc 0.114
wandb: 
wandb: üöÄ View run dry-sweep-660 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9yf2ypo0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000645-9yf2ypo0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uof4mb7b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000701-uof4mb7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-661
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uof4mb7b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.65it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 159.14it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.68it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 162.44it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 159.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 162.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 164.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 164.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 163.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 162.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 164.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 163.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 160.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 161.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 161.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 161.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 159.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.31921
wandb: sub_train_loss 0.75628
wandb:       test_acc 0.271
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run smart-sweep-661 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/uof4mb7b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000701-uof4mb7b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: csl4p1y1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000716-csl4p1y1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-662
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/csl4p1y1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.16it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 119.36it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 126.35it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 134.87it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 136.39it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 135.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 138.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 139.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 142.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 144.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 147.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 147.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 137.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 131.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 129.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 131.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 134.92it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 139.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 141.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 144.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.329
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.2645
wandb: sub_train_loss 0.78397
wandb:       test_acc 0.288
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run breezy-sweep-662 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/csl4p1y1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000716-csl4p1y1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 30hsyycy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000732-30hsyycy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-663
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/30hsyycy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.83it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 159.81it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 161.59it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 163.01it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 162.78it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 164.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 165.20it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 165.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 165.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 164.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 155.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 157.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 158.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 159.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 159.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 157.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 156.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.437
wandb: best_valid_acc 0.444
wandb:  sub_train_acc 0.45386
wandb: sub_train_loss 0.6335
wandb:       test_acc 0.437
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run whole-sweep-663 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/30hsyycy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000732-30hsyycy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3li1nibu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000747-3li1nibu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-664
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3li1nibu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.95it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.29it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.64it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 134.05it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 135.62it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 135.68it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 137.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 143.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 144.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 136.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 139.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 139.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 140.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 141.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 143.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 143.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 142.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 140.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 140.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 140.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.378
wandb: best_valid_acc 0.382
wandb:  sub_train_acc 0.30809
wandb: sub_train_loss 0.60307
wandb:       test_acc 0.386
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run fine-sweep-664 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3li1nibu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000747-3li1nibu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hq97vkxg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000802-hq97vkxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-665
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hq97vkxg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.25it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.08it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 167.06it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 166.99it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 166.83it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 167.05it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 166.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 165.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 167.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 169.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 169.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 170.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 168.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 167.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 167.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 167.84it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 165.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.482
wandb: best_valid_acc 0.484
wandb:  sub_train_acc 0.39585
wandb: sub_train_loss 0.67755
wandb:       test_acc 0.486
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run dandy-sweep-665 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hq97vkxg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000802-hq97vkxg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2wy0kb2t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000821-2wy0kb2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-666
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2wy0kb2t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.67it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.12it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 133.01it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 135.74it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 139.34it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 143.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 150.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 155.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 159.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 161.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 160.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 161.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 164.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 161.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 160.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 158.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 154.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.438
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.36189
wandb: sub_train_loss 0.67075
wandb:       test_acc 0.442
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run golden-sweep-666 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2wy0kb2t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000821-2wy0kb2t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3iduwaf9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000837-3iduwaf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-667
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3iduwaf9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.53it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 143.30it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 141.90it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 142.90it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 140.38it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 137.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 136.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 135.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 133.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 131.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 134.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 136.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 139.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 141.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 142.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 142.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 143.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 141.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 140.01it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 141.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.552
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.44965
wandb: sub_train_loss 0.54104
wandb:       test_acc 0.552
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run skilled-sweep-667 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3iduwaf9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000837-3iduwaf9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 65louxk9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000851-65louxk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-668
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/65louxk9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 158.90it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 160.71it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 163.01it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 163.18it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 160.71it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 160.48it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 158.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 160.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 161.41it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 163.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 163.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 162.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 162.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 161.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 159.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 157.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 157.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.546
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.42771
wandb: sub_train_loss 0.56349
wandb:       test_acc 0.546
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run volcanic-sweep-668 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/65louxk9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000851-65louxk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aeg98bal with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000907-aeg98bal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-669
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/aeg98bal
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.57it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.96it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.60it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.10it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 156.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 156.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 155.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 153.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 151.49it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 148.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 147.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 145.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 144.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 145.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 144.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 144.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 144.17it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 144.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.54764
wandb: sub_train_loss 0.71972
wandb:       test_acc 0.601
wandb:      valid_acc 0.616
wandb: 
wandb: üöÄ View run true-sweep-669 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/aeg98bal
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000907-aeg98bal/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h9q8qjwg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000922-h9q8qjwg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-670
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h9q8qjwg
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.03it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.11it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 138.51it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 140.32it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 142.49it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 145.63it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 148.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 152.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 140.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 146.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 150.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 151.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 146.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 144.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 145.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 146.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 146.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 147.41it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 149.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.519
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.48813
wandb: sub_train_loss 0.61082
wandb:       test_acc 0.523
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run helpful-sweep-670 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h9q8qjwg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000922-h9q8qjwg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tztacgb9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000943-tztacgb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-671
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tztacgb9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.04it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.13it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.30it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 155.33it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 155.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 150.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 150.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 149.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 149.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 150.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 148.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 145.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 143.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 143.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 147.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.672
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.66877
wandb: sub_train_loss 0.51468
wandb:       test_acc 0.664
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run lucky-sweep-671 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tztacgb9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000943-tztacgb9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n8e2a5ya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001000-n8e2a5ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-672
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n8e2a5ya
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.28it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.34it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 137.73it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 143.35it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 147.72it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 149.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 148.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 150.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 147.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 147.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 148.03it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 148.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 149.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 147.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 148.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 148.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 146.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 142.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 140.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.645
wandb: best_valid_acc 0.65
wandb:  sub_train_acc 0.63781
wandb: sub_train_loss 0.78446
wandb:       test_acc 0.645
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run wandering-sweep-672 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/n8e2a5ya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001000-n8e2a5ya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bpx4s24x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001022-bpx4s24x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-673
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bpx4s24x
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 272.66it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 263.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 283.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 290.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 294.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 297.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.273
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.24106
wandb: sub_train_loss 1.72988
wandb:       test_acc 0.273
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run wise-sweep-673 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bpx4s24x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001022-bpx4s24x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: myruhy6g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001036-myruhy6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-674
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/myruhy6g
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 253.82it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 255.60it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 248.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 239.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 242.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 247.10it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 255.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 252.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.296
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.25188
wandb: sub_train_loss 1.73168
wandb:       test_acc 0.296
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run logical-sweep-674 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/myruhy6g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001036-myruhy6g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ojaghrp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001052-3ojaghrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-675
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3ojaghrp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 276.96it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 274.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 267.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 267.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 269.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 269.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 267.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.3168
wandb: sub_train_loss 1.74479
wandb:       test_acc 0.322
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run usual-sweep-675 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3ojaghrp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001052-3ojaghrp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z8wh1l1o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001107-z8wh1l1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-676
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z8wh1l1o
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.41it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 209.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 213.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 210.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 209.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 217.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 227.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 232.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 222.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.322
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.30899
wandb: sub_train_loss 1.74565
wandb:       test_acc 0.322
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run sweet-sweep-676 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z8wh1l1o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001107-z8wh1l1o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m1l3tb3m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001121-m1l3tb3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-677
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m1l3tb3m
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 276.37it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 282.08it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 283.41it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 294.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 298.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 299.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 296.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.389
wandb: best_valid_acc 0.44
wandb:  sub_train_acc 0.37271
wandb: sub_train_loss 1.75274
wandb:       test_acc 0.395
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run solar-sweep-677 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/m1l3tb3m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001121-m1l3tb3m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8sye274l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001137-8sye274l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-678
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8sye274l
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.49it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 191.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 188.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 202.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 217.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 229.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 239.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 252.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 230.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.402
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.38263
wandb: sub_train_loss 1.7525
wandb:       test_acc 0.403
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run zesty-sweep-678 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8sye274l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001137-8sye274l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0wtgs24p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001153-0wtgs24p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-679
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0wtgs24p
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 279.93it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 283.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 284.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 269.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 280.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 289.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 284.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.262
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.25008
wandb: sub_train_loss 1.75775
wandb:       test_acc 0.267
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run major-sweep-679 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0wtgs24p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001153-0wtgs24p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zlwp8542 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001208-zlwp8542
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-680
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zlwp8542
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 284.56it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 300.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 301.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 305.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 308.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 303.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 300.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.264
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.25729
wandb: sub_train_loss 1.75761
wandb:       test_acc 0.268
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run kind-sweep-680 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zlwp8542
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001208-zlwp8542/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cdzre224 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001219-cdzre224
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-681
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cdzre224
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 275.46it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 254.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 243.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 248.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 246.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 256.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 265.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 258.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.203
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.20349
wandb: sub_train_loss 1.76103
wandb:       test_acc 0.205
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run royal-sweep-681 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/cdzre224
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001219-cdzre224/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: svwo4qda with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001234-svwo4qda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-682
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/svwo4qda
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 250.90it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 258.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 256.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 257.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 261.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 271.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 278.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.184
wandb:  sub_train_acc 0.20559
wandb: sub_train_loss 1.76121
wandb:       test_acc 0.206
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run eager-sweep-682 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/svwo4qda
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001234-svwo4qda/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u1bxyafu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001250-u1bxyafu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-683
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1bxyafu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 298.58it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 285.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 282.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 283.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 282.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 283.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 284.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.201
wandb: best_valid_acc 0.182
wandb:  sub_train_acc 0.14457
wandb: sub_train_loss 1.76323
wandb:       test_acc 0.128
wandb:      valid_acc 0.098
wandb: 
wandb: üöÄ View run peachy-sweep-683 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/u1bxyafu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001250-u1bxyafu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zzqvq8n7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001304-zzqvq8n7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-684
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zzqvq8n7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 313.28it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 318.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 318.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 315.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 310.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 309.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 312.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.191
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.1569
wandb: sub_train_loss 1.76275
wandb:       test_acc 0.139
wandb:      valid_acc 0.11
wandb: 
wandb: üöÄ View run jumping-sweep-684 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zzqvq8n7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001304-zzqvq8n7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ap1e9nrz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001320-ap1e9nrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-685
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ap1e9nrz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 269.40it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 255.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 241.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 239.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 244.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 254.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 265.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 257.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.343
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.3162
wandb: sub_train_loss 1.76507
wandb:       test_acc 0.319
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run vocal-sweep-685 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ap1e9nrz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001320-ap1e9nrz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e2ig8gp0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001335-e2ig8gp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-686
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2ig8gp0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.60it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 271.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 261.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 247.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 254.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 261.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 266.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 263.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.328
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.29306
wandb: sub_train_loss 1.76471
wandb:       test_acc 0.299
wandb:      valid_acc 0.276
wandb: 
wandb: üöÄ View run likely-sweep-686 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2ig8gp0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001335-e2ig8gp0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gckp9e0y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001351-gckp9e0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-687
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gckp9e0y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 296.87it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 299.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 299.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 249.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 251.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 249.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 252.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 260.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.59273
wandb: sub_train_loss 1.7674
wandb:       test_acc 0.599
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run magic-sweep-687 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gckp9e0y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001351-gckp9e0y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2aqd3yc9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001406-2aqd3yc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-688
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2aqd3yc9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 291.91it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 300.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 303.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 305.04it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 303.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 303.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 302.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.512
wandb:  sub_train_acc 0.50917
wandb: sub_train_loss 1.76744
wandb:       test_acc 0.508
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run glad-sweep-688 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2aqd3yc9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001406-2aqd3yc9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0ctt79w0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001422-0ctt79w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-689
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0ctt79w0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.14it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 179.14it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 182.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 185.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 184.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 182.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 183.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 187.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 191.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 190.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.305
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.2657
wandb: sub_train_loss 1.40375
wandb:       test_acc 0.298
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run restful-sweep-689 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/0ctt79w0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001422-0ctt79w0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k382alos with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001437-k382alos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-690
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k382alos
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.90it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.09it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 147.94it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 144.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 143.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 141.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 145.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 148.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 150.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 152.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 153.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 150.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.313
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.27532
wandb: sub_train_loss 1.39739
wandb:       test_acc 0.313
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run dandy-sweep-690 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/k382alos
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001437-k382alos/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i6pidneh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001459-i6pidneh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-691
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i6pidneh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.17it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 172.55it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 172.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 174.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 175.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 177.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 177.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 181.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 184.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 188.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 181.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.3183
wandb: sub_train_loss 1.46129
wandb:       test_acc 0.307
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run hopeful-sweep-691 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i6pidneh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001459-i6pidneh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d3w5lavm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001513-d3w5lavm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-692
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d3w5lavm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.03it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.32it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.70it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 166.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 171.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 170.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 166.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 170.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 150.59it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 133.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 136.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.33
wandb: best_valid_acc 0.394
wandb:  sub_train_acc 0.32402
wandb: sub_train_loss 1.47197
wandb:       test_acc 0.33
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run sweet-sweep-692 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/d3w5lavm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001513-d3w5lavm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5r9fnnis with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001529-5r9fnnis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-693
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5r9fnnis
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.17it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 180.16it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 185.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 189.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 189.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 182.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 172.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 171.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 169.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 160.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.38112
wandb: sub_train_loss 1.50616
wandb:       test_acc 0.414
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run bright-sweep-693 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5r9fnnis
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001529-5r9fnnis/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: waxqpb6e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001545-waxqpb6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-694
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/waxqpb6e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.41it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 179.51it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.07it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 174.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 173.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 176.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 179.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 179.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 178.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.504
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.45026
wandb: sub_train_loss 1.51013
wandb:       test_acc 0.505
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run tough-sweep-694 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/waxqpb6e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001545-waxqpb6e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: l2ps5h3u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001606-l2ps5h3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-695
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l2ps5h3u
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.24it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.89it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 185.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 188.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 187.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 181.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 181.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 178.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 176.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 172.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.22
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.24677
wandb: sub_train_loss 1.54805
wandb:       test_acc 0.22
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run soft-sweep-695 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/l2ps5h3u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001606-l2ps5h3u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wq37qh5q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001621-wq37qh5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-696
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wq37qh5q
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.66it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 193.80it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 184.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 181.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 179.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 176.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 166.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 167.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 172.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 177.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.333
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.33273
wandb: sub_train_loss 1.55663
wandb:       test_acc 0.333
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run good-sweep-696 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wq37qh5q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001621-wq37qh5q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ahph6f30 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001636-ahph6f30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-697
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ahph6f30
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.86it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 174.86it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 174.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 131.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 120.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 119.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 125.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 132.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 132.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 137.53it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 149.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 160.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.483
wandb: best_valid_acc 0.484
wandb:  sub_train_acc 0.48001
wandb: sub_train_loss 1.56651
wandb:       test_acc 0.485
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run ethereal-sweep-697 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ahph6f30
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001636-ahph6f30/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 15se8ync with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001654-15se8ync
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-698
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/15se8ync
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 162.44it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 172.51it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 176.56it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 177.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 178.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 176.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 178.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 177.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 177.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 177.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.377
wandb: best_valid_acc 0.346
wandb:  sub_train_acc 0.38623
wandb: sub_train_loss 1.57163
wandb:       test_acc 0.378
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run jolly-sweep-698 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/15se8ync
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001654-15se8ync/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rw9jvg63 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001707-rw9jvg63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-699
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rw9jvg63
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.07it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 163.24it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 162.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 164.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 163.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 162.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 160.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 163.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 167.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 167.50it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 168.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.281
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.32492
wandb: sub_train_loss 1.59312
wandb:       test_acc 0.287
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run polar-sweep-699 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/rw9jvg63
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001707-rw9jvg63/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8etxb3p8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001722-8etxb3p8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-700
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8etxb3p8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.14it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.81it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 165.48it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 169.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 168.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 164.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 153.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 149.88it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 150.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 151.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 155.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.26901
wandb: sub_train_loss 1.58619
wandb:       test_acc 0.227
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run giddy-sweep-700 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8etxb3p8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001722-8etxb3p8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zkd34853 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001743-zkd34853
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-701
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zkd34853
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.14it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.15it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 168.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 170.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 167.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 164.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 160.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 158.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 156.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 158.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 161.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.348
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.36309
wandb: sub_train_loss 1.60937
wandb:       test_acc 0.348
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run sweet-sweep-701 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/zkd34853
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001743-zkd34853/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fjmy3aly with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001759-fjmy3aly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-702
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fjmy3aly
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.70it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.01it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 185.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 186.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 192.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 192.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 191.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 192.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 192.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 193.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 191.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.398
wandb: best_valid_acc 0.38
wandb:  sub_train_acc 0.40457
wandb: sub_train_loss 1.59772
wandb:       test_acc 0.398
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run bumbling-sweep-702 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fjmy3aly
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001759-fjmy3aly/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hmigmr8y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001815-hmigmr8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-703
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hmigmr8y
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.63it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 165.58it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 162.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 161.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 159.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 160.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 162.14it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 165.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 168.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 169.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 170.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.667
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.66546
wandb: sub_train_loss 1.61728
wandb:       test_acc 0.671
wandb:      valid_acc 0.678
wandb: 
wandb: üöÄ View run fragrant-sweep-703 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hmigmr8y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001815-hmigmr8y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: plhym2gr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001829-plhym2gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-704
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/plhym2gr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.52it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.16it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 158.84it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 165.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 172.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 176.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 179.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 180.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 173.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 169.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 169.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.593
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.61437
wandb: sub_train_loss 1.61655
wandb:       test_acc 0.595
wandb:      valid_acc 0.634
wandb: 
wandb: üöÄ View run good-sweep-704 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/plhym2gr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001829-plhym2gr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bvf0xmzd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001851-bvf0xmzd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-705
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bvf0xmzd
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.31it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.44it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 122.20it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 117.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 109.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 110.31it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 115.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 115.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 116.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 121.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 123.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 126.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 128.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 130.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 130.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.314
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.27683
wandb: sub_train_loss 1.07524
wandb:       test_acc 0.314
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run sparkling-sweep-705 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bvf0xmzd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001851-bvf0xmzd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4i0wzxcv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001907-4i0wzxcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-706
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4i0wzxcv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.38it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.68it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.98it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 127.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 128.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 128.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 128.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 125.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 129.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 133.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 134.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 133.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 132.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 133.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.24707
wandb: sub_train_loss 1.05104
wandb:       test_acc 0.295
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run wandering-sweep-706 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4i0wzxcv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001907-4i0wzxcv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gve2725b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001922-gve2725b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-707
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gve2725b
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.40it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 127.80it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 128.72it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 128.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 114.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 112.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 115.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 121.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 123.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 124.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 125.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 125.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 124.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 124.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 122.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.384
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.35918
wandb: sub_train_loss 1.15734
wandb:       test_acc 0.39
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run lucky-sweep-707 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gve2725b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001922-gve2725b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lndcr6gr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001943-lndcr6gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-708
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lndcr6gr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.86it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 128.37it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.00it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 132.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 129.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 133.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 132.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 125.39it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 129.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 133.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 136.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 138.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 139.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.312
wandb: best_valid_acc 0.384
wandb:  sub_train_acc 0.3174
wandb: sub_train_loss 1.14576
wandb:       test_acc 0.314
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run firm-sweep-708 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lndcr6gr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001943-lndcr6gr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x9jm1rn7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001959-x9jm1rn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-709
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x9jm1rn7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.02it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 128.60it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 126.26it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 132.09it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 138.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 141.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 141.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 142.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 138.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 137.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 137.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 134.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 136.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.404
wandb: best_valid_acc 0.392
wandb:  sub_train_acc 0.38623
wandb: sub_train_loss 1.24391
wandb:       test_acc 0.396
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run lyric-sweep-709 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/x9jm1rn7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001959-x9jm1rn7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 04g3m8fs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002013-04g3m8fs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-710
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/04g3m8fs
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.67it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.29it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.49it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 120.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 114.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 114.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 116.54it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 115.37it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 116.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 115.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 115.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 119.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 122.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 125.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 127.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.37181
wandb: sub_train_loss 1.27166
wandb:       test_acc 0.411
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run dry-sweep-710 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/04g3m8fs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002013-04g3m8fs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pwlhcw31 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002025-pwlhcw31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-711
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pwlhcw31
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.14it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 129.40it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.82it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 131.73it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 132.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 135.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 136.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 138.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 137.88it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 137.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 137.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 139.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 137.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 138.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.209
wandb: best_valid_acc 0.198
wandb:  sub_train_acc 0.27442
wandb: sub_train_loss 1.33852
wandb:       test_acc 0.209
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run lively-sweep-711 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pwlhcw31
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002025-pwlhcw31/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hfxfktfp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002040-hfxfktfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-712
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hfxfktfp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.99it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.66it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 138.69it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 138.12it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 138.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 136.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 125.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 115.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 115.87it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 114.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 117.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 120.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 122.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 125.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.542
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.50376
wandb: sub_train_loss 1.30735
wandb:       test_acc 0.542
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run ethereal-sweep-712 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/hfxfktfp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002040-hfxfktfp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lcq953mv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002056-lcq953mv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-713
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lcq953mv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 125.59it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 129.72it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 134.23it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 137.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 140.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 139.44it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 139.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 139.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 138.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 138.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 135.82it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 133.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 134.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 136.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.545
wandb: best_valid_acc 0.532
wandb:  sub_train_acc 0.50015
wandb: sub_train_loss 1.35482
wandb:       test_acc 0.544
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run playful-sweep-713 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lcq953mv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002056-lcq953mv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v2f4nv2e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002110-v2f4nv2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-714
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v2f4nv2e
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.98it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.54it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 142.22it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 142.69it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 143.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 143.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 142.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 141.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 139.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 136.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 136.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 133.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 132.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.359
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.35528
wandb: sub_train_loss 1.33207
wandb:       test_acc 0.363
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run smart-sweep-714 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v2f4nv2e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002110-v2f4nv2e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: coo66tcz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002126-coo66tcz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-715
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/coo66tcz
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.36it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.97it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 148.35it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 149.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 149.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 149.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 150.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 146.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 143.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 144.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 145.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 141.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 141.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.285
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.30117
wandb: sub_train_loss 1.42629
wandb:       test_acc 0.285
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run rose-sweep-715 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/coo66tcz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002126-coo66tcz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzkvcb6j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002142-nzkvcb6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-716
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzkvcb6j
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.17it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.71it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 136.50it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 137.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 134.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 126.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 122.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 110.54it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 111.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 116.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 119.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 124.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 123.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 126.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.263
wandb: best_valid_acc 0.252
wandb:  sub_train_acc 0.30087
wandb: sub_train_loss 1.38013
wandb:       test_acc 0.263
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run leafy-sweep-716 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/nzkvcb6j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002142-nzkvcb6j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xehnh7in with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002156-xehnh7in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-717
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xehnh7in
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.93it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 104.69it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 96.74it/s]  23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 101.37it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 106.59it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 110.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 112.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 114.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 117.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 118.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 122.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 124.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 120.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 114.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 112.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 111.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.479
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.47911
wandb: sub_train_loss 1.43625
wandb:       test_acc 0.489
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run ethereal-sweep-717 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xehnh7in
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002156-xehnh7in/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 59f00u33 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002212-59f00u33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-718
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59f00u33
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.71it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.38it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.84it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 146.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 145.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 139.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 134.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 133.03it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 136.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 138.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 139.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.571
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.54914
wandb: sub_train_loss 1.39523
wandb:       test_acc 0.571
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run charmed-sweep-718 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/59f00u33
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002212-59f00u33/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s62eaxh3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002228-s62eaxh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-719
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s62eaxh3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.24it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 134.84it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 132.44it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 131.31it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 132.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 133.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 134.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 133.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 134.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 135.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 135.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 132.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 130.13it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 127.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.522
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.5242
wandb: sub_train_loss 1.4543
wandb:       test_acc 0.522
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run usual-sweep-719 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s62eaxh3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002228-s62eaxh3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lp9d1s1s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002243-lp9d1s1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-720
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lp9d1s1s
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.08it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.51it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 142.95it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 143.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 142.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 138.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 140.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 142.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 141.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 141.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 142.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 140.67it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 136.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.65134
wandb: sub_train_loss 1.43193
wandb:       test_acc 0.653
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run fiery-sweep-720 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/lp9d1s1s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002243-lp9d1s1s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2nc3p788 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002254-2nc3p788
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-721
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2nc3p788
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 278.91it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 277.94it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 276.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 265.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 264.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 262.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 253.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 256.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 259.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 274.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.31
wandb: best_valid_acc 0.296
wandb:  sub_train_acc 0.27112
wandb: sub_train_loss 1.69646
wandb:       test_acc 0.309
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run dainty-sweep-721 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/2nc3p788
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002254-2nc3p788/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yi827wsv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002310-yi827wsv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-722
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yi827wsv
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 210.29it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 206.46it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 216.25it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 221.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 222.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 234.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 238.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 250.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 252.13it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 253.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 260.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 261.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 243.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.285
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.25188
wandb: sub_train_loss 1.69624
wandb:       test_acc 0.287
wandb:      valid_acc 0.254
wandb: 
wandb: üöÄ View run rare-sweep-722 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/yi827wsv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002310-yi827wsv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f854f4eq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002327-f854f4eq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-723
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f854f4eq
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 240.99it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 262.10it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 265.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 257.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 257.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 250.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 255.08it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 261.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 264.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 265.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 258.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 258.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.353
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.33213
wandb: sub_train_loss 1.71937
wandb:       test_acc 0.356
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run dulcet-sweep-723 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/f854f4eq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002327-f854f4eq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8bx8nfh3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002342-8bx8nfh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-724
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8bx8nfh3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 275.33it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 269.43it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 246.34it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 249.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 247.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 246.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 253.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 255.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 251.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 254.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 254.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 253.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.365
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.33664
wandb: sub_train_loss 1.71988
wandb:       test_acc 0.369
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run dainty-sweep-724 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8bx8nfh3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002342-8bx8nfh3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9n5567s9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002356-9n5567s9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-725
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9n5567s9
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 272.44it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 272.10it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 242.08it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 227.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 213.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 224.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 228.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 232.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 229.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 244.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 256.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 242.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.408
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.3706
wandb: sub_train_loss 1.73302
wandb:       test_acc 0.404
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run breezy-sweep-725 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9n5567s9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002356-9n5567s9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i409cmjr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002408-i409cmjr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-726
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i409cmjr
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 274.03it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 260.84it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 244.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 246.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 256.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 270.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 276.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 279.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:00<00:00, 280.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 276.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 269.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.414
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.3697
wandb: sub_train_loss 1.73282
wandb:       test_acc 0.407
wandb:      valid_acc 0.406
wandb: 
wandb: üöÄ View run laced-sweep-726 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i409cmjr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002408-i409cmjr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8ammz00z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002423-8ammz00z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-727
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8ammz00z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 213.19it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 236.05it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 233.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 232.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 233.08it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 231.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 229.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 232.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 239.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 254.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 256.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 243.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 239.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.256
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.24016
wandb: sub_train_loss 1.73961
wandb:       test_acc 0.251
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run astral-sweep-727 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8ammz00z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002423-8ammz00z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 263mih5o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002437-263mih5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-728
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/263mih5o
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 248.97it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 270.15it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 278.61it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 277.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 278.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 279.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 279.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 282.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 278.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 268.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 273.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.25
wandb: best_valid_acc 0.23
wandb:  sub_train_acc 0.23685
wandb: sub_train_loss 1.73937
wandb:       test_acc 0.248
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run true-sweep-728 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/263mih5o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002437-263mih5o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: akpskjdu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002449-akpskjdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-729
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/akpskjdu
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 258.13it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 262.75it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:00, 273.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 269.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 271.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 271.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 268.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 273.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 273.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 272.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 271.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.216
wandb: best_valid_acc 0.198
wandb:  sub_train_acc 0.21431
wandb: sub_train_loss 1.74557
wandb:       test_acc 0.215
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run bumbling-sweep-729 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/akpskjdu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002449-akpskjdu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s5m57cj1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002504-s5m57cj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-730
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5m57cj1
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 263.07it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 268.78it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 274.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 276.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 275.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 267.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 248.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:00<00:00, 226.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 227.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 237.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 245.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 250.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.182
wandb:  sub_train_acc 0.20439
wandb: sub_train_loss 1.7447
wandb:       test_acc 0.198
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run dainty-sweep-730 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s5m57cj1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002504-s5m57cj1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dmpkwz4f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002524-dmpkwz4f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-731
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dmpkwz4f
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 293.14it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 292.00it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 295.56it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 304.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 309.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 312.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 312.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 315.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:00<00:00, 315.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 309.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.223
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.08687
wandb: sub_train_loss 1.7472
wandb:       test_acc 0.08
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run floral-sweep-731 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/dmpkwz4f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002524-dmpkwz4f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: meazq58a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002540-meazq58a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-732
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/meazq58a
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 270.80it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 272.93it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 264.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 270.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 271.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 271.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 273.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 279.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 282.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 276.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 274.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.203
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.08837
wandb: sub_train_loss 1.74796
wandb:       test_acc 0.08
wandb:      valid_acc 0.06
wandb: 
wandb: üöÄ View run wild-sweep-732 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/meazq58a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002540-meazq58a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z9pvr6si with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002555-z9pvr6si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-733
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z9pvr6si
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 246.34it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 243.16it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 239.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 243.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 239.83it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 244.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 240.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 236.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 246.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 259.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 268.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 252.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.297
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.24797
wandb: sub_train_loss 1.75043
wandb:       test_acc 0.247
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run fearless-sweep-733 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/z9pvr6si
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002555-z9pvr6si/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: osavv2bn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002611-osavv2bn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-734
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/osavv2bn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.94it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 236.03it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 232.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 245.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 261.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 270.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 277.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 279.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 279.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 279.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 269.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.352
wandb: best_valid_acc 0.358
wandb:  sub_train_acc 0.26721
wandb: sub_train_loss 1.75013
wandb:       test_acc 0.256
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run zany-sweep-734 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/osavv2bn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002611-osavv2bn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: if6qvzed with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002626-if6qvzed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-735
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/if6qvzed
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 294.92it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 297.13it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 285.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 283.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 279.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 276.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 276.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 279.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:00<00:00, 283.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 287.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.523
wandb: best_valid_acc 0.522
wandb:  sub_train_acc 0.54103
wandb: sub_train_loss 1.75432
wandb:       test_acc 0.537
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run lucky-sweep-735 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/if6qvzed
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002626-if6qvzed/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ixhwkhof with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002641-ixhwkhof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-736
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ixhwkhof
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.60it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 290.98it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 301.79it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 298.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 303.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 308.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 311.81it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 313.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:00<00:00, 310.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 306.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.607
wandb: best_valid_acc 0.598
wandb:  sub_train_acc 0.59243
wandb: sub_train_loss 1.75412
wandb:       test_acc 0.602
wandb:      valid_acc 0.596
wandb: 
wandb: üöÄ View run young-sweep-736 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/ixhwkhof
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002641-ixhwkhof/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gu7mkpid with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002652-gu7mkpid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-737
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gu7mkpid
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.05it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.31it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 192.69it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 191.26it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 195.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 198.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 196.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 196.15it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 197.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 195.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 192.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 190.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 194.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 196.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 195.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.151
wandb: best_valid_acc 0.146
wandb:  sub_train_acc 0.1596
wandb: sub_train_loss 1.07719
wandb:       test_acc 0.165
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run giddy-sweep-737 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/gu7mkpid
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002652-gu7mkpid/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tfcy8xjt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002707-tfcy8xjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-738
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tfcy8xjt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.18it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 188.34it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 177.20it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 173.28it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 171.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 168.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 166.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 164.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 159.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 163.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 167.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 170.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 172.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 171.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 168.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 171.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.159
wandb: best_valid_acc 0.154
wandb:  sub_train_acc 0.159
wandb: sub_train_loss 1.1074
wandb:       test_acc 0.165
wandb:      valid_acc 0.138
wandb: 
wandb: üöÄ View run stilted-sweep-738 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tfcy8xjt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002707-tfcy8xjt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v0x376mn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002722-v0x376mn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-739
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v0x376mn
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.48it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 164.26it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 167.39it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.52it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 176.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 175.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 175.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 174.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 175.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 177.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 173.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 169.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 165.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 163.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 162.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 161.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.32582
wandb: sub_train_loss 1.21819
wandb:       test_acc 0.306
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run sunny-sweep-739 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/v0x376mn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002722-v0x376mn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8zxgn0zy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002737-8zxgn0zy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-740
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zxgn0zy
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.92it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.47it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.11it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.65it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 147.64it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 149.53it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 155.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 162.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 164.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 147.45it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 150.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 149.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 156.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 163.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 166.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 170.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 174.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.32251
wandb: sub_train_loss 1.21814
wandb:       test_acc 0.307
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run smart-sweep-740 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/8zxgn0zy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002737-8zxgn0zy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: to3ajwke with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002759-to3ajwke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-741
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/to3ajwke
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.23it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 130.29it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 124.08it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 119.06it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 124.03it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 125.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 127.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 135.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 141.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 142.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 145.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 146.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 150.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 155.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 159.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 159.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 162.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 166.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 167.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.534
wandb: best_valid_acc 0.564
wandb:  sub_train_acc 0.45837
wandb: sub_train_loss 1.29991
wandb:       test_acc 0.523
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run divine-sweep-741 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/to3ajwke
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002759-to3ajwke/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4pdblbh0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002815-4pdblbh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-742
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4pdblbh0
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.65it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 188.52it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 190.76it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 188.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 190.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 191.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 194.31it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 192.73it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 192.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 192.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 188.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 185.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 184.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 186.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 183.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.327
wandb: best_valid_acc 0.3
wandb:  sub_train_acc 0.30568
wandb: sub_train_loss 1.30182
wandb:       test_acc 0.31
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run grateful-sweep-742 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/4pdblbh0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002815-4pdblbh0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wyyccyin with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002829-wyyccyin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-743
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wyyccyin
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.46it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.52it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 191.77it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 190.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 185.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 184.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 187.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 190.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 190.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 193.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 193.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 191.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 190.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 188.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 186.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.223
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.27893
wandb: sub_train_loss 1.3728
wandb:       test_acc 0.227
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run generous-sweep-743 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/wyyccyin
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002829-wyyccyin/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o428bg9s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002845-o428bg9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-744
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o428bg9s
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.51it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 148.66it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.03it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 155.37it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 157.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 157.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 157.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 155.30it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 154.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 154.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 166.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 172.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 175.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 177.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 180.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 185.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 186.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.402
wandb: best_valid_acc 0.396
wandb:  sub_train_acc 0.40818
wandb: sub_train_loss 1.36519
wandb:       test_acc 0.407
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run silver-sweep-744 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/o428bg9s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002845-o428bg9s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3szra0w6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002901-3szra0w6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-745
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3szra0w6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.35it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 174.35it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.52it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 181.77it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 182.25it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 178.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 175.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 176.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 178.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 182.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 180.66it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 174.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 167.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 170.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 172.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 174.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.5
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.4746
wandb: sub_train_loss 1.39764
wandb:       test_acc 0.5
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run lucky-sweep-745 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3szra0w6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002901-3szra0w6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 146f9grj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002921-146f9grj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-746
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/146f9grj
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.77it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 178.15it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 177.10it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 176.10it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 174.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 174.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 169.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 171.90it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 172.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 172.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 170.69it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 169.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 167.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 168.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 170.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 171.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.402
wandb:  sub_train_acc 0.41088
wandb: sub_train_loss 1.39042
wandb:       test_acc 0.412
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run still-sweep-746 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/146f9grj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002921-146f9grj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: caret1b2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002936-caret1b2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-747
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/caret1b2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.57it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 159.11it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.28it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 160.64it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 164.09it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 164.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 165.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 169.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 172.70it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 174.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 174.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 173.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 173.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 168.36it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 166.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 164.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 166.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.341
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.36159
wandb: sub_train_loss 1.42991
wandb:       test_acc 0.341
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run eternal-sweep-747 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/caret1b2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002936-caret1b2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3z8b5scc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002951-3z8b5scc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-748
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3z8b5scc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.28it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.67it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.59it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 174.78it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 174.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 174.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 156.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 167.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 177.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 185.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 187.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 187.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 185.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 186.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 185.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.382
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.42441
wandb: sub_train_loss 1.43195
wandb:       test_acc 0.386
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run efficient-sweep-748 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3z8b5scc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002951-3z8b5scc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h3n0htln with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003007-h3n0htln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-749
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h3n0htln
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.72it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.40it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 170.62it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 168.66it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 167.62it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 160.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 153.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 134.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 119.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 111.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 108.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 106.65it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 108.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 112.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 132.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 144.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 152.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 154.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.483
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.474
wandb: sub_train_loss 1.46052
wandb:       test_acc 0.482
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run polished-sweep-749 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/h3n0htln
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003007-h3n0htln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5f53k0cx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003022-5f53k0cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-750
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5f53k0cx
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.17it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 132.23it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 129.97it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 128.80it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 126.65it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 127.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 139.04it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 147.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 159.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 170.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 176.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 175.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 171.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 170.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 168.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 166.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 163.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.439
wandb: best_valid_acc 0.41
wandb:  sub_train_acc 0.44184
wandb: sub_train_loss 1.45455
wandb:       test_acc 0.444
wandb:      valid_acc 0.41
wandb: 
wandb: üöÄ View run eager-sweep-750 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5f53k0cx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003022-5f53k0cx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5e8sfge7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003043-5e8sfge7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-751
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5e8sfge7
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.50it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.46it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 151.28it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 158.04it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 162.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 167.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 169.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 174.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 176.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 177.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 174.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 174.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 178.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 181.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 181.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 182.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.65855
wandb: sub_train_loss 1.48719
wandb:       test_acc 0.66
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run polished-sweep-751 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/5e8sfge7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003043-5e8sfge7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tkpbrak2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003059-tkpbrak2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-752
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tkpbrak2
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.13it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 186.89it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 188.63it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 190.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 190.50it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 189.91it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 189.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 187.95it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 188.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 188.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 190.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 192.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 192.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 194.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 194.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.64
wandb: best_valid_acc 0.67
wandb:  sub_train_acc 0.64923
wandb: sub_train_loss 1.48024
wandb:       test_acc 0.643
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run dry-sweep-752 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tkpbrak2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003059-tkpbrak2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i57kjinp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003114-i57kjinp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-753
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i57kjinp
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.84it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.94it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 142.90it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 139.45it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 136.47it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 134.38it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 130.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 132.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 135.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 136.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 139.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 141.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 142.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 142.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 139.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 138.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 138.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 136.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 134.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 132.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.323
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.27592
wandb: sub_train_loss 0.41933
wandb:       test_acc 0.329
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run twilight-sweep-753 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/i57kjinp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003114-i57kjinp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bi81p4d3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003125-bi81p4d3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-754
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bi81p4d3
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.30it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 111.98it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 100.65it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 100.79it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 100.33it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 100.36it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 111.91it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 118.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 116.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 115.80it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 119.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 121.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 121.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 125.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 129.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 133.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 136.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 132.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 131.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 134.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 134.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 135.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.339
wandb: best_valid_acc 0.318
wandb:  sub_train_acc 0.27562
wandb: sub_train_loss 0.43619
wandb:       test_acc 0.336
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run sage-sweep-754 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/bi81p4d3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003125-bi81p4d3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e2ve16a4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003140-e2ve16a4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-755
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2ve16a4
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.05it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.60it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 127.82it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 130.80it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 131.66it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 129.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 129.17it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 130.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 128.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 132.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 135.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 136.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 138.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 142.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 143.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 135.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 130.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 127.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 125.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 123.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 122.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.32792
wandb: sub_train_loss 0.59295
wandb:       test_acc 0.303
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run eager-sweep-755 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/e2ve16a4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003140-e2ve16a4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: br1y87tm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003155-br1y87tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-756
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/br1y87tm
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.15it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 133.92it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 139.11it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 142.49it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 144.82it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 143.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 142.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 139.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 129.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 126.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 127.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 124.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 123.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 120.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 119.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 115.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 112.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 112.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 111.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 111.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 113.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 113.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.36159
wandb: sub_train_loss 0.50312
wandb:       test_acc 0.416
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run easy-sweep-756 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/br1y87tm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003155-br1y87tm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pift38nt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003210-pift38nt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-757
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pift38nt
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.51it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.11it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 109.41it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 107.17it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 110.23it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 109.66it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 108.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 115.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 123.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 129.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 132.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 133.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 135.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 136.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 136.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 136.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 136.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 136.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 137.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 139.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 138.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 136.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.549
wandb: best_valid_acc 0.59
wandb:  sub_train_acc 0.46468
wandb: sub_train_loss 0.6436
wandb:       test_acc 0.499
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run swept-sweep-757 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/pift38nt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003210-pift38nt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xcm6ni8w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003227-xcm6ni8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-758
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xcm6ni8w
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 121.52it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 108.40it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 124.63it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.51it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 136.69it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 140.28it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 141.45it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 142.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 142.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 143.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 143.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 143.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 142.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 142.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 142.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 142.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 143.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 142.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 142.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 142.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.477
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.4226
wandb: sub_train_loss 0.66008
wandb:       test_acc 0.483
wandb:      valid_acc 0.448
wandb: 
wandb: üöÄ View run devoted-sweep-758 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/xcm6ni8w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003227-xcm6ni8w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: solahy2t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003242-solahy2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-759
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/solahy2t
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.80it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 129.82it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 118.52it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 125.96it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 125.28it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 126.08it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 126.48it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 129.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 128.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 129.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 128.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 132.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 137.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 139.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 141.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 141.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 136.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 133.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 129.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 128.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 126.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.514
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.4731
wandb: sub_train_loss 0.77695
wandb:       test_acc 0.514
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run pretty-sweep-759 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/solahy2t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003242-solahy2t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9vmzrs64 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003253-9vmzrs64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-760
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9vmzrs64
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.97it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 129.99it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 130.22it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 120.62it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 124.29it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 126.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 122.75it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 123.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 123.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 125.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 126.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 127.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 127.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 128.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 129.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 133.80it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 137.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 133.10it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 130.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 130.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 129.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.567
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.50526
wandb: sub_train_loss 0.7806
wandb:       test_acc 0.567
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run skilled-sweep-760 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/9vmzrs64
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003253-9vmzrs64/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fkmvxj8z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003309-fkmvxj8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-761
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fkmvxj8z
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.36it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.61it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 117.65it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 123.04it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 124.40it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 121.81it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 122.15it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 126.89it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 128.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 128.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 128.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 129.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 125.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 123.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 121.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 121.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 123.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 125.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 124.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 125.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 125.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 126.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.612
wandb: best_valid_acc 0.64
wandb:  sub_train_acc 0.56357
wandb: sub_train_loss 0.76308
wandb:       test_acc 0.613
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run resilient-sweep-761 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/fkmvxj8z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003309-fkmvxj8z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3bk3t0m6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003324-3bk3t0m6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-762
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3bk3t0m6
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.59it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 128.54it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 130.84it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 125.08it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 113.83it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 101.19it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 97.97it/s]  34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:02, 95.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 110.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 119.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 124.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 125.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 127.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 130.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 133.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 136.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 137.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 138.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 138.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 134.97it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 136.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 125.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.54764
wandb: sub_train_loss 0.80006
wandb:       test_acc 0.583
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run cerulean-sweep-762 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/3bk3t0m6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003324-3bk3t0m6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g6gra6uh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003339-g6gra6uh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-763
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g6gra6uh
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.36it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 122.69it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 124.59it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 126.18it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 126.23it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 125.96it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 128.22it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 129.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 129.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 127.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 125.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 129.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 132.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 133.43it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 128.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 129.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 131.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 132.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 132.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 135.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 137.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.589
wandb: best_valid_acc 0.602
wandb:  sub_train_acc 0.55936
wandb: sub_train_loss 0.92177
wandb:       test_acc 0.589
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run copper-sweep-763 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/g6gra6uh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003339-g6gra6uh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mfw52tjc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003356-mfw52tjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-764
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mfw52tjc
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.60it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.54it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 140.91it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 140.88it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 138.39it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 136.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 135.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 133.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 134.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 134.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 134.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 135.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 135.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 134.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 132.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 129.67it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 128.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 128.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 128.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 127.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 127.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.55
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.53532
wandb: sub_train_loss 0.88441
wandb:       test_acc 0.549
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run true-sweep-764 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/mfw52tjc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003356-mfw52tjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p6ep5r2c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003412-p6ep5r2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-765
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p6ep5r2c
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.82it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.61it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.71it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.18it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 136.46it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 138.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 140.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 141.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 140.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 142.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 143.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 143.91it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 140.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 137.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 129.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 129.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 131.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 131.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 131.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 131.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.616
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.60174
wandb: sub_train_loss 0.96214
wandb:       test_acc 0.617
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run floral-sweep-765 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/p6ep5r2c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003412-p6ep5r2c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tru9jlqa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003427-tru9jlqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-766
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tru9jlqa
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.31it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 128.61it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 126.16it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 124.25it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 123.62it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 123.10it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 123.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 125.05it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 129.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 127.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 125.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 124.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 123.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 121.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 120.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 119.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 119.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 119.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 124.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 123.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 125.53it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 127.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.611
wandb: best_valid_acc 0.624
wandb:  sub_train_acc 0.59754
wandb: sub_train_loss 0.9484
wandb:       test_acc 0.609
wandb:      valid_acc 0.622
wandb: 
wandb: üöÄ View run eternal-sweep-766 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/tru9jlqa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003427-tru9jlqa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s624uut8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003441-s624uut8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-767
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s624uut8
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.66it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.62it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 126.75it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 120.26it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 118.92it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 123.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 126.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 129.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 132.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 131.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 133.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 135.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 138.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 139.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 136.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 134.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 134.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 133.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 133.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 131.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 130.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.633
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.63661
wandb: sub_train_loss 1.03035
wandb:       test_acc 0.64
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run denim-sweep-767 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/s624uut8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003441-s624uut8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b7xpuydf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CiteseerGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003457-b7xpuydf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-768
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/sweeps/dmkp0e91
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b7xpuydf
  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 3327 num_edges 9228
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.33it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.56it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.36it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 138.48it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 137.87it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 136.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 136.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 137.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 140.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 142.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 142.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 142.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 143.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 143.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 143.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 143.47it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 144.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 143.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 143.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 142.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.659
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.65795
wandb: sub_train_loss 0.98672
wandb:       test_acc 0.658
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run denim-sweep-768 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected/runs/b7xpuydf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_citeseer_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003457-b7xpuydf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
