nohup: ignoring input
wandb: Agent Starting Run: mi70pkvc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Currently logged in as: jamesli-wks (jamesli-wks-johns-hopkins-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_115903-mi70pkvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mi70pkvc
Create sweep with ID: 6gsz5jym
Sweep URL: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:00<01:02,  3.21it/s] 10%|‚ñà         | 20/200 [00:00<00:02, 61.02it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 102.26it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 130.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 150.54it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 164.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 174.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 181.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 184.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 184.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.422
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.50581
wandb: sub_train_loss 0.0
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run glowing-sweep-1 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mi70pkvc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_115903-mi70pkvc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bwu2uuel with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_115918-bwu2uuel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bwu2uuel
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 203.05it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 207.29it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 209.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 209.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 205.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 207.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 208.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 209.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 209.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 208.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.39
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.46554
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run zesty-sweep-2 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bwu2uuel
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_115918-bwu2uuel/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gkkinzcj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_115934-gkkinzcj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gkkinzcj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.57it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.89it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 183.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 185.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 189.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 187.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 185.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 189.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 191.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 194.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.536
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.52341
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.197
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run eager-sweep-3 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gkkinzcj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_115934-gkkinzcj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9vuez768 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_115949-9vuez768
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9vuez768
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.59it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 191.10it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 185.34it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 189.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 188.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 187.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 186.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 186.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 186.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 185.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.548
wandb: sub_train_loss 0.0
wandb:       test_acc 0.51
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run fast-sweep-4 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9vuez768
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_115949-9vuez768/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yoq5z1ch with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120005-yoq5z1ch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yoq5z1ch
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.62it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 189.95it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 187.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 190.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 193.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 195.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 198.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 199.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 200.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.678
wandb:  sub_train_acc 0.56322
wandb: sub_train_loss 0.00111
wandb:       test_acc 0.317
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run magic-sweep-5 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yoq5z1ch
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120005-yoq5z1ch/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k046begi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120020-k046begi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k046begi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.71it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 176.32it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 169.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 170.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 170.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 169.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 173.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 175.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 173.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 177.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.69
wandb: best_valid_acc 0.718
wandb:  sub_train_acc 0.44505
wandb: sub_train_loss 0.0
wandb:       test_acc 0.382
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run winter-sweep-6 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k046begi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120020-k046begi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cabc66vp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120036-cabc66vp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cabc66vp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.60it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 193.10it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 192.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 194.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 196.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 197.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 197.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 198.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 198.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.61379
wandb: sub_train_loss 0.0
wandb:       test_acc 0.48
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run glamorous-sweep-7 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cabc66vp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120036-cabc66vp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h37x127g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120050-h37x127g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h37x127g
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.01it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.02it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 195.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 195.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 187.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 190.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 194.69it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 197.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 199.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.51676
wandb: sub_train_loss 0.0
wandb:       test_acc 0.301
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run radiant-sweep-8 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h37x127g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120050-h37x127g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t7eosoiu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120106-t7eosoiu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t7eosoiu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.47it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 196.55it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 194.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 198.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 195.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 177.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 167.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 166.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 170.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 170.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.32074
wandb: sub_train_loss 0.40762
wandb:       test_acc 0.268
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run deft-sweep-9 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t7eosoiu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120106-t7eosoiu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vh68pj28 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120121-vh68pj28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vh68pj28
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.73it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.37it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 174.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 182.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 186.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 189.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 192.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 196.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 199.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 201.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.56581
wandb: sub_train_loss 0.00017
wandb:       test_acc 0.552
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run fragrant-sweep-10 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vh68pj28
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120121-vh68pj28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a8donnhl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120137-a8donnhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a8donnhl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.64it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 196.98it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 198.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 198.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 198.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 199.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 200.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 198.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 198.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.44703
wandb: sub_train_loss 0.53331
wandb:       test_acc 0.376
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run floral-sweep-11 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a8donnhl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120137-a8donnhl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yrv10s73 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120156-yrv10s73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yrv10s73
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.87it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 193.34it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 192.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 191.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 190.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 193.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 194.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 194.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 195.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 195.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.69154
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.692
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run absurd-sweep-12 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yrv10s73
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120156-yrv10s73/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2b7ogxpj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120211-2b7ogxpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2b7ogxpj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.68it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 185.26it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 188.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 186.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 182.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 177.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 173.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 172.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 172.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 171.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.48811
wandb: sub_train_loss 0.19383
wandb:       test_acc 0.483
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run fiery-sweep-13 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2b7ogxpj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120211-2b7ogxpj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dj48ehe1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120226-dj48ehe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dj48ehe1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.89it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.69it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 181.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 182.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 179.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 177.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 174.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 172.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 169.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 168.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.46473
wandb: sub_train_loss 0.00358
wandb:       test_acc 0.516
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run good-sweep-14 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dj48ehe1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120226-dj48ehe1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: skpk4r7j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120242-skpk4r7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/skpk4r7j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.78it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 169.27it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 164.39it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 170.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 172.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 173.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 174.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 175.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 176.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 177.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 178.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.38297
wandb: sub_train_loss 0.00026
wandb:       test_acc 0.386
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run azure-sweep-15 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/skpk4r7j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120242-skpk4r7j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ipgnhm2l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120257-ipgnhm2l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ipgnhm2l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.11it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 186.29it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 188.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 190.42it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 192.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 185.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 185.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 186.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 184.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 181.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.45433
wandb: sub_train_loss 0.01581
wandb:       test_acc 0.396
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run floral-sweep-16 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ipgnhm2l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120257-ipgnhm2l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: adorqcvb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120313-adorqcvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/adorqcvb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.34it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 167.04it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 168.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 170.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 169.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 170.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 171.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 171.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 170.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 171.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 171.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.41
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.44768
wandb: sub_train_loss 0.0
wandb:       test_acc 0.269
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run sage-sweep-17 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/adorqcvb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120313-adorqcvb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9fxrco3a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120327-9fxrco3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9fxrco3a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.85it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.05it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 170.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 170.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 164.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 165.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 163.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 162.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 162.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.424
wandb: best_valid_acc 0.464
wandb:  sub_train_acc 0.42694
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run fresh-sweep-18 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9fxrco3a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120327-9fxrco3a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: akxgcami with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120343-akxgcami
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/akxgcami
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.19it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.82it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 161.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 160.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 161.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 162.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 164.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 164.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 165.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 164.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 165.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá
wandb:      valid_acc ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.536
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.46508
wandb: sub_train_loss 0.0
wandb:       test_acc 0.471
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run laced-sweep-19 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/akxgcami
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120343-akxgcami/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 95ss4vgc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120358-95ss4vgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/95ss4vgc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.93it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.64it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 158.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 157.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 157.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 156.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 156.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 155.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.598
wandb: best_valid_acc 0.612
wandb:  sub_train_acc 0.48496
wandb: sub_train_loss 0.0
wandb:       test_acc 0.359
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run daily-sweep-20 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/95ss4vgc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120358-95ss4vgc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ayfjeyc0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120414-ayfjeyc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ayfjeyc0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.36it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 159.39it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 156.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 153.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 152.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 152.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 152.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 151.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 150.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 153.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 155.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 154.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.53933
wandb: sub_train_loss 0.00078
wandb:       test_acc 0.428
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run hearty-sweep-21 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ayfjeyc0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120414-ayfjeyc0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ik9vxfww with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120429-ik9vxfww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ik9vxfww
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.74it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 159.22it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 158.19it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 159.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 161.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 161.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 163.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 164.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 164.20it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 165.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 166.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.655
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.56768
wandb: sub_train_loss 0.0
wandb:       test_acc 0.512
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run hearty-sweep-22 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ik9vxfww
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120429-ik9vxfww/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: htlrzs9b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120444-htlrzs9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/htlrzs9b
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.31it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 169.69it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 168.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 165.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 166.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 169.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 168.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 167.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 166.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 158.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 160.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.51935
wandb: sub_train_loss 0.0
wandb:       test_acc 0.501
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run vital-sweep-23 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/htlrzs9b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120444-htlrzs9b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6j9an3cy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120500-6j9an3cy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6j9an3cy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.94it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.13it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 155.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 154.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 156.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 156.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 156.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 155.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÖ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.44479
wandb: sub_train_loss 0.00903
wandb:       test_acc 0.432
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run spring-sweep-24 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6j9an3cy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120500-6j9an3cy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 65hp7235 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120515-65hp7235
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/65hp7235
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.75it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 129.85it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.42it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 155.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 157.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 162.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 165.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 166.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 166.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 167.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 167.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 161.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.63306
wandb: sub_train_loss 0.00375
wandb:       test_acc 0.423
wandb:      valid_acc 0.448
wandb: 
wandb: üöÄ View run sleek-sweep-25 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/65hp7235
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120515-65hp7235/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b4n510jn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120531-b4n510jn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b4n510jn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.93it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 164.21it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 167.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 170.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 165.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 158.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 164.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 169.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 172.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 173.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 174.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñà‚ñá‚ñá‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.729
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.57514
wandb: sub_train_loss 0.00178
wandb:       test_acc 0.552
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run logical-sweep-26 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b4n510jn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120531-b4n510jn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ympoel45 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120546-ympoel45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ympoel45
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 162.28it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.17it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 168.62it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 170.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 172.23it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 171.55it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 171.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 170.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 170.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 170.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 170.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.59238
wandb: sub_train_loss 0.12427
wandb:       test_acc 0.571
wandb:      valid_acc 0.622
wandb: 
wandb: üöÄ View run sunny-sweep-27 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ympoel45
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120546-ympoel45/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b86p75ih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120601-b86p75ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b86p75ih
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.97it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 161.19it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 167.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 170.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 169.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 169.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 171.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 172.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 171.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.54734
wandb: sub_train_loss 0.0
wandb:       test_acc 0.462
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run good-sweep-28 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b86p75ih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120601-b86p75ih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qhxuk8c1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120617-qhxuk8c1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qhxuk8c1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 162.16it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.76it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 170.53it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 171.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 172.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 171.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 172.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 171.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 172.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 172.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 171.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.6045
wandb: sub_train_loss 0.05229
wandb:       test_acc 0.578
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run pretty-sweep-29 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qhxuk8c1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120617-qhxuk8c1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cx4l8s34 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120632-cx4l8s34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cx4l8s34
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.21it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.52it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 148.89it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 152.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 151.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 150.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 151.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 151.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 150.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 150.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 150.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 156.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.58097
wandb: sub_train_loss 0.12423
wandb:       test_acc 0.541
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run swept-sweep-30 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cx4l8s34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120632-cx4l8s34/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7amtedlm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120648-7amtedlm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7amtedlm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.93it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 164.89it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 166.82it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 164.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 166.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 166.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 167.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 168.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 168.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 169.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.57747
wandb: sub_train_loss 0.3453
wandb:       test_acc 0.581
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run avid-sweep-31 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7amtedlm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120648-7amtedlm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zd7up821 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120703-zd7up821
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zd7up821
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.91it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.14it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 140.38it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 148.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 151.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 150.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 151.57it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 152.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 158.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 162.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 163.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 164.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 155.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÉ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.5547
wandb: sub_train_loss 0.00019
wandb:       test_acc 0.535
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run bright-sweep-32 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zd7up821
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120703-zd7up821/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nl4q3gpx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120718-nl4q3gpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nl4q3gpx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.62it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.52it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 150.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 151.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 151.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 151.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 149.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 148.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 148.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.404
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.47507
wandb: sub_train_loss 0.0
wandb:       test_acc 0.299
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run zany-sweep-33 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nl4q3gpx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120718-nl4q3gpx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: udy1g1z7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120733-udy1g1z7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/udy1g1z7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.14it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.06it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 138.87it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 137.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 139.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 140.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 138.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 135.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 135.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 129.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 131.38it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 133.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 134.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.45245
wandb: sub_train_loss 0.0
wandb:       test_acc 0.288
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run vivid-sweep-34 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/udy1g1z7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120733-udy1g1z7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9glk6e6v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120750-9glk6e6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9glk6e6v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.84it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 152.12it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 153.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 150.92it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 147.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 146.50it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 145.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 146.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 147.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 144.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 143.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 143.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 143.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.4135
wandb: sub_train_loss 0.0
wandb:       test_acc 0.317
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run noble-sweep-35 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9glk6e6v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120750-9glk6e6v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z98lgxz3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120804-z98lgxz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z98lgxz3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.93it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.03it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 145.73it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 148.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 149.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 148.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 148.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 148.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 147.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 148.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 148.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 149.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 151.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.65
wandb: best_valid_acc 0.67
wandb:  sub_train_acc 0.40376
wandb: sub_train_loss 0.0
wandb:       test_acc 0.179
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run floral-sweep-36 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z98lgxz3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120804-z98lgxz3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p0zm7ag6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120820-p0zm7ag6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p0zm7ag6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.58it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.68it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.34it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 144.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 140.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 115.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 101.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 99.25it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 111.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 120.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 128.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 134.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 122.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.685
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.56692
wandb: sub_train_loss 0.0
wandb:       test_acc 0.515
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run dandy-sweep-37 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p0zm7ag6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120820-p0zm7ag6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pdqpa5ye with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120836-pdqpa5ye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pdqpa5ye
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.16it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 129.11it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 128.29it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 112.82it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 119.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 124.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 130.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 134.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 137.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 140.13it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 140.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 143.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 144.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.677
wandb: best_valid_acc 0.678
wandb:  sub_train_acc 0.3854
wandb: sub_train_loss 0.0
wandb:       test_acc 0.26
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run unique-sweep-38 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pdqpa5ye
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120836-pdqpa5ye/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j8r273gz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120851-j8r273gz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j8r273gz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.51it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.53it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 136.87it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 134.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 137.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 141.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 136.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 133.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 131.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 130.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 134.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 136.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 131.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.45524
wandb: sub_train_loss 0.49132
wandb:       test_acc 0.323
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run upbeat-sweep-39 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j8r273gz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120851-j8r273gz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0fgcev8q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120906-0fgcev8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0fgcev8q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.39it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 132.49it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 126.98it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 131.09it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 134.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 137.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 137.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 137.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 140.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 141.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 141.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 142.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 144.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.54009
wandb: sub_train_loss 0.0
wandb:       test_acc 0.458
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run fanciful-sweep-40 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0fgcev8q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120906-0fgcev8q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yg7bp78a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120922-yg7bp78a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yg7bp78a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.41it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.00it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 130.67it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 134.90it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 130.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 117.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 122.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 128.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 131.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 134.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 134.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 128.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 131.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.56946
wandb: sub_train_loss 0.00485
wandb:       test_acc 0.532
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run stellar-sweep-41 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yg7bp78a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120922-yg7bp78a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 46k8mgj6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120937-46k8mgj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/46k8mgj6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.15it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 115.24it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 108.57it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 108.40it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 106.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 105.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 101.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:01, 101.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 105.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 109.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 110.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 110.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 114.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 126.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 131.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.5757
wandb: sub_train_loss 0.17692
wandb:       test_acc 0.473
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run morning-sweep-42 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/46k8mgj6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120937-46k8mgj6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v5kpx384 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_120952-v5kpx384
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v5kpx384
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.04it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.32it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 98.58it/s]  21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 95.60it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 94.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 96.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 100.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 102.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:01, 100.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 102.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 100.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 102.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 104.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 101.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 107.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 115.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 121.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 106.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.60795
wandb: sub_train_loss 0.52115
wandb:       test_acc 0.542
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run pious-sweep-43 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v5kpx384
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_120952-v5kpx384/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: souhfqn3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121008-souhfqn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/souhfqn3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.94it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 137.49it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 136.66it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 139.06it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 137.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 137.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 137.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 135.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 138.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 140.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 142.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 144.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 146.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.57554
wandb: sub_train_loss 0.22185
wandb:       test_acc 0.568
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run scarlet-sweep-44 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/souhfqn3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121008-souhfqn3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3i5jgop7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121023-3i5jgop7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3i5jgop7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  2%|‚ñè         | 4/200 [00:00<00:05, 32.98it/s]  4%|‚ñç         | 8/200 [00:00<00:05, 32.70it/s] 10%|‚ñâ         | 19/200 [00:00<00:03, 57.24it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:03, 45.59it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:04, 41.07it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:03, 48.01it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:03, 42.62it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:01<00:03, 39.37it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:01<00:03, 37.79it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:01<00:03, 44.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:01<00:03, 41.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:01<00:03, 38.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:01<00:03, 38.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:01<00:02, 45.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:02<00:02, 41.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:02<00:02, 38.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:02<00:02, 41.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:02<00:02, 45.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:02<00:02, 40.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:02<00:02, 38.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:02<00:01, 47.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:03<00:01, 42.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:03<00:01, 39.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:03<00:01, 37.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:03<00:01, 44.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:03<00:01, 41.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:03<00:01, 38.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:03<00:00, 43.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:03<00:00, 43.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:04<00:00, 39.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:04<00:00, 37.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:04<00:00, 44.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:04<00:00, 40.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:04<00:00, 38.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:04<00:00, 36.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:04<00:00, 41.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.734
wandb:  sub_train_acc 0.48684
wandb: sub_train_loss 1.3523
wandb:       test_acc 0.44
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run swift-sweep-45 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3i5jgop7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121023-3i5jgop7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c9jqdkss with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121039-c9jqdkss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/c9jqdkss
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 107.21it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 108.92it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:03, 54.85it/s]  22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:02, 56.15it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:02, 54.90it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:01<00:03, 46.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:01<00:03, 44.22it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:01<00:02, 53.29it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:01<00:02, 46.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:01<00:02, 41.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:01<00:02, 48.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:01<00:02, 43.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:02<00:02, 40.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:02<00:01, 47.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:02<00:01, 42.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:02<00:01, 39.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:02<00:01, 39.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:02<00:01, 47.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:02<00:01, 42.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:03<00:01, 39.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:03<00:00, 48.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:03<00:00, 43.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:03<00:00, 40.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:03<00:00, 40.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:03<00:00, 48.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:04<00:00, 42.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:04<00:00, 39.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:04<00:00, 48.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:04<00:00, 46.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñá‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.52838
wandb: sub_train_loss 0.29317
wandb:       test_acc 0.561
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run morning-sweep-46 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/c9jqdkss
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121039-c9jqdkss/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ko6sh73m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121059-ko6sh73m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ko6sh73m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.43it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.17it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 147.34it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 148.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 148.64it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 149.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 149.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 144.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 144.44it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 143.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 141.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 140.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 141.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.60597
wandb: sub_train_loss 0.31375
wandb:       test_acc 0.653
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run dauntless-sweep-47 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ko6sh73m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121059-ko6sh73m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m5yir7x5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121114-m5yir7x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m5yir7x5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.34it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.49it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.13it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 142.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 144.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 100.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 63.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:01, 52.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:01, 45.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:01, 42.72it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:02<00:01, 40.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:02<00:01, 38.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:02<00:01, 36.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:02<00:01, 35.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:02<00:01, 35.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:02<00:01, 34.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:02<00:01, 33.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:02<00:01, 37.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:03<00:00, 38.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:03<00:00, 36.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:03<00:00, 35.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:03<00:00, 34.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:03<00:00, 34.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:03<00:00, 33.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:03<00:00, 33.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:03<00:00, 33.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:04<00:00, 33.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:04<00:00, 49.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.491
wandb: sub_train_loss 0.11161
wandb:       test_acc 0.498
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run jumping-sweep-48 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m5yir7x5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121114-m5yir7x5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mbusv4ou with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121129-mbusv4ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mbusv4ou
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  2%|‚ñè         | 6/300 [00:00<00:05, 56.77it/s]  4%|‚ñç         | 12/300 [00:00<00:06, 41.18it/s]  6%|‚ñå         | 17/300 [00:00<00:07, 38.23it/s]  7%|‚ñã         | 21/300 [00:00<00:07, 36.71it/s]  8%|‚ñä         | 25/300 [00:00<00:07, 36.04it/s] 10%|‚ñâ         | 29/300 [00:00<00:07, 35.58it/s] 11%|‚ñà         | 33/300 [00:00<00:07, 35.36it/s] 12%|‚ñà‚ñè        | 37/300 [00:01<00:07, 35.20it/s] 14%|‚ñà‚ñé        | 41/300 [00:01<00:07, 35.09it/s] 15%|‚ñà‚ñå        | 45/300 [00:01<00:07, 35.00it/s] 16%|‚ñà‚ñã        | 49/300 [00:01<00:07, 34.74it/s] 18%|‚ñà‚ñä        | 53/300 [00:01<00:07, 34.63it/s] 19%|‚ñà‚ñâ        | 57/300 [00:01<00:07, 34.59it/s] 20%|‚ñà‚ñà        | 61/300 [00:01<00:06, 34.71it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:01<00:06, 34.48it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:01<00:06, 34.30it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:02<00:06, 34.35it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:02<00:06, 34.48it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:02<00:04, 49.05it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:02<00:04, 43.74it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:02<00:04, 40.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:02<00:05, 38.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:02<00:05, 37.49it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:02<00:05, 36.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:03<00:05, 36.18it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:03<00:05, 35.65it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:03<00:05, 35.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:03<00:04, 35.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:03<00:04, 34.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:03<00:04, 34.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:03<00:04, 34.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:03<00:04, 34.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:04<00:04, 34.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:04<00:04, 34.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:04<00:04, 34.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:04<00:04, 34.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:04<00:03, 41.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:04<00:02, 47.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:04<00:02, 42.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:04<00:02, 39.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:05<00:02, 38.39it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:05<00:02, 37.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:05<00:02, 36.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:05<00:02, 36.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:05<00:02, 35.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:05<00:02, 35.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:05<00:02, 35.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:05<00:02, 35.37it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:05<00:02, 35.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:06<00:02, 35.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:06<00:02, 34.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:06<00:01, 34.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:06<00:01, 34.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:06<00:01, 34.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:06<00:01, 34.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:06<00:00, 51.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:06<00:00, 44.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:07<00:00, 41.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:07<00:00, 39.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:07<00:00, 38.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:07<00:00, 37.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:07<00:00, 36.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:07<00:00, 36.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:07<00:00, 35.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:07<00:00, 35.41it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:08<00:00, 35.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:08<00:00, 37.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.41
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.51098
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run cerulean-sweep-49 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mbusv4ou
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121129-mbusv4ou/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xpoc9lp8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121150-xpoc9lp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xpoc9lp8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  1%|‚ñè         | 4/300 [00:00<00:08, 34.55it/s]  3%|‚ñé         | 8/300 [00:00<00:08, 34.77it/s]  4%|‚ñç         | 12/300 [00:00<00:08, 34.60it/s]  5%|‚ñå         | 16/300 [00:00<00:08, 34.72it/s]  7%|‚ñã         | 20/300 [00:00<00:08, 34.73it/s]  8%|‚ñä         | 24/300 [00:00<00:07, 34.81it/s]  9%|‚ñâ         | 28/300 [00:00<00:07, 34.65it/s] 11%|‚ñà         | 32/300 [00:00<00:07, 34.71it/s] 12%|‚ñà‚ñè        | 36/300 [00:01<00:07, 34.76it/s] 13%|‚ñà‚ñé        | 40/300 [00:01<00:07, 34.75it/s] 15%|‚ñà‚ñç        | 44/300 [00:01<00:07, 34.51it/s] 16%|‚ñà‚ñå        | 48/300 [00:01<00:07, 34.21it/s] 17%|‚ñà‚ñã        | 52/300 [00:01<00:07, 34.11it/s] 19%|‚ñà‚ñä        | 56/300 [00:01<00:07, 33.50it/s] 20%|‚ñà‚ñà        | 60/300 [00:01<00:07, 33.70it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:01<00:06, 34.44it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:01<00:02, 79.11it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:02<00:03, 67.23it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:02<00:03, 53.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:02<00:04, 46.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:02<00:04, 43.17it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:02<00:04, 40.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:03<00:04, 39.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:03<00:04, 38.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:03<00:04, 37.14it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:03<00:04, 36.46it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:03<00:04, 36.08it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:03<00:04, 35.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:03<00:04, 35.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:03<00:04, 35.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:03<00:04, 34.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:04<00:04, 34.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:04<00:03, 38.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:04<00:02, 60.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:04<00:02, 49.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:04<00:02, 44.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:04<00:02, 41.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:04<00:02, 39.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:05<00:02, 38.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:05<00:02, 37.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:05<00:02, 36.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:05<00:02, 35.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:05<00:02, 35.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:05<00:02, 35.05it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:05<00:01, 35.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:05<00:01, 35.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:06<00:01, 34.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:06<00:01, 34.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:06<00:01, 34.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:06<00:01, 34.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:06<00:00, 43.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:06<00:00, 50.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:06<00:00, 44.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:06<00:00, 41.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:07<00:00, 39.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:07<00:00, 37.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:07<00:00, 36.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:07<00:00, 36.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:07<00:00, 35.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 39.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.4
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.52549
wandb: sub_train_loss 0.0
wandb:       test_acc 0.368
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run silver-sweep-50 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xpoc9lp8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121150-xpoc9lp8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qbosof79 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121210-qbosof79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qbosof79
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  2%|‚ñè         | 6/300 [00:00<00:04, 58.90it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 102.55it/s] 11%|‚ñà         | 32/300 [00:00<00:04, 57.14it/s]  13%|‚ñà‚ñé        | 39/300 [00:00<00:05, 48.03it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:05, 43.79it/s] 17%|‚ñà‚ñã        | 50/300 [00:01<00:06, 41.49it/s] 18%|‚ñà‚ñä        | 55/300 [00:01<00:06, 39.45it/s] 20%|‚ñà‚ñà        | 60/300 [00:01<00:06, 38.22it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:01<00:06, 37.43it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:01<00:06, 36.72it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:01<00:06, 36.08it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:01<00:06, 35.61it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:01<00:06, 35.37it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:02<00:06, 35.22it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:02<00:06, 34.68it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:02<00:05, 34.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:02<00:05, 34.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:02<00:03, 49.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:02<00:04, 43.98it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:02<00:04, 40.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:02<00:04, 38.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:03<00:04, 37.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:03<00:04, 37.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:03<00:04, 36.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:03<00:04, 35.94it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:03<00:04, 35.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:03<00:04, 35.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:03<00:04, 35.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:03<00:04, 34.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:03<00:04, 34.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:04<00:04, 34.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:04<00:03, 34.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:04<00:03, 34.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:04<00:03, 34.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:04<00:03, 34.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:04<00:02, 40.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:04<00:02, 48.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:04<00:02, 43.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:05<00:02, 40.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:05<00:02, 38.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:05<00:02, 37.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:05<00:02, 37.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:05<00:02, 36.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:05<00:02, 36.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:05<00:02, 35.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:05<00:02, 35.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:05<00:01, 35.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:06<00:01, 34.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:06<00:01, 34.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:06<00:01, 34.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:06<00:01, 34.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:06<00:01, 33.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:06<00:01, 33.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:06<00:01, 34.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:06<00:00, 43.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:07<00:00, 45.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:07<00:00, 41.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:07<00:00, 39.42it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:07<00:00, 37.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:07<00:00, 37.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:07<00:00, 36.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 38.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.522
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.50647
wandb: sub_train_loss 0.0
wandb:       test_acc 0.286
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run wild-sweep-51 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qbosof79
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121210-qbosof79/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5cgd7a34 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121231-5cgd7a34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5cgd7a34
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  1%|‚ñè         | 4/300 [00:00<00:08, 34.72it/s]  3%|‚ñé         | 8/300 [00:00<00:08, 34.53it/s]  4%|‚ñç         | 12/300 [00:00<00:08, 34.26it/s]  5%|‚ñå         | 16/300 [00:00<00:08, 34.57it/s]  7%|‚ñã         | 20/300 [00:00<00:08, 34.55it/s]  8%|‚ñä         | 24/300 [00:00<00:07, 34.60it/s]  9%|‚ñâ         | 28/300 [00:00<00:07, 34.55it/s] 11%|‚ñà         | 32/300 [00:00<00:07, 34.80it/s] 13%|‚ñà‚ñé        | 39/300 [00:01<00:05, 44.56it/s] 20%|‚ñà‚ñâ        | 59/300 [00:01<00:02, 89.04it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:01<00:01, 122.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:01, 145.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 91.09it/s]  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:02, 64.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:02<00:03, 53.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:02<00:03, 48.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:02<00:03, 44.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:02<00:03, 41.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:03<00:03, 39.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:03<00:03, 38.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:03<00:03, 37.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:03<00:03, 36.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:03<00:03, 36.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:03<00:02, 48.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:03<00:02, 43.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:03<00:02, 40.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:04<00:02, 39.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:04<00:02, 38.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:04<00:02, 37.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:04<00:02, 36.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:04<00:02, 35.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:04<00:02, 35.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:04<00:01, 35.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:04<00:01, 35.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:05<00:01, 35.17it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:05<00:01, 34.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:05<00:01, 34.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:05<00:01, 34.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:05<00:01, 34.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:05<00:01, 34.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:05<00:01, 34.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:05<00:00, 51.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:05<00:00, 55.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:06<00:00, 47.46it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:06<00:00, 43.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:06<00:00, 40.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:06<00:00, 45.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.602
wandb: best_valid_acc 0.62
wandb:  sub_train_acc 0.55587
wandb: sub_train_loss 0.0
wandb:       test_acc 0.602
wandb:      valid_acc 0.62
wandb: 
wandb: üöÄ View run royal-sweep-52 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5cgd7a34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121231-5cgd7a34/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rdydx8jc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121251-rdydx8jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rdydx8jc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.77it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 186.95it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 189.48it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 185.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 190.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 191.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 192.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 195.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 184.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 186.29it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 187.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 187.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 187.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 187.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 190.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.691
wandb: best_valid_acc 0.708
wandb:  sub_train_acc 0.57752
wandb: sub_train_loss 0.0
wandb:       test_acc 0.515
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run lively-sweep-53 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rdydx8jc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121251-rdydx8jc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3u5xdybf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121307-3u5xdybf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3u5xdybf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 189.74it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 195.37it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 197.71it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 200.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 202.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 203.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 203.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 203.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 204.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 204.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 203.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 200.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 200.53it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 199.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 201.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.51534
wandb: sub_train_loss 0.0
wandb:       test_acc 0.299
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run copper-sweep-54 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3u5xdybf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121307-3u5xdybf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yfeq5b5a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121343-yfeq5b5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yfeq5b5a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.39it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 192.54it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 194.56it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 197.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 194.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 196.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 195.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 197.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 196.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 196.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 196.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 196.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 191.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 192.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 195.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.745
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.6467
wandb: sub_train_loss 0.0
wandb:       test_acc 0.692
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run summer-sweep-55 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yfeq5b5a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121343-yfeq5b5a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q0o1ijep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121358-q0o1ijep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q0o1ijep
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.30it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 193.55it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 196.45it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 197.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 199.15it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 201.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 203.59it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 204.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 204.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 205.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 204.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 203.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 200.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 193.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÉ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.39666
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.39
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run crisp-sweep-56 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q0o1ijep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121358-q0o1ijep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ttqtr2rf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121413-ttqtr2rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ttqtr2rf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.12it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 199.24it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 194.38it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 193.91it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 188.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 177.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 171.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 167.43it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 166.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 174.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 178.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 172.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 171.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 171.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 167.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.61267
wandb: sub_train_loss 0.0
wandb:       test_acc 0.648
wandb:      valid_acc 0.664
wandb: 
wandb: üöÄ View run glorious-sweep-57 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ttqtr2rf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121413-ttqtr2rf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rf46n1ja with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121429-rf46n1ja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rf46n1ja
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.50it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.01it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 190.70it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.21it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 195.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 199.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 201.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 203.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 204.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 205.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 204.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 204.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 202.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 202.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 200.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.691
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.46599
wandb: sub_train_loss 0.00011
wandb:       test_acc 0.388
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run whole-sweep-58 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rf46n1ja
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121429-rf46n1ja/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r77u3ah8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121444-r77u3ah8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r77u3ah8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.56it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 197.99it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 199.95it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 201.31it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 201.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 203.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 203.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 202.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 202.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 202.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 200.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 199.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 197.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 197.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 199.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.682
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.42907
wandb: sub_train_loss 10.8179
wandb:       test_acc 0.416
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run denim-sweep-59 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r77u3ah8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121444-r77u3ah8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ojkbaszb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121500-ojkbaszb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojkbaszb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.49it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.96it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 170.64it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 172.11it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 172.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 173.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 173.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 173.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 174.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 174.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 174.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 174.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 175.14it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 175.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 174.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 174.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.741
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.51529
wandb: sub_train_loss 0.0
wandb:       test_acc 0.511
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run drawn-sweep-60 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojkbaszb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121500-ojkbaszb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uit3y9jw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121515-uit3y9jw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uit3y9jw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.29it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 187.97it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 191.22it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 192.38it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 193.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 193.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 193.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 193.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 192.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 189.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 190.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 188.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 183.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 182.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.53248
wandb: sub_train_loss 0.0
wandb:       test_acc 0.557
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run kind-sweep-61 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uit3y9jw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121515-uit3y9jw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y8px7hcx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121530-y8px7hcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/y8px7hcx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.16it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 188.97it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 191.55it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 194.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 194.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 190.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 188.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 191.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 182.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 167.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 161.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 163.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 153.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 157.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 161.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.36136
wandb: sub_train_loss 9e-05
wandb:       test_acc 0.31
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run laced-sweep-62 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/y8px7hcx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121530-y8px7hcx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1k8g28t3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121546-1k8g28t3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1k8g28t3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.72it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.70it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 163.58it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 174.31it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 180.67it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 185.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 177.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 169.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 167.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 165.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 162.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 163.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 165.83it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 166.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 166.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 166.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.28057
wandb: sub_train_loss 0.05864
wandb:       test_acc 0.255
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run good-sweep-63 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1k8g28t3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121546-1k8g28t3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tuivgeax with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121601-tuivgeax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tuivgeax
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.05it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.19it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 186.33it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 188.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 187.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 187.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 181.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 184.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 185.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 187.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 188.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 186.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 188.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 190.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 190.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.60775
wandb: sub_train_loss 0.0
wandb:       test_acc 0.621
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run decent-sweep-64 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tuivgeax
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121601-tuivgeax/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iixmnt46 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121617-iixmnt46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iixmnt46
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.72it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.39it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.82it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 165.92it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 161.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 158.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 158.21it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 159.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 162.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 165.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 165.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 165.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 165.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 168.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 170.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 172.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 173.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.46523
wandb: sub_train_loss 0.0
wandb:       test_acc 0.408
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run visionary-sweep-65 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iixmnt46
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121617-iixmnt46/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4y15bw2f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121631-4y15bw2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4y15bw2f
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:04, 71.23it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 74.61it/s]  9%|‚ñä         | 26/300 [00:00<00:04, 66.25it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:03, 67.11it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:03, 66.07it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:03, 65.99it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:03, 65.85it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:03, 66.93it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:01<00:03, 66.66it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:01<00:03, 65.32it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:01<00:03, 67.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:01<00:02, 70.53it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:02, 72.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:02, 73.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:02, 70.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:02, 69.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:02<00:02, 66.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:02<00:02, 64.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:02<00:02, 66.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:02<00:02, 66.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:02<00:02, 62.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:02<00:01, 62.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 61.02it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 60.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 61.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:03<00:01, 61.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:03<00:01, 59.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:03<00:01, 58.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:03<00:01, 61.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:03<00:01, 63.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:03<00:00, 63.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:03<00:00, 62.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:03<00:00, 62.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:03<00:00, 63.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:04<00:00, 64.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:04<00:00, 65.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:04<00:00, 65.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:04<00:00, 67.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÇ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.427
wandb: best_valid_acc 0.45
wandb:  sub_train_acc 0.41208
wandb: sub_train_loss 0.0
wandb:       test_acc 0.345
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run vocal-sweep-66 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4y15bw2f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121631-4y15bw2f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dyb7sz54 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121652-dyb7sz54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dyb7sz54
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  1%|‚ñè         | 4/300 [00:00<00:09, 32.52it/s]  4%|‚ñé         | 11/300 [00:00<00:06, 46.50it/s]  5%|‚ñå         | 16/300 [00:00<00:07, 39.90it/s]  7%|‚ñã         | 21/300 [00:00<00:07, 37.08it/s] 10%|‚ñâ         | 29/300 [00:00<00:05, 46.39it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:06, 41.94it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:06, 39.17it/s] 15%|‚ñà‚ñç        | 44/300 [00:01<00:06, 38.36it/s] 17%|‚ñà‚ñã        | 50/300 [00:01<00:05, 43.61it/s] 18%|‚ñà‚ñä        | 55/300 [00:01<00:06, 40.37it/s] 20%|‚ñà‚ñà        | 60/300 [00:01<00:06, 38.12it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:01<00:04, 50.14it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:01<00:05, 43.90it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:01<00:05, 40.56it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:02<00:05, 40.50it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:02<00:04, 44.45it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:02<00:04, 40.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:02<00:05, 38.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:02<00:04, 47.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:02<00:04, 42.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:02<00:04, 39.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:03<00:04, 40.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:03<00:03, 44.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:03<00:04, 40.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:03<00:04, 38.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:03<00:03, 42.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:03<00:03, 39.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:03<00:03, 37.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:03<00:03, 36.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:04<00:03, 42.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:04<00:03, 39.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:04<00:03, 37.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:04<00:02, 42.41it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:04<00:02, 41.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:04<00:02, 38.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:04<00:02, 37.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:04<00:02, 43.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:05<00:02, 40.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:05<00:02, 38.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:05<00:02, 36.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:05<00:01, 44.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:05<00:01, 40.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:05<00:01, 38.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:05<00:01, 40.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:06<00:01, 41.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:06<00:01, 38.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:06<00:01, 36.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:06<00:00, 39.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:06<00:00, 42.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:06<00:00, 39.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:06<00:00, 37.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:06<00:00, 44.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:07<00:00, 40.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:07<00:00, 38.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:07<00:00, 38.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 40.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÅ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÅ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.593
wandb: best_valid_acc 0.64
wandb:  sub_train_acc 0.48593
wandb: sub_train_loss 0.0
wandb:       test_acc 0.222
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run cosmic-sweep-67 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dyb7sz54
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121652-dyb7sz54/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rlkjyfq7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121713-rlkjyfq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rlkjyfq7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.47it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.72it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 164.78it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 166.63it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 167.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 169.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 170.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 171.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 172.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 173.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 173.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 174.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 175.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 176.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 170.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 173.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.49054
wandb: sub_train_loss 0.0
wandb:       test_acc 0.486
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run splendid-sweep-68 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rlkjyfq7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121713-rlkjyfq7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8kx1i5kz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121727-8kx1i5kz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8kx1i5kz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.23it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.54it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 161.15it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 163.38it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 162.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 157.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 158.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 163.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 166.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 169.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 170.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 170.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 171.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 171.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 170.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 171.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 171.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.635
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.52031
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.511
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run eternal-sweep-69 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8kx1i5kz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121727-8kx1i5kz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kddg4fxq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121743-kddg4fxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kddg4fxq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.67it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.64it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 150.23it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 153.04it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 154.70it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 155.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 154.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 155.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 155.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 155.29it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 153.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 154.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 157.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 161.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 164.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 164.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 164.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 164.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.54379
wandb: sub_train_loss 0.0
wandb:       test_acc 0.484
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run cool-sweep-70 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kddg4fxq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121743-kddg4fxq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5uxjlokv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121759-5uxjlokv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5uxjlokv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.65it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.89it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 175.23it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 176.50it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 176.23it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 175.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 176.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 175.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 174.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 173.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 171.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 169.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 164.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 163.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 163.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 164.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.50297
wandb: sub_train_loss 0.0
wandb:       test_acc 0.437
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run tough-sweep-71 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5uxjlokv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121759-5uxjlokv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w5hnbivv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121813-w5hnbivv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5hnbivv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.91it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.34it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 170.82it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 171.44it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 172.52it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 171.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 170.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 168.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 165.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 158.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 157.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 157.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 156.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 161.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 163.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 165.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 167.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.52701
wandb: sub_train_loss 0.0
wandb:       test_acc 0.57
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run different-sweep-72 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5hnbivv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121813-w5hnbivv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pugbxth2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121829-pugbxth2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pugbxth2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.44it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.73it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.67it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 163.84it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 156.52it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 153.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 153.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 153.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 154.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 156.16it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 156.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 153.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 154.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 154.54it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 159.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 163.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 166.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.65279
wandb: sub_train_loss 0.17363
wandb:       test_acc 0.679
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run dutiful-sweep-73 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pugbxth2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121829-pugbxth2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9f8opijt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121845-9f8opijt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9f8opijt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.50it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.82it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 174.69it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 164.20it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 168.87it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 172.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 175.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 177.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 177.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 178.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 177.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 177.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 177.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 178.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 179.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 179.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñá‚ñÅ‚ñÑ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.55039
wandb: sub_train_loss 0.0
wandb:       test_acc 0.43
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run wobbly-sweep-74 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9f8opijt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121845-9f8opijt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8wdwz85y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121900-8wdwz85y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8wdwz85y
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.98it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 169.69it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 163.68it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 161.97it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 167.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 170.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 172.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 172.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 175.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 176.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 177.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 178.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 178.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 179.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 168.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 159.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.53299
wandb: sub_train_loss 0.0
wandb:       test_acc 0.348
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run hearty-sweep-75 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8wdwz85y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121900-8wdwz85y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sfmgjkzx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121911-sfmgjkzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sfmgjkzx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.12it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.11it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 170.17it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 169.73it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 170.12it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 171.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 173.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 174.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 176.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 176.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 176.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 176.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 174.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 172.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 173.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 175.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.5196
wandb: sub_train_loss 0.0
wandb:       test_acc 0.5
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run golden-sweep-76 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sfmgjkzx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121911-sfmgjkzx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eqww6di3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121927-eqww6di3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/eqww6di3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.43it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 155.11it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 148.24it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 145.15it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 144.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 142.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 142.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 141.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 142.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 144.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 144.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 144.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 150.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 155.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 159.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 161.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 160.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 161.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.49257
wandb: sub_train_loss 0.28171
wandb:       test_acc 0.422
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run graceful-sweep-77 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/eqww6di3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121927-eqww6di3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7bbhv7sm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121942-7bbhv7sm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7bbhv7sm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.33it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 179.18it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 180.91it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 180.03it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 178.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 178.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 178.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 178.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 178.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 177.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 175.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 174.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 174.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 173.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 174.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 174.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.56966
wandb: sub_train_loss 0.0
wandb:       test_acc 0.544
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run lemon-sweep-78 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7bbhv7sm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121942-7bbhv7sm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l0l85bn3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_121956-l0l85bn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0l85bn3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.72it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 161.05it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 163.78it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 165.41it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 165.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 166.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 166.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 166.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 167.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 167.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 167.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 167.89it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 168.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 168.32it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 169.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 169.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 164.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.49409
wandb: sub_train_loss 0.33053
wandb:       test_acc 0.501
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run volcanic-sweep-79 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0l85bn3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_121956-l0l85bn3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sr1tbwoc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122012-sr1tbwoc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sr1tbwoc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.01it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 161.67it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.85it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 161.97it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 162.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 155.79it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 160.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 164.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 167.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 168.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 170.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 172.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 172.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 166.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 165.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 165.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 165.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.742
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.41502
wandb: sub_train_loss 4e-05
wandb:       test_acc 0.418
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run rosy-sweep-80 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sr1tbwoc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122012-sr1tbwoc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ouxsz2vt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122028-ouxsz2vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ouxsz2vt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.14it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.15it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.71it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.63it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 143.20it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 131.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 131.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 132.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 134.62it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 136.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 135.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 135.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 135.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 136.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 138.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 138.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 137.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 136.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 137.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.4242
wandb: sub_train_loss 0.0
wandb:       test_acc 0.293
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run twilight-sweep-81 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ouxsz2vt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122028-ouxsz2vt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pv0pvzqa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122043-pv0pvzqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pv0pvzqa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.80it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.84it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.24it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.98it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 143.47it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 145.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 146.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 146.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 147.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 147.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 143.73it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 145.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 147.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 147.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 149.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 146.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 146.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 144.29it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 146.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.407
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.46417
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run crimson-sweep-82 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pv0pvzqa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122043-pv0pvzqa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5letkehp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122058-5letkehp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5letkehp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.81it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.68it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.10it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.73it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 145.06it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 145.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 145.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 143.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 142.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 141.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 142.57it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 142.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 142.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 142.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 142.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 142.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 141.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 142.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÜ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.601
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.4874
wandb: sub_train_loss 0.0
wandb:       test_acc 0.521
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run electric-sweep-83 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5letkehp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122058-5letkehp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 57kp261f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122120-57kp261f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/57kp261f
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.13it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.55it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.67it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.37it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 154.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 153.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 152.77it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 151.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 150.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 151.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 151.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 152.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 152.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 152.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 152.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñà‚ñÇ‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.568
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.52751
wandb: sub_train_loss 0.07227
wandb:       test_acc 0.489
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run lucky-sweep-84 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/57kp261f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122120-57kp261f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 06oxgmuh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122133-06oxgmuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/06oxgmuh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.56it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.47it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.40it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.17it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.66it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 148.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 148.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 147.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 146.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 145.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 143.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 142.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 141.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 140.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 140.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 140.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 139.10it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 138.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 136.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 136.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.678
wandb: best_valid_acc 0.704
wandb:  sub_train_acc 0.60506
wandb: sub_train_loss 0.0
wandb:       test_acc 0.474
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run astral-sweep-85 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/06oxgmuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122133-06oxgmuh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2tiucaoc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122146-2tiucaoc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2tiucaoc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.87it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.22it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 148.75it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 148.70it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 148.13it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 148.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 150.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 148.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 141.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 133.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 131.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 131.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 131.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 127.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 126.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 124.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 123.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 130.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 136.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 138.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÇ‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.671
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.59913
wandb: sub_train_loss 0.0
wandb:       test_acc 0.462
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run deft-sweep-86 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2tiucaoc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122146-2tiucaoc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e0xjzsts with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122202-e0xjzsts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e0xjzsts
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.80it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.01it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 130.82it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 130.09it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 125.66it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 125.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 126.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 131.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 135.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 139.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 141.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 144.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 146.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 146.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 148.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 148.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 149.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 145.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 146.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 145.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.56292
wandb: sub_train_loss 0.0
wandb:       test_acc 0.327
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run spring-sweep-87 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e0xjzsts
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122202-e0xjzsts/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ew4lkhbc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122218-ew4lkhbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ew4lkhbc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.16it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.39it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 141.27it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 140.87it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.04it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.69it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 141.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 142.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 144.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 145.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 146.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 144.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 143.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 143.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 143.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 144.05it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 144.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 143.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 145.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÑ‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.60004
wandb: sub_train_loss 0.0
wandb:       test_acc 0.512
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run bumbling-sweep-88 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ew4lkhbc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122218-ew4lkhbc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 851cyv5c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122233-851cyv5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/851cyv5c
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.72it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 139.34it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 142.75it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 145.78it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 145.41it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 145.07it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 144.34it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 144.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 145.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 145.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 146.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 144.94it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 143.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 144.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 145.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 144.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 145.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 145.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 145.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÜ‚ñá‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÅ‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.5757
wandb: sub_train_loss 0.0
wandb:       test_acc 0.554
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run floral-sweep-89 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/851cyv5c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122233-851cyv5c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q03utrb2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122248-q03utrb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q03utrb2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.39it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.52it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.77it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.34it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 149.16it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 148.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 147.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 148.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 148.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 148.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 148.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 149.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 147.69it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 146.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 145.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 145.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 146.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 146.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 146.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.57027
wandb: sub_train_loss 0.0
wandb:       test_acc 0.572
wandb:      valid_acc 0.622
wandb: 
wandb: üöÄ View run legendary-sweep-90 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q03utrb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122248-q03utrb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6pon5kai with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122303-6pon5kai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6pon5kai
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.56it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 147.01it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 148.19it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 145.28it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 139.37it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 131.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 130.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 132.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 134.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 136.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 137.02it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 138.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 138.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 139.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 142.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 141.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 142.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 143.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 143.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 144.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÑ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.69336
wandb: sub_train_loss 0.52968
wandb:       test_acc 0.674
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run toasty-sweep-91 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6pon5kai
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122303-6pon5kai/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ww61l4nu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122321-ww61l4nu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ww61l4nu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.58it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.84it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.81it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 150.36it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.57it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 149.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 146.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 138.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 135.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 135.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 139.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 142.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 144.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 146.60it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 147.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 149.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 149.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 149.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 150.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.693
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.64898
wandb: sub_train_loss 0.08467
wandb:       test_acc 0.675
wandb:      valid_acc 0.692
wandb: 
wandb: üöÄ View run wandering-sweep-92 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ww61l4nu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122321-ww61l4nu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xqeijix2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122336-xqeijix2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xqeijix2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.15it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 123.13it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.86it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 130.01it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 133.28it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 135.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 137.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 138.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 138.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 138.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 138.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 138.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 137.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 137.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 137.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 136.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 136.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 137.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 137.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 137.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 137.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.692
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.54197
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.518
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run deep-sweep-93 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xqeijix2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122336-xqeijix2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: owdhk50t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122352-owdhk50t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/owdhk50t
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.66it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.47it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.35it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.41it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 150.58it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 150.97it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 151.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 150.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 150.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 150.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 151.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 150.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 150.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 148.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 149.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 149.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 149.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 150.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 150.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.32906
wandb: sub_train_loss 1.74837
wandb:       test_acc 0.197
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run sleek-sweep-94 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/owdhk50t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122352-owdhk50t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rr8fp2bx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122407-rr8fp2bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rr8fp2bx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.36it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.08it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 137.23it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 138.55it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 138.33it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 137.01it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 138.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 140.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 136.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 139.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 141.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 144.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 145.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 146.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 148.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 150.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 151.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 151.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 150.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.6042
wandb: sub_train_loss 0.98504
wandb:       test_acc 0.643
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run usual-sweep-95 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rr8fp2bx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122407-rr8fp2bx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2480pxx8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122422-2480pxx8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2480pxx8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.47it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.02it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.00it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 138.05it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 140.05it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 141.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 141.40it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 138.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 137.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 142.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 145.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 147.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 149.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 150.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 150.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 151.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 151.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 151.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 150.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.60324
wandb: sub_train_loss 0.41181
wandb:       test_acc 0.6
wandb:      valid_acc 0.642
wandb: 
wandb: üöÄ View run still-sweep-96 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2480pxx8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122422-2480pxx8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bq9dqfd1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122436-bq9dqfd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bq9dqfd1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.51it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 134.12it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 138.61it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 141.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 141.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 141.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 140.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 144.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 147.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 149.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 150.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 150.52it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 151.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.456
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.36907
wandb: sub_train_loss 0.0
wandb:       test_acc 0.371
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run dulcet-sweep-97 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bq9dqfd1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122436-bq9dqfd1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1vyn9adh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122451-1vyn9adh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1vyn9adh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.68it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.32it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.25it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 146.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 150.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 152.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 153.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 153.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 153.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 153.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.451
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.39377
wandb: sub_train_loss 0.0
wandb:       test_acc 0.404
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run restful-sweep-98 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1vyn9adh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122451-1vyn9adh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pbjeutvp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122507-pbjeutvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pbjeutvp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.39it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 123.19it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 127.64it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 130.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 133.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 136.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 136.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 136.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 137.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 138.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 141.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 144.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 147.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.617
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.35822
wandb: sub_train_loss 0.23849
wandb:       test_acc 0.272
wandb:      valid_acc 0.276
wandb: 
wandb: üöÄ View run wandering-sweep-99 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pbjeutvp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122507-pbjeutvp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h96yuuh1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122522-h96yuuh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h96yuuh1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.32it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.90it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.41it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 150.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 151.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 153.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 155.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 156.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 158.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 158.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 157.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 156.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.56829
wandb: sub_train_loss 0.03795
wandb:       test_acc 0.521
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run distinctive-sweep-100 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h96yuuh1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122522-h96yuuh1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: frhh92lj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122538-frhh92lj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/frhh92lj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.31it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.30it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 141.70it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 141.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 143.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 144.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 143.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 143.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 143.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 140.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 137.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 135.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 135.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.55896
wandb: sub_train_loss 0.61353
wandb:       test_acc 0.499
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run dry-sweep-101 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/frhh92lj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122538-frhh92lj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wa2i9vtn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122553-wa2i9vtn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wa2i9vtn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.08it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 132.80it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.48it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 133.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 137.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 135.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 136.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 138.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 139.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 140.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 140.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 140.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.47036
wandb: sub_train_loss 0.02956
wandb:       test_acc 0.424
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run wild-sweep-102 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wa2i9vtn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122553-wa2i9vtn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gu6lacy1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122608-gu6lacy1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gu6lacy1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.12it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 107.07it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 109.16it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 108.65it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 106.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 112.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 114.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 117.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 122.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 126.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 123.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 121.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 121.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 122.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 122.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.35021
wandb: sub_train_loss 0.3326
wandb:       test_acc 0.319
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run solar-sweep-103 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gu6lacy1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122608-gu6lacy1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s5pci051 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122624-s5pci051
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s5pci051
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.83it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.47it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 154.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 148.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 146.81it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 148.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 149.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 149.59it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 149.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.5937
wandb: sub_train_loss 0.14314
wandb:       test_acc 0.554
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run drawn-sweep-104 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s5pci051
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122624-s5pci051/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hla2c3mb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122638-hla2c3mb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hla2c3mb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.21it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.51it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.24it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 153.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 152.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 153.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 153.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 154.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 154.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 154.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.762
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.45357
wandb: sub_train_loss 0.43558
wandb:       test_acc 0.477
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run rural-sweep-105 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hla2c3mb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122638-hla2c3mb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yr10a9pt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122654-yr10a9pt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yr10a9pt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.57it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.59it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 153.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 154.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 154.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.52589
wandb: sub_train_loss 2.38648
wandb:       test_acc 0.509
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run helpful-sweep-106 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yr10a9pt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122654-yr10a9pt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yyw301aq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122710-yyw301aq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yyw301aq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.61it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.00it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 142.81it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 142.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 141.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 142.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 142.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 144.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 145.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 146.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 147.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.48877
wandb: sub_train_loss 0.66376
wandb:       test_acc 0.464
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run deft-sweep-107 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yyw301aq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122710-yyw301aq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0kah8zit with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122725-0kah8zit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0kah8zit
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.89it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.33it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.07it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 126.89it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 127.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 132.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 135.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 137.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 138.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 138.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 137.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 137.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 138.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 139.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.64513
wandb: sub_train_loss 0.07292
wandb:       test_acc 0.639
wandb:      valid_acc 0.662
wandb: 
wandb: üöÄ View run wobbly-sweep-108 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0kah8zit
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122725-0kah8zit/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kh12hkoi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122740-kh12hkoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kh12hkoi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.99it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.81it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 144.63it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 143.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 145.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 146.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 146.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 147.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 146.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 147.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 147.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 147.57it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 147.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.57433
wandb: sub_train_loss 0.40169
wandb:       test_acc 0.591
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run resilient-sweep-109 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kh12hkoi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122740-kh12hkoi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2pgcsrb6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122755-2pgcsrb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2pgcsrb6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.36it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.44it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 151.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 154.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 154.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 150.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 149.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 148.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.72709
wandb: sub_train_loss 0.20484
wandb:       test_acc 0.751
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run devoted-sweep-110 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2pgcsrb6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122755-2pgcsrb6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vjlcq1iw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122811-vjlcq1iw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vjlcq1iw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.58it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.50it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 135.88it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 138.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 141.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 144.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 145.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 146.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 147.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 148.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 148.22it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 144.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 141.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.71532
wandb: sub_train_loss 0.43673
wandb:       test_acc 0.764
wandb:      valid_acc 0.752
wandb: 
wandb: üöÄ View run sweepy-sweep-111 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vjlcq1iw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122811-vjlcq1iw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k69a83cl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122826-k69a83cl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k69a83cl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 139.91it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 137.76it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 143.13it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 144.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 145.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 148.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 149.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 146.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 146.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 147.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 148.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 148.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.52924
wandb: sub_train_loss 0.43829
wandb:       test_acc 0.518
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run serene-sweep-112 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k69a83cl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122826-k69a83cl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wcdwwmcl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122848-wcdwwmcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wcdwwmcl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.27it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 112.46it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 112.31it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 112.73it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 111.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 111.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 112.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 112.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 112.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 112.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 111.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 112.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 112.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 113.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 113.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.483
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.39342
wandb: sub_train_loss 0.0
wandb:       test_acc 0.464
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run rose-sweep-113 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wcdwwmcl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122848-wcdwwmcl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qd3fxqts with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122900-qd3fxqts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qd3fxqts
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.86it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.05it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.08it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 121.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 119.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 118.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 117.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 117.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 118.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 117.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 117.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 118.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 119.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 120.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 119.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.441
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.2475
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run giddy-sweep-114 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qd3fxqts
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122900-qd3fxqts/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4pqoafp3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122915-4pqoafp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4pqoafp3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.00it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.51it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.13it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 119.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 118.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 117.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 115.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 114.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 114.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 114.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 114.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 115.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 117.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 118.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 118.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 116.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.31491
wandb: sub_train_loss 0.25723
wandb:       test_acc 0.231
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run celestial-sweep-115 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4pqoafp3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122915-4pqoafp3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 56wzose2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122930-56wzose2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/56wzose2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.80it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.42it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.51it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 116.17it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 114.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 115.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 115.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 115.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 115.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 115.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 114.96it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 115.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 114.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 113.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.532
wandb: best_valid_acc 0.574
wandb:  sub_train_acc 0.41878
wandb: sub_train_loss 0.43522
wandb:       test_acc 0.407
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run electric-sweep-116 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/56wzose2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122930-56wzose2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n7ls7yo1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_122945-n7ls7yo1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/n7ls7yo1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 119.88it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.54it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.08it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 121.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 122.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 123.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 119.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 117.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 116.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 117.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 112.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 103.05it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 98.99it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 99.14it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 102.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 103.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.51362
wandb: sub_train_loss 0.18423
wandb:       test_acc 0.506
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run dry-sweep-117 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/n7ls7yo1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_122945-n7ls7yo1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kz2r36tb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123001-kz2r36tb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kz2r36tb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.36it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 102.74it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 99.20it/s]  22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.02it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 103.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 104.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 105.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 105.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 106.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 108.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 105.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 102.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 100.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 100.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 101.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 103.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 105.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 104.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.699
wandb: best_valid_acc 0.734
wandb:  sub_train_acc 0.61566
wandb: sub_train_loss 0.11786
wandb:       test_acc 0.673
wandb:      valid_acc 0.67
wandb: 
wandb: üöÄ View run bright-sweep-118 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kz2r36tb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123001-kz2r36tb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v30u9w2b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123016-v30u9w2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v30u9w2b
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.45it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 99.12it/s]  16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 100.67it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.51it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 103.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 104.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 106.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 108.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 108.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 110.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 110.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 111.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 111.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 110.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 111.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 112.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 115.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.63199
wandb: sub_train_loss 0.33291
wandb:       test_acc 0.628
wandb:      valid_acc 0.6
wandb: 
wandb: üöÄ View run wandering-sweep-119 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v30u9w2b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123016-v30u9w2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u7sd8fjg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123031-u7sd8fjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u7sd8fjg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 113.25it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.45it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 113.72it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.13it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 114.97it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 116.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 114.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 115.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 116.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 116.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 116.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 116.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 116.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 116.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 117.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.70817
wandb: sub_train_loss 0.21344
wandb:       test_acc 0.721
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run radiant-sweep-120 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u7sd8fjg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123031-u7sd8fjg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l5m2z1ho with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123047-l5m2z1ho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-121
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l5m2z1ho
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 105.81it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 107.73it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 108.14it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 107.62it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 108.40it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 109.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 109.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 110.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 106.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 104.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 102.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 101.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 101.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 101.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 100.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 100.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 101.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 104.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.40919
wandb: sub_train_loss 0.54807
wandb:       test_acc 0.413
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run fresh-sweep-121 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l5m2z1ho
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123047-l5m2z1ho/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p7pkrtcu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123103-p7pkrtcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-122
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p7pkrtcu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.30it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 110.34it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.63it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 112.70it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 112.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 111.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 109.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 110.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 111.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 110.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 109.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 108.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 107.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 106.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 107.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 109.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.55784
wandb: sub_train_loss 0.46857
wandb:       test_acc 0.514
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run iconic-sweep-122 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p7pkrtcu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123103-p7pkrtcu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: awmx8s0j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123118-awmx8s0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/awmx8s0j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 113.32it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.69it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.46it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 100.83it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 104.69it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 110.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 115.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 118.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 117.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 108.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 112.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 115.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 117.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 119.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 121.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.706
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.55931
wandb: sub_train_loss 0.46098
wandb:       test_acc 0.517
wandb:      valid_acc 0.556
wandb: 
wandb: üöÄ View run swift-sweep-123 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/awmx8s0j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123118-awmx8s0j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mtd4vq45 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123133-mtd4vq45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-124
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mtd4vq45
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.80it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.77it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.01it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 119.65it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 120.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 121.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 121.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 119.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 117.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 116.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 104.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 96.08it/s]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 91.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 87.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 84.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 83.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 84.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 101.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.42314
wandb: sub_train_loss 0.85177
wandb:       test_acc 0.409
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run valiant-sweep-124 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mtd4vq45
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123133-mtd4vq45/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fxzw0jan with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123151-fxzw0jan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-125
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fxzw0jan
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 109.00it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 107.43it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 107.15it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 106.58it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 105.23it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 105.93it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 107.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 108.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 109.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 109.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 109.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 111.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 109.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 109.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 108.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 106.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 109.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.52792
wandb: sub_train_loss 0.62323
wandb:       test_acc 0.52
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run dulcet-sweep-125 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fxzw0jan
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123151-fxzw0jan/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w25ce9s3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123207-w25ce9s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-126
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w25ce9s3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.36it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 122.19it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 122.74it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 121.56it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 120.22it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 118.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 120.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 121.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 121.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 121.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 121.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 121.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 121.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 120.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 119.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.48638
wandb: sub_train_loss 0.77263
wandb:       test_acc 0.488
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run feasible-sweep-126 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w25ce9s3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123207-w25ce9s3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pybv51uq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123222-pybv51uq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pybv51uq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.27it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.12it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 113.40it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.57it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 112.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 112.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 113.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 112.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 112.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 112.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 111.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 112.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 111.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 110.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 108.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.768
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.60902
wandb: sub_train_loss 0.66015
wandb:       test_acc 0.611
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run dutiful-sweep-127 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pybv51uq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123222-pybv51uq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m0qstkfe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123236-m0qstkfe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-128
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m0qstkfe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.55it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.06it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 121.32it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 121.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 121.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 119.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 119.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 119.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 120.28it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 119.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 118.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 118.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 118.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 117.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 116.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.776
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.43303
wandb: sub_train_loss 0.91284
wandb:       test_acc 0.372
wandb:      valid_acc 0.382
wandb: 
wandb: üöÄ View run spring-sweep-128 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m0qstkfe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123236-m0qstkfe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f05tzdg2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123252-f05tzdg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-129
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f05tzdg2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.85it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.40it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.29it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.83it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 91.08it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 90.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 91.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 91.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 91.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 89.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:01, 89.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 90.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 86.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 80.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 78.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 79.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 79.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:02<00:00, 80.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:02<00:00, 79.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 80.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 85.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.423
wandb: best_valid_acc 0.442
wandb:  sub_train_acc 0.21885
wandb: sub_train_loss 0.0005
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run unique-sweep-129 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f05tzdg2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123252-f05tzdg2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3llfmc0n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123307-3llfmc0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3llfmc0n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.51it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 97.46it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 96.68it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 95.61it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 96.41it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 93.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 92.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 91.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 91.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 91.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 92.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 92.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 92.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 91.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 90.85it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 89.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 89.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 89.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:02<00:00, 89.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 89.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 91.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.408
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.3356
wandb: sub_train_loss 0.0
wandb:       test_acc 0.353
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run rare-sweep-130 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3llfmc0n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123307-3llfmc0n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5mjtgpdn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123329-5mjtgpdn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5mjtgpdn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.37it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 97.43it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 100.67it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 101.76it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 102.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 103.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 102.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 100.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 97.65it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 96.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 90.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 91.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 91.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 92.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 93.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 93.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 93.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 93.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:02<00:00, 93.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.591
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.49642
wandb: sub_train_loss 0.03136
wandb:       test_acc 0.503
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run noble-sweep-131 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5mjtgpdn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123329-5mjtgpdn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lcdgd3ww with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123343-lcdgd3ww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-132
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lcdgd3ww
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.09it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.99it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.00it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 97.55it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 98.06it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 98.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 98.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 99.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 99.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:00, 99.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 99.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 98.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 97.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 97.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 97.37it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 98.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 99.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 99.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 99.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.5127
wandb: sub_train_loss 0.26268
wandb:       test_acc 0.608
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run smooth-sweep-132 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lcdgd3ww
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123343-lcdgd3ww/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8cpqczqm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123359-8cpqczqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-133
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8cpqczqm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 95.53it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.91it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.41it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 94.36it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.32it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 94.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 94.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 94.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 94.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 94.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 92.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 92.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 90.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 89.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 88.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 88.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:02<00:00, 90.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 91.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.64067
wandb: sub_train_loss 0.16255
wandb:       test_acc 0.688
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run royal-sweep-133 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8cpqczqm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123359-8cpqczqm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oi3jyq8j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123414-oi3jyq8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-134
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oi3jyq8j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.82it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 102.29it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.70it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.61it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 100.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 99.37it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:01, 98.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 97.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 96.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 96.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 95.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 95.42it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 96.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 97.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 95.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 95.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 95.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.49805
wandb: sub_train_loss 0.25365
wandb:       test_acc 0.504
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run fresh-sweep-134 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oi3jyq8j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123414-oi3jyq8j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 51xse598 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123429-51xse598
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-135
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/51xse598
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.77it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.24it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.54it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 96.72it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 97.69it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.22it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 97.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 98.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 96.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 94.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 90.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 88.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 87.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 85.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 84.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 83.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 82.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 82.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:02<00:00, 83.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 83.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.64898
wandb: sub_train_loss 0.47332
wandb:       test_acc 0.627
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run fiery-sweep-135 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/51xse598
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123429-51xse598/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mwl8vv8h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123446-mwl8vv8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-136
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mwl8vv8h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 95.72it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 97.28it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.43it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 95.02it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 95.96it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.12it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 96.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 98.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 98.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 98.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 97.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 97.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 96.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 95.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 95.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 95.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 95.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 96.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 95.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.53639
wandb: sub_train_loss 0.17066
wandb:       test_acc 0.461
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run avid-sweep-136 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mwl8vv8h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123446-mwl8vv8h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h0pdnxdu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123502-h0pdnxdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0pdnxdu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.37it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 97.55it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 98.34it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 98.75it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 98.79it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 99.16it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 99.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 99.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 99.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:00, 99.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 97.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 94.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 88.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 83.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 84.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 87.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 90.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 90.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 91.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.67612
wandb: sub_train_loss 0.64988
wandb:       test_acc 0.676
wandb:      valid_acc 0.684
wandb: 
wandb: üöÄ View run robust-sweep-137 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0pdnxdu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123502-h0pdnxdu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 79te96ar with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123517-79te96ar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-138
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79te96ar
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.88it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 101.92it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.29it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.87it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 102.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 103.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 103.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 102.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 102.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 102.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 102.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 102.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 102.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 102.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 102.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 102.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 102.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.38692
wandb: sub_train_loss 0.9673
wandb:       test_acc 0.405
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run earthy-sweep-138 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79te96ar
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123517-79te96ar/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b4dlq6w0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123532-b4dlq6w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-139
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b4dlq6w0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.30it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 95.65it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.96it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.88it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 93.92it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 94.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 95.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 95.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 95.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 95.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 97.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 95.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 93.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 91.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 91.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 92.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 92.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 92.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.65755
wandb: sub_train_loss 0.29944
wandb:       test_acc 0.682
wandb:      valid_acc 0.722
wandb: 
wandb: üöÄ View run visionary-sweep-139 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b4dlq6w0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123532-b4dlq6w0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x7txbepk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123548-x7txbepk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-140
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x7txbepk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.34it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 91.84it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 91.75it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.34it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.69it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 96.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 97.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 98.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 98.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:00, 99.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 99.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 98.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 98.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 97.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 96.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 97.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 97.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 97.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 98.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.50221
wandb: sub_train_loss 0.74576
wandb:       test_acc 0.496
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run icy-sweep-140 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x7txbepk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123548-x7txbepk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vhivc78s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123603-vhivc78s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-141
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vhivc78s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 83.96it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 83.42it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 83.73it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 85.73it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 86.07it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 86.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 85.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 85.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 84.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:01<00:01, 84.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 87.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:01, 87.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 85.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 81.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 83.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 86.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 88.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 90.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:02<00:00, 91.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 90.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 91.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 87.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.67059
wandb: sub_train_loss 0.58866
wandb:       test_acc 0.677
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run cerulean-sweep-141 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vhivc78s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123603-vhivc78s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ygx11mvs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123618-ygx11mvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ygx11mvs
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 89.59it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.57it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 87.30it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 90.33it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 91.65it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 93.04it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 94.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 94.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 94.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:01<00:01, 92.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:01, 92.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 92.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 93.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 95.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 96.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 97.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 97.35it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 97.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 97.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 97.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.58239
wandb: sub_train_loss 0.44282
wandb:       test_acc 0.58
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run golden-sweep-142 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ygx11mvs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123618-ygx11mvs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: obfm9b7r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123634-obfm9b7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-143
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/obfm9b7r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.49it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 95.82it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 97.72it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 99.02it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 100.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 100.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 99.84it/s]  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 100.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 101.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 101.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 101.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 101.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 101.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 100.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 97.61it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 98.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 98.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 98.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñá‚ñà‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñà‚ñá‚ñà‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.67698
wandb: sub_train_loss 0.51668
wandb:       test_acc 0.691
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run ethereal-sweep-143 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/obfm9b7r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123634-obfm9b7r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wotb3bex with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123650-wotb3bex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-144
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wotb3bex
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.45it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 98.47it/s]  16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 95.39it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 94.26it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 93.45it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 93.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 93.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 92.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 91.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 91.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 92.55it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 92.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 92.94it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 92.88it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 92.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 92.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 92.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 92.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 92.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.42405
wandb: sub_train_loss 0.86548
wandb:       test_acc 0.435
wandb:      valid_acc 0.406
wandb: 
wandb: üöÄ View run kind-sweep-144 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wotb3bex
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123650-wotb3bex/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ee7n97aj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123704-ee7n97aj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-145
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ee7n97aj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.64it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.06it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.29it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.19it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 147.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 144.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 143.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 143.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 144.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 144.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 143.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 143.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 144.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 144.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 143.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 146.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 148.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 150.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 151.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.505
wandb: best_valid_acc 0.528
wandb:  sub_train_acc 0.41086
wandb: sub_train_loss 0.0
wandb:       test_acc 0.416
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run apricot-sweep-145 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ee7n97aj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123704-ee7n97aj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x2l4aimo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123720-x2l4aimo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-146
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x2l4aimo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.21it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 152.19it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 151.02it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 150.19it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 151.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 147.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 143.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 141.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 141.31it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 144.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 148.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 138.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 124.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 123.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 125.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 127.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 130.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 130.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 130.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 129.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.45
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.35873
wandb: sub_train_loss 0.0
wandb:       test_acc 0.369
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run daily-sweep-146 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x2l4aimo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123720-x2l4aimo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yzxxw28d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123735-yzxxw28d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzxxw28d
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.41it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.56it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 151.19it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 151.68it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 151.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 152.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 152.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 152.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 152.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 152.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 152.61it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 152.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 151.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 151.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 151.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 151.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 151.74it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 151.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.668
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.49881
wandb: sub_train_loss 0.00018
wandb:       test_acc 0.488
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run iconic-sweep-147 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzxxw28d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123735-yzxxw28d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6pspoeff with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123750-6pspoeff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-148
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6pspoeff
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.07it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.71it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.05it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.09it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 152.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 150.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 147.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 148.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 150.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 150.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 151.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 152.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 152.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 153.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 153.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 153.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 153.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.581
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.46163
wandb: sub_train_loss 0.02196
wandb:       test_acc 0.446
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run blooming-sweep-148 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6pspoeff
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123750-6pspoeff/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: psjdf1qk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123805-psjdf1qk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-149
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/psjdf1qk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.92it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 149.57it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 149.32it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.24it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 150.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 151.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 152.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 153.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 152.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 141.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 137.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 134.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 134.92it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 134.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 133.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 135.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 133.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 134.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.45357
wandb: sub_train_loss 0.38794
wandb:       test_acc 0.464
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run iconic-sweep-149 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/psjdf1qk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123805-psjdf1qk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4wxg74ka with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123821-4wxg74ka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-150
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4wxg74ka
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.87it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 137.48it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 129.92it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 123.90it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 122.92it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 122.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 123.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 121.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 121.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 123.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 121.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 119.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 118.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 120.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 123.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 122.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 123.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 123.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 124.32it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 125.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 126.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 126.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.2541
wandb: sub_train_loss 0.34273
wandb:       test_acc 0.2
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run vibrant-sweep-150 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4wxg74ka
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123821-4wxg74ka/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nyqtcxgp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123845-nyqtcxgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-151
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nyqtcxgp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.37it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.18it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.43it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 148.48it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 148.42it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 147.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 148.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 149.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 150.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 148.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 148.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 147.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 148.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 147.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 142.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 144.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 145.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 146.53it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 147.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.6433
wandb: sub_train_loss 0.09497
wandb:       test_acc 0.641
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run hearty-sweep-151 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nyqtcxgp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123845-nyqtcxgp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tw2aatxa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123858-tw2aatxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tw2aatxa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.06it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.96it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.46it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.24it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.36it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 140.71it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 141.03it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 138.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 138.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 139.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 138.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 137.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 135.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 136.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 135.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 136.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 137.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 138.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 136.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.64148
wandb: sub_train_loss 0.15119
wandb:       test_acc 0.673
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run woven-sweep-152 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tw2aatxa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123858-tw2aatxa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a3f45g7j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123920-a3f45g7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-153
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a3f45g7j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.39it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 128.86it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.90it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 132.20it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 138.01it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 142.71it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 145.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 146.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 144.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 142.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 141.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 141.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 142.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 141.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 140.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 142.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 143.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 144.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 144.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 142.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.66892
wandb: sub_train_loss 0.05577
wandb:       test_acc 0.65
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run rosy-sweep-153 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a3f45g7j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123920-a3f45g7j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fmv7qld0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123932-fmv7qld0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-154
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fmv7qld0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.73it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.45it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 147.44it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 146.26it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 144.90it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 144.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 144.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 143.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 143.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 143.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 142.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 143.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 142.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 139.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 139.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 139.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 139.66it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 139.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 139.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 138.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.766
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.35188
wandb: sub_train_loss 0.28609
wandb:       test_acc 0.286
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run solar-sweep-154 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fmv7qld0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123932-fmv7qld0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hkjyd5va with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_123950-hkjyd5va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-155
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hkjyd5va
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.36it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.59it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.39it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 154.69it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 155.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 155.14it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 155.22it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 155.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 156.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 156.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 154.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 155.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 156.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 156.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 157.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 157.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.68565
wandb: sub_train_loss 0.09754
wandb:       test_acc 0.702
wandb:      valid_acc 0.736
wandb: 
wandb: üöÄ View run sparkling-sweep-155 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hkjyd5va
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_123950-hkjyd5va/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0efe1ahe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124003-0efe1ahe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-156
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0efe1ahe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.93it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.19it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.73it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 139.02it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 143.66it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.13it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 149.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 151.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 151.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 151.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 151.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 152.44it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 152.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 152.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 152.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 154.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 156.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 157.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 156.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÉ‚ñà‚ñà‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÉ‚ñà‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.772
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.62154
wandb: sub_train_loss 0.22666
wandb:       test_acc 0.636
wandb:      valid_acc 0.636
wandb: 
wandb: üöÄ View run fresh-sweep-156 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0efe1ahe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124003-0efe1ahe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vq8qxxhm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124018-vq8qxxhm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-157
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vq8qxxhm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 121.74it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.76it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 130.35it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 136.63it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 135.11it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 136.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 138.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 139.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 130.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 138.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 143.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 147.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 149.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 152.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 153.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 154.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 155.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 155.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 156.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.767
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.67718
wandb: sub_train_loss 0.18131
wandb:       test_acc 0.705
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run helpful-sweep-157 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vq8qxxhm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124018-vq8qxxhm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5syngrv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124034-i5syngrv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5syngrv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.68it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 151.80it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 154.43it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 152.51it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 153.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 153.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 154.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 155.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 154.80it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 151.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 151.07it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 152.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 153.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 153.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 152.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 151.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 151.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.37506
wandb: sub_train_loss 0.7155
wandb:       test_acc 0.36
wandb:      valid_acc 0.382
wandb: 
wandb: üöÄ View run swift-sweep-158 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5syngrv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124034-i5syngrv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1nwragna with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124054-1nwragna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-159
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1nwragna
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.94it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 131.70it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.06it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.77it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.32it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 133.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 139.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 140.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 140.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 142.85it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 146.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 148.38it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 149.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 150.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 151.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 151.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 150.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 147.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.771
wandb: best_valid_acc 0.81
wandb:  sub_train_acc 0.73936
wandb: sub_train_loss 0.2589
wandb:       test_acc 0.753
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run playful-sweep-159 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1nwragna
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124054-1nwragna/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0qgxn2zo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124110-0qgxn2zo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-160
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0qgxn2zo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.65it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 138.72it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 140.86it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 142.35it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 143.05it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 146.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 147.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 146.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 145.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 144.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 143.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 142.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 143.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 146.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 146.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 148.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 149.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 151.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 152.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñÉ‚ñÇ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.793
wandb: best_valid_acc 0.812
wandb:  sub_train_acc 0.5336
wandb: sub_train_loss 2.24683
wandb:       test_acc 0.512
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run brisk-sweep-160 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0qgxn2zo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124110-0qgxn2zo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mi1tzeeg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124125-mi1tzeeg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-161
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mi1tzeeg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.00it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.45it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.93it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 117.24it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 118.54it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 120.12it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 121.10it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 121.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 122.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 122.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 122.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 121.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 122.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 122.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 121.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 120.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 120.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 121.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 122.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 122.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 122.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 122.21it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 118.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.23158
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run polar-sweep-161 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mi1tzeeg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124125-mi1tzeeg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8c3bgpul with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124141-8c3bgpul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-162
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8c3bgpul
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.88it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.01it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 121.48it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 119.33it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 120.09it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 119.31it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 120.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 120.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 120.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 121.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 120.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 117.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 116.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 114.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 115.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 111.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 110.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 111.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 112.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 115.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 116.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 117.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 118.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.529
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.36796
wandb: sub_train_loss 0.0
wandb:       test_acc 0.405
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run expert-sweep-162 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8c3bgpul
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124141-8c3bgpul/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d2rwzdgr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124201-d2rwzdgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d2rwzdgr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 113.54it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.47it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.53it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 111.26it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 111.20it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 112.63it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 112.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 112.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 112.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 113.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 113.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 113.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 113.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 112.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 113.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 113.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 100.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 99.28it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 98.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 96.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 95.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 94.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 93.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 92.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 90.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 89.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 103.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.54
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.42557
wandb: sub_train_loss 0.00079
wandb:       test_acc 0.43
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run skilled-sweep-163 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d2rwzdgr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124201-d2rwzdgr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jn3oo2gq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124216-jn3oo2gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-164
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jn3oo2gq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.67it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 119.96it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.18it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 121.30it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 119.92it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 120.64it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 121.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 121.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 122.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 122.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 122.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 121.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 120.97it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 120.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 119.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 118.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 113.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 115.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 116.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 118.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 118.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 118.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 119.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñá‚ñá‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñà‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.529
wandb: best_valid_acc 0.564
wandb:  sub_train_acc 0.52427
wandb: sub_train_loss 0.07031
wandb:       test_acc 0.51
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run effortless-sweep-164 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jn3oo2gq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124216-jn3oo2gq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1u0fnr5b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124232-1u0fnr5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-165
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1u0fnr5b
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.24it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.73it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.24it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 121.28it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 119.84it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 119.50it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 119.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 120.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 117.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 115.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 113.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 112.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 112.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 111.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 110.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 113.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 111.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 102.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 99.10it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 97.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 100.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 106.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 111.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 113.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.691
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.56449
wandb: sub_train_loss 0.1091
wandb:       test_acc 0.568
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run breezy-sweep-165 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1u0fnr5b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124232-1u0fnr5b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ph688uw2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124247-ph688uw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ph688uw2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.02it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.18it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 120.30it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 121.48it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 120.07it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 121.59it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 122.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 111.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 105.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 102.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 100.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 98.85it/s]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 97.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 95.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 100.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:01, 104.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 105.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 105.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 104.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 104.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 104.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 101.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 101.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 101.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 103.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 106.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.6116
wandb: sub_train_loss 0.03635
wandb:       test_acc 0.687
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run rural-sweep-166 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ph688uw2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124247-ph688uw2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vrfrte73 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124302-vrfrte73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vrfrte73
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.20it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.38it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 123.18it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 122.62it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 123.18it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.38it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 124.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 123.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 120.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 119.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 118.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 117.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 115.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 112.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 112.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 113.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 106.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 95.82it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 98.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 104.91it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 108.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 111.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 113.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.57113
wandb: sub_train_loss 0.46078
wandb:       test_acc 0.585
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run noble-sweep-167 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vrfrte73
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124302-vrfrte73/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nelg3c33 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124318-nelg3c33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nelg3c33
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.55it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.22it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 118.95it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 119.82it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 119.34it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 119.73it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 120.15it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 120.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 121.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 121.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 120.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 117.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 111.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 112.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 112.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 115.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 117.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 119.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 120.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 121.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 122.45it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 121.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 119.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.71081
wandb: sub_train_loss 0.25949
wandb:       test_acc 0.713
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run stellar-sweep-168 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nelg3c33
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124318-nelg3c33/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8wnqzstp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124333-8wnqzstp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-169
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8wnqzstp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.65it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.43it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.70it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 122.54it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 120.69it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 120.45it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 120.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 119.66it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 120.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 119.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 116.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 116.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 118.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 118.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 119.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 106.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 105.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 103.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 104.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 102.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 96.18it/s]  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 95.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 97.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 100.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.774
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.71877
wandb: sub_train_loss 0.19007
wandb:       test_acc 0.725
wandb:      valid_acc 0.752
wandb: 
wandb: üöÄ View run morning-sweep-169 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8wnqzstp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124333-8wnqzstp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g87clvds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124348-g87clvds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-170
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g87clvds
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.91it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.17it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 118.68it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 118.41it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 117.62it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 114.55it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 111.03it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 107.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 104.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 105.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 106.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 100.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 96.36it/s]  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 94.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 92.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 94.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:01, 93.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 91.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 87.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 86.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 82.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 80.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 77.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 74.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 76.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 87.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 93.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñá‚ñà‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.64604
wandb: sub_train_loss 0.25827
wandb:       test_acc 0.654
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run blooming-sweep-170 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g87clvds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124348-g87clvds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ryquj62q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124404-ryquj62q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-171
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ryquj62q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 84.77it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 92.23it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 94.64it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 103.07it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 106.69it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 109.09it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 110.74it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 111.72it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 113.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 114.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 115.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 116.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 116.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 116.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 115.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 115.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 116.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 116.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 116.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 116.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 115.78it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 115.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 115.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 116.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 115.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.68291
wandb: sub_train_loss 0.33287
wandb:       test_acc 0.663
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run desert-sweep-171 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ryquj62q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124404-ryquj62q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pmww8sd9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124419-pmww8sd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-172
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pmww8sd9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.16it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.40it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 104.61it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 94.18it/s]  18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 91.32it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 95.66it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 101.02it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 107.24it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 108.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 111.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 113.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 113.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 115.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 116.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 118.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 116.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 113.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 110.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 111.47it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 114.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 116.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 118.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 117.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 115.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 115.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.53218
wandb: sub_train_loss 0.46131
wandb:       test_acc 0.575
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run brisk-sweep-172 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pmww8sd9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124419-pmww8sd9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tkms4bn9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124434-tkms4bn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkms4bn9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.31it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 119.69it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.80it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 122.87it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 123.33it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 122.25it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 121.79it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 121.64it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 120.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 119.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 117.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 116.90it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 116.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 115.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 114.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 111.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 107.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 104.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 102.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 101.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 101.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 105.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 108.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 112.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.776
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.69661
wandb: sub_train_loss 0.12963
wandb:       test_acc 0.719
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run drawn-sweep-173 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkms4bn9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124434-tkms4bn9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r02bvem9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124450-r02bvem9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-174
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r02bvem9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 112.51it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.12it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 116.62it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 119.04it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 121.25it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 121.60it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 122.81it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 123.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 124.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 121.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 119.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 118.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 112.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 105.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 106.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 108.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 109.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 108.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 108.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 107.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 106.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 105.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 111.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 114.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.77
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.37648
wandb: sub_train_loss 0.94423
wandb:       test_acc 0.355
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run effortless-sweep-174 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r02bvem9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124450-r02bvem9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j1j0vqtd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124505-j1j0vqtd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-175
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j1j0vqtd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.97it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.15it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 111.77it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 109.46it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 108.86it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 109.96it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 111.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 112.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 112.64it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 113.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 114.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 113.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 111.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 112.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 107.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 100.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 104.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 107.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 109.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 111.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 112.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 114.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 114.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 114.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 115.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.51215
wandb: sub_train_loss 0.56276
wandb:       test_acc 0.545
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run gallant-sweep-175 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j1j0vqtd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124505-j1j0vqtd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: neo6tmqd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124521-neo6tmqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-176
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/neo6tmqd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.97it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 116.89it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 116.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 116.97it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 104.51it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 103.74it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 109.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 110.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 111.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 112.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 112.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 112.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 113.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 112.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 112.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 113.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 113.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 113.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 114.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 114.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 115.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 115.37it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 114.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 114.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.788
wandb: best_valid_acc 0.81
wandb:  sub_train_acc 0.51646
wandb: sub_train_loss 0.81754
wandb:       test_acc 0.528
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run breezy-sweep-176 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/neo6tmqd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124521-neo6tmqd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e431l3h2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124536-e431l3h2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-177
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e431l3h2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.07it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 99.00it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 98.85it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.26it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 94.10it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 88.84it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 82.52it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 81.76it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 83.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 84.58it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 83.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 86.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 89.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 92.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 93.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 93.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 93.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 94.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:02<00:01, 94.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 95.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 95.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 96.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 96.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 96.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 96.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 95.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 93.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 92.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 92.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 94.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.21093
wandb: sub_train_loss 0.0
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run dazzling-sweep-177 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e431l3h2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124536-e431l3h2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f17cwk1q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124551-f17cwk1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f17cwk1q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 96.82it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.80it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 98.25it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.20it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 96.22it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 94.81it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 93.81it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 93.68it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 90.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 88.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 90.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 89.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 80.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 78.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 79.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 83.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 85.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:02<00:01, 87.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 90.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 91.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 89.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 90.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 87.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 88.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 90.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 92.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:03<00:00, 94.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 96.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 97.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.472
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.25156
wandb: sub_train_loss 0.0
wandb:       test_acc 0.178
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run eager-sweep-178 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f17cwk1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124551-f17cwk1q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8fbu3pdp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124606-8fbu3pdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-179
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8fbu3pdp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.26it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.10it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 97.90it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 98.69it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 98.90it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 99.39it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 98.67it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 98.97it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 97.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 98.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 97.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 96.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 94.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 93.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 89.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 81.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 85.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 89.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 92.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 94.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 95.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 96.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 96.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 97.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 96.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 96.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 96.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 96.31it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 96.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñà‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.49323
wandb: sub_train_loss 0.01254
wandb:       test_acc 0.498
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run ethereal-sweep-179 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8fbu3pdp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124606-8fbu3pdp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0pxphbcf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124622-0pxphbcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-180
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0pxphbcf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 99.79it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 100.71it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 100.68it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 101.18it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 101.82it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 102.09it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 92.09it/s]  29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 83.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 82.81it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 81.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:02, 80.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:02, 80.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:02, 80.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 83.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 85.92it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 88.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 91.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 91.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 91.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 91.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 92.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 91.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 92.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 92.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 93.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 93.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:03<00:00, 93.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 93.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 94.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.523
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.53766
wandb: sub_train_loss 0.1999
wandb:       test_acc 0.486
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run dashing-sweep-180 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0pxphbcf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124622-0pxphbcf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pzf20qxt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124638-pzf20qxt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-181
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pzf20qxt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.82it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.81it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.52it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 94.99it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 94.10it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.54it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 90.88it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 88.36it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 88.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 93.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 94.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 94.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 95.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 95.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 95.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 95.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 96.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 96.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 97.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 99.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 99.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 100.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 98.67it/s]  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 97.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 98.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 98.35it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 98.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 98.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.53345
wandb: sub_train_loss 0.10374
wandb:       test_acc 0.506
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run giddy-sweep-181 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pzf20qxt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124638-pzf20qxt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mvs57nhp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124653-mvs57nhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-182
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mvs57nhp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.96it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 99.79it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 99.83it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 100.03it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 88.97it/s]  21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 80.91it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 83.01it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 85.84it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:01<00:02, 88.39it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 89.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:02, 89.88it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 91.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 93.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 94.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 92.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 88.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 85.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:02<00:01, 87.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 89.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 90.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 90.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 90.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 91.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 91.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 92.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 93.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 94.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 94.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 94.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.5403
wandb: sub_train_loss 0.34513
wandb:       test_acc 0.518
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run vocal-sweep-182 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mvs57nhp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124653-mvs57nhp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tizuz77b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124708-tizuz77b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tizuz77b
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.26it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 98.95it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 97.34it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.09it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 97.56it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 98.24it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 98.71it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 98.35it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 98.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 99.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 99.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 98.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 98.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 98.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 98.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 97.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 97.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 96.39it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 95.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 93.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 93.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 91.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 91.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 91.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 91.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 91.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 91.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 91.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 90.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.60897
wandb: sub_train_loss 0.17988
wandb:       test_acc 0.621
wandb:      valid_acc 0.644
wandb: 
wandb: üöÄ View run winter-sweep-183 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tizuz77b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124708-tizuz77b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t2m1wxf2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124723-t2m1wxf2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-184
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t2m1wxf2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.77it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 99.35it/s] 10%|‚ñà         | 31/300 [00:00<00:02, 99.52it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 99.29it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 99.35it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 100.12it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 100.39it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:02, 100.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:02, 100.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:01, 101.02it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 101.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 100.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 100.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 100.91it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 100.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 100.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 98.46it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 97.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 96.76it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 96.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 94.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 92.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 93.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 95.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 96.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 97.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 97.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 95.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.68195
wandb: sub_train_loss 0.16274
wandb:       test_acc 0.701
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run swift-sweep-184 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t2m1wxf2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124723-t2m1wxf2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hj5ahiay with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124739-hj5ahiay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-185
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hj5ahiay
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 83.30it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 82.43it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 83.02it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 87.92it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 91.10it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 90.84it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 90.16it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 88.81it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 89.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 88.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 88.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 89.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 88.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 89.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 89.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 90.23it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 89.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 88.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 88.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 89.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 90.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 91.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 91.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 90.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 90.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 92.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 93.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:03<00:00, 94.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 94.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 95.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.70208
wandb: sub_train_loss 0.09632
wandb:       test_acc 0.712
wandb:      valid_acc 0.728
wandb: 
wandb: üöÄ View run vivid-sweep-185 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hj5ahiay
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124739-hj5ahiay/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wpcgj9xb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124754-wpcgj9xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-186
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wpcgj9xb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.99it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 99.49it/s] 10%|‚ñà         | 31/300 [00:00<00:02, 99.58it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 100.86it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 100.45it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 99.46it/s]  25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 100.01it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 99.18it/s]  32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:02, 98.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:01, 98.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 95.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 95.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 96.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 97.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 98.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 98.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 99.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 100.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:00, 101.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 101.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 102.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 102.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 102.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 102.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 101.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 101.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 100.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.20it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.52909
wandb: sub_train_loss 0.62762
wandb:       test_acc 0.538
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run distinctive-sweep-186 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wpcgj9xb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124754-wpcgj9xb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6db9tu1r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124810-6db9tu1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-187
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6db9tu1r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 93.50it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.56it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.74it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 97.62it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 98.35it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 98.79it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 98.88it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 98.30it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 98.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 98.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 99.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 99.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 99.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 99.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 99.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 99.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 99.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 100.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:01, 100.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 100.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 100.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 100.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 99.95it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 97.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 95.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 94.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 94.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 94.38it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 94.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 97.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.66045
wandb: sub_train_loss 0.31785
wandb:       test_acc 0.667
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run fancy-sweep-187 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6db9tu1r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124810-6db9tu1r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yf4nbdxk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124826-yf4nbdxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yf4nbdxk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.15it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 93.30it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.12it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.48it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.71it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 91.95it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 92.10it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 92.12it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 94.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 97.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 98.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 99.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 99.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 99.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 100.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 100.36it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 98.36it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 94.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 91.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:01, 90.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 88.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 85.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 86.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 87.77it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 89.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 90.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 91.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 92.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 92.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.66851
wandb: sub_train_loss 0.15326
wandb:       test_acc 0.66
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run sweet-sweep-188 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yf4nbdxk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124826-yf4nbdxk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p7ssg18v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124840-p7ssg18v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-189
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p7ssg18v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.03it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.57it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.00it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.63it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 91.66it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 89.26it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 88.82it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 89.13it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 89.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 89.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 89.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 90.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 90.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 90.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 88.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 88.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 88.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 88.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:02<00:01, 88.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 88.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 88.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 89.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 89.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 89.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 89.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 88.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 89.45it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:03<00:00, 91.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 90.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 90.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.48648
wandb: sub_train_loss 1.22057
wandb:       test_acc 0.45
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run scarlet-sweep-189 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p7ssg18v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124840-p7ssg18v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w6fpgwuf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124856-w6fpgwuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-190
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w6fpgwuf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.09it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 87.72it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 86.90it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:03, 85.76it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 88.20it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 90.57it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 91.59it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 92.33it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 92.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 92.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:02, 91.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 91.08it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 91.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 91.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 92.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 93.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 93.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 93.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:02<00:01, 93.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 94.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 94.55it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 94.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 94.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 94.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 95.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 96.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 97.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 97.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 98.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.752
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.45555
wandb: sub_train_loss 1.04006
wandb:       test_acc 0.458
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run dutiful-sweep-190 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w6fpgwuf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124856-w6fpgwuf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g8whlk3v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124911-g8whlk3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-191
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g8whlk3v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.45it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.75it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.18it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.28it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 89.33it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 90.22it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 91.30it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.81it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 93.39it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 93.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 93.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 93.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 93.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 93.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 94.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 94.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 94.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 94.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 95.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 95.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 95.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 94.63it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 94.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 93.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 93.46it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 93.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 93.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.799
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.69072
wandb: sub_train_loss 0.29793
wandb:       test_acc 0.723
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run gallant-sweep-191 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g8whlk3v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124911-g8whlk3v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7a89b5b1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124927-7a89b5b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-192
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7a89b5b1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.34it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.67it/s] 10%|‚ñà         | 31/300 [00:00<00:02, 98.81it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 98.28it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 94.72it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 91.23it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 90.10it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 90.77it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 90.76it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 90.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:02, 91.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 93.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 94.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 96.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 97.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 97.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 98.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 98.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 99.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 99.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 99.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 99.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 99.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 99.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 99.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 99.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 99.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 99.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 99.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.40386
wandb: sub_train_loss 0.88159
wandb:       test_acc 0.405
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run true-sweep-192 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7a89b5b1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124927-7a89b5b1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1qenxulo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124942-1qenxulo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1qenxulo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.31it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 200.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 202.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 200.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 202.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 202.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 204.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 205.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 206.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.403
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.39408
wandb: sub_train_loss 0.1442
wandb:       test_acc 0.399
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run bright-sweep-193 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1qenxulo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124942-1qenxulo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nj58e23h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_124958-nj58e23h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-194
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nj58e23h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 207.38it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 205.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 204.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 204.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 204.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 204.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 204.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 202.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 203.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.40706
wandb: sub_train_loss 0.1545
wandb:       test_acc 0.416
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run twilight-sweep-194 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nj58e23h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_124958-nj58e23h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ze7hytqt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125013-ze7hytqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-195
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ze7hytqt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 190.33it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 192.97it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 195.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 197.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 199.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 202.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 203.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 204.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 206.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 202.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.513
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.42674
wandb: sub_train_loss 0.08786
wandb:       test_acc 0.513
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run feasible-sweep-195 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ze7hytqt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125013-ze7hytqt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5xhilf2k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125028-5xhilf2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-196
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5xhilf2k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 185.64it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 190.45it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 193.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 195.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 195.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 196.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 196.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 196.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 197.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 197.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.46346
wandb: sub_train_loss 0.09172
wandb:       test_acc 0.491
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run stoic-sweep-196 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5xhilf2k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125028-5xhilf2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0zpsn67h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125044-0zpsn67h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-197
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0zpsn67h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.00it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.69it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 176.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 179.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 188.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 194.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 199.57it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 202.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 204.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.488
wandb: best_valid_acc 0.514
wandb:  sub_train_acc 0.52772
wandb: sub_train_loss 0.08199
wandb:       test_acc 0.485
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run flowing-sweep-197 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0zpsn67h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125044-0zpsn67h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e69q16xy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125059-e69q16xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e69q16xy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.42it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 194.43it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 194.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 196.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 196.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 195.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 197.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 196.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 196.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.509
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.58183
wandb: sub_train_loss 0.06262
wandb:       test_acc 0.514
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run eternal-sweep-198 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e69q16xy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125059-e69q16xy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lheh3qpx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125114-lheh3qpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lheh3qpx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.54it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 189.03it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 189.94it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 192.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 191.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 191.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 192.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 192.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 192.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 191.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 191.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.685
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.67221
wandb: sub_train_loss 0.03028
wandb:       test_acc 0.691
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run gallant-sweep-199 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lheh3qpx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125114-lheh3qpx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qs63ao53 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125130-qs63ao53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qs63ao53
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 199.26it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 199.68it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 192.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 187.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 187.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 183.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 181.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 177.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 177.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 176.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.659
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.65948
wandb: sub_train_loss 0.03323
wandb:       test_acc 0.659
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run lunar-sweep-200 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qs63ao53
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125130-qs63ao53/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: drxsz0mo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125150-drxsz0mo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/drxsz0mo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.79it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 188.43it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 191.64it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 191.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 194.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 195.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 195.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 195.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 195.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 195.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.70016
wandb: sub_train_loss 0.02625
wandb:       test_acc 0.695
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run radiant-sweep-201 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/drxsz0mo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125150-drxsz0mo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zwov01h0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125206-zwov01h0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-202
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zwov01h0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.68it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 192.85it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 191.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 191.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 188.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 188.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 190.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 190.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 191.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 179.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.68996
wandb: sub_train_loss 0.03912
wandb:       test_acc 0.673
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run fine-sweep-202 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zwov01h0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125206-zwov01h0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pxz4t3cz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125222-pxz4t3cz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pxz4t3cz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.27it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.69it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 177.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 172.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 169.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 167.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 164.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 163.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 168.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 176.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.68479
wandb: sub_train_loss 0.02605
wandb:       test_acc 0.694
wandb:      valid_acc 0.734
wandb: 
wandb: üöÄ View run likely-sweep-203 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pxz4t3cz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125222-pxz4t3cz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2d2x88ky with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125237-2d2x88ky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-204
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2d2x88ky
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.32it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.42it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 195.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 196.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 199.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 200.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 201.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 202.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 202.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 200.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.69965
wandb: sub_train_loss 0.01876
wandb:       test_acc 0.713
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run major-sweep-204 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2d2x88ky
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125237-2d2x88ky/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sw4may6x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125253-sw4may6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-205
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sw4may6x
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.45it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 171.21it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 179.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 186.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 188.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 191.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 191.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 192.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 192.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 192.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.68489
wandb: sub_train_loss 0.02474
wandb:       test_acc 0.666
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run gentle-sweep-205 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sw4may6x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125253-sw4may6x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rertl2s2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125307-rertl2s2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-206
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rertl2s2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.11it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 188.15it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 190.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 191.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 192.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 193.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 193.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 194.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 195.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.70716
wandb: sub_train_loss 0.01736
wandb:       test_acc 0.691
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run solar-sweep-206 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rertl2s2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125307-rertl2s2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jystbrth with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125323-jystbrth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-207
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jystbrth
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.66it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 179.23it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 176.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 176.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 174.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 176.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 176.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 176.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 176.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 175.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.71071
wandb: sub_train_loss 0.01111
wandb:       test_acc 0.712
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run clean-sweep-207 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jystbrth
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125323-jystbrth/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mgo621xy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125339-mgo621xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-208
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mgo621xy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.72it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.37it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 168.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 164.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 166.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 177.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 184.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 187.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 191.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 193.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.69772
wandb: sub_train_loss 0.01257
wandb:       test_acc 0.701
wandb:      valid_acc 0.734
wandb: 
wandb: üöÄ View run rare-sweep-208 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mgo621xy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125339-mgo621xy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kns5r7ok with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125355-kns5r7ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-209
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kns5r7ok
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.49it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.81it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 175.29it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 174.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 171.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 171.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 172.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 172.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 173.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 175.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 175.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.442
wandb:  sub_train_acc 0.39326
wandb: sub_train_loss 0.12255
wandb:       test_acc 0.373
wandb:      valid_acc 0.41
wandb: 
wandb: üöÄ View run neat-sweep-209 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kns5r7ok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125355-kns5r7ok/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e1ym6eee with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125411-e1ym6eee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-210
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e1ym6eee
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.06it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.83it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 162.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 165.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 166.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 169.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 171.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 173.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 173.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 174.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.396
wandb: sub_train_loss 0.13081
wandb:       test_acc 0.412
wandb:      valid_acc 0.406
wandb: 
wandb: üöÄ View run efficient-sweep-210 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e1ym6eee
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125411-e1ym6eee/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: avte8zxe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125427-avte8zxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-211
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/avte8zxe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.12it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.08it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 158.07it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 156.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 155.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 157.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 158.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 158.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 153.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 149.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 147.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 150.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.509
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.45164
wandb: sub_train_loss 0.13623
wandb:       test_acc 0.505
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run clear-sweep-211 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/avte8zxe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125427-avte8zxe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uog4ju9c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125442-uog4ju9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-212
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uog4ju9c
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.81it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.01it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 177.38it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.14it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 177.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 176.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 172.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 170.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 173.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 176.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.40214
wandb: sub_train_loss 0.10299
wandb:       test_acc 0.479
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run still-sweep-212 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uog4ju9c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125442-uog4ju9c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ypwvukw9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125457-ypwvukw9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-213
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ypwvukw9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.63it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.81it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 175.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 173.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 170.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 164.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 162.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 168.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 169.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 173.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 173.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.519
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.54942
wandb: sub_train_loss 0.17934
wandb:       test_acc 0.523
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run mild-sweep-213 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ypwvukw9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125457-ypwvukw9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5dxpeq79 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125521-5dxpeq79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-214
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dxpeq79
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.99it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.92it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 160.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 162.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 162.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 161.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 159.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 155.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 151.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 153.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 156.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.532
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.45702
wandb: sub_train_loss 0.13299
wandb:       test_acc 0.497
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run lemon-sweep-214 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dxpeq79
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125521-5dxpeq79/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mqxtgiaf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125536-mqxtgiaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-215
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mqxtgiaf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.27it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 167.72it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 167.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 167.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 165.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 168.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 169.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 170.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 169.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 170.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.66709
wandb: sub_train_loss 0.04276
wandb:       test_acc 0.719
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run dulcet-sweep-215 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mqxtgiaf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125536-mqxtgiaf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9cy9kbq7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125552-9cy9kbq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-216
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9cy9kbq7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.93it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.91it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 165.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 165.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 166.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 165.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 166.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 165.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 166.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 166.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.62373
wandb: sub_train_loss 0.05882
wandb:       test_acc 0.721
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run misunderstood-sweep-216 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9cy9kbq7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125552-9cy9kbq7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l2t8ogem with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125607-l2t8ogem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-217
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l2t8ogem
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.54it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 140.68it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.98it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 148.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 154.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 160.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 162.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 161.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 161.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 161.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 161.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.62763
wandb: sub_train_loss 0.26188
wandb:       test_acc 0.527
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run iconic-sweep-217 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l2t8ogem
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125607-l2t8ogem/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q9uqjdto with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125622-q9uqjdto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q9uqjdto
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.61it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.73it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 172.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 175.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 176.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 176.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 177.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 177.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 177.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.69818
wandb: sub_train_loss 0.0317
wandb:       test_acc 0.714
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run blooming-sweep-218 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q9uqjdto
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125622-q9uqjdto/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eee1ytv3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125638-eee1ytv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-219
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/eee1ytv3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.73it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.27it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 167.28it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 169.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 170.22it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 171.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 170.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 170.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 169.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 169.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 169.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.70482
wandb: sub_train_loss 0.01907
wandb:       test_acc 0.722
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run leafy-sweep-219 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/eee1ytv3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125638-eee1ytv3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j4s061t7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125653-j4s061t7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-220
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j4s061t7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.64it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.36it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.11it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 159.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 162.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 167.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 169.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 170.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 168.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 169.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 172.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.69088
wandb: sub_train_loss 0.03701
wandb:       test_acc 0.706
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run vital-sweep-220 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j4s061t7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125653-j4s061t7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ybgls4vq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125709-ybgls4vq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-221
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ybgls4vq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.65it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.95it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 158.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 157.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 157.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 160.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 159.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 159.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 161.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 160.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.70006
wandb: sub_train_loss 0.01342
wandb:       test_acc 0.689
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run prime-sweep-221 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ybgls4vq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125709-ybgls4vq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: za86sk7e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125723-za86sk7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/za86sk7e
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.78it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 169.70it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 168.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 172.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 171.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 171.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 170.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 172.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 174.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 176.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 176.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.69159
wandb: sub_train_loss 0.02298
wandb:       test_acc 0.689
wandb:      valid_acc 0.692
wandb: 
wandb: üöÄ View run peachy-sweep-222 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/za86sk7e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125723-za86sk7e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hy75s2un with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125739-hy75s2un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-223
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hy75s2un
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.24it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.40it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 163.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 164.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 167.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 169.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 170.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 169.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 168.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 167.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.766
wandb: best_valid_acc 0.802
wandb:  sub_train_acc 0.56383
wandb: sub_train_loss 0.46254
wandb:       test_acc 0.54
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run effortless-sweep-223 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hy75s2un
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125739-hy75s2un/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4s0jgs6v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125755-4s0jgs6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-224
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4s0jgs6v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.25it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 158.10it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 159.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 163.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 164.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 165.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 166.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 167.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 168.62it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 168.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 168.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.729
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.59801
wandb: sub_train_loss 0.07506
wandb:       test_acc 0.59
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run laced-sweep-224 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4s0jgs6v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125755-4s0jgs6v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ghmkaqwa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125810-ghmkaqwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-225
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ghmkaqwa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.74it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.71it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 153.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 154.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 154.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 154.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 153.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.407
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.39372
wandb: sub_train_loss 0.23452
wandb:       test_acc 0.393
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run bumbling-sweep-225 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ghmkaqwa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125810-ghmkaqwa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xe8065nf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125827-xe8065nf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-226
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xe8065nf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.54it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.59it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 152.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 151.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 149.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 150.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 150.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 150.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 149.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.415
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.38971
wandb: sub_train_loss 0.20372
wandb:       test_acc 0.322
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run copper-sweep-226 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xe8065nf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125827-xe8065nf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u04y4vi0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125842-u04y4vi0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-227
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u04y4vi0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.38it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.22it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 152.86it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 153.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 154.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 154.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 154.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 155.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 155.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 154.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 154.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.41614
wandb: sub_train_loss 0.14751
wandb:       test_acc 0.489
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run autumn-sweep-227 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u04y4vi0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125842-u04y4vi0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b5covsml with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125857-b5covsml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-228
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b5covsml
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.28it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 114.76it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 106.97it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 116.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 123.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 129.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 132.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 133.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 136.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 137.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 138.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 140.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 140.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 140.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.507
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.40635
wandb: sub_train_loss 0.56284
wandb:       test_acc 0.427
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run earthy-sweep-228 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b5covsml
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125857-b5covsml/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: upyd65vl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125913-upyd65vl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-229
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/upyd65vl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.49it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.37it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.38it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 138.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 137.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 138.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 138.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 139.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 140.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 140.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 139.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 139.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 138.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.607
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.44373
wandb: sub_train_loss 0.59777
wandb:       test_acc 0.347
wandb:      valid_acc 0.374
wandb: 
wandb: üöÄ View run efficient-sweep-229 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/upyd65vl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125913-upyd65vl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ly1qcq9w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125928-ly1qcq9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-230
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ly1qcq9w
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.43it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 138.47it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 136.53it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 122.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 128.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 129.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 130.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 130.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 129.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 130.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 136.76it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 141.31it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 144.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.517
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.49221
wandb: sub_train_loss 0.19891
wandb:       test_acc 0.511
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run zany-sweep-230 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ly1qcq9w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125928-ly1qcq9w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1khpvxrz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125944-1khpvxrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-231
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1khpvxrz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.42it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 137.26it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.65it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 127.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 128.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 129.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 128.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 126.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 124.87it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 128.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 128.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 126.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 125.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 130.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.6572
wandb: sub_train_loss 0.06018
wandb:       test_acc 0.677
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run visionary-sweep-231 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1khpvxrz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125944-1khpvxrz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wog9wukr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_125959-wog9wukr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-232
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wog9wukr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.06it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.26it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 144.23it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 143.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 142.56it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 142.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 142.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 143.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 143.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 144.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 146.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.56484
wandb: sub_train_loss 0.49462
wandb:       test_acc 0.293
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run breezy-sweep-232 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wog9wukr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_125959-wog9wukr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o6wn9889 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130015-o6wn9889
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-233
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/o6wn9889
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.26it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.73it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.61it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 151.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 152.57it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 152.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 151.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 150.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 151.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 151.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 151.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 152.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.664
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.52772
wandb: sub_train_loss 0.26094
wandb:       test_acc 0.435
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run resilient-sweep-233 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/o6wn9889
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130015-o6wn9889/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uvqghu2s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130029-uvqghu2s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-234
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uvqghu2s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.05it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.94it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 143.24it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 144.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 141.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 142.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 140.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 137.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 133.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 131.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.58726
wandb: sub_train_loss 0.18235
wandb:       test_acc 0.604
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run frosty-sweep-234 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uvqghu2s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130029-uvqghu2s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b9xmpbtc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130045-b9xmpbtc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-235
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b9xmpbtc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.71it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.41it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.97it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 146.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 147.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 147.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 146.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 146.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 146.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 146.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 144.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 143.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.51808
wandb: sub_train_loss 0.45708
wandb:       test_acc 0.533
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run rosy-sweep-235 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b9xmpbtc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130045-b9xmpbtc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: htzh7gfj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130101-htzh7gfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-236
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/htzh7gfj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.18it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.49it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.72it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 139.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 138.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 138.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 139.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 140.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 142.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 142.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 142.40it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 142.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 144.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.61728
wandb: sub_train_loss 1.42517
wandb:       test_acc 0.515
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run rosy-sweep-236 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/htzh7gfj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130101-htzh7gfj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fun3qtwp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130115-fun3qtwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-237
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fun3qtwp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.77it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.66it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.63it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 142.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 138.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 137.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 134.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 131.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 129.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 128.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 126.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.509
wandb: sub_train_loss 1.51296
wandb:       test_acc 0.43
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run summer-sweep-237 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fun3qtwp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130115-fun3qtwp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i82isbeu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130131-i82isbeu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-238
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i82isbeu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.47it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.47it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.78it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 146.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 146.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 147.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 148.92it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 148.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 146.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 145.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 141.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 139.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.67536
wandb: sub_train_loss 0.16196
wandb:       test_acc 0.678
wandb:      valid_acc 0.704
wandb: 
wandb: üöÄ View run rosy-sweep-238 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i82isbeu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130131-i82isbeu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gt0sx2qx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130147-gt0sx2qx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-239
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gt0sx2qx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.94it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.71it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 154.75it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 153.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 153.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 153.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 151.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 151.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 151.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÜ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.806
wandb:  sub_train_acc 0.5162
wandb: sub_train_loss 3.14499
wandb:       test_acc 0.504
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run trim-sweep-239 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gt0sx2qx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130147-gt0sx2qx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 76q946y6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130201-76q946y6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-240
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/76q946y6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.50it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.37it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.34it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 144.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 144.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 143.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 143.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 143.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 142.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 143.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 142.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.812
wandb:  sub_train_acc 0.56165
wandb: sub_train_loss 0.553
wandb:       test_acc 0.562
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run amber-sweep-240 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/76q946y6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130201-76q946y6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x5p9xpcb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130223-x5p9xpcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-241
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x5p9xpcb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 202.03it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 201.82it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 202.59it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 204.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 206.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 206.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 207.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 208.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 208.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 209.06it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 209.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 208.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 208.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 208.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 207.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.41
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.41523
wandb: sub_train_loss 0.00776
wandb:       test_acc 0.38
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run desert-sweep-241 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x5p9xpcb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130223-x5p9xpcb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vdlg9jeb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130238-vdlg9jeb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-242
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vdlg9jeb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.95it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 198.04it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 194.62it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 196.16it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 193.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 194.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 196.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 193.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 192.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 192.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 191.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 191.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 191.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 189.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.40229
wandb: sub_train_loss 0.00963
wandb:       test_acc 0.387
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run wobbly-sweep-242 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vdlg9jeb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130238-vdlg9jeb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t6a4ragt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130253-t6a4ragt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-243
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t6a4ragt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.18it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 193.61it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 193.34it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 194.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 192.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 194.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 195.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 197.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 195.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 195.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 195.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 195.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 195.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 193.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.441
wandb: best_valid_acc 0.472
wandb:  sub_train_acc 0.45017
wandb: sub_train_loss 0.00123
wandb:       test_acc 0.44
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run floral-sweep-243 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t6a4ragt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130253-t6a4ragt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yko8qgcu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130308-yko8qgcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-244
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yko8qgcu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 191.06it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 189.38it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 192.58it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 194.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 193.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 191.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 189.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 187.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 186.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 185.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 185.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 184.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 183.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 180.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 179.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.512
wandb:  sub_train_acc 0.42714
wandb: sub_train_loss 0.02134
wandb:       test_acc 0.489
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run fearless-sweep-244 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yko8qgcu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130308-yko8qgcu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nzhrzjs1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130324-nzhrzjs1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-245
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nzhrzjs1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.80it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.79it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 185.73it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 190.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 194.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 196.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 197.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 198.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 198.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 197.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 197.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 197.64it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 198.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 195.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.55
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.60841
wandb: sub_train_loss 0.00337
wandb:       test_acc 0.55
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run devout-sweep-245 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nzhrzjs1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130324-nzhrzjs1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cfs6gzdi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130339-cfs6gzdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-246
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cfs6gzdi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.00it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.10it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 191.80it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 192.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 195.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 197.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 200.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 199.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 198.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 198.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 200.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 200.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 200.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.535
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.5869
wandb: sub_train_loss 0.00339
wandb:       test_acc 0.536
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run legendary-sweep-246 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cfs6gzdi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130339-cfs6gzdi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sr06dj2k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130354-sr06dj2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-247
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sr06dj2k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 189.03it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 192.83it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 171.53it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 154.68it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 152.00it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 146.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 147.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 156.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 149.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 151.55it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 153.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 164.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 176.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 185.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 191.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 194.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.686
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.65213
wandb: sub_train_loss 0.00312
wandb:       test_acc 0.644
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run light-sweep-247 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sr06dj2k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130354-sr06dj2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kkqs60hh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130410-kkqs60hh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-248
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kkqs60hh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.13it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 179.83it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 183.57it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 187.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 189.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 189.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 188.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 186.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 187.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 186.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 186.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 183.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 184.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 187.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 189.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.6539
wandb: sub_train_loss 0.00229
wandb:       test_acc 0.724
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run silvery-sweep-248 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kkqs60hh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130410-kkqs60hh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lv4842t1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130425-lv4842t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lv4842t1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.84it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 185.40it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 186.48it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 189.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 191.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 188.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 186.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 189.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 190.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 190.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 188.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 179.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 179.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 180.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 184.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.67779
wandb: sub_train_loss 0.00155
wandb:       test_acc 0.678
wandb:      valid_acc 0.71
wandb: 
wandb: üöÄ View run absurd-sweep-249 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lv4842t1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130425-lv4842t1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 23fytkov with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130440-23fytkov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-250
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/23fytkov
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.92it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 164.80it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.58it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 172.52it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 179.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 183.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 189.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 190.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 191.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 191.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 193.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 193.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 191.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 189.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 189.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.70366
wandb: sub_train_loss 0.00167
wandb:       test_acc 0.728
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run autumn-sweep-250 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/23fytkov
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130440-23fytkov/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 256i1tav with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130456-256i1tav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-251
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/256i1tav
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 176.81it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 179.64it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 182.84it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 188.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 191.19it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 192.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 189.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 192.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 188.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 185.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 182.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 179.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 177.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 175.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 178.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.69625
wandb: sub_train_loss 0.00306
wandb:       test_acc 0.7
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run tough-sweep-251 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/256i1tav
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130456-256i1tav/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yzkz5opm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130512-yzkz5opm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-252
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzkz5opm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.15it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 152.59it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 155.00it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 156.65it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 159.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 161.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 161.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 166.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 166.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 171.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 174.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 170.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 169.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 170.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 174.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 177.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.68707
wandb: sub_train_loss 0.0043
wandb:       test_acc 0.698
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run distinctive-sweep-252 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzkz5opm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130512-yzkz5opm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 805uofoz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130527-805uofoz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-253
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/805uofoz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.14it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.30it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 190.43it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 188.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 178.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 177.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 174.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 176.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 176.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 175.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 173.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 170.18it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 165.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 164.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 165.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 171.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.66476
wandb: sub_train_loss 0.0009
wandb:       test_acc 0.608
wandb:      valid_acc 0.634
wandb: 
wandb: üöÄ View run splendid-sweep-253 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/805uofoz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130527-805uofoz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jae0o9z4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130542-jae0o9z4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-254
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jae0o9z4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 189.51it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.25it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 190.59it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 193.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 194.12it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 195.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 194.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 195.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 196.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 196.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 196.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 196.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 197.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 197.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 194.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.706
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.68099
wandb: sub_train_loss 0.0011
wandb:       test_acc 0.628
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run morning-sweep-254 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jae0o9z4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130542-jae0o9z4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tkk75n9y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130558-tkk75n9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-255
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkk75n9y
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.67it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 187.99it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 190.53it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 191.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 191.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 193.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 194.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 195.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 195.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 195.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 195.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 195.21it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 195.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 195.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 195.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.72207
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.731
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run treasured-sweep-255 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkk75n9y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130558-tkk75n9y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nim7iuib with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130619-nim7iuib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-256
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nim7iuib
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.55it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 180.33it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 183.73it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 185.96it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 186.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 187.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 188.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 189.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 191.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 192.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 193.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 194.37it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 194.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 194.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 195.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.72825
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.749
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run wild-sweep-256 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nim7iuib
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130619-nim7iuib/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ae4qhpv0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130632-ae4qhpv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ae4qhpv0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.97it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.82it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 160.85it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 164.32it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 166.52it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 164.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 162.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 165.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 166.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 168.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 168.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 169.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 169.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 170.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 170.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 170.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.395
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.43211
wandb: sub_train_loss 0.00035
wandb:       test_acc 0.408
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run proud-sweep-257 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ae4qhpv0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130632-ae4qhpv0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: etpv979m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130647-etpv979m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-258
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/etpv979m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.82it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.78it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 163.89it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 165.40it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 166.24it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 165.73it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 166.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 166.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 167.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 167.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 167.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 166.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 165.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 165.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 165.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 166.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 165.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.40057
wandb: sub_train_loss 0.00848
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run quiet-sweep-258 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/etpv979m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130647-etpv979m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: co820ign with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130702-co820ign
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-259
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/co820ign
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.56it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 169.02it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 173.07it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 173.55it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 172.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 174.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 176.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 177.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 179.09it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 179.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 180.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 180.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 180.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 179.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 179.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 179.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.53
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.41071
wandb: sub_train_loss 0.04111
wandb:       test_acc 0.53
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run sparkling-sweep-259 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/co820ign
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130702-co820ign/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0cvfbdpf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130717-0cvfbdpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0cvfbdpf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.19it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.21it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 169.38it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 169.58it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 169.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 169.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 169.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 171.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 173.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 174.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 175.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 175.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 176.13it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 176.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 175.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 174.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.522
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.49881
wandb: sub_train_loss 0.00288
wandb:       test_acc 0.481
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run gentle-sweep-260 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0cvfbdpf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130717-0cvfbdpf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i07hdgaq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130733-i07hdgaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-261
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i07hdgaq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.91it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.12it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 165.20it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 166.23it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 166.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 168.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 168.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 168.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 169.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 168.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 169.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 169.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 167.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 167.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 167.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 166.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 165.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.696
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.47101
wandb: sub_train_loss 0.00423
wandb:       test_acc 0.537
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run cerulean-sweep-261 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i07hdgaq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130733-i07hdgaq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xymswwj0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130749-xymswwj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-262
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xymswwj0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.55it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.43it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 171.43it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 169.95it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 167.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 166.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 168.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 171.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 173.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 173.11it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 173.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 174.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 174.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 174.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 174.48it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 173.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.51012
wandb: sub_train_loss 0.00383
wandb:       test_acc 0.513
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run curious-sweep-262 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xymswwj0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130749-xymswwj0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g28ddpqu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130803-g28ddpqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-263
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g28ddpqu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.28it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 161.59it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 159.98it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 158.71it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 160.77it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 164.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 165.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 167.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 167.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 164.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 158.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 156.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 156.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 154.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 157.10it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 159.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 161.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.60354
wandb: sub_train_loss 0.00031
wandb:       test_acc 0.536
wandb:      valid_acc 0.556
wandb: 
wandb: üöÄ View run different-sweep-263 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g28ddpqu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130803-g28ddpqu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8zdyobea with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130819-8zdyobea
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-264
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8zdyobea
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.73it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 171.90it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 170.06it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 169.16it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 167.66it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 165.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 164.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 165.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 166.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 166.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 167.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 167.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 167.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 168.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 168.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 168.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 168.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.60694
wandb: sub_train_loss 0.00014
wandb:       test_acc 0.53
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run distinctive-sweep-264 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8zdyobea
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130819-8zdyobea/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5wy0vygb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130834-5wy0vygb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-265
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5wy0vygb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.18it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.87it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 164.55it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 164.19it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 164.30it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 167.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 169.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 171.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 172.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 173.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 173.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 173.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 174.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 173.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 174.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 174.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 171.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.58528
wandb: sub_train_loss 0.33941
wandb:       test_acc 0.407
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run northern-sweep-265 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5wy0vygb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130834-5wy0vygb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bpcapt3v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130852-bpcapt3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-266
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bpcapt3v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.02it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.17it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 167.59it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 168.84it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 166.99it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 167.07it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 167.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 168.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 166.39it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 164.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 162.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 160.33it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 156.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 156.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 159.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 161.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 163.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.59431
wandb: sub_train_loss 0.29544
wandb:       test_acc 0.487
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run dainty-sweep-266 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bpcapt3v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130852-bpcapt3v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 44dmeg5p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130906-44dmeg5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-267
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/44dmeg5p
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.74it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.83it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.48it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 149.73it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 147.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 152.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 154.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 156.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 157.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 154.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 154.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 156.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 155.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 150.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 152.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 158.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.60521
wandb: sub_train_loss 0.35484
wandb:       test_acc 0.578
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run spring-sweep-267 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/44dmeg5p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130906-44dmeg5p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mxfsr4ka with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130922-mxfsr4ka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-268
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mxfsr4ka
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.95it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 144.72it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 143.51it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 142.16it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 142.23it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 141.09it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 142.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 136.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 133.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 129.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 128.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 131.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 133.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 140.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 141.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 143.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 146.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 151.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 153.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.689
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.55242
wandb: sub_train_loss 0.25042
wandb:       test_acc 0.531
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run morning-sweep-268 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mxfsr4ka
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130922-mxfsr4ka/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6x1t9w19 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130938-6x1t9w19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-269
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6x1t9w19
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.15it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.60it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 169.37it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 170.05it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 169.45it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 169.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 167.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 168.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 168.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 167.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 168.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 160.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 155.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 152.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 149.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 146.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 152.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.71821
wandb: sub_train_loss 0.0025
wandb:       test_acc 0.741
wandb:      valid_acc 0.728
wandb: 
wandb: üöÄ View run distinctive-sweep-269 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6x1t9w19
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130938-6x1t9w19/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lz6m8fmn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_130952-lz6m8fmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-270
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lz6m8fmn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.93it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 173.34it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 173.18it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 174.25it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 171.27it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 171.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 173.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 174.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 174.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 173.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 173.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 171.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 173.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 174.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 175.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 174.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.69793
wandb: sub_train_loss 0.42898
wandb:       test_acc 0.67
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run fiery-sweep-270 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lz6m8fmn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_130952-lz6m8fmn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mb2wnbd5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131008-mb2wnbd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-271
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mb2wnbd5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.22it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.13it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.41it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 161.07it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 160.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 162.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 162.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 162.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 163.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 164.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 163.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 164.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 166.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 166.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 166.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 165.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 165.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.46904
wandb: sub_train_loss 2.21794
wandb:       test_acc 0.495
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run comfy-sweep-271 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mb2wnbd5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131008-mb2wnbd5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u0uqzeco with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131024-u0uqzeco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-272
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u0uqzeco
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.38it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.05it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.27it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 161.56it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 162.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 160.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 160.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 156.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 151.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 147.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 146.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 145.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 144.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 144.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 143.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 147.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 147.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 144.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.769
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.61039
wandb: sub_train_loss 0.67158
wandb:       test_acc 0.607
wandb:      valid_acc 0.622
wandb: 
wandb: üöÄ View run royal-sweep-272 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u0uqzeco
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131024-u0uqzeco/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5koduy1o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131039-5koduy1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-273
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5koduy1o
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.85it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.97it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.54it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 136.10it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 131.93it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 129.63it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 128.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 127.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 126.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 126.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 125.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 124.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 127.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 132.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 134.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 136.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 138.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 139.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 137.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 136.96it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 135.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÇ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.36
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.39266
wandb: sub_train_loss 0.13148
wandb:       test_acc 0.386
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run dainty-sweep-273 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5koduy1o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131039-5koduy1o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5dqnmz4q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131101-5dqnmz4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-274
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dqnmz4q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.02it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.61it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.48it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 148.34it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 145.12it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 144.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 143.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 141.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 141.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 141.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 139.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 140.64it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 142.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 142.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 141.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 142.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 144.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 145.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 146.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.408
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.40123
wandb: sub_train_loss 0.01313
wandb:       test_acc 0.327
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run fancy-sweep-274 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dqnmz4q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131101-5dqnmz4q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ma0mbw2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131116-1ma0mbw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-275
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ma0mbw2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.66it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.20it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.52it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.84it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 157.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 156.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 155.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 155.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 151.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 150.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 150.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 148.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 145.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 145.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 147.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 148.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 147.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 147.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 148.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.521
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.43318
wandb: sub_train_loss 0.04746
wandb:       test_acc 0.49
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run worthy-sweep-275 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ma0mbw2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131116-1ma0mbw2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: stwthx5l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131131-stwthx5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-276
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/stwthx5l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.60it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.46it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.82it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 139.37it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.78it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 131.27it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 112.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 117.00it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 127.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 134.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 136.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 140.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 144.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 147.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 148.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 149.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 150.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 150.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 150.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.503
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.51377
wandb: sub_train_loss 0.82148
wandb:       test_acc 0.304
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run valiant-sweep-276 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/stwthx5l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131131-stwthx5l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b3jam7rz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131147-b3jam7rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-277
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b3jam7rz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.64it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.38it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.68it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.01it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.50it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 149.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 149.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 150.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 151.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 151.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 151.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 150.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 149.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 150.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 150.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 150.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 150.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 150.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 149.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.644
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.49074
wandb: sub_train_loss 0.09571
wandb:       test_acc 0.46
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run splendid-sweep-277 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b3jam7rz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131147-b3jam7rz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ua6gs0ai with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131202-ua6gs0ai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-278
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ua6gs0ai
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.54it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 129.66it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 124.61it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 114.00it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 124.12it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 127.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 129.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 131.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 134.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 137.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 138.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 139.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 140.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 139.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 138.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 140.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 141.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 138.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 138.57it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 139.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.66
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.53634
wandb: sub_train_loss 0.60972
wandb:       test_acc 0.407
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run devout-sweep-278 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ua6gs0ai
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131202-ua6gs0ai/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b6ep0uyq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131217-b6ep0uyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-279
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b6ep0uyq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.67it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 124.50it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 129.44it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 131.88it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 134.67it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 138.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 143.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 145.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 146.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 146.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 148.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 146.77it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 147.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 148.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 148.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 149.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 150.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 151.02it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 151.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.50281
wandb: sub_train_loss 0.39685
wandb:       test_acc 0.501
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run balmy-sweep-279 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b6ep0uyq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131217-b6ep0uyq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: du5gnacl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131233-du5gnacl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-280
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/du5gnacl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.22it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.21it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 149.59it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 148.10it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 148.65it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 147.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 147.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 147.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 147.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 147.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 144.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 143.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 142.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 144.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 145.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 146.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 147.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 149.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 150.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.48202
wandb: sub_train_loss 1.11859
wandb:       test_acc 0.19
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run desert-sweep-280 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/du5gnacl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131233-du5gnacl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hzhs8gq1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131248-hzhs8gq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-281
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hzhs8gq1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.86it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.06it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 141.85it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.32it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.85it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 142.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 140.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 138.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 136.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 134.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 135.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 136.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 136.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 136.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 136.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 136.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 137.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 137.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 137.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.55744
wandb: sub_train_loss 1.46042
wandb:       test_acc 0.54
wandb:      valid_acc 0.556
wandb: 
wandb: üöÄ View run azure-sweep-281 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hzhs8gq1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131248-hzhs8gq1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: srae91o2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131304-srae91o2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-282
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/srae91o2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.02it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.12it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 133.29it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 130.73it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 127.23it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 126.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 125.09it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 125.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 128.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 131.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 129.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 128.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 126.33it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 124.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 127.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 130.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 132.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 133.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 134.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 135.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 135.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.5933
wandb: sub_train_loss 0.04956
wandb:       test_acc 0.601
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run golden-sweep-282 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/srae91o2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131304-srae91o2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qsjr9pi7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131319-qsjr9pi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-283
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qsjr9pi7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.80it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.84it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.31it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 143.08it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.59it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 140.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 139.29it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 140.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 139.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 139.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 140.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 141.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 141.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 142.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 142.96it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 140.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 138.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 134.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 133.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.54471
wandb: sub_train_loss 0.45146
wandb:       test_acc 0.555
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run gallant-sweep-283 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qsjr9pi7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131319-qsjr9pi7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 95yy0op1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131334-95yy0op1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-284
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/95yy0op1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.66it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.58it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.44it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.75it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 145.17it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 144.33it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 143.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 143.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 143.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 143.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 140.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 140.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 140.94it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 141.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 141.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 141.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 141.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 141.08it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 140.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.51418
wandb: sub_train_loss 1.34183
wandb:       test_acc 0.469
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run gallant-sweep-284 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/95yy0op1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131334-95yy0op1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0m4g9dwr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131351-0m4g9dwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-285
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0m4g9dwr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.92it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 133.38it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 134.78it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 138.03it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 139.64it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 139.82it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 140.51it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 139.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 141.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 142.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 144.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 144.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 144.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 140.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 140.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 139.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 141.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 140.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 141.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 141.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.42111
wandb: sub_train_loss 1.52061
wandb:       test_acc 0.377
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run good-sweep-285 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0m4g9dwr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131351-0m4g9dwr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b8y3zpjv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131407-b8y3zpjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-286
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b8y3zpjv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.65it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 131.80it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 137.25it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 138.74it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 137.65it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 139.47it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 138.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 137.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 139.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 141.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 142.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 143.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 142.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 143.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 144.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 142.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 141.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 140.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 139.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 140.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.5479
wandb: sub_train_loss 0.61081
wandb:       test_acc 0.527
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run faithful-sweep-286 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b8y3zpjv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131407-b8y3zpjv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 683iu6f9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131421-683iu6f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-287
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/683iu6f9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.03it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 139.43it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 140.63it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 141.43it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 141.64it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 142.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 142.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 142.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 142.83it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 141.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 141.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 138.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 132.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 135.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 138.75it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 139.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 138.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 139.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 140.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 141.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.46021
wandb: sub_train_loss 0.37121
wandb:       test_acc 0.458
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run cerulean-sweep-287 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/683iu6f9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131421-683iu6f9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 18i3ifb8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131437-18i3ifb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-288
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/18i3ifb8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.53it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.11it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.44it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 138.83it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 134.20it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 129.27it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 128.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 125.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 113.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 116.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 118.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 121.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 121.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 121.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 121.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 122.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 122.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 122.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 124.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 116.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 125.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 125.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.37414
wandb: sub_train_loss 1.2025
wandb:       test_acc 0.375
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run bumbling-sweep-288 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/18i3ifb8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131437-18i3ifb8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7ekonj2y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131453-7ekonj2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-289
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7ekonj2y
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.89it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 132.04it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 136.46it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 135.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 139.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 141.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 143.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 145.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 146.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 146.66it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 147.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 146.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 146.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.399
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.40929
wandb: sub_train_loss 0.10131
wandb:       test_acc 0.418
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run ruby-sweep-289 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7ekonj2y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131453-7ekonj2y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gc7brdln with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131507-gc7brdln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-290
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gc7brdln
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.25it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 140.86it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 142.52it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 145.58it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 144.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 145.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 145.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 148.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 150.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 151.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 151.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.49
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.42238
wandb: sub_train_loss 0.11417
wandb:       test_acc 0.481
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run devoted-sweep-290 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gc7brdln
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131507-gc7brdln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u8fcjuvz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131523-u8fcjuvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-291
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8fcjuvz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.17it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.64it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.79it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 153.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 155.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 156.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 157.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 158.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 158.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.509
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.48506
wandb: sub_train_loss 0.09072
wandb:       test_acc 0.491
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run warm-sweep-291 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8fcjuvz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131523-u8fcjuvz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m6l2p2bz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131539-m6l2p2bz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-292
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m6l2p2bz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.55it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.19it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.03it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 149.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 149.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 149.46it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 149.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 148.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 148.32it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 148.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 149.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 148.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.49216
wandb: sub_train_loss 0.11466
wandb:       test_acc 0.481
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run rosy-sweep-292 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m6l2p2bz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131539-m6l2p2bz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r2zqcme6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131554-r2zqcme6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-293
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r2zqcme6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.70it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.88it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.35it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 140.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 140.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 140.13it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 138.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 137.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 135.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 135.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 134.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 133.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.507
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.51027
wandb: sub_train_loss 0.12328
wandb:       test_acc 0.489
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run desert-sweep-293 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r2zqcme6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131554-r2zqcme6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dfuj45f0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131609-dfuj45f0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-294
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfuj45f0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.01it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.56it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 132.58it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.54it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 128.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 128.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 127.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 129.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 134.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 138.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 140.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 141.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 142.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.442
wandb: best_valid_acc 0.49
wandb:  sub_train_acc 0.4663
wandb: sub_train_loss 0.10999
wandb:       test_acc 0.423
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run iconic-sweep-294 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfuj45f0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131609-dfuj45f0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i7f0s6hi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131624-i7f0s6hi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i7f0s6hi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.09it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.56it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 139.32it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 137.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 139.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 139.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 139.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 136.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 136.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 137.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 125.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 120.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 122.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 126.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.67642
wandb: sub_train_loss 0.15659
wandb:       test_acc 0.694
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run glowing-sweep-295 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i7f0s6hi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131624-i7f0s6hi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e6svv6nk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131640-e6svv6nk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-296
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e6svv6nk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.23it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 150.51it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.06it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 143.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 145.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 145.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 140.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 134.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 131.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 130.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 132.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 125.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 123.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.66633
wandb: sub_train_loss 0.16305
wandb:       test_acc 0.677
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run laced-sweep-296 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e6svv6nk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131640-e6svv6nk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8cn5rlso with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131655-8cn5rlso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-297
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8cn5rlso
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.79it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.03it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 139.20it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 139.72it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 141.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 139.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 139.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 140.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 139.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 139.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 137.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 135.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 137.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.714
wandb: sub_train_loss 0.16692
wandb:       test_acc 0.708
wandb:      valid_acc 0.728
wandb: 
wandb: üöÄ View run stoic-sweep-297 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8cn5rlso
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131655-8cn5rlso/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1u7hms3g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131710-1u7hms3g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-298
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1u7hms3g
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 139.50it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.39it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.67it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 148.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 148.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 149.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 150.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 151.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 151.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 151.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 152.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.72161
wandb: sub_train_loss 0.14776
wandb:       test_acc 0.723
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run efficient-sweep-298 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1u7hms3g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131710-1u7hms3g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b392ib4q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131726-b392ib4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-299
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b392ib4q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.49it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 139.88it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 138.31it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 137.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 137.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 137.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 137.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 137.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 137.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 136.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 133.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 129.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 136.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.699
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.7102
wandb: sub_train_loss 0.17341
wandb:       test_acc 0.705
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run super-sweep-299 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b392ib4q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131726-b392ib4q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yjhrypob with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131741-yjhrypob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-300
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yjhrypob
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.83it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 139.20it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 143.02it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 142.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 145.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 146.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 148.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 148.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 146.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 144.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 140.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 139.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 124.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.7246
wandb: sub_train_loss 0.15916
wandb:       test_acc 0.716
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run zesty-sweep-300 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yjhrypob
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131741-yjhrypob/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ep10w3v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131757-1ep10w3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-301
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ep10w3v
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.21it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 141.33it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.36it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 140.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 141.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 142.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 142.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 143.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 142.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 142.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.71618
wandb: sub_train_loss 0.17437
wandb:       test_acc 0.728
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run colorful-sweep-301 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ep10w3v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131757-1ep10w3v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qocert9e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131813-qocert9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-302
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qocert9e
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.92it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 129.38it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 126.87it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 129.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 131.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 130.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 133.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 134.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 135.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 136.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 136.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 136.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 137.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 136.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.71025
wandb: sub_train_loss 0.19965
wandb:       test_acc 0.724
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run copper-sweep-302 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qocert9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131813-qocert9e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2qnssvua with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131827-2qnssvua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-303
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2qnssvua
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 89.97it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 120.68it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 135.06it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 138.23it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 140.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 141.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 143.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 141.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 144.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 146.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 144.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 144.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 144.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.746
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.763
wandb: sub_train_loss 0.23754
wandb:       test_acc 0.756
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run stoic-sweep-303 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2qnssvua
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131827-2qnssvua/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q8gyix68 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131843-q8gyix68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-304
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q8gyix68
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.92it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.00it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 138.44it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 141.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 141.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 140.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 140.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 136.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 133.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 131.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 133.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 136.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 137.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.73936
wandb: sub_train_loss 0.24687
wandb:       test_acc 0.744
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run clean-sweep-304 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q8gyix68
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131843-q8gyix68/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: upoaj8sm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131858-upoaj8sm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-305
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/upoaj8sm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.42it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 119.14it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.68it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 116.93it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 115.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 115.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 114.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 112.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 111.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 109.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 108.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 110.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 111.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 116.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.401
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.31278
wandb: sub_train_loss 0.08933
wandb:       test_acc 0.202
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run cool-sweep-305 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/upoaj8sm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131858-upoaj8sm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0fq7t4au with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131913-0fq7t4au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-306
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0fq7t4au
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 107.84it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 109.78it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 110.35it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 109.60it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 109.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 108.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 110.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 110.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 104.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 103.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 103.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 102.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 100.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 106.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 109.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 113.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 114.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.343
wandb: sub_train_loss 0.07365
wandb:       test_acc 0.295
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run vocal-sweep-306 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0fq7t4au
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131913-0fq7t4au/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a264chbn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131928-a264chbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-307
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a264chbn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.91it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.93it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 114.88it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.86it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 112.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 112.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 115.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 116.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 116.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 116.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 115.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 114.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 113.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 112.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.50079
wandb: sub_train_loss 0.14864
wandb:       test_acc 0.507
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run polished-sweep-307 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a264chbn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131928-a264chbn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m61if52i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_131944-m61if52i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-308
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m61if52i
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 107.62it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 105.67it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 103.05it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.53it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 104.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 105.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 106.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 106.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 107.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 106.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 105.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 105.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 106.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 106.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 106.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 110.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 107.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.48126
wandb: sub_train_loss 0.11735
wandb:       test_acc 0.493
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run logical-sweep-308 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m61if52i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_131944-m61if52i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kibqmw5m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132000-kibqmw5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kibqmw5m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.55it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.75it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 121.43it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 120.69it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 121.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 122.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 120.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 117.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 113.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 111.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 110.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 109.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 108.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.601
wandb: best_valid_acc 0.622
wandb:  sub_train_acc 0.502
wandb: sub_train_loss 0.12719
wandb:       test_acc 0.464
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run autumn-sweep-309 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kibqmw5m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132000-kibqmw5m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 85o7y3ou with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132016-85o7y3ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-310
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/85o7y3ou
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.70it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.31it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.33it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.61it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 108.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 106.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 106.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 108.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 109.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 109.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 107.64it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 109.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 111.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 113.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 115.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 116.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.556
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.53294
wandb: sub_train_loss 0.11398
wandb:       test_acc 0.492
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run wandering-sweep-310 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/85o7y3ou
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132016-85o7y3ou/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j6msqagi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132031-j6msqagi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-311
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j6msqagi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.96it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.73it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.19it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 120.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 120.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 120.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 119.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 116.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 113.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 112.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 112.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 112.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 112.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 112.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 112.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 112.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.69027
wandb: sub_train_loss 0.09179
wandb:       test_acc 0.696
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run visionary-sweep-311 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j6msqagi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132031-j6msqagi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fbgyslfg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132047-fbgyslfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-312
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fbgyslfg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.74it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 117.90it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 116.21it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 115.08it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 116.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 117.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 115.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 115.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 114.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 114.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 114.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 113.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 113.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 112.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 115.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 117.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.68682
wandb: sub_train_loss 0.12114
wandb:       test_acc 0.701
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run pretty-sweep-312 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fbgyslfg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132047-fbgyslfg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e5fu0jnr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132102-e5fu0jnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-313
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e5fu0jnr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.15it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.96it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.72it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 118.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 118.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 119.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 119.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 119.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 120.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 120.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 120.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 120.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 121.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 121.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.71289
wandb: sub_train_loss 0.10829
wandb:       test_acc 0.705
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run usual-sweep-313 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e5fu0jnr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132102-e5fu0jnr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0musmhp0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132117-0musmhp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-314
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0musmhp0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 107.92it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 105.27it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.10it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.35it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 105.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 103.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 105.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 106.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 95.99it/s]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 90.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 88.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 87.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 89.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 97.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 101.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 104.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.79it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.705
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.70589
wandb: sub_train_loss 0.12626
wandb:       test_acc 0.712
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run valiant-sweep-314 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0musmhp0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132117-0musmhp0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: npsq9igk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132133-npsq9igk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-315
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/npsq9igk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.08it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 118.07it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 118.95it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 117.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 116.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 116.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 116.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 116.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 116.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 112.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 110.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 112.46it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 110.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 106.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 107.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 108.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.71771
wandb: sub_train_loss 0.1916
wandb:       test_acc 0.715
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run zany-sweep-315 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/npsq9igk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132133-npsq9igk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jepomfg9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132149-jepomfg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-316
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jepomfg9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.27it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 123.36it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.45it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.79it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 122.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 122.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 122.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 122.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 122.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 122.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 121.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 118.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 120.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 117.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.70736
wandb: sub_train_loss 0.16058
wandb:       test_acc 0.705
wandb:      valid_acc 0.736
wandb: 
wandb: üöÄ View run hearty-sweep-316 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jepomfg9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132149-jepomfg9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0l7pc3vp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132203-0l7pc3vp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-317
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0l7pc3vp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.96it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.21it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.80it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.58it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 123.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 124.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 122.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 122.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 121.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 122.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 122.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 122.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 122.78it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 122.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.71963
wandb: sub_train_loss 0.19715
wandb:       test_acc 0.723
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run logical-sweep-317 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0l7pc3vp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132203-0l7pc3vp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nim7qa40 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132219-nim7qa40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-318
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nim7qa40
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 106.91it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 98.96it/s]  16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 101.34it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.89it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 103.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 103.12it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 103.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 93.60it/s]  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:01, 96.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 94.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 96.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 97.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 102.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 106.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 109.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 110.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 113.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 104.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.72825
wandb: sub_train_loss 0.14262
wandb:       test_acc 0.734
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run effortless-sweep-318 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nim7qa40
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132219-nim7qa40/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: swu81jnb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132234-swu81jnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-319
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/swu81jnb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.98it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.17it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 117.28it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 117.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 119.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 117.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 116.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 115.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 115.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 114.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 114.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 113.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 113.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 113.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 112.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 112.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.74717
wandb: sub_train_loss 0.1966
wandb:       test_acc 0.749
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run peachy-sweep-319 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/swu81jnb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132234-swu81jnb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 524z8kj6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132250-524z8kj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-320
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/524z8kj6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 107.88it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 106.92it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 106.53it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 106.49it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 106.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 105.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 104.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 106.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 104.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 103.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 102.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 101.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 99.96it/s]  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 99.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 99.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 99.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 100.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 101.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 102.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.767
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.77344
wandb: sub_train_loss 0.20611
wandb:       test_acc 0.768
wandb:      valid_acc 0.782
wandb: 
wandb: üöÄ View run zesty-sweep-320 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/524z8kj6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132250-524z8kj6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wc7gtnyl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132332-wc7gtnyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-321
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wc7gtnyl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.80it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 102.70it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 88.36it/s]  22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 91.28it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 90.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 87.40it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 88.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 89.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 89.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:01, 93.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 94.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 97.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 99.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 100.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 102.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 102.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 103.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 103.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.06it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.443
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.28808
wandb: sub_train_loss 0.06951
wandb:       test_acc 0.184
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run hardy-sweep-321 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wc7gtnyl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132332-wc7gtnyl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h0qsv1zi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132347-h0qsv1zi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-322
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0qsv1zi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.22it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.59it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 98.22it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 98.67it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 99.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 100.02it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 96.08it/s]  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 93.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:01, 93.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:01, 93.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 92.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 93.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 94.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 96.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 97.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 97.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 98.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 99.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:02<00:00, 99.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.33788
wandb: sub_train_loss 0.18625
wandb:       test_acc 0.2
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run sweet-sweep-322 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0qsv1zi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132347-h0qsv1zi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p66jccc3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132403-p66jccc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-323
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p66jccc3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 8/200 [00:00<00:02, 78.97it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 86.20it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 90.00it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 91.92it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 93.15it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 94.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 93.78it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 93.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 92.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 92.78it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 92.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 91.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 92.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 92.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 92.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 93.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 96.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 98.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 99.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.3463
wandb: sub_train_loss 0.20332
wandb:       test_acc 0.283
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run classic-sweep-323 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p66jccc3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132403-p66jccc3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6767ld2h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132418-6767ld2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-324
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6767ld2h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.68it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.77it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 85.60it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 83.59it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 83.74it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 81.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 84.44it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 85.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 84.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:01<00:01, 84.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 86.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:01, 88.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 89.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 87.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 87.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 84.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 81.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 86.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:02<00:00, 89.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:02<00:00, 91.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:02<00:00, 92.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 86.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.514
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.45494
wandb: sub_train_loss 0.11705
wandb:       test_acc 0.432
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run fiery-sweep-324 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6767ld2h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132418-6767ld2h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mct26033 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132434-mct26033
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-325
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mct26033
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.03it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.08it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 98.28it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 98.52it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 98.43it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 97.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 97.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 97.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 96.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 96.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 97.06it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 97.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 95.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 93.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 92.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 91.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 90.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 88.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.597
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.60714
wandb: sub_train_loss 0.16747
wandb:       test_acc 0.597
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run splendid-sweep-325 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mct26033
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132434-mct26033/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8yaeo73r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132449-8yaeo73r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-326
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8yaeo73r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 81.27it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 80.45it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 80.80it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:02, 80.26it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 80.43it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 80.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 80.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 81.39it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:01<00:01, 78.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:01<00:01, 81.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:01<00:01, 82.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:01, 82.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 83.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 84.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 84.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 86.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 86.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 85.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:02<00:00, 83.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:02<00:00, 82.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 82.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 84.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 82.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.492
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.47036
wandb: sub_train_loss 0.19213
wandb:       test_acc 0.448
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run silvery-sweep-326 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8yaeo73r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132449-8yaeo73r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 90fccoun with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132505-90fccoun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-327
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/90fccoun
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.05it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 91.80it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 92.57it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 91.66it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 93.43it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 93.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 94.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 94.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 94.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:01<00:01, 93.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 92.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 92.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 93.14it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 94.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 94.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 95.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 96.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 97.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 98.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.71182
wandb: sub_train_loss 0.09471
wandb:       test_acc 0.733
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run upbeat-sweep-327 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/90fccoun
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132505-90fccoun/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8ug73nvf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132521-8ug73nvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-328
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8ug73nvf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 86.04it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 93.58it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 96.15it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 97.03it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 95.99it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 96.66it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 97.41it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 97.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 98.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:01<00:01, 96.56it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 94.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 93.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 92.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 91.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 92.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 93.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 94.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 95.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 96.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 95.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.66963
wandb: sub_train_loss 0.10972
wandb:       test_acc 0.703
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run balmy-sweep-328 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8ug73nvf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132521-8ug73nvf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0l8b6ljd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132536-0l8b6ljd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-329
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0l8b6ljd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.18it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.00it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 97.38it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 96.56it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.97it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 91.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 89.69it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 86.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 85.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:01<00:01, 85.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:01, 85.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 85.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 85.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 86.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 87.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 88.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 88.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 88.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:02<00:00, 88.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 89.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 88.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 88.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.70026
wandb: sub_train_loss 0.14103
wandb:       test_acc 0.695
wandb:      valid_acc 0.714
wandb: 
wandb: üöÄ View run dulcet-sweep-329 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0l8b6ljd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132536-0l8b6ljd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: efg60fkz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132552-efg60fkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-330
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/efg60fkz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.03it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 99.31it/s]  16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 99.46it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 99.46it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 99.49it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 99.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 99.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 100.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:01, 100.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:00, 99.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 99.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 99.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 99.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 99.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 99.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 99.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 99.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 100.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 100.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.87it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.70533
wandb: sub_train_loss 0.12303
wandb:       test_acc 0.708
wandb:      valid_acc 0.714
wandb: 
wandb: üöÄ View run mild-sweep-330 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/efg60fkz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132552-efg60fkz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oh7kkp3f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132608-oh7kkp3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-331
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oh7kkp3f
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.14it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.82it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.64it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 92.14it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 90.63it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 90.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 89.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 89.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 89.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:01<00:01, 88.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:01, 86.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 86.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 86.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 86.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 85.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 84.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 84.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 84.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:02<00:00, 83.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:02<00:00, 83.88it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 84.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 87.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.73196
wandb: sub_train_loss 0.11579
wandb:       test_acc 0.733
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run dutiful-sweep-331 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oh7kkp3f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132608-oh7kkp3f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kigu6jwp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132623-kigu6jwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-332
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kigu6jwp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  2%|‚ñé         | 5/200 [00:00<00:08, 23.21it/s]  8%|‚ñä         | 15/200 [00:00<00:03, 52.73it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:02, 69.49it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:02, 79.52it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 85.82it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 89.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 93.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 94.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:01<00:01, 94.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:01<00:01, 95.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:00, 95.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 95.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 93.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 92.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 92.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 92.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 92.83it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:02<00:00, 93.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 93.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 93.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 88.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.714
wandb:  sub_train_acc 0.70036
wandb: sub_train_loss 0.16563
wandb:       test_acc 0.692
wandb:      valid_acc 0.704
wandb: 
wandb: üöÄ View run usual-sweep-332 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kigu6jwp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132623-kigu6jwp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n6oagse3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132639-n6oagse3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-333
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/n6oagse3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 95.70it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.12it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.68it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 96.97it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 97.37it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 98.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 99.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 100.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:01, 100.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:00, 100.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 100.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 99.78it/s]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 99.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 99.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 99.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 99.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 99.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 99.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 99.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.67094
wandb: sub_train_loss 0.15581
wandb:       test_acc 0.68
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run sparkling-sweep-333 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/n6oagse3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132639-n6oagse3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xwjnj6y0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132653-xwjnj6y0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-334
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xwjnj6y0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 92.33it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.56it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 95.39it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 96.79it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 97.10it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.27it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 97.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 97.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 97.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 97.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 98.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 98.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 99.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 99.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 99.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 100.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 99.95it/s]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 99.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 99.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.775
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.70776
wandb: sub_train_loss 0.18148
wandb:       test_acc 0.723
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run proud-sweep-334 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xwjnj6y0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132653-xwjnj6y0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gfihcyoa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132709-gfihcyoa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-335
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gfihcyoa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.88it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 97.22it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.74it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 96.91it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 98.35it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 97.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 95.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 94.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 95.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:01, 96.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 97.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 98.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 98.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 98.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 98.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 99.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 100.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 99.74it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 99.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.812
wandb:  sub_train_acc 0.7419
wandb: sub_train_loss 0.27467
wandb:       test_acc 0.728
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run amber-sweep-335 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gfihcyoa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132709-gfihcyoa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5rohtghe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132725-5rohtghe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-336
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5rohtghe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.55it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 100.94it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.08it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.06it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 101.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 101.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 100.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 100.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:01, 100.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 100.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 100.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 100.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 100.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 100.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 100.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 100.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 100.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 100.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 100.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.59974
wandb: sub_train_loss 0.45923
wandb:       test_acc 0.598
wandb:      valid_acc 0.62
wandb: 
wandb: üöÄ View run lyric-sweep-336 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5rohtghe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132725-5rohtghe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z4x1ch4q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132740-z4x1ch4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-337
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z4x1ch4q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.59it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.96it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.87it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.03it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 137.92it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 138.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 138.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 140.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 142.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 144.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 145.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 146.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 147.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 148.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 149.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 150.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 149.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 148.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 148.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.479
wandb: best_valid_acc 0.502
wandb:  sub_train_acc 0.38753
wandb: sub_train_loss 0.00521
wandb:       test_acc 0.432
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run daily-sweep-337 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z4x1ch4q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132740-z4x1ch4q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yi3ttara with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132755-yi3ttara
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-338
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yi3ttara
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.87it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.27it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.09it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.99it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 151.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 148.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 149.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 149.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 148.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 147.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 145.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 144.49it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 143.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 140.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 140.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 141.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 142.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 141.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 142.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.476
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.3995
wandb: sub_train_loss 0.01148
wandb:       test_acc 0.436
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run eternal-sweep-338 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yi3ttara
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132755-yi3ttara/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kt4ro01x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132810-kt4ro01x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-339
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kt4ro01x
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.53it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 134.52it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.14it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 131.46it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 130.70it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 134.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 134.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 134.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 132.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 135.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 140.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 144.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 146.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 149.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 150.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 151.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 151.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 151.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 152.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.493
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.48638
wandb: sub_train_loss 0.01267
wandb:       test_acc 0.497
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run rich-sweep-339 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kt4ro01x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132810-kt4ro01x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2nfr7zvi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132826-2nfr7zvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-340
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2nfr7zvi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.57it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.72it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.17it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.48it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 144.28it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 143.73it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 144.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 146.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 144.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 143.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 142.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 142.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 145.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 146.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 149.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 150.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 151.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 153.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 155.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.565
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.49064
wandb: sub_train_loss 0.03309
wandb:       test_acc 0.492
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run robust-sweep-340 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2nfr7zvi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132826-2nfr7zvi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jixzj0qx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132842-jixzj0qx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-341
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jixzj0qx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.53it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.22it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 138.32it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 135.29it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 134.28it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 135.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 138.09it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 137.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 137.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 138.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 139.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 139.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 139.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 142.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 145.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 147.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 150.45it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 152.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 153.81it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 154.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.493
wandb: best_valid_acc 0.522
wandb:  sub_train_acc 0.55105
wandb: sub_train_loss 0.02983
wandb:       test_acc 0.518
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run toasty-sweep-341 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jixzj0qx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132842-jixzj0qx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bfzd5f9g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132857-bfzd5f9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-342
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bfzd5f9g
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.64it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.47it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 151.15it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 150.60it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 151.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 152.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 152.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 153.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 154.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 155.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 155.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 154.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 153.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 153.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 152.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 152.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 151.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 149.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.53117
wandb: sub_train_loss 0.04752
wandb:       test_acc 0.493
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run tough-sweep-342 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bfzd5f9g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132857-bfzd5f9g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: twn3iz7c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132912-twn3iz7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-343
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/twn3iz7c
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.71it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 147.46it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 146.04it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 144.29it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 144.31it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 143.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 143.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 146.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 148.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 149.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 148.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 146.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 144.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 147.37it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 146.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 147.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 147.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 145.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 144.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.693
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.68854
wandb: sub_train_loss 0.06336
wandb:       test_acc 0.691
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run morning-sweep-343 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/twn3iz7c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132912-twn3iz7c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dl3088wa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132927-dl3088wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-344
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dl3088wa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.32it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.13it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 144.69it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 144.51it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 140.13it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 138.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 138.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 138.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 139.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 139.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 138.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 137.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 137.38it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 137.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 137.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 138.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 135.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 134.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 133.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 132.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.671
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.67667
wandb: sub_train_loss 0.0593
wandb:       test_acc 0.685
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run easy-sweep-344 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dl3088wa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132927-dl3088wa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4hwtfhcx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132943-4hwtfhcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-345
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4hwtfhcx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.42it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.49it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.24it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 142.79it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 141.79it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 142.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 142.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 143.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 145.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 145.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 146.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 142.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 142.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 141.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 139.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 140.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 142.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 144.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 144.67it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 144.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.72455
wandb: sub_train_loss 0.04474
wandb:       test_acc 0.738
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run kind-sweep-345 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4hwtfhcx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132943-4hwtfhcx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a2lo5dn0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_132959-a2lo5dn0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-346
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a2lo5dn0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.98it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 136.12it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 133.71it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 132.06it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 134.07it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 132.36it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 133.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 134.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 135.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 136.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 136.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 136.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 136.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 136.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 137.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 137.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 137.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 137.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 137.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 136.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 137.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.72562
wandb: sub_train_loss 0.04681
wandb:       test_acc 0.741
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run vivid-sweep-346 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a2lo5dn0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_132959-a2lo5dn0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: owylco0e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133013-owylco0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-347
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/owylco0e
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.82it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.95it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.62it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 152.78it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 152.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 152.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 152.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 153.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 153.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 152.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 153.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 152.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 148.49it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 146.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 143.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 140.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.72825
wandb: sub_train_loss 0.04383
wandb:       test_acc 0.726
wandb:      valid_acc 0.752
wandb: 
wandb: üöÄ View run confused-sweep-347 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/owylco0e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133013-owylco0e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ttubucll with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133029-ttubucll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-348
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ttubucll
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.28it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.44it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 152.92it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 152.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 153.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 154.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 154.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 154.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 153.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 153.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 153.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 152.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 152.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 153.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 153.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.72582
wandb: sub_train_loss 0.04537
wandb:       test_acc 0.724
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run toasty-sweep-348 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ttubucll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133029-ttubucll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2in5q79w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133043-2in5q79w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-349
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2in5q79w
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.38it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 127.77it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.97it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 127.97it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 133.03it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 134.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 138.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 143.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 146.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 148.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 147.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 145.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 143.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 140.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 140.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 139.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 140.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 141.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 140.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 141.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.72156
wandb: sub_train_loss 0.0672
wandb:       test_acc 0.74
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run avid-sweep-349 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2in5q79w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133043-2in5q79w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ufpfum2l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133059-ufpfum2l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-350
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ufpfum2l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.60it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.37it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.13it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 147.37it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 147.63it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 148.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 149.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 149.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 149.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 149.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 149.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 150.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 151.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 152.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 152.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 153.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 154.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 154.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 155.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.7316
wandb: sub_train_loss 0.06254
wandb:       test_acc 0.744
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run colorful-sweep-350 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ufpfum2l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133059-ufpfum2l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5fsoh8o1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133115-5fsoh8o1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-351
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5fsoh8o1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.92it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 141.98it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.52it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 150.12it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 151.53it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 150.01it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 145.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 146.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 145.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 145.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 145.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 147.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 150.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 151.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 146.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 143.72it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 143.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 141.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 141.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.74479
wandb: sub_train_loss 0.06294
wandb:       test_acc 0.734
wandb:      valid_acc 0.782
wandb: 
wandb: üöÄ View run dazzling-sweep-351 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5fsoh8o1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133115-5fsoh8o1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y3j4b3pi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133130-y3j4b3pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-352
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/y3j4b3pi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.90it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.38it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 140.37it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 139.92it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 140.43it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 140.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 139.40it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 138.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 139.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 140.54it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 140.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 139.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 138.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 140.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 140.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 139.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 140.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 141.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 141.11it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 141.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.73399
wandb: sub_train_loss 0.05552
wandb:       test_acc 0.738
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run azure-sweep-352 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/y3j4b3pi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133130-y3j4b3pi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l4h1b8kb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133146-l4h1b8kb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-353
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l4h1b8kb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.97it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.56it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 118.24it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 120.02it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 120.10it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 120.42it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 119.52it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 118.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 117.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 118.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 119.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 120.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 121.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 121.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 119.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 117.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 116.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 115.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 115.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 116.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 115.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 115.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 114.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.52
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.38236
wandb: sub_train_loss 0.00266
wandb:       test_acc 0.415
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run feasible-sweep-353 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l4h1b8kb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133146-l4h1b8kb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 79q98ten with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133201-79q98ten
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-354
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79q98ten
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.59it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.44it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.36it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 113.40it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 116.46it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 115.03it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 112.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 112.62it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 112.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 112.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 112.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 111.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 111.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 112.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 112.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 112.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 111.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 111.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 111.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 110.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 112.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 112.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 113.36it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 113.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.459
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.40615
wandb: sub_train_loss 0.00111
wandb:       test_acc 0.425
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run vivid-sweep-354 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79q98ten
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133201-79q98ten/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pb7yn63q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133221-pb7yn63q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-355
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pb7yn63q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.40it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.09it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 122.22it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 120.33it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 117.87it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 117.03it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 117.13it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 117.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 116.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 116.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 115.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 114.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 114.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 115.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 115.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 117.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 119.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 120.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 121.90it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 122.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 121.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 121.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 122.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.525
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.48719
wandb: sub_train_loss 0.02537
wandb:       test_acc 0.496
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run true-sweep-355 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pb7yn63q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133221-pb7yn63q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ej8nuny with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133237-3ej8nuny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-356
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3ej8nuny
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.41it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 107.62it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 108.89it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 109.71it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 111.13it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 111.61it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 112.41it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 112.94it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 112.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 111.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 112.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 112.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 114.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 115.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 114.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 116.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 116.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 116.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 114.47it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 113.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 115.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 117.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 118.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 118.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.525
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.52985
wandb: sub_train_loss 0.08227
wandb:       test_acc 0.514
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run silvery-sweep-356 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3ej8nuny
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133237-3ej8nuny/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7x3kg4o9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133252-7x3kg4o9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-357
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7x3kg4o9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.04it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 114.52it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 115.68it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 117.85it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 115.96it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 114.70it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 112.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 113.09it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 112.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 112.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 112.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 113.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 112.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 112.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 112.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 111.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 111.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 111.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 111.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 111.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 111.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 111.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 112.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 113.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.598
wandb:  sub_train_acc 0.57732
wandb: sub_train_loss 0.11204
wandb:       test_acc 0.535
wandb:      valid_acc 0.556
wandb: 
wandb: üöÄ View run gentle-sweep-357 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7x3kg4o9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133252-7x3kg4o9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ftcznq3r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133308-ftcznq3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-358
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ftcznq3r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.47it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.66it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 117.29it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 119.04it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 118.18it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 119.37it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 120.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 120.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 119.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 118.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 118.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 119.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 119.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 119.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 119.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 120.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 119.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 117.44it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 115.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 113.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 113.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 115.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 116.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 116.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.51448
wandb: sub_train_loss 0.14164
wandb:       test_acc 0.482
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run frosty-sweep-358 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ftcznq3r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133308-ftcznq3r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gs67kon4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133323-gs67kon4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-359
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gs67kon4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.91it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.31it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 122.26it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 121.11it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 120.65it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 114.25it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 112.05it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 114.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 116.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 117.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 117.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 118.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 119.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 120.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 120.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 119.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 107.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 106.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 110.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 112.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 112.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 112.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 112.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.70051
wandb: sub_train_loss 0.22991
wandb:       test_acc 0.718
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run autumn-sweep-359 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gs67kon4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133323-gs67kon4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j26ms7vy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133338-j26ms7vy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-360
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j26ms7vy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 104.96it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 106.86it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 106.41it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 103.15it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 100.70it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 101.97it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 103.37it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 104.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 105.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 106.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 107.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 108.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 108.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 108.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 108.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 108.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 109.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 108.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 109.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 109.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 108.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 108.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 108.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 109.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 109.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 108.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 106.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 107.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.7205
wandb: sub_train_loss 0.12067
wandb:       test_acc 0.747
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run helpful-sweep-360 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j26ms7vy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133338-j26ms7vy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ipv1486b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133403-ipv1486b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-361
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ipv1486b
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.37it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 118.63it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 119.46it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 118.88it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 118.64it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 118.24it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 119.39it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 120.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 118.10it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 117.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 117.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 117.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 117.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 117.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 117.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 117.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 117.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 117.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 116.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 116.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 117.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 118.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 118.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 118.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.68007
wandb: sub_train_loss 0.05863
wandb:       test_acc 0.73
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run leafy-sweep-361 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ipv1486b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133403-ipv1486b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7cjsp23n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133419-7cjsp23n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-362
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7cjsp23n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.17it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.68it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 122.30it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 122.67it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 122.94it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.15it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.26it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 117.27it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 112.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 112.94it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 114.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 116.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 116.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 118.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 119.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 118.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 120.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 121.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 122.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 122.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 122.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 117.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 115.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.72973
wandb: sub_train_loss 0.03697
wandb:       test_acc 0.749
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run silver-sweep-362 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7cjsp23n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133419-7cjsp23n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a9eionvy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133435-a9eionvy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-363
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a9eionvy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.72it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.15it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 116.34it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 118.68it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 120.46it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 121.29it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 121.84it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 122.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 122.44it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 122.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 121.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 121.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 122.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 119.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 119.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 120.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 110.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 103.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 98.89it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 97.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 97.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 96.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 97.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 95.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.741
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.70771
wandb: sub_train_loss 0.05578
wandb:       test_acc 0.728
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run youthful-sweep-363 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a9eionvy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133435-a9eionvy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 03xo1h7r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133452-03xo1h7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-364
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/03xo1h7r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.36it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 111.18it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 113.40it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.33it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 114.72it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 115.30it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 112.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 114.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 114.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 114.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 112.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 108.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 104.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 106.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 108.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 110.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 111.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 110.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 111.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 112.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 113.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 113.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 112.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 111.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 111.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.73992
wandb: sub_train_loss 0.06117
wandb:       test_acc 0.753
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run trim-sweep-364 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/03xo1h7r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133452-03xo1h7r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7sobkt07 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133506-7sobkt07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7sobkt07
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 96.33it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.25it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.51it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.78it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 95.95it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 94.43it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 95.80it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 97.02it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 98.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 98.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 97.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 97.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 100.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 103.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 105.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 106.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 107.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 107.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 108.55it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 109.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 110.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 110.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 111.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 111.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 112.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 112.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 112.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 104.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.70214
wandb: sub_train_loss 0.1651
wandb:       test_acc 0.717
wandb:      valid_acc 0.73
wandb: 
wandb: üöÄ View run cosmic-sweep-365 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7sobkt07
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133506-7sobkt07/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q8xldbdf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133521-q8xldbdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q8xldbdf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.63it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 119.59it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 119.21it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 118.32it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 117.52it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 118.34it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 118.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 117.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 115.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 114.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 115.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 115.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 115.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 115.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 116.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 116.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 117.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 119.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 118.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 119.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 120.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 110.95it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 104.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 101.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.73987
wandb: sub_train_loss 0.08266
wandb:       test_acc 0.759
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run balmy-sweep-366 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q8xldbdf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133521-q8xldbdf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9idhjra8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133535-9idhjra8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-367
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9idhjra8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 107.55it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 108.84it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 109.98it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 109.37it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 109.13it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 111.96it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 113.92it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 113.02it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 112.93it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 112.08it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 112.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 112.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 114.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 116.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 117.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 117.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 118.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 119.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 119.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 120.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 120.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 120.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 118.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 118.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.781
wandb: best_valid_acc 0.808
wandb:  sub_train_acc 0.75301
wandb: sub_train_loss 0.05114
wandb:       test_acc 0.746
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run dark-sweep-367 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9idhjra8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133535-9idhjra8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8f591czm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133551-8f591czm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-368
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8f591czm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.11it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.03it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.70it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 119.29it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 120.02it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 120.84it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 121.70it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 121.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 121.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 121.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 121.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 121.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 121.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 121.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 121.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 121.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 122.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 122.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 122.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 122.91it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 122.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 122.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 122.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.792
wandb: best_valid_acc 0.816
wandb:  sub_train_acc 0.69372
wandb: sub_train_loss 0.08079
wandb:       test_acc 0.67
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run eager-sweep-368 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8f591czm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133551-8f591czm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: entg09ez with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133606-entg09ez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-369
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/entg09ez
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.98it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 99.69it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 100.67it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 101.31it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 101.74it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 101.16it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 101.34it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 101.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:02, 99.45it/s]  36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:01, 97.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 98.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 99.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 99.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 99.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 99.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 100.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 100.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:01, 101.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:02<00:00, 101.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 100.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 97.54it/s]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 88.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 84.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 79.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 84.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 89.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 91.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 94.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.514
wandb:  sub_train_acc 0.27058
wandb: sub_train_loss 0.05317
wandb:       test_acc 0.183
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run glad-sweep-369 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/entg09ez
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133606-entg09ez/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7zdu99xi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133622-7zdu99xi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-370
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7zdu99xi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.10it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 89.53it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 88.11it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:03, 86.82it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 85.78it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 87.87it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 90.08it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 91.89it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 92.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:01<00:02, 93.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 90.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 90.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 89.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 89.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 88.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 90.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 92.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 94.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:02<00:01, 95.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 95.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 96.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 96.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 96.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 96.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 97.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 95.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 93.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 96.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 98.49it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 100.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.56it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.418
wandb: best_valid_acc 0.452
wandb:  sub_train_acc 0.31349
wandb: sub_train_loss 0.00093
wandb:       test_acc 0.241
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run royal-sweep-370 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7zdu99xi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133622-7zdu99xi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lpx2ph24 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133638-lpx2ph24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-371
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lpx2ph24
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.05it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.89it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 94.67it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 93.95it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 95.05it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 97.64it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 98.91it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 99.45it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:02, 99.83it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:01, 100.44it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 100.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 100.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 100.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 100.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 100.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 100.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 100.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 100.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 101.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 100.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 98.54it/s]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 99.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 99.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 100.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 99.98it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 99.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 100.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.43it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.504
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.45179
wandb: sub_train_loss 0.26493
wandb:       test_acc 0.449
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run cosmic-sweep-371 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lpx2ph24
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133638-lpx2ph24/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s5v1w9an with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133653-s5v1w9an
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-372
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s5v1w9an
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.62it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.13it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 97.71it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 98.28it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 98.77it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 99.25it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 99.17it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 99.64it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 99.37it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:01, 99.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 99.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 99.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 100.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 100.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 101.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 101.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 101.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 101.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 101.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 101.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 101.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 100.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 100.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 101.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 101.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 101.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 101.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 101.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 100.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.511
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.43445
wandb: sub_train_loss 0.18695
wandb:       test_acc 0.438
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run charmed-sweep-372 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s5v1w9an
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133653-s5v1w9an/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bxl7wjtr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133708-bxl7wjtr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-373
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bxl7wjtr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 86.15it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 82.70it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 82.07it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 83.76it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:03, 84.05it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 85.49it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 86.89it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 87.45it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 90.94it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:01<00:02, 92.35it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 93.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 91.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 90.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 90.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 88.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 87.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 86.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 86.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:02<00:01, 85.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:02<00:01, 83.06it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 82.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 82.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:01, 84.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 84.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 86.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 87.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 88.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 89.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:03<00:00, 90.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:03<00:00, 90.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 90.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 87.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÉ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.44261
wandb: sub_train_loss 0.34227
wandb:       test_acc 0.392
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run usual-sweep-373 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bxl7wjtr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133708-bxl7wjtr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i3de7zbx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133724-i3de7zbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-374
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i3de7zbx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 96.33it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.95it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 94.45it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.65it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.38it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 94.11it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 96.02it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 97.22it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 98.74it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:01, 99.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 98.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 97.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 97.19it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 95.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 95.86it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 96.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 97.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 98.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 95.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:01, 94.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 95.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 94.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 86.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 85.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 88.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 90.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 92.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 91.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:03<00:00, 91.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.571
wandb: best_valid_acc 0.598
wandb:  sub_train_acc 0.63078
wandb: sub_train_loss 0.28482
wandb:       test_acc 0.552
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run toasty-sweep-374 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i3de7zbx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133724-i3de7zbx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wp3yetq6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133738-wp3yetq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-375
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wp3yetq6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.88it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 101.45it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 101.28it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 96.86it/s]  18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 94.91it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 93.03it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 92.48it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 91.56it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:02, 89.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 88.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:02, 87.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:02, 86.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 86.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 87.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 87.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 88.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 88.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 87.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:02<00:01, 86.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 87.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 88.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 89.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 89.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 87.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 87.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 87.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 87.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 87.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:03<00:00, 86.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 87.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 86.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.63499
wandb: sub_train_loss 0.10586
wandb:       test_acc 0.581
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run resilient-sweep-375 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wp3yetq6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133738-wp3yetq6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xwhrmdff with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133754-xwhrmdff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-376
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xwhrmdff
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.40it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.49it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.98it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 95.33it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 93.85it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 97.11it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 99.51it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 101.00it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:02, 101.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:01, 101.52it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 101.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 101.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 101.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 102.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 102.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 103.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 102.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 102.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 102.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 102.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 103.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 103.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 102.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 102.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 103.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 103.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 102.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 101.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.65192
wandb: sub_train_loss 0.04899
wandb:       test_acc 0.709
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run playful-sweep-376 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xwhrmdff
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133754-xwhrmdff/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aqqxtluq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133810-aqqxtluq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-377
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aqqxtluq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.06it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 100.14it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 101.43it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 101.48it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 101.23it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 100.96it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 101.29it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 100.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:02, 100.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 100.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 100.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 100.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 100.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 98.74it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 95.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 93.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 91.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 90.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 92.74it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 92.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 90.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 90.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 90.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 90.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 90.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 88.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 91.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 90.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.66679
wandb: sub_train_loss 0.47551
wandb:       test_acc 0.7
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run ruby-sweep-377 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aqqxtluq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133810-aqqxtluq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 63e3hjlu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133824-63e3hjlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-378
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/63e3hjlu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 88.28it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 88.85it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 89.07it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 89.37it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 88.59it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 87.84it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 88.63it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 88.91it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 88.86it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:01<00:02, 89.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 88.30it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:02, 88.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:02, 88.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 88.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 88.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 88.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 88.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 88.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 88.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:02<00:01, 89.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 89.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 89.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:01, 89.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 89.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 89.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 89.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 89.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 89.71it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 89.26it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:03<00:00, 89.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 89.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 89.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.6783
wandb: sub_train_loss 0.51257
wandb:       test_acc 0.735
wandb:      valid_acc 0.73
wandb: 
wandb: üöÄ View run genial-sweep-378 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/63e3hjlu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133824-63e3hjlu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7ss4ucd3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133841-7ss4ucd3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-379
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7ss4ucd3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 89.83it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 90.91it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 90.15it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 87.77it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 88.08it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 86.11it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 87.06it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 87.95it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 89.34it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:01<00:02, 88.13it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:02, 87.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 84.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:02, 85.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 86.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 87.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 88.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 89.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 89.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:02<00:01, 89.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:02<00:01, 90.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:02<00:01, 90.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 91.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 91.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 91.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 91.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 91.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 91.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 91.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:03<00:00, 91.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 90.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 88.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.71446
wandb: sub_train_loss 0.11959
wandb:       test_acc 0.714
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run lilac-sweep-379 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7ss4ucd3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133841-7ss4ucd3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xqshktjy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133901-xqshktjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-380
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xqshktjy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.66it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 99.89it/s]  11%|‚ñà         | 32/300 [00:00<00:02, 99.16it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 100.07it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 101.03it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 101.19it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 101.51it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 101.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 101.74it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 102.18it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 101.65it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 101.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 101.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 100.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 100.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 100.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 100.16it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:01, 100.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 101.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 101.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 101.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 100.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 92.50it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 84.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 78.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 77.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 76.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 76.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.60643
wandb: sub_train_loss 1.54257
wandb:       test_acc 0.658
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run stellar-sweep-380 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xqshktjy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133901-xqshktjy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tbeeuz6q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133917-tbeeuz6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-381
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tbeeuz6q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.33it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 101.39it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 101.99it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 100.36it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 100.66it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 101.04it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 101.66it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 101.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 102.37it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 102.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 101.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 101.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 101.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 102.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 102.17it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 102.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 103.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:01, 100.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 101.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 102.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 102.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 102.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 93.96it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 93.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 94.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 95.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 96.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 100.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.53122
wandb: sub_train_loss 1.46223
wandb:       test_acc 0.537
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run fragrant-sweep-381 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tbeeuz6q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133917-tbeeuz6q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uhtfykcr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133932-uhtfykcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-382
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uhtfykcr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.17it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.43it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 96.83it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 96.37it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 96.98it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.93it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 96.20it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 97.10it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 97.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 97.49it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 95.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 94.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 92.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 93.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 92.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 93.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 92.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 88.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 88.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 87.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 86.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 86.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 87.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 87.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 88.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 88.72it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 88.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 87.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:03<00:00, 87.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 86.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 86.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.745
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.67257
wandb: sub_train_loss 0.23533
wandb:       test_acc 0.687
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run twilight-sweep-382 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uhtfykcr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133932-uhtfykcr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: suy1bcnj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_133948-suy1bcnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-383
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/suy1bcnj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.16it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.18it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 91.80it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.60it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 91.50it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 89.39it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 89.73it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 89.19it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 91.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 92.06it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:02, 92.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 91.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 91.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 92.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 93.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 94.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 94.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 94.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 94.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 95.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 96.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 97.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 98.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 97.94it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 98.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 98.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 99.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 100.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 100.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.00it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.71882
wandb: sub_train_loss 0.79879
wandb:       test_acc 0.76
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run ethereal-sweep-383 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/suy1bcnj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_133948-suy1bcnj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kq2cv0f9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134002-kq2cv0f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kq2cv0f9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.85it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 100.41it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 99.83it/s]  14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 98.99it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 97.62it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 95.53it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 94.67it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 91.53it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 90.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 89.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 90.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 91.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 90.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 91.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 90.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 89.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 91.16it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 90.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 91.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 91.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 90.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 90.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 91.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 92.89it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 92.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 91.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 93.55it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 94.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 95.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.774
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.76594
wandb: sub_train_loss 0.32126
wandb:       test_acc 0.742
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run smart-sweep-384 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kq2cv0f9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134002-kq2cv0f9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yd0wmgjw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134021-yd0wmgjw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-385
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yd0wmgjw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 176.81it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.26it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 185.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 186.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 188.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 189.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 190.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 190.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 187.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 186.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.414
wandb:  sub_train_acc 0.51489
wandb: sub_train_loss 0.0
wandb:       test_acc 0.413
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run eternal-sweep-385 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yd0wmgjw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134021-yd0wmgjw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: obe86vig with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134036-obe86vig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-386
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/obe86vig
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.12it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 157.01it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.29it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 160.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 169.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 175.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 178.83it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 180.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 182.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 182.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 183.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.45
wandb:  sub_train_acc 0.51859
wandb: sub_train_loss 0.0
wandb:       test_acc 0.41
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run electric-sweep-386 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/obe86vig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134036-obe86vig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tr1qfsjm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134053-tr1qfsjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-387
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tr1qfsjm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.92it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.14it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 171.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 170.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 170.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 170.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 172.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 158.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 159.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 160.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 164.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.525
wandb: best_valid_acc 0.566
wandb:  sub_train_acc 0.57194
wandb: sub_train_loss 0.0
wandb:       test_acc 0.24
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run honest-sweep-387 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tr1qfsjm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134053-tr1qfsjm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4mw6acl0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134107-4mw6acl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-388
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4mw6acl0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.30it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 179.02it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 179.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 178.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 178.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 180.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 179.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 181.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 178.73it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 177.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.646
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.52178
wandb: sub_train_loss 0.0
wandb:       test_acc 0.641
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run rural-sweep-388 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4mw6acl0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134107-4mw6acl0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dzbwol4t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134123-dzbwol4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-389
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dzbwol4t
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.96it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.02it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 183.12it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 184.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 185.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 186.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 186.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 186.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 186.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 186.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.686
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.59928
wandb: sub_train_loss 0.0
wandb:       test_acc 0.531
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run silvery-sweep-389 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dzbwol4t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134123-dzbwol4t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q2zv1ko7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134138-q2zv1ko7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-390
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q2zv1ko7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 170.68it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.24it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 177.59it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 179.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 180.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 179.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 180.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 181.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 182.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.58954
wandb: sub_train_loss 0.0
wandb:       test_acc 0.528
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run lively-sweep-390 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q2zv1ko7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134138-q2zv1ko7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yt92vmqi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134159-yt92vmqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-391
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yt92vmqi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.50it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.93it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 172.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 169.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 156.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 152.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 158.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 165.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 168.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 170.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 173.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.30502
wandb: sub_train_loss 0.0
wandb:       test_acc 0.25
wandb:      valid_acc 0.276
wandb: 
wandb: üöÄ View run hearty-sweep-391 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yt92vmqi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134159-yt92vmqi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: czsofk1p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134214-czsofk1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-392
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/czsofk1p
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 180.64it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 183.11it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 185.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 186.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 186.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 184.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 179.50it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 179.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 180.71it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 181.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.55516
wandb: sub_train_loss 0.0
wandb:       test_acc 0.465
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run vibrant-sweep-392 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/czsofk1p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134214-czsofk1p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bhbogsr5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134229-bhbogsr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-393
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bhbogsr5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.54it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.68it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 178.50it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 179.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 179.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 179.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 174.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 171.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 170.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñÖ‚ñá‚ñá‚ñÉ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.61267
wandb: sub_train_loss 0.0
wandb:       test_acc 0.605
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run whole-sweep-393 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bhbogsr5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134229-bhbogsr5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9isas709 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134245-9isas709
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-394
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9isas709
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.19it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 167.97it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 164.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 163.82it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 161.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 162.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 163.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 164.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 164.93it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 164.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 165.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.66374
wandb: sub_train_loss 0.10099
wandb:       test_acc 0.715
wandb:      valid_acc 0.734
wandb: 
wandb: üöÄ View run treasured-sweep-394 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9isas709
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134245-9isas709/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k012pmcm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134300-k012pmcm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-395
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k012pmcm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.68it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 178.29it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 179.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 179.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 180.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 180.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 181.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 181.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 181.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 180.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.54608
wandb: sub_train_loss 0.0
wandb:       test_acc 0.442
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run divine-sweep-395 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/k012pmcm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134300-k012pmcm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: blgksesk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134316-blgksesk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-396
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/blgksesk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.17it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.58it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 165.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 168.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 170.89it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 172.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 172.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 171.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 170.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 174.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 176.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.55363
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.497
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run wobbly-sweep-396 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/blgksesk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134316-blgksesk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fbphfe32 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134331-fbphfe32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-397
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fbphfe32
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.24it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.79it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 168.40it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 167.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 170.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 172.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 173.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 173.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 174.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 175.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 168.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.50489
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.449
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run vague-sweep-397 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fbphfe32
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134331-fbphfe32/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dty88loy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134347-dty88loy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-398
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dty88loy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.54it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 172.23it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 173.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 174.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 175.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 176.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 176.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 176.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 174.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 175.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 176.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.5689
wandb: sub_train_loss 0.0
wandb:       test_acc 0.541
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run vague-sweep-398 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dty88loy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134347-dty88loy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7knks1tc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134402-7knks1tc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-399
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7knks1tc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.17it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 148.72it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 157.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 161.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 164.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 164.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 166.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 166.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 166.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 166.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 166.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 163.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.755
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.54592
wandb: sub_train_loss 0.0
wandb:       test_acc 0.535
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run stellar-sweep-399 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7knks1tc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134402-7knks1tc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x2nflqpl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134417-x2nflqpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-400
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x2nflqpl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.86it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.73it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.08it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 166.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 167.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 167.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 168.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 169.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 170.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 171.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 171.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.697
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.48669
wandb: sub_train_loss 0.0
wandb:       test_acc 0.501
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run peachy-sweep-400 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x2nflqpl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134417-x2nflqpl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vo0kv96o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134438-vo0kv96o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-401
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vo0kv96o
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.93it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.86it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.48it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 147.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 146.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 147.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 142.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 124.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 121.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 128.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 130.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 133.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 140.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.44403
wandb: sub_train_loss 0.0
wandb:       test_acc 0.296
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run true-sweep-401 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vo0kv96o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134438-vo0kv96o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r4dli3vx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134454-r4dli3vx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-402
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r4dli3vx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.94it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.99it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 157.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 158.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 158.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 159.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 159.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 159.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 159.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.396
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.47746
wandb: sub_train_loss 0.0
wandb:       test_acc 0.324
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run avid-sweep-402 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r4dli3vx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134454-r4dli3vx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2f5ctfct with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134508-2f5ctfct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-403
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2f5ctfct
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.57it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 148.77it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 152.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 152.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 153.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 155.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 155.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 155.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 155.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.626
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.40113
wandb: sub_train_loss 0.0
wandb:       test_acc 0.398
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run rare-sweep-403 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2f5ctfct
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134508-2f5ctfct/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b63mshgp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134524-b63mshgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-404
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b63mshgp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.91it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.52it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 157.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 157.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 157.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 156.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 156.53it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 156.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 156.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.621
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.47842
wandb: sub_train_loss 0.0
wandb:       test_acc 0.188
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run lucky-sweep-404 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b63mshgp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134524-b63mshgp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lpcp9zsw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134539-lpcp9zsw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-405
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lpcp9zsw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.01it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 157.01it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 158.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 159.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 160.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 161.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 161.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 161.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 161.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 162.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 161.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÖ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.602
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.46767
wandb: sub_train_loss 0.0
wandb:       test_acc 0.489
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run quiet-sweep-405 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lpcp9zsw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134539-lpcp9zsw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6tdg57ek with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134555-6tdg57ek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-406
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6tdg57ek
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.63it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 150.60it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 156.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 156.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 157.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 157.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 158.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 158.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 157.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.625
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.52655
wandb: sub_train_loss 0.0
wandb:       test_acc 0.364
wandb:      valid_acc 0.364
wandb: 
wandb: üöÄ View run soft-sweep-406 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6tdg57ek
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134555-6tdg57ek/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2h4msf2o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134610-2h4msf2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-407
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2h4msf2o
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.14it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.16it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 157.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 157.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 157.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 156.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 156.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 156.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 157.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 157.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñà‚ñá‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.683
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.44383
wandb: sub_train_loss 0.0
wandb:       test_acc 0.199
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run wild-sweep-407 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2h4msf2o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134610-2h4msf2o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 351maqya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134631-351maqya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-408
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/351maqya
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.90it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.02it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.50it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 144.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 147.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 148.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 146.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 144.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 143.94it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 139.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 138.12it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 137.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.681
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.58868
wandb: sub_train_loss 0.0
wandb:       test_acc 0.443
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run fanciful-sweep-408 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/351maqya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134631-351maqya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9ocqogjm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134646-9ocqogjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-409
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9ocqogjm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.72it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.97it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 148.72it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 151.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 153.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 155.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 157.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 156.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 155.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 153.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 152.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 154.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.57849
wandb: sub_train_loss 0.0
wandb:       test_acc 0.459
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run ethereal-sweep-409 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9ocqogjm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134646-9ocqogjm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5vgpg9dp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134702-5vgpg9dp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-410
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5vgpg9dp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.99it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.86it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 153.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 152.38it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 150.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 145.90it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 145.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 146.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 149.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 151.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 151.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 153.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.013 MB of 0.014 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñà‚ñá‚ñá‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.63356
wandb: sub_train_loss 0.0
wandb:       test_acc 0.641
wandb:      valid_acc 0.67
wandb: 
wandb: üöÄ View run trim-sweep-410 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5vgpg9dp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134702-5vgpg9dp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kdz937rz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134718-kdz937rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-411
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kdz937rz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.16it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.69it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.30it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 152.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 153.09it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 149.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 146.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 148.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 150.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.37313
wandb: sub_train_loss 0.13752
wandb:       test_acc 0.245
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run wise-sweep-411 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kdz937rz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134718-kdz937rz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rfjvescl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134733-rfjvescl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-412
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rfjvescl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.80it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.93it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 155.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 155.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 156.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 157.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 157.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 158.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 158.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.60126
wandb: sub_train_loss 0.0
wandb:       test_acc 0.528
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run faithful-sweep-412 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rfjvescl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134733-rfjvescl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w3jlxpi2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134751-w3jlxpi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-413
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w3jlxpi2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.76it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.35it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 144.33it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 146.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 147.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 147.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 147.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 148.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 147.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 148.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 149.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 148.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 148.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.696
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.54324
wandb: sub_train_loss 0.0
wandb:       test_acc 0.483
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run comfy-sweep-413 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w3jlxpi2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134751-w3jlxpi2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 81ymxfif with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134806-81ymxfif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-414
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/81ymxfif
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.09it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.75it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.71it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 149.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 148.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 149.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 150.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 150.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 150.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 150.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 150.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 150.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.50855
wandb: sub_train_loss 0.00061
wandb:       test_acc 0.48
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run desert-sweep-414 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/81ymxfif
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134806-81ymxfif/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b8adz66j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134821-b8adz66j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-415
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b8adz66j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.44it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.87it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.53it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 146.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 147.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 147.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 147.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 147.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 147.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 148.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 148.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.55698
wandb: sub_train_loss 0.0
wandb:       test_acc 0.569
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run misty-sweep-415 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b8adz66j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134821-b8adz66j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 14tgg635 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134837-14tgg635
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-416
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/14tgg635
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.87it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.65it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.60it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 144.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 144.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 143.02it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 141.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 142.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 143.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 144.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 144.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñá‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.52751
wandb: sub_train_loss 1.4867
wandb:       test_acc 0.518
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run peachy-sweep-416 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/14tgg635
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134837-14tgg635/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: awrgf6cd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134852-awrgf6cd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-417
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/awrgf6cd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.76it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 129.24it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 128.51it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 128.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 129.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 130.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 130.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 128.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 126.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 124.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 122.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 123.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 121.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 120.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 116.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.407
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.42253
wandb: sub_train_loss 0.0
wandb:       test_acc 0.202
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run autumn-sweep-417 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/awrgf6cd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134852-awrgf6cd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1hrm4hbt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134907-1hrm4hbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-418
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1hrm4hbt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.41it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.76it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 137.06it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 138.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 138.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 139.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 139.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 139.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 139.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 139.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 139.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 139.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 139.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.43161
wandb: sub_train_loss 0.0
wandb:       test_acc 0.335
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run robust-sweep-418 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1hrm4hbt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134907-1hrm4hbt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4lyfvevt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134919-4lyfvevt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-419
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4lyfvevt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 104.72it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 94.25it/s]  16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 91.08it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 88.97it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 89.23it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 88.63it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 83.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 85.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:01<00:01, 87.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 93.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 97.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 99.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 101.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 102.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 103.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 104.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 106.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 105.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.00it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.541
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.51884
wandb: sub_train_loss 0.0
wandb:       test_acc 0.366
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run dark-sweep-419 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4lyfvevt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134919-4lyfvevt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e6vm7gut with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134933-e6vm7gut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-420
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e6vm7gut
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.87it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 127.45it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 127.81it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 126.17it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 127.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 128.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 128.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 129.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 130.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 130.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 130.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 130.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 131.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 130.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:       test_acc ‚ñá‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñá‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.538
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.4344
wandb: sub_train_loss 7.50741
wandb:       test_acc 0.322
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run deep-sweep-420 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e6vm7gut
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134933-e6vm7gut/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5mpxueoq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_134949-5mpxueoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-421
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5mpxueoq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.76it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 123.61it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.41it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 125.37it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 125.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 118.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 113.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 112.76it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 111.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 110.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 114.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 120.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 125.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 128.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 130.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:       test_acc ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.648
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.52995
wandb: sub_train_loss 16.99735
wandb:       test_acc 0.452
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run lunar-sweep-421 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5mpxueoq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_134949-5mpxueoq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jd3j9aj4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135005-jd3j9aj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-422
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jd3j9aj4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.35it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 137.74it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 137.24it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 136.09it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 136.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 136.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 136.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 136.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 136.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 136.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 136.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 136.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 135.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 134.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.666
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.47862
wandb: sub_train_loss 0.0
wandb:       test_acc 0.431
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run silver-sweep-422 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jd3j9aj4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135005-jd3j9aj4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9ss0zs20 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135019-9ss0zs20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-423
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9ss0zs20
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 130.19it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 128.88it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 130.83it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 132.62it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 133.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 131.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 129.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 128.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 126.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 127.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 125.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 127.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 131.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 132.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.44733
wandb: sub_train_loss 0.0
wandb:       test_acc 0.274
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run eternal-sweep-423 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9ss0zs20
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135019-9ss0zs20/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o21f4bz5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135035-o21f4bz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-424
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/o21f4bz5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.26it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 126.29it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 129.39it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.45it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 130.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 131.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 131.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 131.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 131.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 131.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 131.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 131.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 130.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 129.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñá‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.689
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.62007
wandb: sub_train_loss 0.0
wandb:       test_acc 0.381
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run restful-sweep-424 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/o21f4bz5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135035-o21f4bz5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0jj8zkxy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135051-0jj8zkxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-425
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0jj8zkxy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.51it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.70it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.45it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.33it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 111.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 111.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 108.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 106.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 107.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 107.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 107.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 107.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 106.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 106.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 106.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 107.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 109.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.693
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.57407
wandb: sub_train_loss 0.29206
wandb:       test_acc 0.495
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run glorious-sweep-425 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0jj8zkxy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135051-0jj8zkxy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lne7yakl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135106-lne7yakl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-426
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lne7yakl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.78it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.55it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.77it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 125.44it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 126.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 126.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 127.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 128.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 128.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 128.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 126.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 125.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 123.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 124.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 125.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.55942
wandb: sub_train_loss 0.0
wandb:       test_acc 0.406
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run smart-sweep-426 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lne7yakl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135106-lne7yakl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qsu1b2j3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135121-qsu1b2j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-427
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qsu1b2j3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.80it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 114.61it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 112.38it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 114.76it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 113.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 114.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 114.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 113.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 114.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 117.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 116.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 115.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 115.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 114.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 115.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 114.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.678
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.59253
wandb: sub_train_loss 0.69839
wandb:       test_acc 0.574
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run eternal-sweep-427 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qsu1b2j3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135121-qsu1b2j3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gp9g6g0o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135136-gp9g6g0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-428
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gp9g6g0o
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.33it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.51it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 124.87it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 126.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 127.41it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 128.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 128.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 129.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 129.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 129.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 128.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 126.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 125.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 126.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 127.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.672
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.40336
wandb: sub_train_loss 3.56253
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run dulcet-sweep-428 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gp9g6g0o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135136-gp9g6g0o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2sk4c0nf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135152-2sk4c0nf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-429
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2sk4c0nf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.59it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.83it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.99it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.90it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 123.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 121.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 119.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 119.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 116.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 115.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 114.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 113.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 113.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.48689
wandb: sub_train_loss 0.92501
wandb:       test_acc 0.493
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run sweet-sweep-429 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2sk4c0nf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135152-2sk4c0nf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qlbwhwgu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135207-qlbwhwgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-430
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qlbwhwgu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.62it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.02it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 122.85it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 124.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 123.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 124.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 125.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 125.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 125.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 126.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 126.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 125.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 125.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 125.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 125.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.51017
wandb: sub_train_loss 0.86556
wandb:       test_acc 0.503
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run divine-sweep-430 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qlbwhwgu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135207-qlbwhwgu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 39d2ly0l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135228-39d2ly0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-431
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/39d2ly0l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.11it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.26it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 123.36it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 121.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 119.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 118.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 118.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 121.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 123.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 124.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 126.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 126.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 126.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 126.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 126.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.67531
wandb: sub_train_loss 1.2842
wandb:       test_acc 0.676
wandb:      valid_acc 0.696
wandb: 
wandb: üöÄ View run toasty-sweep-431 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/39d2ly0l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135228-39d2ly0l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6o00dneu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135243-6o00dneu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-432
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6o00dneu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.37it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.18it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 119.38it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 123.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 125.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 126.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 126.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 128.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 127.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 129.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 129.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 130.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 130.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 130.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.767
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.53796
wandb: sub_train_loss 0.55676
wandb:       test_acc 0.514
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run whole-sweep-432 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6o00dneu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135243-6o00dneu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l0g6ijbo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135259-l0g6ijbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-433
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0g6ijbo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 176.53it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 180.64it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 181.08it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 179.22it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 174.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 169.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 167.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 166.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 167.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 168.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 168.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 168.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 167.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 167.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 165.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 166.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.414
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.48806
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run sage-sweep-433 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0g6ijbo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135259-l0g6ijbo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u8eyrk5t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135314-u8eyrk5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-434
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8eyrk5t
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.92it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.03it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.94it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 177.70it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 178.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 179.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 180.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 181.09it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 181.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 181.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 182.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 182.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 181.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 181.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 183.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 184.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.48872
wandb: sub_train_loss 0.0
wandb:       test_acc 0.346
wandb:      valid_acc 0.374
wandb: 
wandb: üöÄ View run sage-sweep-434 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8eyrk5t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135314-u8eyrk5t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6rh8w157 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135329-6rh8w157
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-435
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6rh8w157
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.76it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 178.85it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 180.96it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 182.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 181.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 183.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 185.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 186.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 187.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 188.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 188.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 189.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 189.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 187.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 187.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.63
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.44353
wandb: sub_train_loss 0.0
wandb:       test_acc 0.491
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run true-sweep-435 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6rh8w157
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135329-6rh8w157/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zv5bb63k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135351-zv5bb63k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-436
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zv5bb63k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.70it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.94it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.28it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 171.76it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 174.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 174.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 174.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 174.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 175.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 176.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 177.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 177.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 170.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 165.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 159.35it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 154.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÅ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÑ‚ñÅ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.55794
wandb: sub_train_loss 0.0
wandb:       test_acc 0.52
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run dainty-sweep-436 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zv5bb63k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135351-zv5bb63k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4y0y273n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135406-4y0y273n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-437
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4y0y273n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.58it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.75it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 178.13it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 178.15it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 177.35it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 178.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 179.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 181.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 184.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 185.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 184.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 182.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 181.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 179.63it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 180.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 181.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.617
wandb: best_valid_acc 0.64
wandb:  sub_train_acc 0.53314
wandb: sub_train_loss 0.0
wandb:       test_acc 0.447
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run radiant-sweep-437 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4y0y273n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135406-4y0y273n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rkun5vto with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135422-rkun5vto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-438
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rkun5vto
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.98it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.22it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 178.25it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 178.22it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 179.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 179.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 177.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 176.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 178.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 178.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 180.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 180.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 180.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 180.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 176.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 174.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.686
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.4555
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.188
wandb: 
wandb: üöÄ View run ruby-sweep-438 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rkun5vto
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135422-rkun5vto/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vgijiuwo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135437-vgijiuwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-439
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vgijiuwo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.34it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.13it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 183.61it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 184.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 185.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 186.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 182.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 179.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 177.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 177.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 178.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 178.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 179.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 179.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 179.11it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 177.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.50388
wandb: sub_train_loss 0.0
wandb:       test_acc 0.406
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run misunderstood-sweep-439 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vgijiuwo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135437-vgijiuwo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fgrm15kj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135453-fgrm15kj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fgrm15kj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.90it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.55it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.54it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 179.61it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 181.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 176.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 172.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 170.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 169.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 167.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 167.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 168.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 169.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 169.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 169.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 168.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.714
wandb:  sub_train_acc 0.42385
wandb: sub_train_loss 0.0
wandb:       test_acc 0.241
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run usual-sweep-440 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/fgrm15kj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135453-fgrm15kj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vsp0k3j5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135509-vsp0k3j5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-441
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vsp0k3j5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.43it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 161.88it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 164.09it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 165.02it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 165.37it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 167.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 166.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 166.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 167.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 166.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 166.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 166.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 165.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 164.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 164.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 163.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 164.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 165.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.57245
wandb: sub_train_loss 0.0
wandb:       test_acc 0.475
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run worldly-sweep-441 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vsp0k3j5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135509-vsp0k3j5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zb1pklz1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135521-zb1pklz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-442
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zb1pklz1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.63it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 178.23it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 180.50it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 174.53it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 166.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 167.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 167.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 164.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 162.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 160.64it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 160.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 159.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 159.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 162.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 167.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 172.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñà‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.48856
wandb: sub_train_loss 0.0
wandb:       test_acc 0.425
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run sweet-sweep-442 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zb1pklz1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135521-zb1pklz1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 27o18cgh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135536-27o18cgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-443
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/27o18cgh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.67it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 173.07it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 175.73it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 175.81it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 174.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 171.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 170.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 170.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 170.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 170.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 170.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 169.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 169.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 171.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 173.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 174.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.692
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.50251
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.429
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run smart-sweep-443 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/27o18cgh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135536-27o18cgh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tnts17fe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135551-tnts17fe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-444
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tnts17fe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 158.27it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 169.26it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 173.19it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 174.38it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 172.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 171.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 172.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 173.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 172.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 173.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 173.76it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 175.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 176.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 177.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 178.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 178.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.705
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.3887
wandb: sub_train_loss 0.0
wandb:       test_acc 0.302
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run lunar-sweep-444 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tnts17fe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135551-tnts17fe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uvaash5n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135607-uvaash5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-445
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uvaash5n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.58it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 163.04it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.56it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 168.82it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 168.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 169.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 170.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 171.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 171.97it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 172.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 173.40it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 172.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 173.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 173.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 174.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 175.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.57047
wandb: sub_train_loss 0.0
wandb:       test_acc 0.543
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run vibrant-sweep-445 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uvaash5n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135607-uvaash5n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h861d1vm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135623-h861d1vm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-446
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h861d1vm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.74it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.69it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 171.95it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.73it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 174.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 175.93it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 176.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 177.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 177.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 176.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 176.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 176.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 173.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 169.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 170.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 172.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.6252
wandb: sub_train_loss 0.0
wandb:       test_acc 0.619
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run glad-sweep-446 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h861d1vm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135623-h861d1vm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: twhskjdo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135638-twhskjdo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-447
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/twhskjdo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.98it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.96it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.28it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 166.22it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 165.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 166.02it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 164.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 164.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 165.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 164.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 164.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 166.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 167.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 166.19it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 164.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 159.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 156.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÅ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.71639
wandb: sub_train_loss 0.0
wandb:       test_acc 0.702
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run noble-sweep-447 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/twhskjdo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135638-twhskjdo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8momql5g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135653-8momql5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-448
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8momql5g
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.74it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.89it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.72it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 160.41it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 161.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 162.94it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 160.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 155.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 153.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 154.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 157.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 159.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 160.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 158.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 158.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 158.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 155.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 153.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.62758
wandb: sub_train_loss 0.0
wandb:       test_acc 0.631
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run different-sweep-448 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8momql5g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135653-8momql5g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zqj2ayfa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135709-zqj2ayfa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-449
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zqj2ayfa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.54it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 143.77it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.72it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 154.04it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 156.56it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 157.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 158.19it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 157.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 157.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 157.41it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 156.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 154.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 155.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 156.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 156.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 157.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 157.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 159.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.41
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.44038
wandb: sub_train_loss 0.0
wandb:       test_acc 0.257
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run gentle-sweep-449 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zqj2ayfa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135709-zqj2ayfa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4zawoa78 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135726-4zawoa78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-450
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4zawoa78
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 158.14it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.75it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.65it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 158.60it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 159.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 159.83it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 160.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 160.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 161.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 160.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 160.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 160.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 160.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 160.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 160.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 160.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 160.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÇ‚ñá‚ñà‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñà‚ñÇ‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.405
wandb: best_valid_acc 0.43
wandb:  sub_train_acc 0.36253
wandb: sub_train_loss 0.0
wandb:       test_acc 0.268
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run happy-sweep-450 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4zawoa78
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135726-4zawoa78/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lauybzpl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135742-lauybzpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-451
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lauybzpl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.05it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.08it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.24it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.47it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 98.38it/s]  32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 112.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 123.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 130.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 136.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 140.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 143.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 145.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 147.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 149.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 149.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 149.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 143.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 136.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.59071
wandb: sub_train_loss 0.0
wandb:       test_acc 0.51
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run dandy-sweep-451 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lauybzpl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135742-lauybzpl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bvaku83c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135757-bvaku83c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-452
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bvaku83c
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.00it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 149.75it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 143.34it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 140.34it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 137.95it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 142.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 144.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 145.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 148.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 150.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 147.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 149.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 150.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 150.92it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 151.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 151.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 151.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 152.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 152.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.608
wandb:  sub_train_acc 0.45945
wandb: sub_train_loss 0.0
wandb:       test_acc 0.246
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run noble-sweep-452 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bvaku83c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135757-bvaku83c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ube58gx7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135813-ube58gx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-453
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ube58gx7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.14it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.09it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.95it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 152.31it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 147.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 146.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 146.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 144.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 142.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 140.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 137.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 133.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 138.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 143.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 146.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 149.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 150.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 152.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 153.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.677
wandb: best_valid_acc 0.718
wandb:  sub_train_acc 0.48141
wandb: sub_train_loss 0.0
wandb:       test_acc 0.483
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run kind-sweep-453 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ube58gx7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135813-ube58gx7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a6ezy0f0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135829-a6ezy0f0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-454
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a6ezy0f0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 139.98it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.14it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.48it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 148.39it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.44it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 150.52it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 149.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 149.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 149.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 150.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 152.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 153.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 154.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 155.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 155.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 154.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 152.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 150.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 148.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.676
wandb: best_valid_acc 0.704
wandb:  sub_train_acc 0.46594
wandb: sub_train_loss 0.0
wandb:       test_acc 0.214
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run cosmic-sweep-454 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a6ezy0f0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135829-a6ezy0f0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nvq1fan3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135843-nvq1fan3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-455
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nvq1fan3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.83it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.07it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 157.87it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.01it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 157.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 154.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 153.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 154.14it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 154.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 155.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 154.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 151.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 152.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 151.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 148.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 148.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 149.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 152.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.682
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.59497
wandb: sub_train_loss 0.0
wandb:       test_acc 0.388
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run happy-sweep-455 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nvq1fan3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135843-nvq1fan3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nyu24xjz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135859-nyu24xjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-456
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nyu24xjz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.63it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 154.14it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.17it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.63it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 155.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 155.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 154.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 153.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 154.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 154.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 154.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 153.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 152.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 151.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 152.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 151.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 151.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.48801
wandb: sub_train_loss 0.0
wandb:       test_acc 0.259
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run revived-sweep-456 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nyu24xjz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135859-nyu24xjz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7490mqeq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135915-7490mqeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-457
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7490mqeq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.46it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 151.31it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 153.03it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 147.83it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 148.43it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 148.25it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 151.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 151.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 151.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 150.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 148.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 149.39it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 148.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 147.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 147.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 148.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 149.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 148.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 148.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.67723
wandb: sub_train_loss 0.0
wandb:       test_acc 0.637
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run lucky-sweep-457 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7490mqeq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135915-7490mqeq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yzi62aju with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135930-yzi62aju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-458
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzi62aju
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.50it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.05it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 158.00it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.50it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 150.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 146.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 148.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 151.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 152.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 154.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 154.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 154.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 155.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 155.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 155.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÅ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.42461
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.32
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run deft-sweep-458 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yzi62aju
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135930-yzi62aju/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2vj76wks with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_135945-2vj76wks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-459
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2vj76wks
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.43it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 147.06it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 149.32it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 151.66it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 153.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 152.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 154.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 155.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 156.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 157.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 157.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 156.99it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 156.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 155.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 155.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 156.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 156.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 156.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.696
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.48765
wandb: sub_train_loss 0.0
wandb:       test_acc 0.345
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run gentle-sweep-459 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2vj76wks
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_135945-2vj76wks/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jyny9m72 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140000-jyny9m72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-460
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jyny9m72
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.18it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.22it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.34it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.19it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 145.52it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 146.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 150.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 150.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 150.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 148.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 145.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 143.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 140.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 142.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 146.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 148.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 145.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 141.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 134.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.47776
wandb: sub_train_loss 0.0
wandb:       test_acc 0.363
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run lunar-sweep-460 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jyny9m72
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140000-jyny9m72/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m6viqr8n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140016-m6viqr8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-461
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m6viqr8n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.87it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 139.50it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 141.11it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 142.27it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 142.91it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 140.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 139.86it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 135.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 136.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 139.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 141.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 140.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 141.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 141.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 141.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 143.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 144.16it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 144.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 144.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 143.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñá‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñá‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.57326
wandb: sub_train_loss 0.04519
wandb:       test_acc 0.516
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run lyric-sweep-461 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m6viqr8n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140016-m6viqr8n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5gx8gt7l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140032-5gx8gt7l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-462
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5gx8gt7l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.28it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 138.31it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 141.81it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 144.25it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 144.43it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 145.77it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 145.83it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 146.21it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 147.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 147.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 147.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 145.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 146.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 146.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 144.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 146.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 147.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 146.82it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 146.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.5722
wandb: sub_train_loss 0.0
wandb:       test_acc 0.535
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run proud-sweep-462 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5gx8gt7l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140032-5gx8gt7l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhfsig9n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140047-hhfsig9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-463
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hhfsig9n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.08it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.58it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 134.57it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 137.79it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 139.08it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 141.17it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 140.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 142.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 144.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 144.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 145.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 145.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 144.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 144.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 144.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 144.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 143.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 143.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 143.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 142.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÅ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñÜ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.53041
wandb: sub_train_loss 0.0
wandb:       test_acc 0.546
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run lyric-sweep-463 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hhfsig9n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140047-hhfsig9n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q811sn8r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140103-q811sn8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-464
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q811sn8r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.22it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 127.20it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 134.46it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 138.65it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 140.37it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 141.79it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 143.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 143.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 144.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 145.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 145.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 145.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 145.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 144.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 145.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 144.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 143.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 141.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 143.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 143.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.56119
wandb: sub_train_loss 0.0
wandb:       test_acc 0.579
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run earthy-sweep-464 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q811sn8r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140103-q811sn8r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l8s6a6ky with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140118-l8s6a6ky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-465
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l8s6a6ky
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.06it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.96it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 111.77it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 115.23it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 119.70it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 123.06it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 124.71it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 125.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 127.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 128.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 130.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 130.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 131.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 131.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 131.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 131.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 131.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 130.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 130.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 130.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 130.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 129.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.396
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.43394
wandb: sub_train_loss 0.0
wandb:       test_acc 0.334
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run fallen-sweep-465 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l8s6a6ky
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140118-l8s6a6ky/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lbwwrikv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140133-lbwwrikv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-466
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbwwrikv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.80it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 131.23it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.17it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.10it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.64it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 134.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 134.56it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 134.38it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 134.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 134.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 134.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 134.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 134.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 134.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 133.35it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 133.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 133.84it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 133.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 133.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 133.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.422
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.46853
wandb: sub_train_loss 0.0
wandb:       test_acc 0.252
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run exalted-sweep-466 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbwwrikv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140133-lbwwrikv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uf3udsfq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140149-uf3udsfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-467
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uf3udsfq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.01it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 130.09it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.85it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 134.18it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.95it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 135.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 136.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 135.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 135.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 134.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 133.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 133.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 134.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 134.89it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 134.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 132.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 132.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 133.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 134.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 134.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 134.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.563
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.42735
wandb: sub_train_loss 0.0
wandb:       test_acc 0.259
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run ethereal-sweep-467 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uf3udsfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140149-uf3udsfq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iuootd8d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140204-iuootd8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-468
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iuootd8d
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.24it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 129.14it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.75it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 128.44it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 129.41it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 129.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 130.00it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 130.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 130.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 131.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 131.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 130.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 130.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 130.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 130.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 129.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 129.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 129.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 129.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 130.96it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 127.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.587
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.46645
wandb: sub_train_loss 0.0
wandb:       test_acc 0.256
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run jolly-sweep-468 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iuootd8d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140204-iuootd8d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yniswx4d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140219-yniswx4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-469
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yniswx4d
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.67it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.24it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 119.41it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 123.60it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 122.87it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 125.66it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 127.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 127.16it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 125.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 127.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 129.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 132.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 133.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 133.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 133.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 134.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 135.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 135.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 136.10it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 134.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 135.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñà‚ñà‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.638
wandb: best_valid_acc 0.65
wandb:  sub_train_acc 0.47228
wandb: sub_train_loss 0.0
wandb:       test_acc 0.177
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run vibrant-sweep-469 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yniswx4d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140219-yniswx4d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zdimjwpq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140234-zdimjwpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-470
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zdimjwpq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.77it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.64it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 117.67it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 116.58it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 115.03it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 113.93it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 113.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 110.50it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 112.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 113.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 114.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 114.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 115.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 113.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 112.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 116.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 122.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 123.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 122.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 123.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 123.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 123.77it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 122.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 123.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.669
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.46939
wandb: sub_train_loss 0.0
wandb:       test_acc 0.276
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run skilled-sweep-470 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zdimjwpq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140234-zdimjwpq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j74f5vl5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140252-j74f5vl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-471
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j74f5vl5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.31it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.84it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.28it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 136.62it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 137.35it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 137.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 137.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 138.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 138.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 138.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 138.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 137.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 137.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 137.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 137.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 137.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 138.14it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 138.29it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 137.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 137.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 136.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.57291
wandb: sub_train_loss 0.0
wandb:       test_acc 0.404
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run good-sweep-471 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/j74f5vl5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140252-j74f5vl5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w5agj5km with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140307-w5agj5km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-472
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5agj5km
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.07it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 126.58it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.98it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 129.07it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 130.06it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 131.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 132.82it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 133.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 133.80it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 133.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 133.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 133.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 133.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 132.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 132.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 132.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 132.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 132.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 132.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 133.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 133.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.637
wandb: best_valid_acc 0.658
wandb:  sub_train_acc 0.45007
wandb: sub_train_loss 0.0
wandb:       test_acc 0.208
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run sunny-sweep-472 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5agj5km
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140307-w5agj5km/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: egdhatzk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140322-egdhatzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-473
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/egdhatzk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 106.72it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 99.75it/s]  11%|‚ñà         | 33/300 [00:00<00:02, 101.25it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 106.78it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 107.37it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 108.45it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 108.04it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 107.47it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 105.83it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 105.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 105.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 108.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 113.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 113.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 113.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 118.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 120.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 121.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 123.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 123.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 124.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 126.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 128.23it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 128.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.48471
wandb: sub_train_loss 0.0
wandb:       test_acc 0.372
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run peach-sweep-473 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/egdhatzk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140322-egdhatzk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lyhz3zah with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140338-lyhz3zah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-474
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lyhz3zah
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.40it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.94it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.70it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 126.03it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 127.95it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 127.94it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 127.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 128.33it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 127.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 124.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 120.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 120.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 119.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 122.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 123.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 120.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 117.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 115.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 114.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 114.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 113.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 114.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 114.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.55161
wandb: sub_train_loss 0.0
wandb:       test_acc 0.545
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run elated-sweep-474 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lyhz3zah
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140338-lyhz3zah/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yyyqoo0n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140353-yyyqoo0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-475
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yyyqoo0n
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.41it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 126.56it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 127.51it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 127.25it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 127.43it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 125.70it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 125.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 126.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 126.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 125.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 125.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 125.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 126.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 128.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 127.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 127.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 127.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 128.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 128.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 128.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 128.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 128.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.729
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.60217
wandb: sub_train_loss 0.58898
wandb:       test_acc 0.682
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run rose-sweep-475 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yyyqoo0n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140353-yyyqoo0n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xc4a3xpp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140408-xc4a3xpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-476
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xc4a3xpp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.57it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 129.60it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 130.74it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 131.89it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 131.95it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 131.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 131.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 127.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 127.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 124.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 122.54it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 120.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 118.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 117.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 117.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 117.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 116.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 118.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 119.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 116.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 116.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 115.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 114.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.685
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.64411
wandb: sub_train_loss 0.71685
wandb:       test_acc 0.593
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run decent-sweep-476 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xc4a3xpp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140408-xc4a3xpp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hl2pi8ub with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140423-hl2pi8ub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-477
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hl2pi8ub
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.74it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 126.29it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.05it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 129.39it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 130.14it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 129.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 130.88it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 131.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 131.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 132.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 131.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 131.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 132.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 131.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 130.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 129.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 130.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 130.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 131.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 131.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 131.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñà‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.71852
wandb: sub_train_loss 0.0
wandb:       test_acc 0.738
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run northern-sweep-477 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hl2pi8ub
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140423-hl2pi8ub/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sebazsgu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140439-sebazsgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-478
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sebazsgu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.22it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 122.83it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 124.57it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 126.04it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 122.10it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 122.20it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 124.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 127.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 127.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 129.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 129.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 129.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 128.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 128.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 128.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 127.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 128.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 129.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 130.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 130.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 131.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 132.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.55972
wandb: sub_train_loss 0.02077
wandb:       test_acc 0.539
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run distinctive-sweep-478 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sebazsgu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140439-sebazsgu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p0orjvqs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140454-p0orjvqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-479
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p0orjvqs
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.45it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 119.14it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 118.83it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 119.22it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 119.07it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 120.53it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 121.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 122.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 123.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 125.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 125.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 124.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 123.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 123.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 122.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 122.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 123.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 123.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 124.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 125.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 126.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 126.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 126.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.20809
wandb: sub_train_loss 1.11585
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run earnest-sweep-479 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p0orjvqs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140454-p0orjvqs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0cpd2ikk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140509-0cpd2ikk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-480
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0cpd2ikk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 113.31it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 119.27it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 120.92it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 119.77it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 120.98it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 123.01it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 124.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 125.41it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 126.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 127.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 126.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 124.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 124.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 125.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 124.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 125.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 125.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 125.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 125.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 126.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 126.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 126.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 126.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.66197
wandb: sub_train_loss 0.073
wandb:       test_acc 0.671
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run sweepy-sweep-480 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0cpd2ikk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140509-0cpd2ikk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bnecdw6l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140530-bnecdw6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-481
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bnecdw6l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.45it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.29it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 132.43it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 131.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 133.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 133.01it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 135.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 133.61it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 133.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 133.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 129.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 117.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 116.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.517
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.39839
wandb: sub_train_loss 0.01953
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run snowy-sweep-481 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bnecdw6l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140530-bnecdw6l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 43ia47ag with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140546-43ia47ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-482
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/43ia47ag
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.21it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.89it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.13it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 138.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 140.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 141.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 140.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 134.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 134.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 136.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 137.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.434
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.32774
wandb: sub_train_loss 0.0
wandb:       test_acc 0.276
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run solar-sweep-482 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/43ia47ag
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140546-43ia47ag/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w0oo18rr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140601-w0oo18rr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-483
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w0oo18rr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.17it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 153.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 153.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 152.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 151.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 151.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 151.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 151.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.635
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.5335
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.596
wandb:      valid_acc 0.616
wandb: 
wandb: üöÄ View run apricot-sweep-483 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w0oo18rr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140601-w0oo18rr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nb8es613 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140616-nb8es613
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-484
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nb8es613
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.42it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 138.09it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 137.56it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 136.16it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 136.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 137.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 136.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 134.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 133.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 133.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 133.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 132.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 133.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 132.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.704
wandb:  sub_train_acc 0.54937
wandb: sub_train_loss 0.23197
wandb:       test_acc 0.522
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run eager-sweep-484 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nb8es613
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140616-nb8es613/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2gkarwg9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140631-2gkarwg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-485
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2gkarwg9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.90it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.59it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.21it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 148.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 149.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 148.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 146.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 142.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 141.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 140.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 139.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 139.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 137.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.57793
wandb: sub_train_loss 0.39462
wandb:       test_acc 0.602
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run happy-sweep-485 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2gkarwg9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140631-2gkarwg9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qv61asjv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140652-qv61asjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-486
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qv61asjv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.13it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.33it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.65it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 140.48it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 138.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 139.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 141.25it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 141.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 142.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 143.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 141.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 139.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.5476
wandb: sub_train_loss 0.1718
wandb:       test_acc 0.524
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run swept-sweep-486 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qv61asjv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140652-qv61asjv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yrpfoj4a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140707-yrpfoj4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-487
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yrpfoj4a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.78it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.10it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.36it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 146.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 147.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 147.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 146.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 146.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 146.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 146.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 147.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.68646
wandb: sub_train_loss 0.12771
wandb:       test_acc 0.714
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run avid-sweep-487 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yrpfoj4a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140707-yrpfoj4a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 61fh3et5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140723-61fh3et5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-488
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/61fh3et5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.36it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 129.52it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 132.13it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 133.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 132.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 133.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 133.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 134.55it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 133.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 131.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 130.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 130.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 130.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 135.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.33058
wandb: sub_train_loss 0.68337
wandb:       test_acc 0.267
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run avid-sweep-488 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/61fh3et5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140723-61fh3et5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f5qd4icm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140738-f5qd4icm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-489
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f5qd4icm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.55it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.16it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 146.65it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 148.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 149.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 150.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 150.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 147.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 145.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 146.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 144.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 143.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.806
wandb:  sub_train_acc 0.6782
wandb: sub_train_loss 0.07615
wandb:       test_acc 0.713
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run revived-sweep-489 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f5qd4icm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140738-f5qd4icm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u5h059xx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140755-u5h059xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-490
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u5h059xx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 140.46it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 138.80it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 146.15it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 149.92it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 151.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 153.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 153.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 153.92it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 154.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 153.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 152.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 152.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.762
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.65568
wandb: sub_train_loss 0.17118
wandb:       test_acc 0.677
wandb:      valid_acc 0.692
wandb: 
wandb: üöÄ View run smooth-sweep-490 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u5h059xx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140755-u5h059xx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4b1te6np with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140809-4b1te6np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-491
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4b1te6np
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.20it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.13it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.43it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 133.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 132.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 133.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 134.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 132.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 132.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 131.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 131.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 133.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 133.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 133.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.59492
wandb: sub_train_loss 0.53261
wandb:       test_acc 0.538
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run avid-sweep-491 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4b1te6np
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140809-4b1te6np/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jzfj69hd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140831-jzfj69hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-492
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jzfj69hd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.12it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.96it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.83it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 145.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 145.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 145.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 144.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 146.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 144.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 141.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 142.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 142.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñá
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.64447
wandb: sub_train_loss 0.20814
wandb:       test_acc 0.674
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run fine-sweep-492 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jzfj69hd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140831-jzfj69hd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g2rvh4so with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140846-g2rvh4so
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-493
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g2rvh4so
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.53it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.41it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.97it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 149.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 149.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 147.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 147.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 147.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 143.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 141.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 139.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 136.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.68266
wandb: sub_train_loss 0.24596
wandb:       test_acc 0.682
wandb:      valid_acc 0.678
wandb: 
wandb: üöÄ View run morning-sweep-493 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/g2rvh4so
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140846-g2rvh4so/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1x2vnr9c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140901-1x2vnr9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-494
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1x2vnr9c
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 130.78it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.69it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 137.94it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 137.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 133.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 135.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 135.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 129.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 132.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 135.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 136.59it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 137.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 138.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñá‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñá
wandb:      valid_acc ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.761
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.7242
wandb: sub_train_loss 0.17561
wandb:       test_acc 0.716
wandb:      valid_acc 0.718
wandb: 
wandb: üöÄ View run glad-sweep-494 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1x2vnr9c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140901-1x2vnr9c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8z3oo8iv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140922-8z3oo8iv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-495
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8z3oo8iv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.94it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.40it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.19it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 141.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 141.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 140.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 140.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 140.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 140.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 140.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 139.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 139.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 139.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.63615
wandb: sub_train_loss 0.35202
wandb:       test_acc 0.701
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run gentle-sweep-495 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8z3oo8iv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140922-8z3oo8iv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kyd09wv7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140937-kyd09wv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-496
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kyd09wv7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.81it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 124.34it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 133.35it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 135.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 140.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 143.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 146.26it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 147.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 148.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 148.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 149.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 149.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 149.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.796
wandb: best_valid_acc 0.834
wandb:  sub_train_acc 0.42704
wandb: sub_train_loss 2.70604
wandb:       test_acc 0.433
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run kind-sweep-496 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kyd09wv7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140937-kyd09wv7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b0k5nmxl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_140955-b0k5nmxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-497
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b0k5nmxl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.85it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.97it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 116.11it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 116.57it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 116.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 116.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 113.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 115.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 115.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 114.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 114.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 116.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.561
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.23239
wandb: sub_train_loss 0.0
wandb:       test_acc 0.182
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run summer-sweep-497 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/b0k5nmxl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_140955-b0k5nmxl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cu7tihf6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141017-cu7tihf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-498
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cu7tihf6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.37it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 108.58it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 106.81it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 106.88it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 107.57it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 108.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 111.91it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 114.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 114.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 115.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 115.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 115.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 116.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 116.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 116.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 116.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.45
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.26896
wandb: sub_train_loss 0.0
wandb:       test_acc 0.184
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run devout-sweep-498 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cu7tihf6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141017-cu7tihf6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pw4o7e3e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141032-pw4o7e3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-499
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pw4o7e3e
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.08it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.11it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.62it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.12it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 117.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 117.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 118.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 118.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 118.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 118.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 118.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 118.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 118.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 118.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 118.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 116.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.684
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.40635
wandb: sub_train_loss 0.11123
wandb:       test_acc 0.412
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run peach-sweep-499 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pw4o7e3e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141032-pw4o7e3e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: un7gej5i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141048-un7gej5i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-500
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/un7gej5i
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.94it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 110.55it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 112.72it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.73it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 116.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 117.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 118.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 118.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 117.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 116.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 113.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 114.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 115.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.99it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 116.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.45205
wandb: sub_train_loss 0.7949
wandb:       test_acc 0.429
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run vivid-sweep-500 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/un7gej5i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141048-un7gej5i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q020o42j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141103-q020o42j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-501
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q020o42j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.55it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.91it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 114.59it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.71it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 114.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 115.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 116.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 117.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 118.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 119.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 119.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 119.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 119.79it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 119.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 119.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 119.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.014 MB of 0.023 MB uploadedwandb: / 0.014 MB of 0.023 MB uploadedwandb: - 0.014 MB of 0.023 MB uploadedwandb: \ 0.014 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.745
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.40914
wandb: sub_train_loss 0.23965
wandb:       test_acc 0.369
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run helpful-sweep-501 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/q020o42j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141103-q020o42j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z053rbgm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141121-z053rbgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-502
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z053rbgm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.88it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.64it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 116.87it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 115.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 117.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 117.00it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 116.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 115.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 115.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 115.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 114.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 114.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 114.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 114.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 116.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 116.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.40528
wandb: sub_train_loss 0.11006
wandb:       test_acc 0.373
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run vital-sweep-502 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z053rbgm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141121-z053rbgm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a3xqk4rl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141136-a3xqk4rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-503
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a3xqk4rl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.24it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.14it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.66it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.91it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 112.12it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 111.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 111.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 110.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 108.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 108.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 108.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 107.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 105.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 104.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 103.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 103.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 105.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.50971
wandb: sub_train_loss 0.16803
wandb:       test_acc 0.478
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run honest-sweep-503 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a3xqk4rl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141136-a3xqk4rl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7s2tmnee with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141152-7s2tmnee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-504
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7s2tmnee
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.77it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.40it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.01it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 114.99it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 113.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 114.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 113.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 112.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 111.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 112.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 112.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 112.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 111.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 108.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 107.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 111.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.65963
wandb: sub_train_loss 0.12989
wandb:       test_acc 0.631
wandb:      valid_acc 0.634
wandb: 
wandb: üöÄ View run eager-sweep-504 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7s2tmnee
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141152-7s2tmnee/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9n7gxvmn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141207-9n7gxvmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-505
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9n7gxvmn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.11it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.95it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.02it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.10it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 118.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 117.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 115.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 116.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 113.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 113.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 112.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 112.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 111.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 111.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.73896
wandb: sub_train_loss 0.14093
wandb:       test_acc 0.747
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run magic-sweep-505 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9n7gxvmn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141207-9n7gxvmn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d2zsnl4m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141223-d2zsnl4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-506
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d2zsnl4m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.99it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 97.69it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 102.68it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 104.34it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 104.31it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 106.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 110.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 112.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 112.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 112.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 113.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 113.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 113.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 114.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 115.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 116.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 115.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 111.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.778
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.63346
wandb: sub_train_loss 0.18514
wandb:       test_acc 0.665
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run colorful-sweep-506 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d2zsnl4m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141223-d2zsnl4m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aiape4se with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141237-aiape4se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-507
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aiape4se
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.72it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 112.99it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 114.04it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 114.96it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 116.36it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 117.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 117.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 118.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 117.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 118.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 118.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 117.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 117.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 117.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 117.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 117.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.70411
wandb: sub_train_loss 0.12222
wandb:       test_acc 0.725
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run resilient-sweep-507 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aiape4se
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141237-aiape4se/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dfcy6tlr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141253-dfcy6tlr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-508
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfcy6tlr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.49it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 109.42it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 109.61it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 108.23it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 106.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 107.59it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 108.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 109.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 109.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 111.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 110.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 110.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 110.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 107.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 106.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 107.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 108.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.5793
wandb: sub_train_loss 0.40445
wandb:       test_acc 0.593
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run astral-sweep-508 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfcy6tlr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141253-dfcy6tlr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 05qcvxtk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141308-05qcvxtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-509
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/05qcvxtk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.60it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 111.28it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.53it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.02it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 113.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 114.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 114.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 113.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 112.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 112.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 113.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 113.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 114.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 114.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.68646
wandb: sub_train_loss 0.3857
wandb:       test_acc 0.69
wandb:      valid_acc 0.704
wandb: 
wandb: üöÄ View run major-sweep-509 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/05qcvxtk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141308-05qcvxtk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pxn2tzze with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141324-pxn2tzze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-510
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pxn2tzze
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.72it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.92it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.81it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.89it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 119.03it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 119.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 118.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 118.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 119.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 119.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 119.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 118.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 118.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 116.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 114.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 114.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.53157
wandb: sub_train_loss 1.87502
wandb:       test_acc 0.516
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run morning-sweep-510 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pxn2tzze
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141324-pxn2tzze/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gyr1xln8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141339-gyr1xln8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-511
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gyr1xln8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.21it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 106.60it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 104.56it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 105.59it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 108.18it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 108.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 107.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 108.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 109.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 109.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 111.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 112.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 113.52it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 114.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 114.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 114.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 112.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.55916
wandb: sub_train_loss 1.06079
wandb:       test_acc 0.587
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run revived-sweep-511 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gyr1xln8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141339-gyr1xln8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d9hfy2qw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141354-d9hfy2qw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-512
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d9hfy2qw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.81it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 104.27it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 107.19it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 108.08it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 107.52it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 107.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 109.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 110.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 110.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 108.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 107.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 96.53it/s]  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 98.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 97.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 94.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 95.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 99.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 103.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.812
wandb: best_valid_acc 0.82
wandb:  sub_train_acc 0.77669
wandb: sub_train_loss 0.20133
wandb:       test_acc 0.785
wandb:      valid_acc 0.802
wandb: 
wandb: üöÄ View run generous-sweep-512 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/d9hfy2qw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141354-d9hfy2qw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h899ufru with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141410-h899ufru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-513
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h899ufru
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 86.00it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.87it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 87.13it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 85.53it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 87.08it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 88.09it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 88.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 88.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 89.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:01<00:01, 90.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:01<00:01, 90.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 89.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 89.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 90.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 91.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 92.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 92.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 93.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:02<00:00, 93.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 93.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.486
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.21641
wandb: sub_train_loss 0.0
wandb:       test_acc 0.181
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run genial-sweep-513 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h899ufru
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141410-h899ufru/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l4filodx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141426-l4filodx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-514
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l4filodx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 90.03it/s] 10%|‚ñà         | 20/200 [00:00<00:02, 89.60it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 88.63it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 88.00it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 87.50it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 86.74it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 85.57it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 85.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 84.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 84.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 84.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 84.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 83.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 83.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 84.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 85.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 86.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 87.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:02<00:00, 86.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:02<00:00, 90.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 93.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 87.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.506
wandb: best_valid_acc 0.532
wandb:  sub_train_acc 0.27981
wandb: sub_train_loss 0.0
wandb:       test_acc 0.195
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run fast-sweep-514 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l4filodx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141426-l4filodx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7rm1rio0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141441-7rm1rio0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-515
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7rm1rio0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 8/200 [00:00<00:02, 79.61it/s]  8%|‚ñä         | 17/200 [00:00<00:02, 80.60it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:02, 82.25it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 83.07it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 83.88it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 83.47it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 83.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 84.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 84.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:01<00:01, 73.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:01<00:01, 75.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:01, 76.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:01, 77.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 78.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 78.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 77.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 78.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 79.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:02<00:00, 79.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:02<00:00, 83.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:02<00:00, 88.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:02<00:00, 92.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 82.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.637
wandb: best_valid_acc 0.674
wandb:  sub_train_acc 0.51808
wandb: sub_train_loss 0.15596
wandb:       test_acc 0.509
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run laced-sweep-515 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7rm1rio0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141441-7rm1rio0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yeef0x4m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141456-yeef0x4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-516
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yeef0x4m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.82it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.74it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.66it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 97.51it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 98.18it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 98.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 99.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 98.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 96.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 96.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 97.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 96.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 95.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 94.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 92.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 92.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 92.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 92.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 93.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.612
wandb: best_valid_acc 0.654
wandb:  sub_train_acc 0.33742
wandb: sub_train_loss 0.13408
wandb:       test_acc 0.25
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run effortless-sweep-516 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yeef0x4m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141456-yeef0x4m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u8fnp5wa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141511-u8fnp5wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-517
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8fnp5wa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 89.80it/s] 10%|‚ñâ         | 19/200 [00:00<00:02, 87.51it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 87.77it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 82.03it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 78.59it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 78.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 81.38it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 84.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 86.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:01<00:01, 90.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:01, 87.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:01, 85.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 87.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 89.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 92.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 95.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 96.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 98.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 96.55it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 95.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.62
wandb: best_valid_acc 0.62
wandb:  sub_train_acc 0.53999
wandb: sub_train_loss 0.10004
wandb:       test_acc 0.506
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run eternal-sweep-517 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u8fnp5wa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141511-u8fnp5wa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5qrjttof with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141532-5qrjttof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-518
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5qrjttof
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.04it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 93.95it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 92.47it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.61it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.51it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 95.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 93.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 94.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 95.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 96.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 96.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 96.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 94.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 94.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 94.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 93.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 92.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 92.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.699
wandb: best_valid_acc 0.732
wandb:  sub_train_acc 0.38175
wandb: sub_train_loss 0.39414
wandb:       test_acc 0.275
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run snowy-sweep-518 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5qrjttof
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141532-5qrjttof/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 02ybw6zo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141547-02ybw6zo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-519
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/02ybw6zo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.83it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.57it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 95.74it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.49it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 92.63it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 92.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 91.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 92.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 93.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 93.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 94.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 95.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 95.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 95.75it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 96.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 96.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 97.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 98.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.677
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.63848
wandb: sub_train_loss 0.09768
wandb:       test_acc 0.609
wandb:      valid_acc 0.644
wandb: 
wandb: üöÄ View run amber-sweep-519 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/02ybw6zo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141547-02ybw6zo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ko62ezq8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141603-ko62ezq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-520
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ko62ezq8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.06it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.10it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 99.22it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 99.77it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 100.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 100.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 100.39it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 100.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 100.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 101.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 100.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 100.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 100.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 100.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 100.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 101.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 100.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 100.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 100.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.69793
wandb: sub_train_loss 0.09825
wandb:       test_acc 0.713
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run atomic-sweep-520 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ko62ezq8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141603-ko62ezq8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0nbszdoy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141618-0nbszdoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-521
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0nbszdoy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.81it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 93.89it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.16it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 95.50it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 97.58it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 97.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 98.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 99.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:01, 100.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:00, 100.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 100.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 100.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 100.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 100.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 99.18it/s]  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 99.63it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 99.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 99.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.48735
wandb: sub_train_loss 0.4997
wandb:       test_acc 0.502
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run resilient-sweep-521 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0nbszdoy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141618-0nbszdoy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wf8e96w3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141634-wf8e96w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-522
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wf8e96w3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 92.45it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 91.10it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 92.88it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.99it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.67it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 95.03it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 95.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 96.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 97.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 97.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 97.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 97.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 98.15it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 98.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 98.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 98.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 99.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 99.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.56525
wandb: sub_train_loss 0.56202
wandb:       test_acc 0.529
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run valiant-sweep-522 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wf8e96w3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141634-wf8e96w3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5udvamc3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141650-5udvamc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-523
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5udvamc3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 84.58it/s] 10%|‚ñâ         | 19/200 [00:00<00:02, 89.04it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 90.48it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 93.10it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.97it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 95.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 95.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 95.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 96.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 96.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 97.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 97.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 98.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 98.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 98.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 98.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 97.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 97.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 95.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.25932
wandb: sub_train_loss 1.28661
wandb:       test_acc 0.182
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run dulcet-sweep-523 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5udvamc3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141650-5udvamc3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 74djgjrv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141704-74djgjrv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-524
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/74djgjrv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.54it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.86it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.64it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 96.57it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 97.52it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.31it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 97.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 94.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 93.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 93.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 94.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 93.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 93.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 92.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 91.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 91.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 91.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 92.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.54182
wandb: sub_train_loss 1.17925
wandb:       test_acc 0.54
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run spring-sweep-524 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/74djgjrv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141704-74djgjrv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: huj2a8gz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141720-huj2a8gz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-525
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/huj2a8gz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.32it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.33it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 99.78it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 99.08it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 99.17it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 99.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 99.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 97.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 96.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:00, 97.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 98.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 98.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 99.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 99.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 99.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 99.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 99.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 99.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 98.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.43511
wandb: sub_train_loss 1.32332
wandb:       test_acc 0.448
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run fearless-sweep-525 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/huj2a8gz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141720-huj2a8gz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6lcjidtv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141735-6lcjidtv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-526
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6lcjidtv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.94it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.69it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.63it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 90.66it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 90.29it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 90.11it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 90.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 90.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 90.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 90.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 90.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 89.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 89.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 89.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 89.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 89.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 89.53it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 89.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:02<00:00, 89.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:02<00:00, 89.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.54663
wandb: sub_train_loss 0.79334
wandb:       test_acc 0.539
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run solar-sweep-526 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6lcjidtv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141735-6lcjidtv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e2k1qqq2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141751-e2k1qqq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-527
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e2k1qqq2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.05it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.72it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 89.43it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 90.31it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 90.69it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 89.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 90.00it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 90.58it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 92.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 94.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 95.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 95.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 95.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 95.89it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 96.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 96.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 96.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 96.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:02<00:00, 96.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 96.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà
wandb:       test_acc ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.752
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.43597
wandb: sub_train_loss 4.73751
wandb:       test_acc 0.432
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run fancy-sweep-527 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e2k1qqq2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141751-e2k1qqq2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6qgzwx1q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141806-6qgzwx1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-528
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6qgzwx1q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.93it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 88.17it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 91.34it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 92.84it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 92.87it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 93.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 94.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 94.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 93.63it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 93.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 93.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 93.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 94.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 94.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 93.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 93.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 93.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 93.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:02<00:00, 91.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 91.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.41923
wandb: sub_train_loss 1.01118
wandb:       test_acc 0.441
wandb:      valid_acc 0.446
wandb: 
wandb: üöÄ View run vital-sweep-528 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6qgzwx1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141806-6qgzwx1q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i55jzu4x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141825-i55jzu4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-529
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i55jzu4x
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.79it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.95it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.71it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.35it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 150.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 149.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 149.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 148.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 143.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 140.25it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 139.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 139.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 139.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 141.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 142.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 145.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 146.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 148.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.526
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.3778
wandb: sub_train_loss 0.0
wandb:       test_acc 0.398
wandb:      valid_acc 0.41
wandb: 
wandb: üöÄ View run glamorous-sweep-529 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i55jzu4x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141825-i55jzu4x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pmtqndvs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141841-pmtqndvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-530
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pmtqndvs
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.33it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.96it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.60it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 146.62it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.50it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 148.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 147.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 148.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 147.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 147.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 144.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 141.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 138.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 136.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 133.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 130.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 129.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 129.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 131.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 130.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.52
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.38556
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run dauntless-sweep-530 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pmtqndvs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141841-pmtqndvs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: klvrbbds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141856-klvrbbds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-531
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/klvrbbds
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.36it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.89it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 141.85it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 141.63it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 141.54it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.79it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 141.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 143.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 144.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 144.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 145.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 146.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 147.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 148.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 147.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 148.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 150.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 150.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 150.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.641
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.39083
wandb: sub_train_loss 0.0
wandb:       test_acc 0.353
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run vital-sweep-531 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/klvrbbds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141856-klvrbbds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w8d9hvke with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141912-w8d9hvke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-532
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w8d9hvke
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.97it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.62it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.89it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.45it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 146.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 143.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 146.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 148.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 149.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 150.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 151.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 151.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 149.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 148.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 146.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 146.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 145.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 147.52it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 147.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.535
wandb: best_valid_acc 0.574
wandb:  sub_train_acc 0.53198
wandb: sub_train_loss 0.0
wandb:       test_acc 0.494
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run dandy-sweep-532 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w8d9hvke
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141912-w8d9hvke/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 26x1ww06 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141928-26x1ww06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-533
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/26x1ww06
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.80it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.40it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 137.88it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 139.24it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 139.85it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 139.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 139.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 138.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 137.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 137.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 137.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 137.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 137.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 136.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 136.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 136.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 136.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 136.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 135.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 135.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 135.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.40635
wandb: sub_train_loss 0.0
wandb:       test_acc 0.331
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run dark-sweep-533 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/26x1ww06
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141928-26x1ww06/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u2h8368z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141942-u2h8368z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-534
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u2h8368z
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.17it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 149.18it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 150.90it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 152.62it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 153.05it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 151.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 152.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 152.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 152.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 153.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 153.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 153.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 151.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 149.98it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 150.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 149.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 150.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 150.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.495
wandb: sub_train_loss 0.0
wandb:       test_acc 0.486
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run rare-sweep-534 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u2h8368z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141942-u2h8368z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tukz026s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_141958-tukz026s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-535
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tukz026s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.18it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.04it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.42it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.02it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 153.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 152.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 152.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 150.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 149.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 147.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 146.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 147.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 146.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 146.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 147.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 147.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 147.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.746
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.66831
wandb: sub_train_loss 0.00307
wandb:       test_acc 0.694
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run sleek-sweep-535 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tukz026s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_141958-tukz026s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 45stmryf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142014-45stmryf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-536
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/45stmryf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.25it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.74it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.44it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.51it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 135.60it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 135.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 135.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 135.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 136.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 136.25it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 135.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 135.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 139.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 139.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 140.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 142.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 146.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 148.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 149.72it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 150.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.57113
wandb: sub_train_loss 0.41283
wandb:       test_acc 0.522
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run sweepy-sweep-536 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/45stmryf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142014-45stmryf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: as05dfyv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142029-as05dfyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-537
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/as05dfyv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 109.77it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 117.58it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 122.35it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 124.92it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 127.86it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 126.93it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 127.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 128.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 128.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 128.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 127.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 128.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 132.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 135.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 137.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 138.07it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 138.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 138.43it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 138.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 139.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñà‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.61941
wandb: sub_train_loss 0.46614
wandb:       test_acc 0.663
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run soft-sweep-537 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/as05dfyv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142029-as05dfyv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mpg277dn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142044-mpg277dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-538
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mpg277dn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.37it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.39it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 149.06it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.49it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 148.90it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 148.15it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 146.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 145.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 145.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 147.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 147.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 147.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 144.40it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 141.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 139.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 136.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 138.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 139.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 140.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.782
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.61242
wandb: sub_train_loss 0.84491
wandb:       test_acc 0.591
wandb:      valid_acc 0.612
wandb: 
wandb: üöÄ View run vital-sweep-538 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mpg277dn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142044-mpg277dn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iyzudtto with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142100-iyzudtto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-539
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iyzudtto
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.71it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.57it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 146.08it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 148.79it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 149.95it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 151.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 149.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 147.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 147.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 145.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 145.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 144.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 143.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 143.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 142.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 141.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 142.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 142.49it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 142.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.6819
wandb: sub_train_loss 0.02229
wandb:       test_acc 0.69
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run pretty-sweep-539 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/iyzudtto
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142100-iyzudtto/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hjo4bpfy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142115-hjo4bpfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-540
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hjo4bpfy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.08it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.59it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 148.53it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 147.07it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 149.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 150.54it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 151.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 152.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 150.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 147.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 148.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 149.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 150.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 148.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 145.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 144.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 144.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 142.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 131.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.62357
wandb: sub_train_loss 0.06984
wandb:       test_acc 0.651
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run fresh-sweep-540 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hjo4bpfy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142115-hjo4bpfy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1onrz2nt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142131-1onrz2nt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-541
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1onrz2nt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.36it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.19it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 138.16it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 129.14it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 132.81it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 137.41it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 138.53it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 141.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 143.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 144.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 146.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 148.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 147.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 145.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 143.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 143.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 142.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 142.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 142.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 142.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñÅ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.57357
wandb: sub_train_loss 1.18957
wandb:       test_acc 0.571
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run stoic-sweep-541 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1onrz2nt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142131-1onrz2nt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lyztgfpn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142146-lyztgfpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-542
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lyztgfpn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.80it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.01it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 138.07it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 139.93it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 141.82it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 144.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 145.01it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 141.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 139.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 138.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 138.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 136.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 136.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 136.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 136.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 136.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 139.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 141.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 142.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 141.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.755
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.7244
wandb: sub_train_loss 0.08005
wandb:       test_acc 0.75
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run ethereal-sweep-542 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lyztgfpn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142146-lyztgfpn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ohbmop6k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142201-ohbmop6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-543
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ohbmop6k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.35it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.69it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.04it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.67it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.90it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 124.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 118.09it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 121.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 124.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 124.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 123.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 125.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 126.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 129.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 131.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 131.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 137.15it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 139.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 141.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 142.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 143.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.769
wandb: best_valid_acc 0.802
wandb:  sub_train_acc 0.69919
wandb: sub_train_loss 0.0629
wandb:       test_acc 0.709
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run whole-sweep-543 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ohbmop6k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142201-ohbmop6k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qxuflufp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142217-qxuflufp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-544
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qxuflufp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.58it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.02it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.32it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.43it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.91it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 134.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 135.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 135.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 136.52it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 136.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 136.84it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 138.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 138.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 138.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 138.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 137.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 137.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 137.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 136.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 137.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.778
wandb: best_valid_acc 0.806
wandb:  sub_train_acc 0.77745
wandb: sub_train_loss 0.51242
wandb:       test_acc 0.779
wandb:      valid_acc 0.802
wandb: 
wandb: üöÄ View run expert-sweep-544 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qxuflufp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142217-qxuflufp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cgkd3mrl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142232-cgkd3mrl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-545
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cgkd3mrl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.76it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 111.33it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.62it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 112.15it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 112.97it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 113.80it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 114.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 114.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 115.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 113.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 114.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 115.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 115.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 115.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 116.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 116.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 116.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 114.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 108.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 108.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 105.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 105.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 106.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 107.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 108.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.513
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.29467
wandb: sub_train_loss 0.0
wandb:       test_acc 0.21
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run earthy-sweep-545 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/cgkd3mrl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142232-cgkd3mrl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t0h8e43j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142247-t0h8e43j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-546
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t0h8e43j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 112.68it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.59it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 109.20it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 110.57it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 110.86it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 110.38it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 109.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 108.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 107.24it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 106.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 103.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 102.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 104.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 105.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 106.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 108.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 108.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 107.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 109.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 108.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 107.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 107.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 106.88it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 106.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 106.82it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 106.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 107.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñÉ‚ñÇ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.419
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.24106
wandb: sub_train_loss 0.0
wandb:       test_acc 0.18
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run sunny-sweep-546 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t0h8e43j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142247-t0h8e43j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2krgik41 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142303-2krgik41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-547
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2krgik41
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 105.65it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 108.80it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 109.96it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 98.03it/s]  19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 99.79it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 101.66it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 99.58it/s]  30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 90.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 89.25it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 91.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 93.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 90.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 86.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 86.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 91.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 99.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 104.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:02<00:00, 108.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 110.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 111.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 114.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 115.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 116.77it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 117.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 118.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 102.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.43044
wandb: sub_train_loss 7e-05
wandb:       test_acc 0.428
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run cool-sweep-547 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2krgik41
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142303-2krgik41/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kvar807a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142318-kvar807a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-548
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kvar807a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.58it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.11it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.28it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 119.52it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 118.58it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 118.41it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 116.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 108.49it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 105.75it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 101.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 99.07it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 93.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 88.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 90.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 94.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 99.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:01, 102.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 104.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 106.69it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 108.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 109.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 109.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 110.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 110.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 110.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 106.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñá‚ñà‚ñÉ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñÇ‚ñá‚ñà‚ñÅ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñá‚ñá‚ñà‚ñÇ‚ñá‚ñà‚ñÅ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.584
wandb: best_valid_acc 0.574
wandb:  sub_train_acc 0.3923
wandb: sub_train_loss 0.0
wandb:       test_acc 0.329
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run toasty-sweep-548 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kvar807a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142318-kvar807a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r8rf6dxo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142333-r8rf6dxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-549
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r8rf6dxo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.76it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 106.19it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 108.22it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 110.01it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 111.59it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 112.57it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 113.22it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 112.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 113.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 112.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 110.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 108.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 107.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 107.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 106.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 106.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 106.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 107.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 108.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 108.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 107.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 106.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 106.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 106.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 105.54it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 104.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 108.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.734
wandb:  sub_train_acc 0.43069
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.354
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run icy-sweep-549 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r8rf6dxo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142333-r8rf6dxo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6u06wzpl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142349-6u06wzpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-550
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6u06wzpl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.64it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.07it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 87.84it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 94.64it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 98.59it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 102.79it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 104.00it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 106.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 108.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 110.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 109.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 111.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 112.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 113.72it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 111.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 108.94it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 107.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 104.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 104.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 103.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 102.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 101.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 103.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 107.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 110.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 113.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 106.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.3431
wandb: sub_train_loss 1.6026
wandb:       test_acc 0.233
wandb:      valid_acc 0.232
wandb: 
wandb: üöÄ View run peach-sweep-550 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6u06wzpl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142349-6u06wzpl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5wjyi8ym with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142405-5wjyi8ym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-551
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5wjyi8ym
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 105.20it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 104.90it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 108.08it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 109.33it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 109.07it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 108.74it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 110.77it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 112.26it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 113.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 115.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 116.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 117.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 117.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 117.95it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 118.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 118.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 118.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 118.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 118.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 117.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 116.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 115.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 115.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 116.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 116.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.58741
wandb: sub_train_loss 0.189
wandb:       test_acc 0.639
wandb:      valid_acc 0.656
wandb: 
wandb: üöÄ View run logical-sweep-551 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5wjyi8ym
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142405-5wjyi8ym/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e620uevf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142421-e620uevf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-552
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e620uevf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.17it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.74it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.17it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.71it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.26it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 88.81it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 86.02it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 83.78it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 82.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 84.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 84.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 86.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 89.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 94.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 97.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 99.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 100.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 102.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:02<00:01, 103.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:00, 105.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 107.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 109.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 110.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 110.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 109.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 107.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 109.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 109.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.83it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñÑ‚ñá‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñá‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.65045
wandb: sub_train_loss 0.17976
wandb:       test_acc 0.681
wandb:      valid_acc 0.678
wandb: 
wandb: üöÄ View run feasible-sweep-552 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e620uevf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142421-e620uevf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dlihznp2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142436-dlihznp2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-553
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dlihznp2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 107.82it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 102.95it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 101.68it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 101.05it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 100.31it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 99.61it/s]  26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 101.48it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 101.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 102.49it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 101.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 101.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 98.76it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 92.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 97.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 99.17it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 98.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 97.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:01, 98.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:00, 102.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 103.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 105.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 107.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 107.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 108.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 107.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 108.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 108.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 102.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.746
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.69503
wandb: sub_train_loss 0.09992
wandb:       test_acc 0.698
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run denim-sweep-553 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dlihznp2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142436-dlihznp2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jvc1mvcn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142452-jvc1mvcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-554
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jvc1mvcn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.12it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 106.31it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 107.55it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 107.45it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 100.06it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 100.85it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 104.12it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 105.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 107.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 108.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 109.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 110.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 111.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 111.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 111.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 113.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 113.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 113.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 113.80it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 113.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 112.59it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 112.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 112.63it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 112.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 112.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.61916
wandb: sub_train_loss 0.0341
wandb:       test_acc 0.571
wandb:      valid_acc 0.594
wandb: 
wandb: üöÄ View run proud-sweep-554 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jvc1mvcn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142452-jvc1mvcn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: reb2dtlt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142507-reb2dtlt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-555
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/reb2dtlt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.64it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 100.48it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 103.55it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 105.35it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 105.72it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 106.47it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 104.80it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 105.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 106.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 107.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 105.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 104.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 105.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 106.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 105.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 105.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 105.56it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 104.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 102.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 101.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 99.19it/s]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 100.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 101.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 102.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 104.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 105.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 106.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 104.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.68575
wandb: sub_train_loss 0.20993
wandb:       test_acc 0.709
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run sweepy-sweep-555 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/reb2dtlt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142507-reb2dtlt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: au3p0jam with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142523-au3p0jam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-556
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/au3p0jam
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.94it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 117.09it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 119.14it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 120.29it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 121.44it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 120.71it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 121.10it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 120.64it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 120.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 121.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 121.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 121.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 121.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 121.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 121.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 122.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 122.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 122.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 122.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 122.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 122.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 122.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 120.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.31587
wandb: sub_train_loss 0.62794
wandb:       test_acc 0.227
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run fine-sweep-556 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/au3p0jam
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142523-au3p0jam/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xol3ecq3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142537-xol3ecq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-557
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xol3ecq3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 8/300 [00:00<00:03, 78.29it/s]  6%|‚ñå         | 17/300 [00:00<00:03, 81.41it/s]  9%|‚ñä         | 26/300 [00:00<00:03, 81.46it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:03, 81.02it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:03, 84.25it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 87.43it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 90.95it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 94.28it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 97.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 100.82it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 103.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 104.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 106.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 107.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 107.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 108.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 108.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 108.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 108.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 108.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 107.88it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 107.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 107.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 106.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 105.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 101.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 94.94it/s]  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 95.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 100.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.67318
wandb: sub_train_loss 0.0925
wandb:       test_acc 0.698
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run rich-sweep-557 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xol3ecq3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142537-xol3ecq3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gh2dhito with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142553-gh2dhito
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-558
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gh2dhito
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 107.12it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 110.89it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 112.52it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 114.51it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:03, 67.70it/s]  24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 78.71it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 87.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:01<00:02, 95.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:01, 100.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 104.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 107.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 110.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 112.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 113.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 114.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 113.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 112.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 112.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 112.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 111.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 110.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 110.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 110.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 110.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 107.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 104.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.70148
wandb: sub_train_loss 0.05276
wandb:       test_acc 0.716
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run radiant-sweep-558 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gh2dhito
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142553-gh2dhito/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xg3o4gui with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142609-xg3o4gui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-559
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xg3o4gui
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 104.67it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 102.13it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 103.61it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 104.89it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 105.17it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 105.81it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 101.69it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 97.26it/s]  33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:02, 99.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 99.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 100.74it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 104.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 107.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 109.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 111.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 113.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 115.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 115.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 116.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 116.44it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 117.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 117.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 117.73it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 118.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 118.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.52046
wandb: sub_train_loss 0.76645
wandb:       test_acc 0.532
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run polished-sweep-559 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xg3o4gui
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142609-xg3o4gui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9lj2mz2h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142628-9lj2mz2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-560
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9lj2mz2h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.95it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.48it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 114.03it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 115.04it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 114.31it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 112.52it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 112.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 111.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 111.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 111.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 111.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 110.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 111.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 111.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 112.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 112.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 112.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 113.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 113.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 114.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 114.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 114.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 113.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 110.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 105.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.81
wandb:  sub_train_acc 0.60709
wandb: sub_train_loss 3.03222
wandb:       test_acc 0.609
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run vocal-sweep-560 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9lj2mz2h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142628-9lj2mz2h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dwxbwi0u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142646-dwxbwi0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-561
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dwxbwi0u
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 93.10it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.14it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 87.85it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:03, 81.46it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:03, 77.53it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:03, 79.51it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 78.17it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 76.52it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:01<00:02, 75.00it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:01<00:02, 78.96it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 84.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:02, 87.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 91.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 94.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 96.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 97.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 97.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 96.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:02<00:01, 96.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 95.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 93.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 91.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 89.84it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 90.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 90.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 91.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 93.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:03<00:00, 94.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 95.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:03<00:00, 96.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.448
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.23949
wandb: sub_train_loss 0.0
wandb:       test_acc 0.183
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run deft-sweep-561 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dwxbwi0u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142646-dwxbwi0u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hghr0zmx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142702-hghr0zmx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-562
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hghr0zmx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.38it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 90.88it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.01it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 89.06it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 87.32it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 87.08it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 87.08it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 89.12it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 91.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:01<00:02, 92.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 93.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 95.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 95.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 95.31it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 95.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 96.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 96.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 96.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:02<00:01, 95.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:02<00:01, 94.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:00, 93.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 92.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 91.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 92.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 92.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 94.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 95.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 96.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 96.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 97.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñÅ‚ñÉ‚ñà‚ñá‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.541
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.21819
wandb: sub_train_loss 0.0
wandb:       test_acc 0.18
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run cosmic-sweep-562 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hghr0zmx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142702-hghr0zmx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tl5lipww with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142718-tl5lipww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-563
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tl5lipww
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 96.34it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.86it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 97.17it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.55it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 97.75it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 97.96it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 98.50it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 98.82it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 97.75it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 96.59it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 96.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 96.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 97.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 98.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 98.15it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 98.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 99.59it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 99.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 100.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 101.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 100.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 101.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 101.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 100.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 98.61it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 98.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 99.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 97.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.45894
wandb: sub_train_loss 1.70559
wandb:       test_acc 0.429
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run iconic-sweep-563 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tl5lipww
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142718-tl5lipww/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yb9j8mdw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142733-yb9j8mdw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-564
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yb9j8mdw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 88.50it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 91.36it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 92.71it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 93.11it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 92.98it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 93.40it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 93.53it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 93.58it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 94.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 94.04it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:02, 93.70it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 92.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 88.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 88.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 91.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 93.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 95.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 96.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:02<00:01, 97.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 98.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 98.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 99.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 100.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 100.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 100.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 99.81it/s]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 100.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 100.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 100.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.00it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.66
wandb: best_valid_acc 0.658
wandb:  sub_train_acc 0.26125
wandb: sub_train_loss 0.12509
wandb:       test_acc 0.245
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run desert-sweep-564 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yb9j8mdw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142733-yb9j8mdw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 05b33u7q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142752-05b33u7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-565
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/05b33u7q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 84.88it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 86.78it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 86.75it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 86.64it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 88.78it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 88.53it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 87.49it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 86.31it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 85.43it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:01<00:02, 84.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 83.89it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:02, 83.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:02, 85.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:02, 82.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 82.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 84.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 85.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 85.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:02<00:01, 86.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:02<00:01, 86.99it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 87.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 88.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:01, 88.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 87.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 87.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 88.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 88.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 89.22it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:03<00:00, 89.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:03<00:00, 90.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 90.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 89.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 87.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÉ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.57833
wandb: sub_train_loss 0.2573
wandb:       test_acc 0.617
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run woven-sweep-565 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/05b33u7q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142752-05b33u7q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3zq1ox3z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142808-3zq1ox3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-566
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3zq1ox3z
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.84it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.00it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 84.00it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:03, 72.26it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:03, 71.71it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:03, 73.97it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:03, 77.62it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 77.56it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:01<00:02, 78.27it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:01<00:02, 78.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 77.92it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:02, 78.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 74.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:02, 72.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:02, 74.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:02, 75.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:02, 75.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 76.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:02<00:01, 75.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:02<00:01, 77.70it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:02<00:01, 78.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:02<00:01, 80.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 80.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 79.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:01, 78.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:01, 78.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 77.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:03<00:00, 76.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:03<00:00, 78.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:03<00:00, 81.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:03<00:00, 86.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:03<00:00, 91.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 93.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 95.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 80.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.51078
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.479
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run misunderstood-sweep-566 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3zq1ox3z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142808-3zq1ox3z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yuhqjkmv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142824-yuhqjkmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-567
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yuhqjkmv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.60it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 90.82it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 91.75it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.78it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.32it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.27it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 92.03it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 92.22it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 91.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:02, 89.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 87.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 87.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 87.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 87.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 88.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 89.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:02<00:01, 89.57it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 89.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 90.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 88.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 87.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 86.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 85.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 85.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 84.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:03<00:00, 84.00it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:03<00:00, 83.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 83.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 83.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 88.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.70467
wandb: sub_train_loss 0.4636
wandb:       test_acc 0.717
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run drawn-sweep-567 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yuhqjkmv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142824-yuhqjkmv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rcfc1g4r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142839-rcfc1g4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-568
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rcfc1g4r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.69it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.98it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 98.33it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.94it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 95.91it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.41it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 94.76it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 93.85it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 94.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 93.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 92.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 92.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 92.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 92.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 91.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 91.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 90.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 88.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 85.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 85.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 84.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 87.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 90.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 91.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 93.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 93.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 94.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:03<00:00, 94.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 94.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 94.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.59223
wandb: sub_train_loss 0.56863
wandb:       test_acc 0.584
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run sparkling-sweep-568 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rcfc1g4r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142839-rcfc1g4r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9el4zqep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142854-9el4zqep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-569
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9el4zqep
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.89it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 98.49it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 98.95it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 98.74it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 98.20it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 98.71it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 99.29it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 99.70it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 99.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:01, 99.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 99.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 99.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 98.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 98.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 98.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 97.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 98.39it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 99.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:01, 99.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 99.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 99.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 91.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 83.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 81.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 81.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 83.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 86.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 88.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 89.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.57423
wandb: sub_train_loss 2.58529
wandb:       test_acc 0.522
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run eager-sweep-569 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9el4zqep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142854-9el4zqep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jzj1p8ay with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142910-jzj1p8ay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-570
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jzj1p8ay
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.10it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.68it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 94.03it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.67it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 90.77it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 90.37it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 90.52it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.51it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 90.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:02, 85.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:02, 84.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 84.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 84.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 83.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 83.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 82.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:02<00:01, 80.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 80.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 82.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:01, 85.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 88.07it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 90.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 91.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 93.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 93.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:03<00:00, 93.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:03<00:00, 93.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 94.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.761
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.58949
wandb: sub_train_loss 0.32305
wandb:       test_acc 0.623
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run leafy-sweep-570 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jzj1p8ay
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142910-jzj1p8ay/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ke4ok3b7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142925-ke4ok3b7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-571
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ke4ok3b7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 86.64it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 86.63it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 87.98it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 83.12it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:03, 80.53it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:03, 78.18it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:03, 78.30it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:03, 76.36it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 78.52it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:01<00:02, 80.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:01<00:02, 81.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:02, 82.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 82.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:02, 83.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 83.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 85.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 85.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 85.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:02<00:01, 86.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:02<00:01, 86.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:02<00:01, 85.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 85.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 83.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:01, 82.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 82.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 81.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 81.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:03<00:00, 79.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:03<00:00, 78.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:03<00:00, 78.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:03<00:00, 76.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 76.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 75.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 77.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 81.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá
wandb:      valid_acc ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.61505
wandb: sub_train_loss 0.43394
wandb:       test_acc 0.651
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run azure-sweep-571 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ke4ok3b7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142925-ke4ok3b7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t7n0ouf9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142941-t7n0ouf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-572
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t7n0ouf9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 89.91it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 89.88it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 90.76it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 90.27it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 89.45it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 89.75it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 89.82it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 89.38it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 87.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:01<00:02, 87.28it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:02, 86.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:02, 87.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:02, 87.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 87.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 88.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 89.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 90.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 90.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:02<00:01, 90.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 90.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 90.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 91.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 92.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 92.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 92.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 91.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 91.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 91.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 92.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 91.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.65933
wandb: sub_train_loss 0.4241
wandb:       test_acc 0.669
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run fancy-sweep-572 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/t7n0ouf9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142941-t7n0ouf9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 20e24pzv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_142957-20e24pzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-573
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/20e24pzv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 93.34it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 93.05it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.83it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 93.08it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 94.89it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.54it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 96.70it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 97.48it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 97.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 98.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 96.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 95.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 94.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 93.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 93.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 93.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 94.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 93.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 92.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 92.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 91.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 91.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 91.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 91.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 91.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 92.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 93.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 94.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 93.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.767
wandb: best_valid_acc 0.802
wandb:  sub_train_acc 0.71187
wandb: sub_train_loss 0.13865
wandb:       test_acc 0.722
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run divine-sweep-573 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/20e24pzv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_142957-20e24pzv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l0qcybvq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143011-l0qcybvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-574
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0qcybvq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.17it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 90.39it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.00it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 94.99it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 96.33it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 96.22it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 96.18it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 97.51it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 98.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:01, 98.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 99.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 99.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 99.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 99.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 99.19it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 99.12it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 95.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 93.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 93.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 93.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 93.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 93.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 93.36it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 93.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 93.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 93.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 94.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 93.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:03<00:00, 93.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.39316
wandb: sub_train_loss 1.03361
wandb:       test_acc 0.353
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run serene-sweep-574 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/l0qcybvq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143011-l0qcybvq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: axzb807y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143027-axzb807y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-575
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/axzb807y
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 87.58it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 84.86it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 82.02it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 81.79it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:03, 83.54it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 86.16it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 88.20it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 89.68it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 90.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:01<00:02, 90.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 90.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:02, 91.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 91.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 91.08it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 90.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 89.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 88.95it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 89.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:02<00:01, 89.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 88.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 88.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:01, 88.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 86.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 86.69it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 88.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 88.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 88.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:03<00:00, 87.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:03<00:00, 87.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 86.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 85.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 87.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.798
wandb: best_valid_acc 0.814
wandb:  sub_train_acc 0.31815
wandb: sub_train_loss 1.05216
wandb:       test_acc 0.346
wandb:      valid_acc 0.344
wandb: 
wandb: üöÄ View run driven-sweep-575 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/axzb807y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143027-axzb807y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ssu7obaw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143042-ssu7obaw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-576
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ssu7obaw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.80it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.82it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.87it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.22it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.17it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.74it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 92.99it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 92.80it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 93.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 93.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 93.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 93.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 94.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 94.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 93.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 91.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 91.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 90.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 89.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 89.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:01, 89.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 90.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 89.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 88.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 86.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 85.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 83.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:03<00:00, 83.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 83.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 82.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 83.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 89.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.46229
wandb: sub_train_loss 1.45307
wandb:       test_acc 0.491
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run cosmic-sweep-576 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ssu7obaw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143042-ssu7obaw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ojjd8ezm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143057-ojjd8ezm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-577
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojjd8ezm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.87it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.07it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 179.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 181.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 181.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 181.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 181.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 181.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 179.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 174.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.453
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.42471
wandb: sub_train_loss 0.00608
wandb:       test_acc 0.273
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run cosmic-sweep-577 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojjd8ezm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143057-ojjd8ezm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ltqtdyew with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143113-ltqtdyew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-578
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ltqtdyew
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.00it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 163.15it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 164.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 167.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 166.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 171.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 176.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 179.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 181.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 182.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.425
wandb: best_valid_acc 0.474
wandb:  sub_train_acc 0.39666
wandb: sub_train_loss 0.00876
wandb:       test_acc 0.403
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run electric-sweep-578 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ltqtdyew
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143113-ltqtdyew/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8lqkpnx3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143128-8lqkpnx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-579
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8lqkpnx3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.68it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 183.79it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 179.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 178.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 183.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 181.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 155.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 147.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 153.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 157.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.41822
wandb: sub_train_loss 0.00896
wandb:       test_acc 0.489
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run major-sweep-579 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8lqkpnx3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143128-8lqkpnx3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lbagof3s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143150-lbagof3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-580
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbagof3s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 177.99it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 179.05it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 180.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 182.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 184.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 184.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 182.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 183.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 181.95it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 174.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.509
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.42547
wandb: sub_train_loss 0.00932
wandb:       test_acc 0.505
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run wild-sweep-580 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbagof3s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143150-lbagof3s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kdfvk25q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143202-kdfvk25q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-581
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kdfvk25q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.70it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 179.98it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 179.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 182.12it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 181.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 182.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 181.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 182.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 183.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 184.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.663
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.57352
wandb: sub_train_loss 0.00676
wandb:       test_acc 0.676
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run generous-sweep-581 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kdfvk25q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143202-kdfvk25q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x6rfftm4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143218-x6rfftm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-582
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x6rfftm4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.43it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 168.66it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 168.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 165.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 160.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 162.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 164.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 170.09it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 173.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 170.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 171.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.588
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.60374
wandb: sub_train_loss 0.00572
wandb:       test_acc 0.593
wandb:      valid_acc 0.604
wandb: 
wandb: üöÄ View run fanciful-sweep-582 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x6rfftm4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143218-x6rfftm4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0kfzdcbd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143233-0kfzdcbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-583
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0kfzdcbd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.68it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.90it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 164.91it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 173.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 177.27it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 179.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 182.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 183.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 183.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 184.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.65745
wandb: sub_train_loss 0.00959
wandb:       test_acc 0.692
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run elated-sweep-583 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0kfzdcbd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143233-0kfzdcbd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x7ol7lld with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143249-x7ol7lld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-584
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x7ol7lld
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.90it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.51it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 178.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 179.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 177.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 180.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 180.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 183.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 183.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 185.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.72
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.6396
wandb: sub_train_loss 0.00184
wandb:       test_acc 0.686
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run hardy-sweep-584 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x7ol7lld
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143249-x7ol7lld/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: auhumvbj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143304-auhumvbj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-585
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/auhumvbj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.22it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 170.35it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 171.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 173.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 175.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 176.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 177.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 179.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 181.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 182.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.67054
wandb: sub_train_loss 0.02586
wandb:       test_acc 0.618
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run different-sweep-585 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/auhumvbj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143304-auhumvbj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ao2008of with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143322-ao2008of
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-586
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ao2008of
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.45it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 169.57it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 172.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 173.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 173.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 174.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 175.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 175.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 176.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 177.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 178.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.703
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.68276
wandb: sub_train_loss 0.00446
wandb:       test_acc 0.649
wandb:      valid_acc 0.686
wandb: 
wandb: üöÄ View run copper-sweep-586 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ao2008of
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143322-ao2008of/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xo0z010o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143338-xo0z010o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-587
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xo0z010o
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.87it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.65it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.36it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 157.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 161.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 165.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 167.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 170.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 171.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 172.51it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 173.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.66476
wandb: sub_train_loss 0.00428
wandb:       test_acc 0.609
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run warm-sweep-587 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xo0z010o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143338-xo0z010o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u9do4fd1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143352-u9do4fd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-588
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u9do4fd1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.88it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 166.22it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 167.66it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.24it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 168.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 168.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 164.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 161.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 160.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 158.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 154.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.6929
wandb: sub_train_loss 0.00242
wandb:       test_acc 0.664
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run magic-sweep-588 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u9do4fd1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143352-u9do4fd1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x6xo758a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143408-x6xo758a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-589
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x6xo758a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.44it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.49it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 171.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 171.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 174.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 175.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 175.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 175.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 175.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 175.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.67054
wandb: sub_train_loss 0.00211
wandb:       test_acc 0.611
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run hardy-sweep-589 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/x6xo758a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143408-x6xo758a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 54zkaos1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143424-54zkaos1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-590
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/54zkaos1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 165.43it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 169.24it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 170.99it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 171.80it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 172.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 172.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 173.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 173.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 172.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 173.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 174.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.6852
wandb: sub_train_loss 0.00142
wandb:       test_acc 0.635
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run golden-sweep-590 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/54zkaos1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143424-54zkaos1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 52z8xrhp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143445-52z8xrhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-591
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/52z8xrhp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.53it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.56it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 162.92it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 165.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 166.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 168.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 169.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 170.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 171.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 172.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 173.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.68469
wandb: sub_train_loss 0.02053
wandb:       test_acc 0.708
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run prime-sweep-591 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/52z8xrhp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143445-52z8xrhp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3y35lyg1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143501-3y35lyg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-592
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3y35lyg1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.43it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 158.21it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 160.62it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 163.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 165.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 166.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 166.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 167.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 167.13it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 168.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 168.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.71268
wandb: sub_train_loss 0.00194
wandb:       test_acc 0.728
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run colorful-sweep-592 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3y35lyg1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143501-3y35lyg1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mjwymdj3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143515-mjwymdj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-593
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mjwymdj3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.32it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.33it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 151.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 147.05it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 142.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 142.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 139.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 138.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 137.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 136.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 136.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 135.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 134.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.42
wandb: best_valid_acc 0.444
wandb:  sub_train_acc 0.39534
wandb: sub_train_loss 0.02475
wandb:       test_acc 0.395
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run fast-sweep-593 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mjwymdj3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143515-mjwymdj3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gz7azpmg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143531-gz7azpmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-594
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gz7azpmg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.90it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.57it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 157.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 159.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 159.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 159.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 159.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 160.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 158.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 159.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.436
wandb:  sub_train_acc 0.39844
wandb: sub_train_loss 0.00635
wandb:       test_acc 0.391
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run pious-sweep-594 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gz7azpmg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143531-gz7azpmg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5kqypmhg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143547-5kqypmhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-595
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5kqypmhg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.61it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.72it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.16it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 150.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 148.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 148.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 149.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 150.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 148.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 148.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 148.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 148.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.38698
wandb: sub_train_loss 0.03632
wandb:       test_acc 0.199
wandb:      valid_acc 0.212
wandb: 
wandb: üöÄ View run hearty-sweep-595 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5kqypmhg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143547-5kqypmhg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kyg0yti6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143601-kyg0yti6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-596
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kyg0yti6
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.52it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.64it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 151.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 150.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 150.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 150.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 151.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 152.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 152.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 152.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.43617
wandb: sub_train_loss 0.01347
wandb:       test_acc 0.503
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run comfy-sweep-596 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/kyg0yti6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143601-kyg0yti6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1pz4hbvc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143617-1pz4hbvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-597
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1pz4hbvc
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.50it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 157.13it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.65it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 158.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 158.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 159.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 159.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 157.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 158.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 159.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 160.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 160.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.677
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.49886
wandb: sub_train_loss 0.00544
wandb:       test_acc 0.59
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run true-sweep-597 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1pz4hbvc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143617-1pz4hbvc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pncxbqtw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143632-pncxbqtw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-598
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pncxbqtw
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.90it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.70it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 136.29it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 143.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 148.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 149.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 146.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 148.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 151.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 153.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 153.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 151.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.666
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.417
wandb: sub_train_loss 1.56386
wandb:       test_acc 0.407
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run quiet-sweep-598 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pncxbqtw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143632-pncxbqtw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u9x4ojea with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143648-u9x4ojea
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-599
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u9x4ojea
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.78it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.97it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.65it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 148.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 147.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 147.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 147.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 147.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 149.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 150.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 150.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 151.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.58432
wandb: sub_train_loss 0.32008
wandb:       test_acc 0.638
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run driven-sweep-599 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u9x4ojea
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143648-u9x4ojea/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zx2tmmrr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143703-zx2tmmrr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-600
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zx2tmmrr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 130.58it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.12it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 142.27it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 139.36it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 138.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 141.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 145.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 146.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 146.35it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 148.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 150.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 151.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 149.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñÖ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.55414
wandb: sub_train_loss 0.00342
wandb:       test_acc 0.535
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run quiet-sweep-600 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zx2tmmrr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143703-zx2tmmrr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ppyq4icj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143724-ppyq4icj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-601
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ppyq4icj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.92it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.11it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 154.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 154.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 153.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 155.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 157.36it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 158.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 159.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 159.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.68722
wandb: sub_train_loss 0.00024
wandb:       test_acc 0.616
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run hardy-sweep-601 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ppyq4icj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143724-ppyq4icj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 285jymiv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143740-285jymiv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-602
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/285jymiv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.66it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.64it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 154.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 154.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 155.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.82it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 151.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 151.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 150.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 149.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 147.23it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 147.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.59177
wandb: sub_train_loss 0.50198
wandb:       test_acc 0.456
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run stilted-sweep-602 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/285jymiv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143740-285jymiv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: toj1tpn5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143756-toj1tpn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-603
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/toj1tpn5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.65it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.58it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 149.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 150.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 152.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 153.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 153.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 153.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 153.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 152.52it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 152.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.62854
wandb: sub_train_loss 0.02934
wandb:       test_acc 0.531
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run legendary-sweep-603 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/toj1tpn5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143756-toj1tpn5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: od0fftjd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143810-od0fftjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-604
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/od0fftjd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.17it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.97it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 147.12it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 148.65it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 150.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 150.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 151.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 151.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 150.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 150.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 150.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 149.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.66207
wandb: sub_train_loss 0.01522
wandb:       test_acc 0.704
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run hopeful-sweep-604 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/od0fftjd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143810-od0fftjd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sht48qao with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143826-sht48qao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-605
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sht48qao
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.20it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.65it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.40it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 143.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 141.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 141.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 142.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 140.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 140.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.74489
wandb: sub_train_loss 0.1971
wandb:       test_acc 0.746
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run worldly-sweep-605 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sht48qao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143826-sht48qao/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5vth96s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143842-i5vth96s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-606
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5vth96s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.91it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.22it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 139.74it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 140.82it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 141.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 142.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 142.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 143.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 143.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 143.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 142.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 142.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 142.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.709
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.52092
wandb: sub_train_loss 5.35774
wandb:       test_acc 0.537
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run prime-sweep-606 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5vth96s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143842-i5vth96s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gtjfrhso with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143856-gtjfrhso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-607
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gtjfrhso
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.13it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.12it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.47it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 147.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 147.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 147.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 147.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 147.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 147.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 147.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.40701
wandb: sub_train_loss 4.23696
wandb:       test_acc 0.435
wandb:      valid_acc 0.41
wandb: 
wandb: üöÄ View run desert-sweep-607 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gtjfrhso
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143856-gtjfrhso/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rw34d8sg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143912-rw34d8sg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-608
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rw34d8sg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.06it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.01it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 140.62it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 141.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 142.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 142.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 142.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 140.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 136.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 133.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 131.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 134.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 137.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.59157
wandb: sub_train_loss 0.16743
wandb:       test_acc 0.581
wandb:      valid_acc 0.596
wandb: 
wandb: üöÄ View run treasured-sweep-608 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rw34d8sg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143912-rw34d8sg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 99s4x3eu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143927-99s4x3eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-609
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/99s4x3eu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.95it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 131.50it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 130.72it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 132.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 130.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 129.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 128.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 129.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 128.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 129.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 129.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 128.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 127.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 123.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.444
wandb:  sub_train_acc 0.47928
wandb: sub_train_loss 0.00779
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run ancient-sweep-609 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/99s4x3eu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143927-99s4x3eu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vtotabfj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_143942-vtotabfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-610
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vtotabfj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.41it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.35it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 133.53it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 134.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 135.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 135.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 133.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 131.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 132.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 132.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 131.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 132.03it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 131.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 130.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.42978
wandb: sub_train_loss 0.00312
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run smooth-sweep-610 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/vtotabfj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_143942-vtotabfj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lq0269k8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144004-lq0269k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-611
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lq0269k8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.22it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.77it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.05it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.54it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 124.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 125.12it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 125.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 125.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 124.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 125.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 127.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 128.79it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 129.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 130.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.62
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.4134
wandb: sub_train_loss 0.07935
wandb:       test_acc 0.206
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run prime-sweep-611 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lq0269k8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144004-lq0269k8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ix3j7uhe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144019-ix3j7uhe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-612
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ix3j7uhe
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 129.99it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 127.76it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 126.51it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 126.98it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 126.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 126.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 126.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 126.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 126.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 129.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 131.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 132.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 130.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 128.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.556
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.46057
wandb: sub_train_loss 0.02318
wandb:       test_acc 0.22
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run astral-sweep-612 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ix3j7uhe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144019-ix3j7uhe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p4m3e9v3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144034-p4m3e9v3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-613
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p4m3e9v3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 8/200 [00:00<00:02, 79.11it/s]  8%|‚ñä         | 17/200 [00:00<00:02, 82.28it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 88.32it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 92.69it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 95.83it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 95.10it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 96.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 101.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 103.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:00, 103.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 105.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 104.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 105.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 104.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 101.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 104.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 104.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 101.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 100.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.681
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.54364
wandb: sub_train_loss 0.37059
wandb:       test_acc 0.513
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run pleasant-sweep-613 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p4m3e9v3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144034-p4m3e9v3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 63qsjrv8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144051-63qsjrv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-614
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/63qsjrv8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.70it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 123.21it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 130.49it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 133.68it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 135.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 135.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 135.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 136.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 134.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 134.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 135.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 133.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 133.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 133.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.673
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.57849
wandb: sub_train_loss 0.3486
wandb:       test_acc 0.532
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run pretty-sweep-614 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/63qsjrv8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144051-63qsjrv8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1ydf0dh3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144106-1ydf0dh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-615
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ydf0dh3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.73it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.81it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 135.15it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 132.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 131.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 132.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 132.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 133.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 133.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 133.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 133.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 133.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 133.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 133.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.45768
wandb: sub_train_loss 0.8782
wandb:       test_acc 0.428
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run different-sweep-615 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1ydf0dh3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144106-1ydf0dh3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ivxfqxf8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144125-ivxfqxf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-616
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ivxfqxf8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.83it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.93it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.88it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 128.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 130.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 132.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 132.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 132.65it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 133.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 134.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 134.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 132.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 132.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.672
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.34818
wandb: sub_train_loss 4.63235
wandb:       test_acc 0.18
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run sweet-sweep-616 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ivxfqxf8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144125-ivxfqxf8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nf75kpk2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144147-nf75kpk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-617
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nf75kpk2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.65it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 130.00it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 129.28it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 130.06it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 128.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 127.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 127.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 128.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 129.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 129.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 129.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 129.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 130.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 129.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.43561
wandb: sub_train_loss 1.38721
wandb:       test_acc 0.412
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run wise-sweep-617 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nf75kpk2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144147-nf75kpk2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ybm2wycz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144203-ybm2wycz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-618
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ybm2wycz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.52it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 130.21it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 132.71it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 135.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 135.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 135.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 136.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 136.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 137.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 137.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 137.20it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 137.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 137.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 137.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.62413
wandb: sub_train_loss 0.26878
wandb:       test_acc 0.419
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run smart-sweep-618 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ybm2wycz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144203-ybm2wycz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oap89muz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144221-oap89muz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-619
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oap89muz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 130.61it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 130.84it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 130.92it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 131.73it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 132.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 132.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 131.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 130.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 127.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 126.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 124.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 119.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 116.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 113.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.56327
wandb: sub_train_loss 1.12732
wandb:       test_acc 0.599
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run valiant-sweep-619 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oap89muz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144221-oap89muz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ljqdyqtl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144236-ljqdyqtl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-620
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ljqdyqtl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.98it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.25it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.99it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 135.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 135.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 136.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 136.39it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 136.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 135.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 136.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 136.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 136.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 136.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.732
wandb:  sub_train_acc 0.47309
wandb: sub_train_loss 0.63331
wandb:       test_acc 0.409
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run eager-sweep-620 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ljqdyqtl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144236-ljqdyqtl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zihpfflk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144252-zihpfflk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-621
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zihpfflk
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.69it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 132.03it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.85it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.43it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 130.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 129.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 130.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 131.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 131.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 132.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 131.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 132.10it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 131.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 131.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.702
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.69128
wandb: sub_train_loss 0.21297
wandb:       test_acc 0.666
wandb:      valid_acc 0.692
wandb: 
wandb: üöÄ View run sage-sweep-621 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zihpfflk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144252-zihpfflk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p8tzxzl8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144307-p8tzxzl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-622
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p8tzxzl8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 106.51it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 99.83it/s]  16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 99.03it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.83it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 107.09it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 106.78it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 108.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 108.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 107.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 107.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 107.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 108.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 107.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 105.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 105.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 104.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 105.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 105.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 105.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.47609
wandb: sub_train_loss 1.54471
wandb:       test_acc 0.427
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run lively-sweep-622 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/p8tzxzl8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144307-p8tzxzl8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nacovqj1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144323-nacovqj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-623
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nacovqj1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.86it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.83it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 119.00it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 118.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 119.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 119.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 120.37it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 121.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 122.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 120.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 116.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 113.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 111.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 110.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 109.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.5054
wandb: sub_train_loss 1.11397
wandb:       test_acc 0.518
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run quiet-sweep-623 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nacovqj1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144323-nacovqj1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z6ssjvpy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144338-z6ssjvpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-624
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z6ssjvpy
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.99it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.17it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 121.36it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.32it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 116.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 114.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 114.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 118.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 120.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 121.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 122.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 123.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 123.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 121.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 118.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.52041
wandb: sub_train_loss 0.68121
wandb:       test_acc 0.515
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run crimson-sweep-624 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z6ssjvpy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144338-z6ssjvpy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e2u690eb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144354-e2u690eb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-625
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e2u690eb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.46it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.23it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 187.27it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 188.98it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 189.48it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 189.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 188.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 186.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 185.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 184.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 185.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 183.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 184.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 184.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 184.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.402
wandb: best_valid_acc 0.438
wandb:  sub_train_acc 0.42395
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.397
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run wobbly-sweep-625 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e2u690eb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144354-e2u690eb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yfu5s4h7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144408-yfu5s4h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-626
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yfu5s4h7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.89it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 178.91it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 179.86it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 180.62it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 182.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 182.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 183.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 183.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 183.60it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 182.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 181.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 181.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 181.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 182.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 183.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.381
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.41426
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.385
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run drawn-sweep-626 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yfu5s4h7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144408-yfu5s4h7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: khap1d23 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144424-khap1d23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-627
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/khap1d23
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.58it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.60it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.12it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 168.35it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 168.81it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 172.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 172.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 172.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 173.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 172.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 172.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 173.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 175.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 178.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 180.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 181.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.517
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.53629
wandb: sub_train_loss 0.0
wandb:       test_acc 0.516
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run silver-sweep-627 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/khap1d23
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144424-khap1d23/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 57j69bne with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144439-57j69bne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-628
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/57j69bne
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.25it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.34it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.29it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 183.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 182.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 180.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 179.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 179.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 181.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 181.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 179.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 177.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 175.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 173.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 174.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.508
wandb: best_valid_acc 0.532
wandb:  sub_train_acc 0.45032
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.305
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run happy-sweep-628 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/57j69bne
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144439-57j69bne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: atv7gn0s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144455-atv7gn0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-629
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/atv7gn0s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.85it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 178.50it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 176.67it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 178.73it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 176.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 173.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 174.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 178.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 179.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 178.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 179.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 179.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 180.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 180.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 180.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 180.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.699
wandb: best_valid_acc 0.714
wandb:  sub_train_acc 0.58772
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.694
wandb:      valid_acc 0.714
wandb: 
wandb: üöÄ View run misunderstood-sweep-629 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/atv7gn0s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144455-atv7gn0s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pjpcvsl1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144509-pjpcvsl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-630
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pjpcvsl1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.34it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.74it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.51it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 170.68it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 167.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 166.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 165.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 166.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 170.13it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 173.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 175.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 176.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 178.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 176.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 176.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 178.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.538
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.58949
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.555
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run breezy-sweep-630 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pjpcvsl1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144509-pjpcvsl1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9xkz5ttj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144531-9xkz5ttj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-631
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9xkz5ttj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.35it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 180.51it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 182.06it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 180.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 178.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 176.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 177.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 177.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 177.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 179.33it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 181.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 182.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 183.59it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 183.17it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 182.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.66968
wandb: sub_train_loss 0.0
wandb:       test_acc 0.733
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run curious-sweep-631 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/9xkz5ttj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144531-9xkz5ttj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6s1hlhym with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144546-6s1hlhym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-632
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6s1hlhym
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.04it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 174.47it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 177.59it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 178.69it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 175.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 175.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 175.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 173.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 175.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 178.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 179.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 179.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 180.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 180.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 179.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 176.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.64523
wandb: sub_train_loss 0.0
wandb:       test_acc 0.695
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run rosy-sweep-632 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6s1hlhym
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144546-6s1hlhym/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mpuqo71l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144602-mpuqo71l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-633
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mpuqo71l
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.43it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 174.23it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.07it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 173.79it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 176.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 178.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 180.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 181.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 180.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 181.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 182.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 182.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 183.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 182.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 181.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.67383
wandb: sub_train_loss 0.00011
wandb:       test_acc 0.683
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run mild-sweep-633 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mpuqo71l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144602-mpuqo71l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ut0jzyvv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144617-ut0jzyvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-634
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ut0jzyvv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.16it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.06it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 174.80it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 173.27it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 175.52it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 177.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 177.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 177.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 176.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 176.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 173.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 170.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 168.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 170.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 171.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 173.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.68459
wandb: sub_train_loss 0.0
wandb:       test_acc 0.714
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run polished-sweep-634 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ut0jzyvv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144617-ut0jzyvv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 38qufkfn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144632-38qufkfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-635
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/38qufkfn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.42it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 164.89it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.07it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 157.82it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 155.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 161.07it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 163.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 160.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 158.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 160.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 160.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 157.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 156.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 155.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 155.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 157.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 157.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 158.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.69
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.67688
wandb: sub_train_loss 0.0
wandb:       test_acc 0.656
wandb:      valid_acc 0.71
wandb: 
wandb: üöÄ View run summer-sweep-635 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/38qufkfn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144632-38qufkfn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nak6txy9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144648-nak6txy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-636
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nak6txy9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.11it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 171.70it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.68it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 174.16it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 167.89it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 165.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 166.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 171.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 173.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 176.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 177.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 178.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 179.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 179.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 180.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 179.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.705
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.64376
wandb: sub_train_loss 0.0
wandb:       test_acc 0.581
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run dauntless-sweep-636 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nak6txy9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144648-nak6txy9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5dzpctdf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144702-5dzpctdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-637
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dzpctdf
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.31it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 167.69it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 169.33it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 168.40it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 164.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 160.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 158.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 155.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 155.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 157.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 163.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 167.66it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 170.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 173.01it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 174.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 175.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 176.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.72846
wandb: sub_train_loss 0.0
wandb:       test_acc 0.736
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run solar-sweep-637 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5dzpctdf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144702-5dzpctdf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 76lsu1rv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144718-76lsu1rv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-638
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/76lsu1rv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.02it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 160.45it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 162.38it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 162.16it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 164.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 165.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 166.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 168.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 168.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 166.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 163.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 163.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 163.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 164.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 163.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 161.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 161.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.67515
wandb: sub_train_loss 0.02368
wandb:       test_acc 0.7
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run volcanic-sweep-638 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/76lsu1rv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144718-76lsu1rv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2zn52zi3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144734-2zn52zi3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-639
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2zn52zi3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.83it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.19it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 158.03it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 163.05it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 166.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 168.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 169.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 170.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 170.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 170.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 170.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 171.08it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 170.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 171.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 169.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 169.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.65502
wandb: sub_train_loss 0.0
wandb:       test_acc 0.66
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run balmy-sweep-639 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2zn52zi3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144734-2zn52zi3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yo2a0q3z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144751-yo2a0q3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-640
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yo2a0q3z
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.12it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.12it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 163.71it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 165.39it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 166.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 167.26it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 167.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 168.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 167.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 167.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 167.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 167.76it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 168.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 167.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 168.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 166.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 167.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.8
wandb:  sub_train_acc 0.71218
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.712
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run glorious-sweep-640 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yo2a0q3z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144751-yo2a0q3z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h17rff4r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144807-h17rff4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-641
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h17rff4r
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.45it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.77it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 159.28it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 160.75it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 160.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 159.70it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 156.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 156.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 157.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 158.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 157.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 156.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 149.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 138.17it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 132.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 138.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 144.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 146.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.401
wandb: best_valid_acc 0.416
wandb:  sub_train_acc 0.40747
wandb: sub_train_loss 0.0
wandb:       test_acc 0.329
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run hardy-sweep-641 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h17rff4r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144807-h17rff4r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lbs43ghu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144823-lbs43ghu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-642
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbs43ghu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.79it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.65it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 144.40it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 144.42it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 143.96it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 143.13it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 142.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 141.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 145.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 149.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 150.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 150.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 151.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 151.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 151.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 151.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 150.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 150.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 150.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.44703
wandb: sub_train_loss 0.0
wandb:       test_acc 0.407
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run ethereal-sweep-642 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbs43ghu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144823-lbs43ghu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 37ydnx2f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144838-37ydnx2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-643
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/37ydnx2f
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.01it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.72it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 142.01it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 143.44it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 144.53it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 144.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 145.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 144.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 144.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 144.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 143.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 142.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 141.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 142.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 143.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 146.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 148.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 148.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 148.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.47604
wandb: sub_train_loss 0.0
wandb:       test_acc 0.486
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run vague-sweep-643 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/37ydnx2f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144838-37ydnx2f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ixmidja3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144853-ixmidja3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-644
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ixmidja3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.61it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.82it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 140.77it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 137.96it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 134.70it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 135.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 136.43it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 136.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 135.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 133.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 130.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 126.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 127.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 125.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 124.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 124.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 124.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 122.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 127.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 131.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 135.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.612
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.43075
wandb: sub_train_loss 0.0
wandb:       test_acc 0.326
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run genial-sweep-644 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ixmidja3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144853-ixmidja3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tn5a4ck3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144908-tn5a4ck3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-645
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tn5a4ck3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.62it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.13it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.25it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 157.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 157.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 158.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 158.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 158.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 154.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 154.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 154.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 154.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 153.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 154.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 154.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 154.76it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 154.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.665
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.46939
wandb: sub_train_loss 0.02962
wandb:       test_acc 0.302
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run iconic-sweep-645 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tn5a4ck3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144908-tn5a4ck3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ahot1qek with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144929-ahot1qek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-646
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ahot1qek
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.02it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 153.13it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 149.29it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 150.83it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 148.80it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 147.73it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 147.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 147.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 145.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 143.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 144.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 144.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 146.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 150.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 152.06it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 154.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 156.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 157.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 157.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.692
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.4913
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.43
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run neat-sweep-646 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ahot1qek
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144929-ahot1qek/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: msfyzzng with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144945-msfyzzng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-647
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/msfyzzng
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.76it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.77it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.96it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 145.77it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 128.86it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 128.80it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 128.57it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 133.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 133.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 131.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 131.29it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 131.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 131.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 130.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 129.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 129.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 129.58it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 128.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 126.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 127.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 129.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.708
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.53989
wandb: sub_train_loss 0.0052
wandb:       test_acc 0.322
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run toasty-sweep-647 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/msfyzzng
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144945-msfyzzng/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 59op6vh9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_144959-59op6vh9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-648
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/59op6vh9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.80it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.73it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.66it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.63it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 132.17it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 139.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 143.96it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 145.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 147.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 149.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 148.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 149.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 149.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 151.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 152.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 153.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 154.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 154.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 154.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.51336
wandb: sub_train_loss 0.48763
wandb:       test_acc 0.465
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run sleek-sweep-648 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/59op6vh9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_144959-59op6vh9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xbj9ptdi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145021-xbj9ptdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-649
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xbj9ptdi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.71it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.76it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.46it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.13it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 151.47it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 154.17it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 155.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 155.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 153.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 154.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 155.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 155.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 154.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 155.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 155.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 155.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 155.50it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 155.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.63042
wandb: sub_train_loss 0.18788
wandb:       test_acc 0.678
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run iconic-sweep-649 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xbj9ptdi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145021-xbj9ptdi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mlhabe9g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145036-mlhabe9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-650
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mlhabe9g
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.29it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.09it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.79it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.65it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 152.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 153.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 153.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 151.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 150.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 151.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 152.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 152.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 152.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 151.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 154.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 155.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 157.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 158.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.738
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.69077
wandb: sub_train_loss 0.00061
wandb:       test_acc 0.686
wandb:      valid_acc 0.698
wandb: 
wandb: üöÄ View run spring-sweep-650 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/mlhabe9g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145036-mlhabe9g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m44hos00 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145052-m44hos00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-651
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m44hos00
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.51it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.40it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 133.51it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 131.39it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 129.28it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 129.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 128.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 129.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 128.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 128.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 128.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 130.46it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 130.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 129.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 128.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 127.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 127.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 126.20it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 125.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 126.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 127.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 127.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.58985
wandb: sub_train_loss 0.06526
wandb:       test_acc 0.589
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run splendid-sweep-651 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m44hos00
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145052-m44hos00/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aruazs8m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145108-aruazs8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-652
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aruazs8m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.82it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 136.44it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 124.64it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 119.67it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 123.62it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 122.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 121.53it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 119.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 123.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 126.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 129.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 134.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 139.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 143.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 145.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 148.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 150.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 151.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 152.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 153.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.741
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.63336
wandb: sub_train_loss 0.08037
wandb:       test_acc 0.652
wandb:      valid_acc 0.636
wandb: 
wandb: üöÄ View run fluent-sweep-652 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aruazs8m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145108-aruazs8m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: etxk6ej3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145123-etxk6ej3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-653
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/etxk6ej3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.71it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.88it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.23it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 147.70it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.77it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 149.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 150.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 151.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 151.58it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 151.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 151.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 151.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 151.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 151.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 151.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 151.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 152.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 152.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.30395
wandb: sub_train_loss 11.21078
wandb:       test_acc 0.219
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run sweepy-sweep-653 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/etxk6ej3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145123-etxk6ej3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4k2q3ywb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145138-4k2q3ywb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-654
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4k2q3ywb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.60it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 108.36it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 115.98it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 118.28it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 120.45it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 115.84it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 115.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 115.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 114.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 117.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 117.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 116.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 114.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 113.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 110.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 111.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 111.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 111.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 115.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 114.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 113.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 117.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 123.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 124.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.4203
wandb: sub_train_loss 0.64042
wandb:       test_acc 0.398
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run sage-sweep-654 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4k2q3ywb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145138-4k2q3ywb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: krx26hoo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145153-krx26hoo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-655
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/krx26hoo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.46it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.77it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 146.44it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.29it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 146.78it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.83it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 148.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 148.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 149.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:00, 149.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 149.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 149.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 149.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 148.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 148.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 148.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 148.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 143.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 141.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.745
wandb: best_valid_acc 0.808
wandb:  sub_train_acc 0.40026
wandb: sub_train_loss 0.96036
wandb:       test_acc 0.402
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run honest-sweep-655 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/krx26hoo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145153-krx26hoo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rr663yus with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145209-rr663yus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-656
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rr663yus
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.17it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.13it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.62it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 127.33it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 130.56it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 130.96it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 131.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 131.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 132.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 132.20it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 132.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 132.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 130.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 132.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 134.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 134.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 135.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 136.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 136.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 136.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 136.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.48755
wandb: sub_train_loss 0.64831
wandb:       test_acc 0.487
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run avid-sweep-656 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rr663yus
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145209-rr663yus/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6bn4q367 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145224-6bn4q367
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-657
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6bn4q367
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.56it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 131.82it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.06it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 122.79it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 121.24it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 119.65it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 119.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 121.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 126.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 128.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 130.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 132.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 133.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 134.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 135.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 135.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 135.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 136.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 136.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 136.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 135.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.408
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.42101
wandb: sub_train_loss 0.0
wandb:       test_acc 0.41
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run electric-sweep-657 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6bn4q367
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145224-6bn4q367/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2xvl5bya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145239-2xvl5bya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-658
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2xvl5bya
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.39it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.37it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 132.84it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 134.45it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 132.47it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 131.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 131.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 132.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 133.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 135.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 135.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 136.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 134.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 133.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 132.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 133.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 135.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 135.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 134.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 133.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 133.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.408
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.4207
wandb: sub_train_loss 0.0
wandb:       test_acc 0.377
wandb:      valid_acc 0.374
wandb: 
wandb: üöÄ View run curious-sweep-658 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2xvl5bya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145239-2xvl5bya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uzwrnmlz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145255-uzwrnmlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-659
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uzwrnmlz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.32it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 118.92it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.05it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 123.37it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 124.47it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.77it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 124.23it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 123.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 122.81it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 121.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 121.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 122.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 123.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 124.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 124.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 123.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 124.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 124.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 124.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 124.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 124.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 123.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 124.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.4066
wandb: sub_train_loss 0.00679
wandb:       test_acc 0.42
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run dry-sweep-659 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uzwrnmlz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145255-uzwrnmlz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0jecl6p8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145310-0jecl6p8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-660
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0jecl6p8
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.48it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.99it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.33it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.29it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 132.85it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 131.75it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 131.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 132.38it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 132.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 133.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 133.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 131.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 132.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 130.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 127.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 127.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 125.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 126.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 127.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 127.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 127.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.626
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.40077
wandb: sub_train_loss 0.00153
wandb:       test_acc 0.407
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run grateful-sweep-660 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0jecl6p8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145310-0jecl6p8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7cbshorq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145326-7cbshorq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-661
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7cbshorq
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.24it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.11it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.17it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.68it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 135.23it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 134.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 137.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 136.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 137.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 136.27it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 135.73it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 136.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 137.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 137.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 137.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 136.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 135.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 134.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 133.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 132.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.52082
wandb: sub_train_loss 0.01046
wandb:       test_acc 0.322
wandb:      valid_acc 0.348
wandb: 
wandb: üöÄ View run stilted-sweep-661 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7cbshorq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145326-7cbshorq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 83n7te4t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145341-83n7te4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-662
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/83n7te4t
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.86it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 128.17it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.40it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 132.60it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 133.12it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 134.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 134.83it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 134.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 135.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 136.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 137.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 137.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 137.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 136.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 137.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 137.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 137.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 137.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 137.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 136.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 135.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.684
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.42882
wandb: sub_train_loss 0.39266
wandb:       test_acc 0.431
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run dry-sweep-662 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/83n7te4t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145341-83n7te4t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hmomuv09 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145356-hmomuv09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-663
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hmomuv09
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.32it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.36it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.55it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.68it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.70it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 135.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 136.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 137.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 137.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 137.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 135.21it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 133.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 133.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 132.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 129.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 127.22it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 127.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 126.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 126.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 126.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.59568
wandb: sub_train_loss 0.09994
wandb:       test_acc 0.365
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run fragrant-sweep-663 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hmomuv09
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145356-hmomuv09/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e1xgxjcj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145412-e1xgxjcj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-664
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e1xgxjcj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.80it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 129.02it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 131.14it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 125.85it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 121.19it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 120.54it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 119.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 116.28it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 114.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 115.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 116.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 117.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 117.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 112.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 114.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 114.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 115.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 115.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 120.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 123.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 126.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 128.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 128.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 120.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.65826
wandb: sub_train_loss 0.101
wandb:       test_acc 0.547
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run proud-sweep-664 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e1xgxjcj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145412-e1xgxjcj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 18huakyh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145432-18huakyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-665
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/18huakyh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.83it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.07it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.73it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 129.69it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 130.28it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 132.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 132.41it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 133.50it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 134.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 134.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 134.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 134.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 134.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 129.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 130.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 131.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 133.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 134.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 135.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 135.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 134.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.52092
wandb: sub_train_loss 0.5071
wandb:       test_acc 0.504
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run faithful-sweep-665 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/18huakyh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145432-18huakyh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4j24t7lt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145448-4j24t7lt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-666
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4j24t7lt
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.34it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.88it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.34it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.51it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.99it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 131.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 131.80it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 133.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 135.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 134.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 134.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 134.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 135.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 135.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 136.42it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 137.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 137.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 138.02it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 138.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 138.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñÖ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñá‚ñà‚ñÖ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.48943
wandb: sub_train_loss 0.36101
wandb:       test_acc 0.389
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run rich-sweep-666 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4j24t7lt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145448-4j24t7lt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 58doec08 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145503-58doec08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-667
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/58doec08
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.11it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 127.06it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 123.91it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 121.64it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 123.73it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 125.06it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 122.80it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 120.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 119.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 123.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 126.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 129.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 129.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 130.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 130.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 131.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 131.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 129.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 129.68it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 130.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 131.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.62489
wandb: sub_train_loss 0.39293
wandb:       test_acc 0.509
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run logical-sweep-667 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/58doec08
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145503-58doec08/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a5kg5v5s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145518-a5kg5v5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-668
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a5kg5v5s
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.50it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 130.66it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.49it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.70it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.33it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 135.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 134.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 135.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 135.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 135.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 135.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 135.29it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 135.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 135.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 135.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 136.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 136.37it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 136.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 136.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 136.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 137.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.34574
wandb: sub_train_loss 0.69873
wandb:       test_acc 0.188
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run astral-sweep-668 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a5kg5v5s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145518-a5kg5v5s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: invv9vh4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145533-invv9vh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-669
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/invv9vh4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.80it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 128.03it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 130.29it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 131.04it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 131.31it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 131.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 132.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 132.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 132.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 132.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 133.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 132.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 132.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 133.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 133.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 133.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 133.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 133.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 133.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 133.23it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 133.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.5015
wandb: sub_train_loss 0.6935
wandb:       test_acc 0.472
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run fine-sweep-669 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/invv9vh4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145533-invv9vh4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oh4a4qid with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145548-oh4a4qid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-670
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oh4a4qid
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.41it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.54it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.75it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.45it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 126.54it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 126.56it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.51it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 126.71it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 128.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 128.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 129.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 129.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 128.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 127.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 128.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 127.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 126.78it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 127.63it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 127.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 128.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 127.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 127.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.64107
wandb: sub_train_loss 0.58206
wandb:       test_acc 0.637
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run deft-sweep-670 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oh4a4qid
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145548-oh4a4qid/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 54thp9ur with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145605-54thp9ur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-671
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/54thp9ur
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:00<00:47,  6.26it/s]  4%|‚ñç         | 12/300 [00:00<00:05, 54.61it/s]  8%|‚ñä         | 25/300 [00:00<00:03, 82.35it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 97.28it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 105.84it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 112.29it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 116.84it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 119.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 121.01it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 122.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 123.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 123.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 124.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 124.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 124.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 124.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 123.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 122.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 122.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 123.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 125.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 125.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 125.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 125.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.769
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.49221
wandb: sub_train_loss 0.62796
wandb:       test_acc 0.489
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run ancient-sweep-671 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/54thp9ur
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145605-54thp9ur/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: smby98t3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145622-smby98t3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-672
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/smby98t3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.15it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 123.22it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.28it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.70it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 125.96it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 126.76it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.40it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 127.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 128.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 127.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 126.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 124.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 120.10it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 117.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 115.38it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 118.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 120.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 122.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 123.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 124.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 125.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 124.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 124.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.38606
wandb: sub_train_loss 0.70493
wandb:       test_acc 0.363
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run stoic-sweep-672 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/smby98t3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145622-smby98t3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4fkaq504 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145636-4fkaq504
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-673
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4fkaq504
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.14it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.98it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.04it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 148.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 148.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 148.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 148.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 148.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 148.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 148.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.449
wandb: best_valid_acc 0.474
wandb:  sub_train_acc 0.39697
wandb: sub_train_loss 0.00699
wandb:       test_acc 0.437
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run jolly-sweep-673 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4fkaq504
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145636-4fkaq504/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5qjssbi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145652-i5qjssbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-674
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5qjssbi
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.07it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 139.93it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 138.60it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 137.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 138.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 141.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 143.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 145.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 145.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 146.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 146.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 147.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 148.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.448
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.39651
wandb: sub_train_loss 0.01952
wandb:       test_acc 0.412
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run drawn-sweep-674 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/i5qjssbi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145652-i5qjssbi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oiz6036a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145707-oiz6036a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-675
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oiz6036a
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.58it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.51it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 135.56it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 126.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 126.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 122.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 123.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 123.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 126.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 129.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 133.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 135.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 135.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 136.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.503
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.50682
wandb: sub_train_loss 0.01694
wandb:       test_acc 0.506
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run stellar-sweep-675 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/oiz6036a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145707-oiz6036a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e0zmwshb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145723-e0zmwshb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-676
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e0zmwshb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.46it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.33it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 145.50it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 144.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 145.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 146.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 146.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 146.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 146.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 145.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 146.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 146.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 146.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.499
wandb: best_valid_acc 0.528
wandb:  sub_train_acc 0.49394
wandb: sub_train_loss 0.01331
wandb:       test_acc 0.493
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run bright-sweep-676 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/e0zmwshb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145723-e0zmwshb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tkgyryxv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145737-tkgyryxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-677
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkgyryxv
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.14it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.92it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.66it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 145.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 145.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 146.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 147.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 148.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 148.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 147.88it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 147.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.513
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.54192
wandb: sub_train_loss 0.04282
wandb:       test_acc 0.513
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run generous-sweep-677 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tkgyryxv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145737-tkgyryxv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tc5iyxms with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145752-tc5iyxms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-678
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tc5iyxms
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.30it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 148.80it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.76it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 148.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 145.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 140.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 137.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 136.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 135.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 134.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 129.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 128.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.504
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.54232
wandb: sub_train_loss 0.03899
wandb:       test_acc 0.512
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run lunar-sweep-678 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tc5iyxms
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145752-tc5iyxms/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 376wfib3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145807-376wfib3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-679
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/376wfib3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.68it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.87it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 147.66it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 141.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 137.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 135.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 131.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 131.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 129.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 131.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 130.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.67505
wandb: sub_train_loss 0.04481
wandb:       test_acc 0.694
wandb:      valid_acc 0.73
wandb: 
wandb: üöÄ View run sparkling-sweep-679 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/376wfib3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145807-376wfib3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0zkp6c7m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145822-0zkp6c7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-680
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0zkp6c7m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 113.69it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.28it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.55it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 127.89it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 128.32it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 130.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 129.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 130.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 130.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 133.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 136.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 136.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 135.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 137.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.686
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.64112
wandb: sub_train_loss 0.07923
wandb:       test_acc 0.656
wandb:      valid_acc 0.682
wandb: 
wandb: üöÄ View run zesty-sweep-680 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0zkp6c7m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145822-0zkp6c7m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ypbe5zg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145838-5ypbe5zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-681
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5ypbe5zg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.17it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.74it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 146.10it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 147.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 146.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 143.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 142.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 142.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 142.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 142.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 143.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 142.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 143.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.72328
wandb: sub_train_loss 0.03938
wandb:       test_acc 0.723
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run atomic-sweep-681 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5ypbe5zg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145838-5ypbe5zg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ylwm205x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145853-ylwm205x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-682
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ylwm205x
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.50it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 142.69it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.66it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 148.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 149.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 149.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 150.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 150.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 150.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.70219
wandb: sub_train_loss 0.04709
wandb:       test_acc 0.707
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run dainty-sweep-682 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ylwm205x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145853-ylwm205x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8mw86hg9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145909-8mw86hg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-683
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8mw86hg9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.88it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.01it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 150.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 141.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 137.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 139.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 140.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 141.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 141.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 142.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 142.35it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 142.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 142.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.714
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.714
wandb: sub_train_loss 0.06357
wandb:       test_acc 0.716
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run giddy-sweep-683 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8mw86hg9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145909-8mw86hg9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zepgfnss with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145926-zepgfnss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-684
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zepgfnss
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.78it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.63it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.38it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 146.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 145.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 146.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 146.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 146.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 144.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 145.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 145.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 147.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.71943
wandb: sub_train_loss 0.05261
wandb:       test_acc 0.713
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run super-sweep-684 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zepgfnss
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145926-zepgfnss/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uopvr5f1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145941-uopvr5f1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-685
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uopvr5f1
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.76it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 141.76it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 144.82it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 146.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 146.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 147.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 147.89it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 148.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 148.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 147.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 147.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.72922
wandb: sub_train_loss 0.05399
wandb:       test_acc 0.75
wandb:      valid_acc 0.778
wandb: 
wandb: üöÄ View run jumping-sweep-685 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uopvr5f1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145941-uopvr5f1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r1a4ikb7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_145956-r1a4ikb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-686
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r1a4ikb7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 118.79it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 113.23it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 108.27it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 106.24it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 102.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 98.39it/s]  40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 96.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 95.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 94.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 94.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 104.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 108.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 107.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 110.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 110.90it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 115.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 106.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.71035
wandb: sub_train_loss 0.04902
wandb:       test_acc 0.715
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run easy-sweep-686 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/r1a4ikb7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_145956-r1a4ikb7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: je024zic with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150018-je024zic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-687
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/je024zic
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.21it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 139.17it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 139.26it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 137.28it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 139.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 141.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 140.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 139.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 137.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 136.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 135.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 135.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 134.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.771
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.76817
wandb: sub_train_loss 0.09066
wandb:       test_acc 0.765
wandb:      valid_acc 0.778
wandb: 
wandb: üöÄ View run likely-sweep-687 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/je024zic
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150018-je024zic/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tlx8euna with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150031-tlx8euna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-688
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tlx8euna
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.07it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 138.52it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 136.28it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 131.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 132.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 131.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 132.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 132.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 131.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 130.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 128.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 127.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 127.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 126.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.751
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.75214
wandb: sub_train_loss 0.06395
wandb:       test_acc 0.762
wandb:      valid_acc 0.798
wandb: 
wandb: üöÄ View run fine-sweep-688 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/tlx8euna
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150031-tlx8euna/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhylmnub with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150046-hhylmnub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-689
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hhylmnub
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.93it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.80it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.04it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 117.98it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 117.44it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 117.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 116.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 116.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 116.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 115.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 116.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 114.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 113.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 112.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 112.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 110.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.456
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.4168
wandb: sub_train_loss 0.00478
wandb:       test_acc 0.456
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run easy-sweep-689 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/hhylmnub
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150046-hhylmnub/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: euish0at with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150102-euish0at
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-690
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/euish0at
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.29it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.64it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 120.73it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 120.47it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 120.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 120.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 119.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 111.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 111.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 111.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 112.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 114.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 114.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 113.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 113.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 112.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.412
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.3849
wandb: sub_train_loss 0.0008
wandb:       test_acc 0.408
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run fancy-sweep-690 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/euish0at
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150102-euish0at/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ocwyrvx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150118-3ocwyrvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-691
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3ocwyrvx
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.64it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 97.98it/s]  16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 99.98it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 99.75it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 100.83it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 104.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 102.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 102.44it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 105.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 108.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 107.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 106.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 105.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 105.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 107.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 108.52it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 109.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 105.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.51
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.5017
wandb: sub_train_loss 0.00706
wandb:       test_acc 0.495
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run neat-sweep-691 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/3ocwyrvx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150118-3ocwyrvx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0krq0ity with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150133-0krq0ity
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-692
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0krq0ity
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.06it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 109.24it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.18it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.63it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 114.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 115.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 114.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 114.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 115.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 116.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 115.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 116.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.516
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.47132
wandb: sub_train_loss 0.05578
wandb:       test_acc 0.476
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run confused-sweep-692 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/0krq0ity
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150133-0krq0ity/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2tyw4dn9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150148-2tyw4dn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-693
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2tyw4dn9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.14it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.75it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.57it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 116.59it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 116.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 117.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 117.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 117.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 118.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 117.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 117.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 115.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 115.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 115.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 116.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 117.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.55191
wandb: sub_train_loss 0.33722
wandb:       test_acc 0.577
wandb:      valid_acc 0.596
wandb: 
wandb: üöÄ View run trim-sweep-693 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2tyw4dn9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150148-2tyw4dn9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4nvdxtxa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150204-4nvdxtxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-694
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4nvdxtxa
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 104.43it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 104.44it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 100.68it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 99.62it/s]  28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 100.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 105.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 106.54it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 107.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 106.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 105.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 105.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 106.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 104.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 103.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 102.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 93.89it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 97.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 102.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.566
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.53781
wandb: sub_train_loss 0.12304
wandb:       test_acc 0.518
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run astral-sweep-694 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4nvdxtxa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150204-4nvdxtxa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6fy9pvgo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150219-6fy9pvgo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-695
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6fy9pvgo
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.11it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 110.53it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 108.38it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 107.92it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 101.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 103.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 103.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 104.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 104.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 105.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 107.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 109.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 111.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 111.21it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 111.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 110.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 107.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 107.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.67343
wandb: sub_train_loss 0.08437
wandb:       test_acc 0.686
wandb:      valid_acc 0.71
wandb: 
wandb: üöÄ View run comic-sweep-695 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/6fy9pvgo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150219-6fy9pvgo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 17ryjrlh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150230-17ryjrlh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-696
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/17ryjrlh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.47it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.89it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.08it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.18it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 118.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 118.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 118.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 118.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 118.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 119.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 119.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 118.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 118.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 118.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 118.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 118.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.745
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.64437
wandb: sub_train_loss 0.1166
wandb:       test_acc 0.663
wandb:      valid_acc 0.696
wandb: 
wandb: üöÄ View run hardy-sweep-696 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/17ryjrlh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150230-17ryjrlh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: itwezqj9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150245-itwezqj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-697
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/itwezqj9
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.96it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 102.60it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 103.99it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 104.27it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 104.83it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 104.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 104.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 104.24it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 104.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 104.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 104.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 104.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 105.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 104.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 96.53it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 87.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 85.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 81.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.70503
wandb: sub_train_loss 0.07262
wandb:       test_acc 0.72
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run confused-sweep-697 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/itwezqj9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150245-itwezqj9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f5781u30 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150301-f5781u30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-698
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f5781u30
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.96it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 103.40it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 101.42it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 103.17it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 101.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 100.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 102.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 104.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 106.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 107.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 105.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 106.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 109.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 110.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 111.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 111.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 112.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 107.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.72465
wandb: sub_train_loss 0.06812
wandb:       test_acc 0.76
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run classic-sweep-698 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f5781u30
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150301-f5781u30/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rtwyxi62 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150321-rtwyxi62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-699
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rtwyxi62
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.87it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 110.85it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 113.74it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.85it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 115.81it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 117.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 118.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 119.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 117.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 116.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 115.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 114.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 114.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 114.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 113.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 112.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.72511
wandb: sub_train_loss 0.04933
wandb:       test_acc 0.753
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run colorful-sweep-699 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rtwyxi62
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150321-rtwyxi62/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ot15sitj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150337-ot15sitj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-700
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ot15sitj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.38it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.87it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.50it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 114.07it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 111.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 110.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 107.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 108.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 107.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 106.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 106.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 106.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 107.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 107.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 107.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 107.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 107.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.70462
wandb: sub_train_loss 0.11807
wandb:       test_acc 0.73
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run sweet-sweep-700 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ot15sitj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150337-ot15sitj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 20eonata with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150353-20eonata
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-701
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/20eonata
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.93it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 100.17it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 100.09it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.79it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 104.59it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 106.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 109.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 110.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 110.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 108.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 107.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 105.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 104.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 108.79it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 111.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 113.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 114.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.70416
wandb: sub_train_loss 0.22107
wandb:       test_acc 0.701
wandb:      valid_acc 0.718
wandb: 
wandb: üöÄ View run distinctive-sweep-701 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/20eonata
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150353-20eonata/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pp6nt0u5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150408-pp6nt0u5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-702
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pp6nt0u5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 103.25it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 106.04it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 108.64it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 109.87it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 111.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 112.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 112.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 113.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 115.18it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 116.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 117.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 117.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 117.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 115.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 114.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 113.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.63351
wandb: sub_train_loss 0.10723
wandb:       test_acc 0.63
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run fluent-sweep-702 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/pp6nt0u5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150408-pp6nt0u5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a6ysgq0q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150425-a6ysgq0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-703
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a6ysgq0q
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.20it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.38it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.85it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 108.92it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 108.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 111.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 112.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 111.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 111.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 110.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 110.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 110.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 110.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 110.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 111.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 111.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 111.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.67064
wandb: sub_train_loss 0.40343
wandb:       test_acc 0.67
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run silvery-sweep-703 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/a6ysgq0q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150425-a6ysgq0q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xm17nz1k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150441-xm17nz1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-704
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xm17nz1k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.27it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 112.94it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.87it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.52it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 113.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 113.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 114.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 114.49it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 115.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 115.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 115.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 115.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 115.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 115.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 115.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 114.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.8
wandb:  sub_train_acc 0.74697
wandb: sub_train_loss 0.0934
wandb:       test_acc 0.746
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run bumbling-sweep-704 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xm17nz1k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150441-xm17nz1k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xyh5pru0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150457-xyh5pru0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-705
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xyh5pru0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 86.09it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.22it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 89.23it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 86.64it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 86.71it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 86.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 87.57it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 88.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 88.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 88.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 87.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 87.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 87.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 86.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 87.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 85.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 84.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 85.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 85.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:02<00:00, 85.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 86.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 87.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 86.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.427
wandb: best_valid_acc 0.444
wandb:  sub_train_acc 0.27869
wandb: sub_train_loss 0.01226
wandb:       test_acc 0.188
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run driven-sweep-705 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xyh5pru0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150457-xyh5pru0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sdm9wqca with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150511-sdm9wqca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-706
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sdm9wqca
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 8/200 [00:00<00:02, 78.51it/s]  8%|‚ñä         | 17/200 [00:00<00:02, 80.41it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:02, 81.47it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:02, 80.94it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 80.57it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 81.56it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 82.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 84.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 86.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:01<00:01, 87.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 88.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 89.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 90.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 91.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 92.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 92.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 92.29it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 92.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:02<00:00, 92.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 91.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 88.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.404
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.23254
wandb: sub_train_loss 0.25005
wandb:       test_acc 0.18
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run cool-sweep-706 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sdm9wqca
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150511-sdm9wqca/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v1vf90di with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150527-v1vf90di
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-707
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v1vf90di
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 89.70it/s] 10%|‚ñâ         | 19/200 [00:00<00:02, 85.09it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 86.49it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 87.33it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 87.49it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 87.89it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 89.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 91.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 91.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:01<00:01, 92.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:01, 93.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 94.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 94.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 92.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 91.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 90.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 91.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 92.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:02<00:00, 93.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:02<00:00, 93.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 91.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.518
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.46052
wandb: sub_train_loss 0.31739
wandb:       test_acc 0.381
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run stellar-sweep-707 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/v1vf90di
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150527-v1vf90di/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bxbppbs4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150542-bxbppbs4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-708
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bxbppbs4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 91.72it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 90.73it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 90.12it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 90.97it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 84.21it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 81.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 79.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 78.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:01<00:01, 78.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 77.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 77.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:01, 77.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:01, 77.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 77.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 77.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 76.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 76.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 79.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:02<00:00, 80.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:02<00:00, 81.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:02<00:00, 82.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 82.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 80.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.53056
wandb: sub_train_loss 0.00613
wandb:       test_acc 0.489
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run rare-sweep-708 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/bxbppbs4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150542-bxbppbs4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 416htcl0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150558-416htcl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-709
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/416htcl0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.34it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 85.85it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 86.58it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 89.82it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 89.37it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 88.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 87.66it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 88.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 89.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 89.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 89.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 89.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 89.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 88.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 88.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 88.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 88.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 89.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 89.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:02<00:00, 88.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:02<00:00, 87.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 88.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.646
wandb: best_valid_acc 0.676
wandb:  sub_train_acc 0.544
wandb: sub_train_loss 0.26112
wandb:       test_acc 0.488
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run lemon-sweep-709 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/416htcl0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150558-416htcl0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 85nibk7y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150619-85nibk7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-710
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/85nibk7y
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 90.90it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 90.18it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 89.57it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 89.08it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 88.04it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 86.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 86.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 85.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 84.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:01<00:01, 81.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 82.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:01, 83.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 83.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 83.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 82.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 82.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 83.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 83.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:02<00:00, 82.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:02<00:00, 83.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 83.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 84.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.706
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.53035
wandb: sub_train_loss 0.68173
wandb:       test_acc 0.566
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run radiant-sweep-710 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/85nibk7y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150619-85nibk7y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s6n31wno with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150643-s6n31wno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-711
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s6n31wno
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.74it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.34it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.42it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 94.38it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 93.08it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 91.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 90.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 89.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 89.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 88.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:01, 88.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 88.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 88.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 88.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 88.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 87.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 87.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 87.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 87.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:02<00:00, 88.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 89.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.59274
wandb: sub_train_loss 0.55101
wandb:       test_acc 0.492
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run laced-sweep-711 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/s6n31wno
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150643-s6n31wno/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zr2s06yu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150658-zr2s06yu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-712
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zr2s06yu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 89.02it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 87.72it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 87.26it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 88.03it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 88.62it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 87.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 85.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 86.42it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 86.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:01<00:01, 89.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 89.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 90.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 90.67it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 91.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 92.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 92.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 93.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 93.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:02<00:00, 93.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 94.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.759
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.6574
wandb: sub_train_loss 0.03105
wandb:       test_acc 0.673
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run legendary-sweep-712 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zr2s06yu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150658-zr2s06yu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 14x70m5k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150713-14x70m5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-713
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/14x70m5k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 8/200 [00:00<00:02, 79.86it/s]  8%|‚ñä         | 17/200 [00:00<00:02, 80.53it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:02, 81.90it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 84.66it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 85.94it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 87.28it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 87.83it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 88.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 89.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:01<00:01, 89.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:01<00:01, 88.57it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:01, 88.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 88.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 88.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 87.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 82.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 82.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 84.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 85.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:02<00:00, 87.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 90.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 87.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.65192
wandb: sub_train_loss 0.12381
wandb:       test_acc 0.72
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run solar-sweep-713 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/14x70m5k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150713-14x70m5k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gs7yyyja with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150729-gs7yyyja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-714
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gs7yyyja
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 91.53it/s] 10%|‚ñà         | 20/200 [00:00<00:02, 88.37it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 86.29it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 87.49it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 90.11it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 87.77it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 85.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 83.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:01<00:01, 80.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:01<00:01, 78.52it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 75.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 73.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:01, 73.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:01, 72.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 74.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 75.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 78.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 82.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:02<00:00, 86.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:02<00:00, 89.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 91.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 83.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.65542
wandb: sub_train_loss 1.10401
wandb:       test_acc 0.7
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run feasible-sweep-714 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gs7yyyja
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150729-gs7yyyja/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ws0t77tz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150743-ws0t77tz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-715
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ws0t77tz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.97it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.05it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 99.66it/s]  21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 97.23it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 93.76it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 91.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 86.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 86.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 87.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 88.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:01, 88.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 88.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 83.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 77.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 80.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 84.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 87.59it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 90.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:02<00:00, 92.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:02<00:00, 94.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñà
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.724
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.62941
wandb: sub_train_loss 1.93878
wandb:       test_acc 0.646
wandb:      valid_acc 0.624
wandb: 
wandb: üöÄ View run good-sweep-715 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ws0t77tz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150743-ws0t77tz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dfciwny2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150759-dfciwny2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-716
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfciwny2
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.74it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.59it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.54it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 92.44it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 90.58it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 91.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 93.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 95.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 97.25it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:00, 98.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 98.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 98.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 98.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 99.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 99.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 99.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 99.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 99.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 99.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.56763
wandb: sub_train_loss 1.6316
wandb:       test_acc 0.586
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run lyric-sweep-716 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dfciwny2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150759-dfciwny2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lswfr5ta with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150815-lswfr5ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-717
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lswfr5ta
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 91.27it/s] 10%|‚ñà         | 20/200 [00:00<00:02, 88.01it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 90.28it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 92.44it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 91.85it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 90.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 90.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 90.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 90.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 90.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 90.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 90.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 90.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 90.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 90.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 90.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 90.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 90.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 90.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.761
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.72962
wandb: sub_train_loss 0.35866
wandb:       test_acc 0.715
wandb:      valid_acc 0.728
wandb: 
wandb: üöÄ View run polar-sweep-717 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lswfr5ta
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150815-lswfr5ta/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yup526fd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150829-yup526fd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-718
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yup526fd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.11it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.38it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 98.10it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 97.81it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 98.23it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 98.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 98.98it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 98.50it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 97.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 98.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 98.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 98.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 96.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 96.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 97.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 96.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 96.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 96.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 96.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.66998
wandb: sub_train_loss 1.22751
wandb:       test_acc 0.696
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run legendary-sweep-718 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/yup526fd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150829-yup526fd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 92kzm8cm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150845-92kzm8cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-719
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/92kzm8cm
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 90.64it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 90.60it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 89.54it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 88.90it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 89.07it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 88.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 89.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 89.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 89.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:01<00:01, 89.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:01<00:01, 89.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 89.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 89.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 89.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 88.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 89.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 89.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 89.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 89.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 88.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:02<00:00, 88.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà
wandb:       test_acc ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.771
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.39377
wandb: sub_train_loss 3.65822
wandb:       test_acc 0.416
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run scarlet-sweep-719 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/92kzm8cm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150845-92kzm8cm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gh08mbvb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150900-gh08mbvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-720
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gh08mbvb
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.52it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.78it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.28it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 94.86it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 95.55it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 95.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 96.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 96.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 96.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 96.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 96.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 95.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 95.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 96.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 96.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 95.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 95.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 95.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 95.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.70538
wandb: sub_train_loss 0.59879
wandb:       test_acc 0.712
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run cerulean-sweep-720 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gh08mbvb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150900-gh08mbvb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: abvsw8p5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150916-abvsw8p5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-721
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/abvsw8p5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.79it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.75it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.73it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 135.01it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.90it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 134.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 136.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 136.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 137.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 138.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 138.33it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 137.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 137.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 137.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 137.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 136.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 136.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 137.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 137.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 138.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.40158
wandb: sub_train_loss 0.00011
wandb:       test_acc 0.413
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run swept-sweep-721 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/abvsw8p5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150916-abvsw8p5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 16abrfpn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150932-16abrfpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-722
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/16abrfpn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.90it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.50it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.97it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.66it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 150.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 151.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 151.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 151.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 152.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 152.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 152.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 152.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 152.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 152.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 152.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 152.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 152.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.435
wandb: best_valid_acc 0.47
wandb:  sub_train_acc 0.3956
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.406
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run cerulean-sweep-722 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/16abrfpn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150932-16abrfpn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1vmcmepp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_150947-1vmcmepp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-723
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1vmcmepp
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.11it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 148.63it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 149.83it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.78it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 149.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 151.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 151.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 151.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 151.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 150.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 150.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 150.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 150.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 150.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 150.51it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 150.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 150.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.501
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.47446
wandb: sub_train_loss 0.00145
wandb:       test_acc 0.479
wandb:      valid_acc 0.49
wandb: 
wandb: üöÄ View run helpful-sweep-723 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1vmcmepp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_150947-1vmcmepp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m5pquh28 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151002-m5pquh28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-724
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m5pquh28
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.87it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.25it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.85it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 148.32it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 148.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 150.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 149.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 146.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 145.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 144.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 143.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 143.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 142.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 142.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 141.21it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 140.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 141.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 143.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 145.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.518
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.49521
wandb: sub_train_loss 0.00024
wandb:       test_acc 0.497
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run stoic-sweep-724 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/m5pquh28
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151002-m5pquh28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: brjhjmbn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151018-brjhjmbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-725
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/brjhjmbn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.83it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.63it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.57it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 146.44it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.64it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 148.30it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 148.42it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 149.44it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 148.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:00, 149.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 149.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 149.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 148.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 148.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 149.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 150.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 150.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 150.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 151.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.589
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.59958
wandb: sub_train_loss 0.00094
wandb:       test_acc 0.588
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run skilled-sweep-725 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/brjhjmbn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151018-brjhjmbn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uxoub0pd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151033-uxoub0pd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-726
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uxoub0pd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.96it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 149.00it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.80it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.40it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 142.82it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 142.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 142.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 142.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 144.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 146.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 147.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 147.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 147.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 148.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 148.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 147.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 148.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 148.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 147.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.608
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.61424
wandb: sub_train_loss 0.00337
wandb:       test_acc 0.613
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run lively-sweep-726 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/uxoub0pd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151033-uxoub0pd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wsmm4lsd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151048-wsmm4lsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-727
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wsmm4lsd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.73it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 140.55it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.11it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 143.21it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 144.04it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 140.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 139.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 143.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 144.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 142.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 143.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 144.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 143.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 142.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 142.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 140.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 142.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 142.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.68611
wandb: sub_train_loss 0.01678
wandb:       test_acc 0.713
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run icy-sweep-727 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/wsmm4lsd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151048-wsmm4lsd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f70xfm09 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151104-f70xfm09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-728
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f70xfm09
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.22it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 131.89it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.88it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 134.87it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 137.31it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 138.55it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 141.75it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 144.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 145.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 147.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 148.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 149.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 149.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 149.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 150.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 150.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 149.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 149.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 148.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.68804
wandb: sub_train_loss 0.09853
wandb:       test_acc 0.708
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run prime-sweep-728 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/f70xfm09
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151104-f70xfm09/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: huop6ca0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151118-huop6ca0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-729
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/huop6ca0
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.49it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.46it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 142.90it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 143.72it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 144.29it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 145.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 147.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 149.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 150.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 150.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 151.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 151.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 151.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 150.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 150.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 151.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 151.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 152.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 152.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.71
wandb: sub_train_loss 0.01367
wandb:       test_acc 0.738
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run eager-sweep-729 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/huop6ca0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151118-huop6ca0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sc4uybm3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151134-sc4uybm3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-730
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sc4uybm3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.85it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 126.71it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 129.58it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 129.31it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 128.84it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 127.34it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 130.48it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 135.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 139.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 141.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 143.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 144.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 144.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 144.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 144.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 144.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 145.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 144.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 145.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 145.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.752
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.71294
wandb: sub_train_loss 0.01727
wandb:       test_acc 0.753
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run glorious-sweep-730 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/sc4uybm3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151134-sc4uybm3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2i8z4us7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151152-2i8z4us7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-731
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2i8z4us7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.42it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 130.59it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.16it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 127.56it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 126.17it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 128.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 130.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 130.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 129.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 128.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 128.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 128.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 128.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 128.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 130.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 129.98it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 130.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 130.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 130.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 130.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 130.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.70051
wandb: sub_train_loss 0.00397
wandb:       test_acc 0.731
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run dashing-sweep-731 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/2i8z4us7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151152-2i8z4us7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4jp6op3j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151207-4jp6op3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-732
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4jp6op3j
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.14it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 139.23it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 138.72it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 138.90it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 137.67it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 137.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 136.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 136.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 136.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 136.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 136.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 135.40it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 135.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 135.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 136.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 135.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 135.86it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 136.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 137.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 138.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 139.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.72339
wandb: sub_train_loss 0.0231
wandb:       test_acc 0.742
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run vital-sweep-732 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/4jp6op3j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151207-4jp6op3j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jttawodn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151221-jttawodn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-733
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jttawodn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.37it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 139.48it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 139.17it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 140.03it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 139.12it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 138.64it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 141.80it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 143.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 144.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 145.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 146.36it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 146.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 146.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 146.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 146.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 146.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 144.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 145.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 144.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 141.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.73459
wandb: sub_train_loss 0.00686
wandb:       test_acc 0.756
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run skilled-sweep-733 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/jttawodn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151221-jttawodn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: on3c6khd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151237-on3c6khd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-734
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/on3c6khd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.68it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.96it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.86it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.94it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 146.53it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 145.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 146.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 146.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 147.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 147.34it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 147.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 147.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 148.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 148.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 144.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 141.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 140.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 140.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 140.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.72597
wandb: sub_train_loss 0.02581
wandb:       test_acc 0.75
wandb:      valid_acc 0.766
wandb: 
wandb: üöÄ View run daily-sweep-734 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/on3c6khd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151237-on3c6khd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gtb796j5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151251-gtb796j5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-735
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gtb796j5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.13it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 129.93it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 129.49it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 128.96it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 128.82it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 130.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 133.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 137.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 140.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 142.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 143.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 142.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 143.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 143.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 142.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 140.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 139.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 138.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 138.42it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 138.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.752
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.69722
wandb: sub_train_loss 0.071
wandb:       test_acc 0.712
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run dandy-sweep-735 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gtb796j5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151251-gtb796j5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1uvmumi7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151307-1uvmumi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-736
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1uvmumi7
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.36it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.71it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.41it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 140.78it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 141.84it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 142.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 142.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 143.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 143.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 143.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 143.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 143.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 143.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 143.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 143.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 143.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 143.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 142.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 142.82it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 142.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.762
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.73972
wandb: sub_train_loss 0.03558
wandb:       test_acc 0.749
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run lemon-sweep-736 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1uvmumi7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151307-1uvmumi7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: db4jg1ym with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151322-db4jg1ym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-737
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/db4jg1ym
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.68it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.33it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 116.05it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.63it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 114.88it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 116.56it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 117.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 117.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 115.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 114.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 113.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 112.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 111.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 111.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 110.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 110.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 112.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 114.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 114.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 113.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 114.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 114.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 110.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 111.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.394
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.35411
wandb: sub_train_loss 0.0
wandb:       test_acc 0.35
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run winter-sweep-737 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/db4jg1ym
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151322-db4jg1ym/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zwdvy1k3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151338-zwdvy1k3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-738
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zwdvy1k3
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.22it/s]  7%|‚ñã         | 22/300 [00:00<00:03, 88.36it/s]  11%|‚ñà         | 33/300 [00:00<00:02, 96.27it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 100.24it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 105.69it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 108.53it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 111.24it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 114.68it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 116.43it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 118.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 119.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 120.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 120.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 121.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 121.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 121.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 122.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 122.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 121.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 121.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 121.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 121.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 121.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.436
wandb: best_valid_acc 0.456
wandb:  sub_train_acc 0.34123
wandb: sub_train_loss 0.0
wandb:       test_acc 0.323
wandb:      valid_acc 0.352
wandb: 
wandb: üöÄ View run chocolate-sweep-738 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/zwdvy1k3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151338-zwdvy1k3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 781obevl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151353-781obevl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-739
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/781obevl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 109.88it/s]  7%|‚ñã         | 22/300 [00:00<00:03, 90.98it/s]  11%|‚ñà         | 33/300 [00:00<00:02, 95.17it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 96.38it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 96.95it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 97.15it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 96.23it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 96.81it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:02, 97.27it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:01, 98.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 99.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 99.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 99.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 100.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 99.63it/s]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 100.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 98.89it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 98.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 98.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 100.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 102.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 104.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 106.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 106.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 107.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 108.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 108.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 108.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 101.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.519
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.48892
wandb: sub_train_loss 0.11452
wandb:       test_acc 0.466
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run colorful-sweep-739 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/781obevl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151353-781obevl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z36pug7h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151408-z36pug7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-740
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z36pug7h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.73it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 93.92it/s]  11%|‚ñà         | 32/300 [00:00<00:02, 91.00it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 98.30it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 103.52it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 107.15it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 111.42it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 113.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 115.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 115.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 115.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 115.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 115.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 116.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 115.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 115.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 116.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 117.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 118.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 118.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 118.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 119.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 119.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 119.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.512
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.49064
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.491
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run quiet-sweep-740 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/z36pug7h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151408-z36pug7h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 80112lvr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151425-80112lvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-741
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/80112lvr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.75it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 111.50it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 110.26it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 109.73it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 110.55it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 110.74it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 109.74it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 109.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 110.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 108.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 108.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 107.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 106.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 107.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 108.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 108.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 109.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 109.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 108.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 108.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 108.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 109.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 109.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 109.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 109.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.648
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.4169
wandb: sub_train_loss 1.48721
wandb:       test_acc 0.317
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run expert-sweep-741 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/80112lvr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151425-80112lvr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aah9e6au with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151439-aah9e6au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-742
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aah9e6au
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 112.73it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 113.16it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 116.17it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 117.90it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 118.24it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 118.88it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 117.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 118.10it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 118.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 118.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 118.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 118.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 118.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 117.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 117.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 117.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 117.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 117.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 118.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 118.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 118.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 119.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 117.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 118.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.68342
wandb: sub_train_loss 0.03667
wandb:       test_acc 0.731
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run skilled-sweep-742 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aah9e6au
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151439-aah9e6au/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 79t8xan4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151456-79t8xan4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-743
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79t8xan4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 117.96it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 119.47it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 120.63it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 119.83it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 119.32it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 119.28it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 119.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 119.97it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 120.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 120.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 119.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 119.90it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 119.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 119.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 119.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 119.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 119.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 119.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 118.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 117.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 118.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 119.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 119.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 119.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.52396
wandb: sub_train_loss 0.33153
wandb:       test_acc 0.5
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run stellar-sweep-743 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/79t8xan4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151456-79t8xan4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dh3x4q8k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151511-dh3x4q8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-744
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dh3x4q8k
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.52it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.06it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 118.34it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 118.64it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 117.98it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 117.92it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 117.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 118.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 118.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 118.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 118.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 118.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 118.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 118.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 117.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 117.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 117.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 117.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 117.09it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 117.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 117.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 117.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 117.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 117.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.783
wandb: best_valid_acc 0.806
wandb:  sub_train_acc 0.52346
wandb: sub_train_loss 0.66675
wandb:       test_acc 0.51
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run drawn-sweep-744 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/dh3x4q8k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151511-dh3x4q8k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xhrjpyml with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151527-xhrjpyml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-745
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xhrjpyml
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.28it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 105.36it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 106.50it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 108.51it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 109.43it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 109.82it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 109.70it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 110.09it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 108.50it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 109.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 110.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 112.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 111.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 111.49it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 111.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 109.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 108.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 107.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 109.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 109.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 111.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 110.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 111.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 109.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 108.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.752
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.43211
wandb: sub_train_loss 1.06568
wandb:       test_acc 0.422
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run wild-sweep-745 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xhrjpyml
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151527-xhrjpyml/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nir24rxj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151542-nir24rxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-746
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nir24rxj
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 105.68it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.04it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 98.66it/s]  14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 98.71it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 100.45it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 102.15it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 104.12it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 104.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 104.25it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 104.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 104.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 105.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 105.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 105.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 104.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 104.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 105.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 106.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 106.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 107.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 107.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 107.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 107.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 107.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 107.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 107.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 107.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 105.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñà
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.52863
wandb: sub_train_loss 1.08712
wandb:       test_acc 0.526
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run divine-sweep-746 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/nir24rxj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151542-nir24rxj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gxj4zn04 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151557-gxj4zn04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-747
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gxj4zn04
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.43it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 108.21it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 106.53it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 104.61it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 107.01it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 108.65it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 110.55it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 111.63it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 110.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 108.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 110.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 110.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 112.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 113.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 114.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 111.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 111.88it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 113.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 113.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 113.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 113.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 112.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 102.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 104.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 106.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.45392
wandb: sub_train_loss 2.24827
wandb:       test_acc 0.466
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run neat-sweep-747 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/gxj4zn04
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151557-gxj4zn04/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5v9nusfn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151621-5v9nusfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-748
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5v9nusfn
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.00it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 113.05it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 112.84it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.57it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 115.23it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 116.18it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 115.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 116.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 115.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 115.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 112.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 111.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 111.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 111.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 110.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 109.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 109.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 109.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 110.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 110.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 109.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 110.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 110.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 110.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñà
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñá‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.63422
wandb: sub_train_loss 2.0272
wandb:       test_acc 0.641
wandb:      valid_acc 0.616
wandb: 
wandb: üöÄ View run snowy-sweep-748 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5v9nusfn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151621-5v9nusfn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ojcm94ln with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151636-ojcm94ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-749
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojcm94ln
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.24it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 108.81it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 106.58it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 108.77it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 109.24it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 108.78it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 105.91it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 105.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 105.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 105.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 105.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 106.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 106.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 108.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 108.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 109.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 108.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 107.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 106.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 107.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 108.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 111.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 113.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 115.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 115.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 116.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.785
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.67738
wandb: sub_train_loss 0.39486
wandb:       test_acc 0.671
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run crimson-sweep-749 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ojcm94ln
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151636-ojcm94ln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rwiyze00 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151652-rwiyze00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-750
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rwiyze00
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 108.42it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.69it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 108.52it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 112.41it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 113.78it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 113.74it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 114.77it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 114.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 114.78it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 114.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 114.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 115.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 115.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 115.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 115.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 115.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 115.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 115.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 113.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 109.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 107.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 105.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 105.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 104.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 103.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.55363
wandb: sub_train_loss 1.05464
wandb:       test_acc 0.533
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run lunar-sweep-750 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rwiyze00
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151652-rwiyze00/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rk8qlhjz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151708-rk8qlhjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-751
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rk8qlhjz
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 109.68it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 111.49it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 112.04it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 109.25it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 111.64it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 113.12it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 114.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 115.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 113.73it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 113.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 114.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 115.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 115.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 115.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 115.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 115.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 113.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 112.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 111.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 110.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 109.71it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 109.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 109.57it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 108.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 108.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.748
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.45915
wandb: sub_train_loss 2.23352
wandb:       test_acc 0.484
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run silver-sweep-751 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/rk8qlhjz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151708-rk8qlhjz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7mcwxp07 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151724-7mcwxp07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-752
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7mcwxp07
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 110.56it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.48it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 111.70it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 111.81it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 112.25it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 112.24it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 113.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 113.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 113.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 112.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 111.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 112.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 112.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 112.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 111.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 112.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 112.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 110.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 110.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 110.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 111.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 110.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 111.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 111.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 111.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.772
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.45276
wandb: sub_train_loss 2.88959
wandb:       test_acc 0.468
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run denim-sweep-752 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7mcwxp07
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151724-7mcwxp07/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1y4prtdl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151739-1y4prtdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-753
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1y4prtdl
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.48it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.05it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.22it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 93.34it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.53it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 91.80it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 91.09it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.76it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 91.97it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 90.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 89.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 89.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 88.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 87.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 86.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 86.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:02<00:01, 86.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 85.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 86.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:01, 86.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 86.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 86.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 85.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 84.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 84.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 84.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:03<00:00, 85.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 84.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 84.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 88.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.504
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.31227
wandb: sub_train_loss 0.0
wandb:       test_acc 0.204
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run golden-sweep-753 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/1y4prtdl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151739-1y4prtdl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lbnrgta5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151755-lbnrgta5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-754
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbnrgta5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.42it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.40it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.61it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.18it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.45it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 93.01it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 93.69it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 93.57it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 91.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 90.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 90.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 91.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 91.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 91.17it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 91.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 92.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 93.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 93.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 93.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 95.32it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 96.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 96.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 96.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 96.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 95.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 94.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 95.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 95.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.473
wandb: best_valid_acc 0.51
wandb:  sub_train_acc 0.31962
wandb: sub_train_loss 0.00043
wandb:       test_acc 0.193
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run upbeat-sweep-754 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/lbnrgta5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151755-lbnrgta5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8tczw8iu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151811-8tczw8iu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-755
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8tczw8iu
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.36it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.05it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 91.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.21it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 91.14it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 90.48it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 91.10it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.05it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 91.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 90.98it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 92.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 94.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 95.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 97.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 97.97it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 98.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 98.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 98.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:00, 99.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 100.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 100.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 100.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 100.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 101.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 101.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 100.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 100.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.55it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.561
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.57549
wandb: sub_train_loss 0.08438
wandb:       test_acc 0.508
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run amber-sweep-755 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/8tczw8iu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151811-8tczw8iu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ehty4efh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151825-ehty4efh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-756
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ehty4efh
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.65it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.77it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 96.72it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 98.27it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 99.53it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 99.04it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 98.61it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 98.62it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 98.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:01, 99.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 99.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 99.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 99.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 99.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 99.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 99.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 98.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 99.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:01, 99.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:00, 99.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 100.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 99.96it/s]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 99.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 99.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 100.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 100.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 100.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 99.93it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.545
wandb: best_valid_acc 0.57
wandb:  sub_train_acc 0.4449
wandb: sub_train_loss 0.27562
wandb:       test_acc 0.397
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run driven-sweep-756 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ehty4efh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151825-ehty4efh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w5opiqj4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151841-w5opiqj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-757
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5opiqj4
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 91.27it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 88.42it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 90.11it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 91.94it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.84it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.33it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 92.19it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.79it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 91.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 91.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 90.86it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 90.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 90.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 90.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 91.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 91.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 91.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 91.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 91.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 91.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 91.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 91.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 90.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 93.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 95.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 94.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 93.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 93.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.66587
wandb: sub_train_loss 0.15878
wandb:       test_acc 0.695
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run apricot-sweep-757 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/w5opiqj4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151841-w5opiqj4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h0s3ni6h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151856-h0s3ni6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-758
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0s3ni6h
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.43it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 98.32it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 99.71it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 98.83it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 99.09it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 99.77it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 99.53it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 99.46it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:02, 99.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:01, 99.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 99.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 100.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 99.97it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 100.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 97.92it/s]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 95.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 94.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 93.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 92.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 92.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 92.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 91.75it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 91.51it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 92.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 91.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 91.44it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 91.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 91.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 91.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.706
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.58594
wandb: sub_train_loss 0.2365
wandb:       test_acc 0.52
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run vocal-sweep-758 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/h0s3ni6h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151856-h0s3ni6h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7i3t4xlg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151920-7i3t4xlg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-759
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7i3t4xlg
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 87.43it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 86.27it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 86.37it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 85.19it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 86.11it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 87.16it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 85.91it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 84.82it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 84.07it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:01<00:02, 84.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 84.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:02, 84.86it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 85.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:02, 85.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 85.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 86.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 86.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 86.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 85.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:02<00:01, 86.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 86.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 86.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 86.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 86.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 87.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 89.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 89.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 90.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:03<00:00, 90.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:03<00:00, 90.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 90.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 89.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 87.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.6186
wandb: sub_train_loss 0.65091
wandb:       test_acc 0.588
wandb:      valid_acc 0.596
wandb: 
wandb: üöÄ View run zesty-sweep-759 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/7i3t4xlg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151920-7i3t4xlg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5jqved9p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151937-5jqved9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-760
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5jqved9p
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.99it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.80it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.37it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 93.76it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.78it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.55it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 91.92it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.03it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 90.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 90.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 89.89it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:02, 89.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 90.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 90.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 90.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 90.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 91.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 91.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 91.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 91.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 91.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 92.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 93.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 94.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 92.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 91.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 90.46it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:03<00:00, 89.74it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 87.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 88.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.772
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.55054
wandb: sub_train_loss 0.39948
wandb:       test_acc 0.575
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run comic-sweep-760 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/5jqved9p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151937-5jqved9p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xucqn5gd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_151953-xucqn5gd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-761
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xucqn5gd
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 87.59it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 89.97it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 91.14it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 92.62it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 93.97it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 95.12it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 95.40it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 94.37it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 94.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 93.34it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:02, 92.25it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 92.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 93.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 92.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 92.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 93.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 93.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 93.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 93.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 94.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 93.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 92.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 91.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 91.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 91.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 92.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 92.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:03<00:00, 92.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:03<00:00, 91.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 91.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.48831
wandb: sub_train_loss 1.63541
wandb:       test_acc 0.47
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run proud-sweep-761 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xucqn5gd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_151953-xucqn5gd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ujcapt0d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152008-ujcapt0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-762
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ujcapt0d
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 91.96it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 90.73it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 90.06it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 90.48it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 88.37it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 87.66it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 87.84it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 88.24it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 87.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:01<00:02, 86.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:02, 87.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:02, 87.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:02, 88.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 89.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 88.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 87.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 87.82it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 86.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:02<00:01, 87.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 88.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 86.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 83.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:01, 81.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 79.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 80.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 80.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 80.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:03<00:00, 79.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:03<00:00, 78.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:03<00:00, 78.37it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 79.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 79.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 84.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.59066
wandb: sub_train_loss 1.1365
wandb:       test_acc 0.602
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run serene-sweep-762 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/ujcapt0d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152008-ujcapt0d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u6g5fg30 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152024-u6g5fg30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-763
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u6g5fg30
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 87.15it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 90.15it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 88.67it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 87.46it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 87.09it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 87.44it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 87.40it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 87.68it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:02, 88.75it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:01<00:02, 88.25it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 88.69it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 89.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 90.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 89.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 90.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 90.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 92.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 93.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 95.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 96.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 96.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 96.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 97.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 98.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 98.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 98.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 98.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 98.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:03<00:00, 98.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 98.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.60329
wandb: sub_train_loss 1.1319
wandb:       test_acc 0.621
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run curious-sweep-763 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/u6g5fg30
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152024-u6g5fg30/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: efeypcf5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152039-efeypcf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-764
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/efeypcf5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.82it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.53it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.01it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 93.61it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 93.90it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.05it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 90.90it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 92.49it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 93.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.80it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 92.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 93.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 93.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 93.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 93.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 93.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 93.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 94.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 93.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 93.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 93.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 92.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 92.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 93.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 92.36it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 92.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 93.95it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 95.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 96.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.51235
wandb: sub_train_loss 0.76619
wandb:       test_acc 0.54
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run zany-sweep-764 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/efeypcf5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152039-efeypcf5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xt9p58h5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152055-xt9p58h5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-765
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xt9p58h5
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.68it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 94.44it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.09it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 87.41it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 85.33it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 83.75it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 83.72it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 84.07it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 84.68it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:01<00:02, 83.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:02, 82.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 83.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:02, 83.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:02, 83.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 84.63it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 85.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 85.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 84.85it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:02<00:01, 85.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:02<00:01, 86.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 86.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 88.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 90.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 92.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 91.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 90.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 90.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:03<00:00, 90.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:03<00:00, 91.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 89.55it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 87.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 86.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.786
wandb: best_valid_acc 0.8
wandb:  sub_train_acc 0.56849
wandb: sub_train_loss 0.56996
wandb:       test_acc 0.566
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run comic-sweep-765 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/xt9p58h5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152055-xt9p58h5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 48vleghr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152111-48vleghr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-766
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/48vleghr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.04it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 96.02it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.98it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 95.02it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.24it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 89.94it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 89.90it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 89.71it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 93.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 94.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 95.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 96.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 97.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 97.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 97.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 97.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 97.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 97.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 97.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 97.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 98.05it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 97.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 97.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 97.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 97.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 97.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 97.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 95.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.51844
wandb: sub_train_loss 0.66126
wandb:       test_acc 0.513
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run magic-sweep-766 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/48vleghr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152111-48vleghr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qcd4ubac with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152126-qcd4ubac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-767
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qcd4ubac
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 82.57it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 83.08it/s]  9%|‚ñâ         | 27/300 [00:00<00:03, 84.58it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 84.99it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:02, 85.32it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 85.22it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 86.12it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 86.04it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 86.12it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:01<00:02, 87.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 86.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:02, 85.26it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 84.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 86.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 87.43it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 89.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 88.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 88.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 88.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 88.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:02<00:01, 89.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 89.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 92.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 93.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 93.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 95.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 94.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 94.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:03<00:00, 95.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:03<00:00, 96.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 96.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb: sub_train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.761
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.47588
wandb: sub_train_loss 1.08816
wandb:       test_acc 0.495
wandb:      valid_acc 0.498
wandb: 
wandb: üöÄ View run fiery-sweep-767 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/qcd4ubac
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152126-qcd4ubac/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aub5yy5p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: PubmedGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240825_152141-aub5yy5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-768
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/sweeps/6gsz5jym
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aub5yy5p
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 19717 num_edges 88651
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 91.95it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.13it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 91.77it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 90.88it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 91.72it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 92.59it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 93.06it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 91.66it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 90.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 90.64it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 90.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 91.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 92.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 92.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 92.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 91.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 91.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 91.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 91.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 91.37it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 91.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 90.75it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 91.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 91.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 90.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 89.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:03<00:00, 90.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:03<00:00, 90.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 88.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.58721
wandb: sub_train_loss 0.6781
wandb:       test_acc 0.582
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run valiant-sweep-768 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp/runs/aub5yy5p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_pubmed_icassp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240825_152141-aub5yy5p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
