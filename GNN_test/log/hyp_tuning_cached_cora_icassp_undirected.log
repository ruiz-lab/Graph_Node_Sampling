nohup: ignoring input
wandb: Agent Starting Run: jgg0x4lr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Currently logged in as: jamesli-wks (jamesli-wks-johns-hopkins-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211437-jgg0x4lr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jgg0x4lr
Create sweep with ID: 75qqj6bw
Sweep URL: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:00<00:59,  3.37it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 118.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 191.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 246.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 279.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 306.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.178
wandb: best_valid_acc 0.188
wandb:  sub_train_acc 0.16987
wandb: sub_train_loss 1.19601
wandb:       test_acc 0.177
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run hardy-sweep-1 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jgg0x4lr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211437-jgg0x4lr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bt64g1jm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211452-bt64g1jm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bt64g1jm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 351.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 364.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 372.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 375.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 377.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 372.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.189
wandb: best_valid_acc 0.194
wandb:  sub_train_acc 0.18131
wandb: sub_train_loss 1.19491
wandb:       test_acc 0.183
wandb:      valid_acc 0.188
wandb: 
wandb: üöÄ View run vibrant-sweep-2 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bt64g1jm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211452-bt64g1jm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: txiusqj2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211508-txiusqj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/txiusqj2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 296.75it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 308.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 314.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 306.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 304.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 313.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 311.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.234
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.22378
wandb: sub_train_loss 1.2524
wandb:       test_acc 0.233
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run proud-sweep-3 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/txiusqj2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211508-txiusqj2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wfpxy2c4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211529-wfpxy2c4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wfpxy2c4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 353.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 363.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 372.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 377.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 380.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 375.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.2271
wandb: sub_train_loss 1.2529
wandb:       test_acc 0.234
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run rare-sweep-4 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wfpxy2c4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211529-wfpxy2c4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wev7rha0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211543-wev7rha0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wev7rha0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 345.46it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 357.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 349.30it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 349.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 349.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 349.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.427
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.33641
wandb: sub_train_loss 1.29636
wandb:       test_acc 0.305
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run driven-sweep-5 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wev7rha0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211543-wev7rha0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s8vhtfty with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211559-s8vhtfty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8vhtfty
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 348.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 349.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 344.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 344.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 342.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 344.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.406
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.34675
wandb: sub_train_loss 1.29693
wandb:       test_acc 0.302
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run vocal-sweep-6 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8vhtfty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211559-s8vhtfty/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u3rn30hs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211620-u3rn30hs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u3rn30hs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 361.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 367.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 365.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 364.02it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 365.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 365.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.323
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.30798
wandb: sub_train_loss 1.32611
wandb:       test_acc 0.313
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run major-sweep-7 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u3rn30hs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211620-u3rn30hs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zwido5h9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211637-zwido5h9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zwido5h9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 314.89it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 333.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 335.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 334.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 341.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 338.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.336
wandb: best_valid_acc 0.348
wandb:  sub_train_acc 0.32607
wandb: sub_train_loss 1.32661
wandb:       test_acc 0.336
wandb:      valid_acc 0.348
wandb: 
wandb: üöÄ View run winter-sweep-8 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zwido5h9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211637-zwido5h9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1o6d6khz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211651-1o6d6khz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1o6d6khz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 327.49it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 331.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 329.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 316.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 305.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 303.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 311.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.474
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.43648
wandb: sub_train_loss 1.34915
wandb:       test_acc 0.476
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run driven-sweep-9 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1o6d6khz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211651-1o6d6khz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9fsqxs3a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211707-9fsqxs3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fsqxs3a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 318.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 326.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 344.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 343.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 344.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 342.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.471
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.4531
wandb: sub_train_loss 1.34905
wandb:       test_acc 0.476
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run lively-sweep-10 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fsqxs3a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211707-9fsqxs3a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wosuaypm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211723-wosuaypm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wosuaypm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 312.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 305.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 306.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 311.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 316.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 319.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 315.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.539
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.52363
wandb: sub_train_loss 1.39228
wandb:       test_acc 0.54
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run smart-sweep-11 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wosuaypm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211723-wosuaypm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: quna3bty with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211738-quna3bty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/quna3bty
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 344.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 351.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 346.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 346.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 342.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 345.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.543
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.52363
wandb: sub_train_loss 1.39177
wandb:       test_acc 0.537
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run stoic-sweep-12 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/quna3bty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211738-quna3bty/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x02dt2qm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211753-x02dt2qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x02dt2qm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 288.34it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 283.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 282.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 287.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 293.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 304.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 299.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.634
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.61928
wandb: sub_train_loss 1.40113
wandb:       test_acc 0.634
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run worldly-sweep-13 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x02dt2qm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211753-x02dt2qm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b7584ydt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211805-b7584ydt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/b7584ydt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 347.16it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 353.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 357.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 354.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 358.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 357.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.614
wandb: best_valid_acc 0.614
wandb:  sub_train_acc 0.5949
wandb: sub_train_loss 1.40168
wandb:       test_acc 0.614
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run fine-sweep-14 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/b7584ydt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211805-b7584ydt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nboi3mnt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211819-nboi3mnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nboi3mnt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 289.14it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 288.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 308.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 322.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 330.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 334.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 323.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.655
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.69609
wandb: sub_train_loss 1.39968
wandb:       test_acc 0.671
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run bumbling-sweep-15 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nboi3mnt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211819-nboi3mnt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yz77r8pa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211829-yz77r8pa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yz77r8pa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 315.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 315.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 305.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 295.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 289.14it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 285.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.69682
wandb: sub_train_loss 1.40035
wandb:       test_acc 0.68
wandb:      valid_acc 0.696
wandb: 
wandb: üöÄ View run stellar-sweep-16 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yz77r8pa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211829-yz77r8pa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bapygemg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211845-bapygemg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bapygemg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.56it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 237.36it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 242.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 237.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 232.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 232.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 233.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 234.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.258
wandb: best_valid_acc 0.272
wandb:  sub_train_acc 0.27991
wandb: sub_train_loss 0.0472
wandb:       test_acc 0.206
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run desert-sweep-17 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bapygemg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211845-bapygemg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 22n62w4k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211901-22n62w4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/22n62w4k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 215.68it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 186.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 198.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 204.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 215.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 224.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 235.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 247.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 228.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.213
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.31536
wandb: sub_train_loss 0.02651
wandb:       test_acc 0.205
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run earthy-sweep-18 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/22n62w4k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211901-22n62w4k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ots02ymy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211915-ots02ymy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ots02ymy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 271.44it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 273.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 276.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 278.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 272.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 269.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 266.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.412
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.25665
wandb: sub_train_loss 0.02865
wandb:       test_acc 0.413
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run frosty-sweep-19 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ots02ymy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211915-ots02ymy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p5ngk3cu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211931-p5ngk3cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p5ngk3cu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 271.86it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 274.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 277.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 279.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 274.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 274.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 274.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.439
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.25997
wandb: sub_train_loss 0.0242
wandb:       test_acc 0.429
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run exalted-sweep-20 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p5ngk3cu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211931-p5ngk3cu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xuwbvlr4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_211946-xuwbvlr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xuwbvlr4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.50it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 253.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 238.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 217.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 215.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 227.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 237.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 235.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.491
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.39993
wandb: sub_train_loss 0.03491
wandb:       test_acc 0.492
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run toasty-sweep-21 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xuwbvlr4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_211946-xuwbvlr4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4mvm5xho with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212007-4mvm5xho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4mvm5xho
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 256.11it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 266.53it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 270.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 269.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 257.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 243.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 248.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 254.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.491
wandb: best_valid_acc 0.506
wandb:  sub_train_acc 0.4003
wandb: sub_train_loss 0.04366
wandb:       test_acc 0.492
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run worthy-sweep-22 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4mvm5xho
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212007-4mvm5xho/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j2rrl67q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212022-j2rrl67q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j2rrl67q
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 244.90it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 243.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 253.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 252.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 245.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 243.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 245.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 248.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.45753
wandb: sub_train_loss 0.01823
wandb:       test_acc 0.625
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run giddy-sweep-23 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j2rrl67q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212022-j2rrl67q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s7nn94gt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212037-s7nn94gt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s7nn94gt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.62it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 266.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 261.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 258.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 260.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 264.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 268.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 265.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.65
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.36595
wandb: sub_train_loss 0.02307
wandb:       test_acc 0.593
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run earthy-sweep-24 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s7nn94gt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212037-s7nn94gt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: srghom36 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212053-srghom36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/srghom36
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 268.06it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 282.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 280.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 278.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 274.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 281.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 281.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.729
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.53619
wandb: sub_train_loss 0.03574
wandb:       test_acc 0.654
wandb:      valid_acc 0.664
wandb: 
wandb: üöÄ View run polished-sweep-25 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/srghom36
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212053-srghom36/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: meofuhwi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212107-meofuhwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/meofuhwi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 226.66it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 231.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 234.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 235.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 234.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 233.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 234.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 227.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 231.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.53988
wandb: sub_train_loss 0.02306
wandb:       test_acc 0.667
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run firm-sweep-26 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/meofuhwi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212107-meofuhwi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hwn61up5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212123-hwn61up5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwn61up5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 239.26it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 231.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 235.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 238.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 245.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 249.83it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 254.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 232.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.69867
wandb: sub_train_loss 0.01907
wandb:       test_acc 0.776
wandb:      valid_acc 0.734
wandb: 
wandb: üöÄ View run winter-sweep-27 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwn61up5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212123-hwn61up5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9crnbh1i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212138-9crnbh1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9crnbh1i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.16it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 211.05it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 210.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 220.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 224.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 242.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 254.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 257.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 240.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.77
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.68612
wandb: sub_train_loss 0.01822
wandb:       test_acc 0.771
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run pious-sweep-28 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9crnbh1i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212138-9crnbh1i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q9evowfj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212149-q9evowfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q9evowfj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 280.62it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 277.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 280.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 281.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 281.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 280.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 279.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.793
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.74446
wandb: sub_train_loss 0.02006
wandb:       test_acc 0.776
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run still-sweep-29 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q9evowfj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212149-q9evowfj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sg7ltutu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212204-sg7ltutu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sg7ltutu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 265.21it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 272.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 271.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 273.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 273.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 274.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 275.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 274.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.769
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.74926
wandb: sub_train_loss 0.01
wandb:       test_acc 0.78
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run silvery-sweep-30 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sg7ltutu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212204-sg7ltutu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rr28ti7w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212220-rr28ti7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rr28ti7w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 177.95it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 190.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 222.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 232.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 195.42it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 195.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 197.83it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 193.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 191.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.781
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.79062
wandb: sub_train_loss 0.00854
wandb:       test_acc 0.782
wandb:      valid_acc 0.778
wandb: 
wandb: üöÄ View run visionary-sweep-31 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rr28ti7w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212220-rr28ti7w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kgje2d1l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212240-kgje2d1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kgje2d1l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 196.82it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 203.86it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 198.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 199.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 201.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 208.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 212.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 213.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 206.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 205.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.783
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.79653
wandb: sub_train_loss 0.00993
wandb:       test_acc 0.785
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run driven-sweep-32 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kgje2d1l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212240-kgje2d1l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rquu300u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212255-rquu300u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rquu300u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.90it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 159.17it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 174.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 183.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 190.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 194.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 196.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 199.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 200.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 201.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.23191
wandb: sub_train_loss 0.02529
wandb:       test_acc 0.133
wandb:      valid_acc 0.134
wandb: 
wandb: üöÄ View run restful-sweep-33 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rquu300u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212255-rquu300u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r4sosqpi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212310-r4sosqpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r4sosqpi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 200.41it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 211.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 216.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 217.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 218.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 220.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 221.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 223.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 220.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.332
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.20864
wandb: sub_train_loss 0.02666
wandb:       test_acc 0.269
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run toasty-sweep-34 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r4sosqpi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212310-r4sosqpi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sraqbb20 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212330-sraqbb20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sraqbb20
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.79it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 177.98it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 162.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 165.14it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 174.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 179.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 182.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 181.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 175.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 177.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.611
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.28582
wandb: sub_train_loss 0.00484
wandb:       test_acc 0.281
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run hopeful-sweep-35 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sraqbb20
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212330-sraqbb20/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x1rh4xps with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212351-x1rh4xps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x1rh4xps
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 213.80it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 211.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 187.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 185.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 181.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 181.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 177.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 180.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 182.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.512
wandb: best_valid_acc 0.518
wandb:  sub_train_acc 0.32312
wandb: sub_train_loss 0.00373
wandb:       test_acc 0.372
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run celestial-sweep-36 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x1rh4xps
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212351-x1rh4xps/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jcj17zsp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212412-jcj17zsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jcj17zsp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.86it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 193.17it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 194.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 185.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 166.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 165.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 164.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 164.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 165.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 168.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.496
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.31425
wandb: sub_train_loss 0.00305
wandb:       test_acc 0.244
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run fast-sweep-37 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jcj17zsp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212412-jcj17zsp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5vsc9q59 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212428-5vsc9q59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5vsc9q59
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 216.92it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 210.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 210.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 211.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 212.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 212.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 213.67it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 211.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 211.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 211.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.464
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.40953
wandb: sub_train_loss 0.00696
wandb:       test_acc 0.289
wandb:      valid_acc 0.322
wandb: 
wandb: üöÄ View run cerulean-sweep-38 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5vsc9q59
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212428-5vsc9q59/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vz3cxfqg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212443-vz3cxfqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vz3cxfqg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.55it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 210.16it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 207.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 202.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 203.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 204.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 205.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 205.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 204.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.561
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.29099
wandb: sub_train_loss 0.08873
wandb:       test_acc 0.36
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run visionary-sweep-39 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vz3cxfqg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212443-vz3cxfqg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: biqeyhkp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212458-biqeyhkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/biqeyhkp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.96it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 200.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 199.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 196.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 195.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 191.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 186.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 186.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 190.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.623
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.47194
wandb: sub_train_loss 0.4941
wandb:       test_acc 0.539
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run cosmic-sweep-40 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/biqeyhkp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212458-biqeyhkp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nf4k6xev with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212514-nf4k6xev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nf4k6xev
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.23it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.85it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 189.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 190.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 189.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 191.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 193.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 202.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 207.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.689
wandb: best_valid_acc 0.704
wandb:  sub_train_acc 0.51662
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.663
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run zany-sweep-41 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nf4k6xev
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212514-nf4k6xev/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 00hf50c3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212529-00hf50c3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/00hf50c3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.42it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 171.45it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 140.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 129.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 139.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 154.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 166.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 175.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 187.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 197.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.45162
wandb: sub_train_loss 0.00244
wandb:       test_acc 0.508
wandb:      valid_acc 0.534
wandb: 
wandb: üöÄ View run lemon-sweep-42 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/00hf50c3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212529-00hf50c3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 390i1vet with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212551-390i1vet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/390i1vet
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 182.87it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 168.55it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 181.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 186.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 190.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 195.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 201.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 206.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 204.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.768
wandb: best_valid_acc 0.742
wandb:  sub_train_acc 0.53877
wandb: sub_train_loss 0.08733
wandb:       test_acc 0.597
wandb:      valid_acc 0.616
wandb: 
wandb: üöÄ View run glamorous-sweep-43 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/390i1vet
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212551-390i1vet/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i6byp00s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212606-i6byp00s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i6byp00s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.20it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 182.87it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 181.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 177.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 175.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 174.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 167.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 175.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 184.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 193.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.46898
wandb: sub_train_loss 0.0437
wandb:       test_acc 0.561
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run easy-sweep-44 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i6byp00s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212606-i6byp00s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xyylwdqv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212622-xyylwdqv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xyylwdqv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.86it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 183.12it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 152.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 161.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 172.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 176.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 189.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 196.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 201.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.78
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.64217
wandb: sub_train_loss 0.05486
wandb:       test_acc 0.672
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run restful-sweep-45 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xyylwdqv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212622-xyylwdqv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 82ywguck with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212637-82ywguck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/82ywguck
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.31it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 200.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 194.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 195.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 193.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 184.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 181.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 170.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 165.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 161.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.57201
wandb: sub_train_loss 0.16439
wandb:       test_acc 0.565
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run expert-sweep-46 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/82ywguck
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212637-82ywguck/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 33id5mhy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212652-33id5mhy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33id5mhy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.25it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.68it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 200.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 204.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 210.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 212.29it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 211.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 210.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 208.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 207.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.769
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.69978
wandb: sub_train_loss 0.0433
wandb:       test_acc 0.671
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run dazzling-sweep-47 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33id5mhy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212652-33id5mhy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2k9zvx5m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212708-2k9zvx5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2k9zvx5m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.25it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 191.56it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 193.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 194.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 191.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 195.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 197.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 198.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 198.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 195.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.57312
wandb: sub_train_loss 0.23802
wandb:       test_acc 0.557
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run leafy-sweep-48 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2k9zvx5m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212708-2k9zvx5m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1vaf2j7c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212723-1vaf2j7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1vaf2j7c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 322.04it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 349.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 361.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 368.61it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 366.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 365.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:00<00:00, 363.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:00<00:00, 365.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 362.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.205
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.17097
wandb: sub_train_loss 0.89722
wandb:       test_acc 0.165
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run glowing-sweep-49 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1vaf2j7c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212723-1vaf2j7c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 33nygbpu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212738-33nygbpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33nygbpu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 364.32it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 371.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 369.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 369.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 372.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 369.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 349.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 353.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.18
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.16765
wandb: sub_train_loss 0.89417
wandb:       test_acc 0.164
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run sleek-sweep-50 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33nygbpu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212738-33nygbpu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c5axgu4y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212750-c5axgu4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c5axgu4y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 362.34it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 368.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 373.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 374.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 370.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 372.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 374.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 374.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.226
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.19092
wandb: sub_train_loss 0.9618
wandb:       test_acc 0.212
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run distinctive-sweep-51 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c5axgu4y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212750-c5axgu4y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t4bf15xn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212804-t4bf15xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t4bf15xn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.55it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:00, 308.05it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 315.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 310.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 318.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 306.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 274.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:00<00:00, 281.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:00<00:00, 291.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 297.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.224
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.21381
wandb: sub_train_loss 0.96184
wandb:       test_acc 0.233
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run solar-sweep-52 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t4bf15xn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212804-t4bf15xn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tpin2219 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212819-tpin2219
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tpin2219
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 255.91it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 280.63it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 289.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 293.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 288.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 296.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 314.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 328.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 332.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 311.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.318
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.29616
wandb: sub_train_loss 1.0161
wandb:       test_acc 0.288
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run clear-sweep-53 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tpin2219
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212819-tpin2219/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i1oj7at6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212835-i1oj7at6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1oj7at6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 358.99it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 363.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 363.31it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 347.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 343.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 330.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:00<00:00, 337.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:00<00:00, 342.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 345.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.321
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.29468
wandb: sub_train_loss 1.01714
wandb:       test_acc 0.282
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run effortless-sweep-54 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1oj7at6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212835-i1oj7at6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pk4fp3ci with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212855-pk4fp3ci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pk4fp3ci
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 355.48it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 364.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 361.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 359.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 362.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:00<00:00, 361.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 355.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:00<00:00, 357.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 359.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.34
wandb:  sub_train_acc 0.30945
wandb: sub_train_loss 1.05187
wandb:       test_acc 0.316
wandb:      valid_acc 0.33
wandb: 
wandb: üöÄ View run balmy-sweep-55 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pk4fp3ci
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212855-pk4fp3ci/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a71jv8ei with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212911-a71jv8ei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a71jv8ei
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 312.44it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:00, 320.86it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 334.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 347.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 347.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 343.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 340.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:00<00:00, 341.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 339.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.323
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.29727
wandb: sub_train_loss 1.0526
wandb:       test_acc 0.312
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run driven-sweep-56 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a71jv8ei
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212911-a71jv8ei/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ncd6qqzk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212931-ncd6qqzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ncd6qqzk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 358.29it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 340.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 336.07it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 339.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 290.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 258.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 283.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:00<00:00, 300.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 305.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.44165
wandb: sub_train_loss 1.0849
wandb:       test_acc 0.485
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run volcanic-sweep-57 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ncd6qqzk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212931-ncd6qqzk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pwkn4vt8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_212951-pwkn4vt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pwkn4vt8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 328.12it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 335.47it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 333.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 330.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 339.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 346.68it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 352.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:00<00:00, 358.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 348.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.496
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.4435
wandb: sub_train_loss 1.08527
wandb:       test_acc 0.495
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run royal-sweep-58 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pwkn4vt8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_212951-pwkn4vt8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mjpe0qw0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213010-mjpe0qw0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mjpe0qw0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 348.18it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 321.85it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 325.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 327.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 330.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 325.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 326.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 332.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 331.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.565
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.53877
wandb: sub_train_loss 1.13136
wandb:       test_acc 0.567
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run sweepy-sweep-59 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mjpe0qw0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213010-mjpe0qw0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wx0cog98 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213023-wx0cog98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wx0cog98
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 333.47it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:00, 338.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 326.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 327.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 333.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 337.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 341.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:00<00:00, 349.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 335.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.554
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.51994
wandb: sub_train_loss 1.13033
wandb:       test_acc 0.56
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run lively-sweep-60 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wx0cog98
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213023-wx0cog98/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lim4w068 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213044-lim4w068
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lim4w068
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 304.82it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 300.75it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 304.31it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 302.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 315.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 324.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 328.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 334.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:00<00:00, 342.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 326.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.65066
wandb: sub_train_loss 1.14319
wandb:       test_acc 0.653
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run wild-sweep-61 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lim4w068
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213044-lim4w068/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r4aepkqy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213058-r4aepkqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r4aepkqy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 329.35it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:00, 279.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 234.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 222.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 236.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 261.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 275.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 291.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 301.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 279.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.648
wandb:  sub_train_acc 0.64549
wandb: sub_train_loss 1.14313
wandb:       test_acc 0.642
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run fearless-sweep-62 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r4aepkqy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213058-r4aepkqy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nop5nd55 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213114-nop5nd55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nop5nd55
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 331.26it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 332.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 326.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 326.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 327.32it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 330.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 326.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 319.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 322.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.683
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.68648
wandb: sub_train_loss 1.13908
wandb:       test_acc 0.666
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run ethereal-sweep-63 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nop5nd55
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213114-nop5nd55/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: efm55id3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213129-efm55id3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/efm55id3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 260.46it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 275.20it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 290.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 296.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 301.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 300.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 287.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 294.75it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:00<00:00, 298.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 295.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.69572
wandb: sub_train_loss 1.13974
wandb:       test_acc 0.671
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run hearty-sweep-64 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/efm55id3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213129-efm55id3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pil5xnbj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213145-pil5xnbj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pil5xnbj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 254.56it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 251.08it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:00, 257.31it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 251.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 251.58it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 254.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 254.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 249.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:00<00:00, 248.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 247.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 247.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 251.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.2
wandb: best_valid_acc 0.21
wandb:  sub_train_acc 0.31425
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.201
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run wobbly-sweep-65 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pil5xnbj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213145-pil5xnbj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x9xneiyl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213159-x9xneiyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x9xneiyl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 266.95it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 261.93it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 248.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 254.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 253.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 248.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 228.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 220.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 229.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 233.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 235.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 238.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.192
wandb: best_valid_acc 0.196
wandb:  sub_train_acc 0.33272
wandb: sub_train_loss 0.00165
wandb:       test_acc 0.191
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run gentle-sweep-66 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x9xneiyl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213159-x9xneiyl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bt2smml0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213221-bt2smml0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bt2smml0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 265.56it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 268.08it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 265.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 254.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 252.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 245.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 243.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 243.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 241.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 245.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 249.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.445
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.34527
wandb: sub_train_loss 0.00027
wandb:       test_acc 0.443
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run eager-sweep-67 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bt2smml0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213221-bt2smml0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mt7aygfj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213237-mt7aygfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mt7aygfj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 247.69it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 243.74it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 238.27it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 241.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 239.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 241.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 239.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 238.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 241.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 245.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 247.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 240.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 241.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.467
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.32164
wandb: sub_train_loss 0.0007
wandb:       test_acc 0.426
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run frosty-sweep-68 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mt7aygfj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213237-mt7aygfj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mdmk5zpm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213251-mdmk5zpm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mdmk5zpm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 211.72it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 198.95it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 218.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 233.25it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 242.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 247.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 248.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 249.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 248.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 252.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 257.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 245.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.573
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.38737
wandb: sub_train_loss 0.00061
wandb:       test_acc 0.519
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run crimson-sweep-69 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mdmk5zpm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213251-mdmk5zpm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 85vmpdtg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213303-85vmpdtg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/85vmpdtg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 261.14it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 275.59it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 281.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 281.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 277.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 276.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 279.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 283.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 287.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 286.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 281.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.648
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.42097
wandb: sub_train_loss 0.00039
wandb:       test_acc 0.553
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run lively-sweep-70 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/85vmpdtg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213303-85vmpdtg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2rs2egcb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213318-2rs2egcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2rs2egcb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 274.15it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 263.65it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 253.84it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 244.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 233.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 228.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 227.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 227.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 227.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 228.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 234.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 237.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.667
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.46381
wandb: sub_train_loss 0.00025
wandb:       test_acc 0.657
wandb:      valid_acc 0.636
wandb: 
wandb: üöÄ View run fanciful-sweep-71 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2rs2egcb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213318-2rs2egcb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0yomt1vz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213332-0yomt1vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0yomt1vz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 257.39it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 250.07it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 260.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 244.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 222.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 226.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 234.16it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 235.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 234.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 242.57it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 248.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 242.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.624
wandb: best_valid_acc 0.614
wandb:  sub_train_acc 0.45126
wandb: sub_train_loss 0.00058
wandb:       test_acc 0.544
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run grateful-sweep-72 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0yomt1vz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213332-0yomt1vz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fmbt3lfz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213348-fmbt3lfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fmbt3lfz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.93it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 210.95it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 218.63it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 228.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 226.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 222.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 216.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 214.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 216.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 227.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 244.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 245.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.732
wandb:  sub_train_acc 0.61337
wandb: sub_train_loss 0.00045
wandb:       test_acc 0.734
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run upbeat-sweep-73 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fmbt3lfz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213348-fmbt3lfz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uosowm6b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213404-uosowm6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uosowm6b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.00it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 271.01it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 266.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 261.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 259.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 261.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 262.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 266.51it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 275.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 280.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 271.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.727
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.57607
wandb: sub_train_loss 0.00037
wandb:       test_acc 0.695
wandb:      valid_acc 0.702
wandb: 
wandb: üöÄ View run proud-sweep-74 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uosowm6b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213404-uosowm6b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fjmu859h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213418-fjmu859h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fjmu859h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 278.90it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:00, 279.78it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 279.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 263.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 253.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 251.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 240.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 240.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 208.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 207.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 209.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 229.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.794
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.69387
wandb: sub_train_loss 0.00025
wandb:       test_acc 0.792
wandb:      valid_acc 0.772
wandb: 
wandb: üöÄ View run distinctive-sweep-75 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fjmu859h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213418-fjmu859h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pv6yk360 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213434-pv6yk360
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pv6yk360
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 211.28it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 211.35it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 222.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 237.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 245.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 249.63it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 254.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 259.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 265.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 269.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 266.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 253.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.786
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.67762
wandb: sub_train_loss 0.00032
wandb:       test_acc 0.784
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run atomic-sweep-76 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pv6yk360
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213434-pv6yk360/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nxwwplwg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213450-nxwwplwg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nxwwplwg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 247.50it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 243.55it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 245.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 250.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 256.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 257.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 260.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 259.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 255.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 257.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 257.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 254.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.776
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.74705
wandb: sub_train_loss 0.00013
wandb:       test_acc 0.774
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run morning-sweep-77 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nxwwplwg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213450-nxwwplwg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ur36qopr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213504-ur36qopr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ur36qopr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 254.51it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 253.72it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 249.21it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 252.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 254.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 259.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 261.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 262.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:00<00:00, 265.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 268.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 267.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 261.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.777
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.72784
wandb: sub_train_loss 0.00016
wandb:       test_acc 0.753
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run balmy-sweep-78 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ur36qopr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213504-ur36qopr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wa3vvrkg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213520-wa3vvrkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wa3vvrkg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 273.96it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 265.64it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 266.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 265.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 262.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 264.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 267.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 267.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 270.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 269.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 267.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.79431
wandb: sub_train_loss 4e-05
wandb:       test_acc 0.784
wandb:      valid_acc 0.772
wandb: 
wandb: üöÄ View run swift-sweep-79 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wa3vvrkg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213520-wa3vvrkg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 405jdblx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213535-405jdblx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/405jdblx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 235.75it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 246.15it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 227.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 226.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 224.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 226.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 230.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 238.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:00<00:00, 247.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 253.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 256.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 243.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.792
wandb: best_valid_acc 0.79
wandb:  sub_train_acc 0.79874
wandb: sub_train_loss 6e-05
wandb:       test_acc 0.793
wandb:      valid_acc 0.79
wandb: 
wandb: üöÄ View run spring-sweep-80 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/405jdblx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213535-405jdblx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k3cwrq6u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213551-k3cwrq6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k3cwrq6u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 202.36it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 201.14it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 205.83it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 199.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 197.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 195.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 190.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 188.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 186.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 189.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 174.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 185.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 192.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 191.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.311
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.20716
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.156
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run genial-sweep-81 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k3cwrq6u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213551-k3cwrq6u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jdnna09h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213606-jdnna09h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jdnna09h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.02it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.15it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 165.06it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 174.45it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 171.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 165.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 162.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 163.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 166.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 165.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 162.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 162.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 164.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 163.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 163.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 157.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 152.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.24668
wandb: sub_train_loss 0.0
wandb:       test_acc 0.293
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run decent-sweep-82 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jdnna09h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213606-jdnna09h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cfsb6zn8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213621-cfsb6zn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cfsb6zn8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.58it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 191.47it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 193.30it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 194.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 186.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 172.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 175.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 177.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 182.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 183.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 183.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 182.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 179.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 181.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 183.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.608
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.33272
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.396
wandb:      valid_acc 0.384
wandb: 
wandb: üöÄ View run trim-sweep-83 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cfsb6zn8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213621-cfsb6zn8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rntpqxiz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213636-rntpqxiz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rntpqxiz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.63it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.73it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 167.95it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 167.77it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 174.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 183.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 191.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 197.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 186.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 177.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 184.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 187.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 190.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 190.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 183.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.595
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.26329
wandb: sub_train_loss 0.00013
wandb:       test_acc 0.461
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run sleek-sweep-84 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rntpqxiz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213636-rntpqxiz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 96pr6xse with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213652-96pr6xse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/96pr6xse
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 157.18it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 160.33it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 154.10it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 145.95it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 150.96it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 155.92it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 161.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 162.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 166.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 169.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 177.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 183.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 189.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 194.93it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 200.02it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 203.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.585
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.40583
wandb: sub_train_loss 0.0001
wandb:       test_acc 0.31
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run lively-sweep-85 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/96pr6xse
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213652-96pr6xse/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rnpq7qbi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213707-rnpq7qbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rnpq7qbi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.39it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 192.76it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 195.49it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 188.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 185.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 182.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 189.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 195.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 198.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 198.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 196.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 195.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 195.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 194.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.563
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.41064
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.335
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run visionary-sweep-86 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rnpq7qbi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213707-rnpq7qbi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 30170pkk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213723-30170pkk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/30170pkk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.55it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 179.79it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 175.99it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 179.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 185.54it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 193.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 197.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 203.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 207.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 210.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 204.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 199.09it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 196.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 190.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.666
wandb: best_valid_acc 0.658
wandb:  sub_train_acc 0.37408
wandb: sub_train_loss 0.0
wandb:       test_acc 0.524
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run ethereal-sweep-87 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/30170pkk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213723-30170pkk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hwz6xj7b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213738-hwz6xj7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwz6xj7b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.99it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.46it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 151.77it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 158.16it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 161.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 163.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 168.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 169.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 170.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 171.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 171.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 177.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 186.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 181.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 185.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 190.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.656
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.46972
wandb: sub_train_loss 0.0034
wandb:       test_acc 0.62
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run rich-sweep-88 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwz6xj7b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213738-hwz6xj7b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k7k5g9fg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213753-k7k5g9fg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k7k5g9fg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.57it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.79it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 181.85it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 182.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 184.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 184.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 186.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 187.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 191.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 192.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 192.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 180.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 170.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 166.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 166.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.60451
wandb: sub_train_loss 0.00336
wandb:       test_acc 0.719
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run glamorous-sweep-89 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k7k5g9fg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213753-k7k5g9fg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ngrfom45 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213809-ngrfom45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ngrfom45
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.45it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 197.29it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 183.84it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 182.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 186.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 188.38it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 191.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 191.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 196.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 198.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 199.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 200.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 202.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 207.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.57866
wandb: sub_train_loss 0.12251
wandb:       test_acc 0.704
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run revived-sweep-90 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ngrfom45
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213809-ngrfom45/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vtrguo0t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213824-vtrguo0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vtrguo0t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.34it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 190.17it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 200.27it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 204.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 207.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 204.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 202.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 200.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 198.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 196.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 196.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 200.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 204.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 207.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 202.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.55945
wandb: sub_train_loss 0.07411
wandb:       test_acc 0.586
wandb:      valid_acc 0.604
wandb: 
wandb: üöÄ View run swift-sweep-91 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vtrguo0t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213824-vtrguo0t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ip1c0ir with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213839-5ip1c0ir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ip1c0ir
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 197.31it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 197.58it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 198.79it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 199.53it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 196.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 197.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 197.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 192.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 186.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 177.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 179.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 175.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 170.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 166.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 163.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.741
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.54173
wandb: sub_train_loss 0.076
wandb:       test_acc 0.567
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run effortless-sweep-92 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ip1c0ir
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213839-5ip1c0ir/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ltru8u3i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213855-ltru8u3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ltru8u3i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.19it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 176.01it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 188.31it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 192.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 194.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 197.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 199.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 200.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 201.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 200.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 186.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 188.33it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 190.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 187.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.759
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.53139
wandb: sub_train_loss 0.59569
wandb:       test_acc 0.548
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run trim-sweep-93 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ltru8u3i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213855-ltru8u3i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: getmt6rz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213910-getmt6rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/getmt6rz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 199.23it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 192.62it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 191.96it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 178.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 175.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 177.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 179.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 183.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 187.04it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 190.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 194.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 189.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 190.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 192.82it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 194.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.785
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.71529
wandb: sub_train_loss 0.00221
wandb:       test_acc 0.75
wandb:      valid_acc 0.754
wandb: 
wandb: üöÄ View run magic-sweep-94 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/getmt6rz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213910-getmt6rz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s528ohb2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213926-s528ohb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s528ohb2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 148.77it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 137.24it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 159.02it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 169.87it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 174.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 178.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 180.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 180.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 182.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 183.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 185.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 187.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 190.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 189.81it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 188.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.52105
wandb: sub_train_loss 0.76509
wandb:       test_acc 0.502
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run faithful-sweep-95 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s528ohb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213926-s528ohb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bfcatj7m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213940-bfcatj7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bfcatj7m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.50it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.76it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.00it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 175.98it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 162.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 156.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 151.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 148.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 149.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 156.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 160.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 162.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 160.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 159.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 158.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 159.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 156.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.792
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.65583
wandb: sub_train_loss 0.11091
wandb:       test_acc 0.637
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run sunny-sweep-96 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bfcatj7m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213940-bfcatj7m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dpzgqe8p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_213952-dpzgqe8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dpzgqe8p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.67it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 255.03it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 272.34it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 282.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 281.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 279.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 280.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.22
wandb: best_valid_acc 0.238
wandb:  sub_train_acc 0.19461
wandb: sub_train_loss 1.40227
wandb:       test_acc 0.206
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run dauntless-sweep-97 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dpzgqe8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_213952-dpzgqe8p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: av9e5jqj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214006-av9e5jqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/av9e5jqj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 275.26it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 229.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 249.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 262.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 259.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 250.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 252.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 254.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.208
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.18833
wandb: sub_train_loss 1.40405
wandb:       test_acc 0.201
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run treasured-sweep-98 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/av9e5jqj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214006-av9e5jqj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u1vqarfn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214021-u1vqarfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u1vqarfn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.59it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 279.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 282.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 283.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 271.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 270.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 275.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.237
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.2212
wandb: sub_train_loss 1.5351
wandb:       test_acc 0.214
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run youthful-sweep-99 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u1vqarfn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214021-u1vqarfn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g44itx0u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214037-g44itx0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g44itx0u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 284.63it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 257.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 256.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 261.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 268.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 265.67it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 266.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 264.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.233
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.21935
wandb: sub_train_loss 1.53517
wandb:       test_acc 0.214
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run serene-sweep-100 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g44itx0u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214037-g44itx0u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 04zc1cic with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214052-04zc1cic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/04zc1cic
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 295.27it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 273.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 279.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 280.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 272.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 270.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 272.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.306
wandb: best_valid_acc 0.33
wandb:  sub_train_acc 0.28619
wandb: sub_train_loss 1.58156
wandb:       test_acc 0.265
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run silver-sweep-101 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/04zc1cic
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214052-04zc1cic/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dsfa2ki2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214103-dsfa2ki2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dsfa2ki2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 305.26it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 300.80it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 299.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 300.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 303.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 303.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 302.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.293
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.28287
wandb: sub_train_loss 1.58104
wandb:       test_acc 0.262
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run colorful-sweep-102 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dsfa2ki2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214103-dsfa2ki2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qzz6uppr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214118-qzz6uppr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qzz6uppr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 253.01it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 251.90it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 258.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 267.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 271.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 273.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 273.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 269.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.269
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.28508
wandb: sub_train_loss 1.61885
wandb:       test_acc 0.266
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run smooth-sweep-103 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qzz6uppr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214118-qzz6uppr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9zwc1fhk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214139-9zwc1fhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9zwc1fhk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 232.76it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 232.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 227.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 228.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 246.53it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 258.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 259.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 252.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.27954
wandb: sub_train_loss 1.61918
wandb:       test_acc 0.272
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run feasible-sweep-104 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9zwc1fhk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214139-9zwc1fhk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h1uqfo36 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214153-h1uqfo36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h1uqfo36
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.08it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 192.81it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 206.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 240.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 259.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 271.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 286.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.469
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.4435
wandb: sub_train_loss 1.64723
wandb:       test_acc 0.46
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run zesty-sweep-105 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h1uqfo36
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214153-h1uqfo36/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rwpu3olh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214209-rwpu3olh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rwpu3olh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 299.29it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 309.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 308.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 295.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 290.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 298.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 299.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.481
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.44535
wandb: sub_train_loss 1.64713
wandb:       test_acc 0.467
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run colorful-sweep-106 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rwpu3olh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214209-rwpu3olh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6xlc7g32 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214229-6xlc7g32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6xlc7g32
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 295.26it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 296.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 297.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 296.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 296.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 299.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 300.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.572
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.52179
wandb: sub_train_loss 1.69483
wandb:       test_acc 0.548
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run rich-sweep-107 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6xlc7g32
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214229-6xlc7g32/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jpb6npvg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214243-jpb6npvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jpb6npvg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 272.21it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 264.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 268.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 264.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 261.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 262.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 266.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 265.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.573
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.5144
wandb: sub_train_loss 1.69498
wandb:       test_acc 0.536
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run dazzling-sweep-108 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jpb6npvg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214243-jpb6npvg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: izkz5hj6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214255-izkz5hj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/izkz5hj6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 297.27it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 281.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 276.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 269.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 265.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 260.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 259.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 265.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.515
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.51883
wandb: sub_train_loss 1.71284
wandb:       test_acc 0.528
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run good-sweep-109 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/izkz5hj6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214255-izkz5hj6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y6sz2qu6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214310-y6sz2qu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y6sz2qu6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 289.04it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 303.91it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 302.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 299.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 296.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 292.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 291.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.565
wandb: best_valid_acc 0.536
wandb:  sub_train_acc 0.55576
wandb: sub_train_loss 1.71318
wandb:       test_acc 0.565
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run rosy-sweep-110 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y6sz2qu6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214310-y6sz2qu6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: er47s9ry with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214324-er47s9ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/er47s9ry
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.74it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 223.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 225.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 223.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 246.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 259.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 267.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 253.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.728
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.63959
wandb: sub_train_loss 1.71814
wandb:       test_acc 0.633
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run hearty-sweep-111 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/er47s9ry
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214324-er47s9ry/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dr67xx2h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214340-dr67xx2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dr67xx2h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 293.17it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 268.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 265.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 268.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 272.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 281.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 278.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.716
wandb: best_valid_acc 0.714
wandb:  sub_train_acc 0.59306
wandb: sub_train_loss 1.71823
wandb:       test_acc 0.573
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run clean-sweep-112 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dr67xx2h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214340-dr67xx2h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dc40rx52 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214356-dc40rx52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dc40rx52
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 200.57it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 194.96it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 193.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 196.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 197.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 195.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 198.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 198.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 198.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 196.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.275
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.25997
wandb: sub_train_loss 0.01709
wandb:       test_acc 0.276
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run pleasant-sweep-113 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dc40rx52
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214356-dc40rx52/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4hdwa340 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214410-4hdwa340
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4hdwa340
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.97it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 183.29it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 188.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 185.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 179.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 178.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 176.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 171.46it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 171.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 173.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.26
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.25923
wandb: sub_train_loss 0.01974
wandb:       test_acc 0.261
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run polar-sweep-114 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4hdwa340
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214410-4hdwa340/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ryell6wd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214447-ryell6wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ryell6wd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.64it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 191.42it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 191.18it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 193.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 194.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 193.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 192.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 193.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 194.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.582
wandb:  sub_train_acc 0.43168
wandb: sub_train_loss 0.06226
wandb:       test_acc 0.576
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run dauntless-sweep-115 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ryell6wd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214447-ryell6wd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3xygqs6z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214501-3xygqs6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3xygqs6z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.99it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.68it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 176.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 179.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 174.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 173.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 171.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 162.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 162.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 161.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.42541
wandb: sub_train_loss 0.07811
wandb:       test_acc 0.543
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run genial-sweep-116 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3xygqs6z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214501-3xygqs6z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n2he3n74 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214517-n2he3n74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/n2he3n74
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.22it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 159.70it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 163.24it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 164.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 168.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 171.84it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 172.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 169.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 174.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 183.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.646
wandb: best_valid_acc 0.668
wandb:  sub_train_acc 0.54099
wandb: sub_train_loss 0.11401
wandb:       test_acc 0.646
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run lilac-sweep-117 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/n2he3n74
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214517-n2he3n74/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fdov9jcl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214533-fdov9jcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdov9jcl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.68it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 162.88it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 176.68it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 182.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 186.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 191.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 192.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 191.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 194.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 195.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.678
wandb:  sub_train_acc 0.56388
wandb: sub_train_loss 0.12419
wandb:       test_acc 0.705
wandb:      valid_acc 0.664
wandb: 
wandb: üöÄ View run icy-sweep-118 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdov9jcl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214533-fdov9jcl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rt9mqr9i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214547-rt9mqr9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rt9mqr9i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.22it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.22it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 162.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 158.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 161.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 165.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 156.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 158.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 160.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 169.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 176.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.692
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.60524
wandb: sub_train_loss 0.16453
wandb:       test_acc 0.701
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run colorful-sweep-119 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rt9mqr9i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214547-rt9mqr9i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zrc809px with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214603-zrc809px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zrc809px
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.95it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 165.89it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 173.97it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 176.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 176.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 180.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 180.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 183.21it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 181.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 177.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.014 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.688
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.60894
wandb: sub_train_loss 0.17569
wandb:       test_acc 0.703
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run bright-sweep-120 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zrc809px
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214603-zrc809px/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e8e5xj57 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214618-e8e5xj57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-121
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e8e5xj57
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 178.75it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.03it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 186.07it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 190.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 192.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 191.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 192.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 196.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 196.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 197.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.77
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.66913
wandb: sub_train_loss 0.25768
wandb:       test_acc 0.77
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run fast-sweep-121 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e8e5xj57
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214618-e8e5xj57/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bpkamu7a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214630-bpkamu7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-122
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bpkamu7a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.95it/s] 10%|‚ñà         | 20/200 [00:00<00:02, 82.34it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:02, 81.18it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 125.44it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 151.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 165.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 177.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 185.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 186.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 185.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 189.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.764
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.67356
wandb: sub_train_loss 0.26444
wandb:       test_acc 0.768
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run driven-sweep-122 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bpkamu7a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214630-bpkamu7a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: colvkgkz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214652-colvkgkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/colvkgkz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.27it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 184.65it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 188.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 189.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 189.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 183.48it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 178.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 168.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 165.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 161.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.775
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.72563
wandb: sub_train_loss 0.38301
wandb:       test_acc 0.791
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run amber-sweep-123 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/colvkgkz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214652-colvkgkz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fk0nqmkz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214707-fk0nqmkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-124
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fk0nqmkz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 163.83it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 163.83it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 163.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 161.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 163.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 169.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 172.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 173.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 173.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 174.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 176.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.782
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.72526
wandb: sub_train_loss 0.34344
wandb:       test_acc 0.798
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run faithful-sweep-124 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fk0nqmkz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214707-fk0nqmkz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bhsio85s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214723-bhsio85s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-125
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bhsio85s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.73it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 156.44it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 165.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 155.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 149.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 146.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 147.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 152.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 154.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 156.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 160.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.796
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.75665
wandb: sub_train_loss 0.43648
wandb:       test_acc 0.767
wandb:      valid_acc 0.758
wandb: 
wandb: üöÄ View run cool-sweep-125 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bhsio85s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214723-bhsio85s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i677xe2l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214738-i677xe2l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-126
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i677xe2l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.55it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 196.72it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 196.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 193.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 190.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 188.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 187.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 187.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 186.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 188.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.792
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.75775
wandb: sub_train_loss 0.39609
wandb:       test_acc 0.782
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run confused-sweep-126 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i677xe2l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214738-i677xe2l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: psou7vyl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214749-psou7vyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/psou7vyl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.18it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 201.04it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 203.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 204.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 200.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 195.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 194.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 193.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 192.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 195.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.812
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.81832
wandb: sub_train_loss 0.41712
wandb:       test_acc 0.815
wandb:      valid_acc 0.788
wandb: 
wandb: üöÄ View run quiet-sweep-127 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/psou7vyl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214749-psou7vyl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jbblyh5q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214804-jbblyh5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-128
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jbblyh5q
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.12it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 164.03it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 161.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 161.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 163.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 173.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 175.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 176.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 182.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 186.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.793
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.79874
wandb: sub_train_loss 0.38937
wandb:       test_acc 0.791
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run hearty-sweep-128 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jbblyh5q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214804-jbblyh5q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gs850svp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214819-gs850svp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-129
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gs850svp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.03it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 136.33it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 132.03it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 129.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 128.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 128.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 124.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 119.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 112.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 110.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 116.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 121.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 124.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 126.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.432
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.22046
wandb: sub_train_loss 0.00045
wandb:       test_acc 0.171
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run soft-sweep-129 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gs850svp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214819-gs850svp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 51uir4t4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214834-51uir4t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/51uir4t4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 129.64it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 132.82it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 133.76it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 132.21it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 130.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 127.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 124.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 120.33it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 113.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 109.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 110.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 113.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 116.76it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 120.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.375
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.19239
wandb: sub_train_loss 0.00117
wandb:       test_acc 0.185
wandb:      valid_acc 0.168
wandb: 
wandb: üöÄ View run valiant-sweep-130 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/51uir4t4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214834-51uir4t4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vbhjk25w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214850-vbhjk25w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vbhjk25w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.24it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.89it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 146.00it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 142.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 141.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 141.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 142.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 143.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 143.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 144.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 143.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 143.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 143.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.456
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.3438
wandb: sub_train_loss 0.00079
wandb:       test_acc 0.344
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run fallen-sweep-131 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vbhjk25w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214850-vbhjk25w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7f7fhes4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214905-7f7fhes4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-132
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7f7fhes4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.70it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 81.10it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 80.02it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 83.56it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 86.45it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 87.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 92.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 100.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 106.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:00, 113.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 117.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 121.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 121.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 122.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 123.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 124.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 128.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.513
wandb: best_valid_acc 0.512
wandb:  sub_train_acc 0.20421
wandb: sub_train_loss 0.00581
wandb:       test_acc 0.172
wandb:      valid_acc 0.16
wandb: 
wandb: üöÄ View run stoic-sweep-132 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7f7fhes4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214905-7f7fhes4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qagogh6a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214925-qagogh6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-133
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qagogh6a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.70it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.90it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 130.08it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 128.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 129.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 130.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 130.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 131.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 134.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 134.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 132.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 127.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 130.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 134.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.667
wandb: best_valid_acc 0.654
wandb:  sub_train_acc 0.51108
wandb: sub_train_loss 0.04658
wandb:       test_acc 0.533
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run fearless-sweep-133 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qagogh6a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214925-qagogh6a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yts1pmf6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_214946-yts1pmf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-134
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yts1pmf6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 130.47it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 132.29it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 130.51it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 130.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 108.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 107.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 108.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 111.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 114.77it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 118.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 121.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 122.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 124.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.37518
wandb: sub_train_loss 0.20179
wandb:       test_acc 0.358
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run swept-sweep-134 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yts1pmf6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_214946-yts1pmf6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: biebphyy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215000-biebphyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-135
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/biebphyy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.37it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 131.63it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 128.01it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 128.37it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 128.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 123.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 126.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 128.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 129.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 131.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 130.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 129.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 127.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 126.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.7
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.55391
wandb: sub_train_loss 0.09876
wandb:       test_acc 0.591
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run fluent-sweep-135 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/biebphyy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215000-biebphyy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rnq189zl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215016-rnq189zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-136
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rnq189zl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.26it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 132.88it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 134.61it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 131.22it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 131.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 130.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 128.37it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 130.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 133.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 126.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 125.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 129.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 130.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 133.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.736
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.5661
wandb: sub_train_loss 0.22257
wandb:       test_acc 0.627
wandb:      valid_acc 0.642
wandb: 
wandb: üöÄ View run bright-sweep-136 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rnq189zl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215016-rnq189zl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ar7ahvug with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215031-ar7ahvug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ar7ahvug
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.35it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 137.62it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 136.81it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 137.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 131.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 137.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 142.99it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 146.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 149.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 146.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 146.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 145.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 143.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.61891
wandb: sub_train_loss 0.13203
wandb:       test_acc 0.658
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run upbeat-sweep-137 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ar7ahvug
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215031-ar7ahvug/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yuzc4ovf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215043-yuzc4ovf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-138
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yuzc4ovf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 125.82it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.71it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 126.91it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 130.03it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 131.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 131.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 130.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 130.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 126.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 125.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 122.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 119.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 122.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 127.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.76
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.45384
wandb: sub_train_loss 0.32624
wandb:       test_acc 0.457
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run sweepy-sweep-138 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yuzc4ovf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215043-yuzc4ovf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 288q65qm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215057-288q65qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-139
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/288q65qm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.72it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.47it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 110.93it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 113.34it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 116.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 118.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 120.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 122.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 120.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 117.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 117.50it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 121.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 124.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 126.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 127.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.48264
wandb: sub_train_loss 0.51371
wandb:       test_acc 0.424
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run sleek-sweep-139 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/288q65qm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215057-288q65qm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9fz7zyqi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215108-9fz7zyqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-140
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fz7zyqi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.35it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.40it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.70it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 130.30it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 134.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 136.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 140.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 137.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 134.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 132.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 129.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 128.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 127.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 127.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.758
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.41876
wandb: sub_train_loss 0.86319
wandb:       test_acc 0.362
wandb:      valid_acc 0.386
wandb: 
wandb: üöÄ View run skilled-sweep-140 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fz7zyqi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215108-9fz7zyqi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 52bwd8qp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215123-52bwd8qp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-141
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/52bwd8qp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.71it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 106.44it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 106.79it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 104.33it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 108.05it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 111.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 115.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 119.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 123.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 125.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 130.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 134.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 136.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 137.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 138.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.762
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.54764
wandb: sub_train_loss 1.13241
wandb:       test_acc 0.568
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run chocolate-sweep-141 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/52bwd8qp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215123-52bwd8qp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0m7crie0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215139-0m7crie0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0m7crie0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.20it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 110.66it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 100.60it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 97.34it/s]  30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 91.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 90.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 94.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 100.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:01<00:00, 104.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 111.27it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 114.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 113.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 114.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 115.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 113.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 116.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.797
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.35192
wandb: sub_train_loss 1.18561
wandb:       test_acc 0.325
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run silver-sweep-142 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0m7crie0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215139-0m7crie0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sp4e0yoj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215153-sp4e0yoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-143
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sp4e0yoj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 137.58it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 140.91it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 142.37it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 145.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 146.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 137.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 134.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 133.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 130.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 129.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 128.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 131.95it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 133.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.811
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.75443
wandb: sub_train_loss 0.22279
wandb:       test_acc 0.749
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run toasty-sweep-143 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sp4e0yoj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215153-sp4e0yoj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5kqbztds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215209-5kqbztds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-144
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5kqbztds
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.99it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.96it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 119.09it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 119.63it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 119.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 122.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 125.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 128.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 130.75it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 134.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 136.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 134.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 133.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 131.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.794
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.57053
wandb: sub_train_loss 0.65347
wandb:       test_acc 0.544
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run dazzling-sweep-144 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5kqbztds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215209-5kqbztds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uk9oa63i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215224-uk9oa63i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-145
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uk9oa63i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 287.76it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 288.80it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 269.95it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 256.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 246.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 242.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 241.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 246.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 240.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 238.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 247.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.18279
wandb: sub_train_loss 1.16449
wandb:       test_acc 0.189
wandb:      valid_acc 0.186
wandb: 
wandb: üöÄ View run radiant-sweep-145 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uk9oa63i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215224-uk9oa63i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8546pvb5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215235-8546pvb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-146
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8546pvb5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 274.54it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 289.34it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 281.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 275.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 272.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 270.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 269.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 272.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 286.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 295.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 283.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.219
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.18131
wandb: sub_train_loss 1.16643
wandb:       test_acc 0.188
wandb:      valid_acc 0.186
wandb: 
wandb: üöÄ View run golden-sweep-146 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8546pvb5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215235-8546pvb5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y5xwl0uu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215251-y5xwl0uu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y5xwl0uu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 287.27it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 291.58it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 293.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 298.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 299.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 308.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 314.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 314.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:00<00:00, 318.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 308.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.215
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.18575
wandb: sub_train_loss 1.34572
wandb:       test_acc 0.171
wandb:      valid_acc 0.158
wandb: 
wandb: üöÄ View run fanciful-sweep-147 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y5xwl0uu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215251-y5xwl0uu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2n4mtkrt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215306-2n4mtkrt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-148
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2n4mtkrt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 285.50it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 278.44it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 286.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 290.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 293.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 294.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 295.19it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 296.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:00<00:00, 296.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 300.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 294.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.228
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.18612
wandb: sub_train_loss 1.34852
wandb:       test_acc 0.167
wandb:      valid_acc 0.158
wandb: 
wandb: üöÄ View run comfy-sweep-148 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2n4mtkrt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215306-2n4mtkrt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qsl80xhf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215321-qsl80xhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-149
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qsl80xhf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 302.16it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 299.95it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 300.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 300.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 301.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 307.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 305.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 305.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:00<00:00, 304.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 304.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.314
wandb:  sub_train_acc 0.25148
wandb: sub_train_loss 1.41271
wandb:       test_acc 0.239
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run cool-sweep-149 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qsl80xhf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215321-qsl80xhf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tlwlss09 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215343-tlwlss09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-150
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tlwlss09
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 287.89it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 300.84it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 309.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 294.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 284.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 275.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 259.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 230.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 248.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 264.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.297
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.25295
wandb: sub_train_loss 1.41362
wandb:       test_acc 0.236
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run deep-sweep-150 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tlwlss09
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215343-tlwlss09/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g6lha537 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215357-g6lha537
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-151
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g6lha537
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 235.25it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 247.18it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 261.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 253.31it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 248.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 235.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 233.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 241.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 245.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 252.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 256.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.269
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.27843
wandb: sub_train_loss 1.46562
wandb:       test_acc 0.255
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run logical-sweep-151 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g6lha537
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215357-g6lha537/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 587x6n0s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215413-587x6n0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/587x6n0s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 310.57it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 275.25it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 271.34it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 280.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 287.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 287.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 284.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 284.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:00<00:00, 291.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 289.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.262
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.27954
wandb: sub_train_loss 1.46684
wandb:       test_acc 0.25
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run revived-sweep-152 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/587x6n0s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215413-587x6n0s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q5kozyae with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215429-q5kozyae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-153
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q5kozyae
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.17it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 280.78it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 287.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 293.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 297.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 300.73it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 308.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 290.63it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:00<00:00, 296.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 296.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.47
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.4579
wandb: sub_train_loss 1.50851
wandb:       test_acc 0.49
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run copper-sweep-153 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q5kozyae
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215429-q5kozyae/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7n1jsy4s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215444-7n1jsy4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-154
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7n1jsy4s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 253.54it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 252.94it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:00, 259.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 256.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 270.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 281.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 288.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 294.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:00<00:00, 291.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 297.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.472
wandb: best_valid_acc 0.474
wandb:  sub_train_acc 0.45569
wandb: sub_train_loss 1.50902
wandb:       test_acc 0.49
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run deep-sweep-154 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7n1jsy4s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215444-7n1jsy4s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5hukvtjk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215500-5hukvtjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-155
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5hukvtjk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 230.20it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 230.72it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 217.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 220.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 225.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 233.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 234.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 233.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 237.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 244.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 250.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 241.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 235.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.020 MB of 0.023 MB uploadedwandb: / 0.020 MB of 0.023 MB uploadedwandb: - 0.020 MB of 0.023 MB uploadedwandb: \ 0.020 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.573
wandb: best_valid_acc 0.544
wandb:  sub_train_acc 0.46566
wandb: sub_train_loss 1.57093
wandb:       test_acc 0.463
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run rural-sweep-155 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5hukvtjk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215500-5hukvtjk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ut82e31t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215517-ut82e31t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-156
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ut82e31t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 234.96it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 257.54it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 278.25it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 279.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 274.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 276.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 285.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 293.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:00<00:00, 297.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 300.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 286.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.562
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.46344
wandb: sub_train_loss 1.56983
wandb:       test_acc 0.471
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run stilted-sweep-156 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ut82e31t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215517-ut82e31t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 58zdk6t7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215532-58zdk6t7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-157
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/58zdk6t7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 264.75it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 268.37it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 272.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 274.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 275.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 276.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 274.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 271.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 270.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 269.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 269.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.65547
wandb: sub_train_loss 1.59344
wandb:       test_acc 0.657
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run glad-sweep-157 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/58zdk6t7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215532-58zdk6t7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: thrs6ljv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215547-thrs6ljv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/thrs6ljv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 262.09it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 269.65it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:00, 268.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 274.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 281.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 281.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 282.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 279.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:00<00:00, 279.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 279.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 278.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.679
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.66691
wandb: sub_train_loss 1.59285
wandb:       test_acc 0.684
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run firm-sweep-158 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/thrs6ljv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215547-thrs6ljv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mzms3fjq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215603-mzms3fjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-159
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mzms3fjq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 239.87it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 259.39it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 277.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 285.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 288.29it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 287.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 285.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 287.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 290.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 297.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.67614
wandb: sub_train_loss 1.59889
wandb:       test_acc 0.678
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run legendary-sweep-159 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mzms3fjq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215603-mzms3fjq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y5beo9xw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215618-y5beo9xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-160
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y5beo9xw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 275.13it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 285.35it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 278.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 266.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 259.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 259.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 269.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 278.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 284.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 293.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 279.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.684
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.70347
wandb: sub_train_loss 1.59736
wandb:       test_acc 0.695
wandb:      valid_acc 0.66
wandb: 
wandb: üöÄ View run fragrant-sweep-160 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y5beo9xw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215618-y5beo9xw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mevkdgid with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215636-mevkdgid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-161
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mevkdgid
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.60it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 174.52it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 183.52it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 188.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 191.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 191.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 189.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 186.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 187.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 187.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 189.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 191.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 192.88it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 191.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 191.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.264
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.27363
wandb: sub_train_loss 0.00021
wandb:       test_acc 0.263
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run pious-sweep-161 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mevkdgid
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215636-mevkdgid/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ww11ub0i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215655-ww11ub0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-162
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ww11ub0i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.55it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 166.30it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 161.68it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 169.22it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 176.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 175.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 174.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 179.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 186.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 192.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 195.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 197.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 199.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 200.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 201.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.284
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.27474
wandb: sub_train_loss 0.00019
wandb:       test_acc 0.284
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run fresh-sweep-162 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ww11ub0i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215655-ww11ub0i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2tzg681f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215710-2tzg681f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2tzg681f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.43it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 170.74it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 172.91it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 177.12it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 175.88it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 177.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 177.64it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 180.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 182.03it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 183.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 186.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 179.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 172.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 164.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 159.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 155.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.42984
wandb: sub_train_loss 0.00251
wandb:       test_acc 0.531
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run crisp-sweep-163 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2tzg681f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215710-2tzg681f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ss4n2gbr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215724-ss4n2gbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-164
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ss4n2gbr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.61it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 184.08it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 195.49it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 200.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 178.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 182.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 188.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 190.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 188.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 190.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 190.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 191.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 195.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 198.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.42688
wandb: sub_train_loss 0.00234
wandb:       test_acc 0.556
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run worldly-sweep-164 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ss4n2gbr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215724-ss4n2gbr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xfgb68zc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215740-xfgb68zc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-165
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfgb68zc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 197.23it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 187.37it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 190.44it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 190.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 190.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 190.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 191.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 193.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 193.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 195.15it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 195.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 196.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 197.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 197.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.712
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.56905
wandb: sub_train_loss 0.02215
wandb:       test_acc 0.701
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run lemon-sweep-165 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfgb68zc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215740-xfgb68zc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3u7a68g8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215755-3u7a68g8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3u7a68g8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 183.74it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 192.42it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 193.41it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 195.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 197.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 196.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 195.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 195.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 196.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 197.59it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 197.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 197.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 196.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 192.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.685
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.55502
wandb: sub_train_loss 0.02363
wandb:       test_acc 0.679
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run sleek-sweep-166 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3u7a68g8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215755-3u7a68g8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 36f6gxi6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215811-36f6gxi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/36f6gxi6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.71it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.29it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 198.30it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 198.41it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 196.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 197.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 197.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 197.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 198.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 198.55it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 198.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 194.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 194.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 191.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.733
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.57607
wandb: sub_train_loss 0.02928
wandb:       test_acc 0.704
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run fresh-sweep-167 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/36f6gxi6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215811-36f6gxi6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ddho9jod with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215826-ddho9jod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ddho9jod
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.42it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 179.55it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 183.74it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 186.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 186.18it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 188.21it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 190.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 191.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 192.04it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 193.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 192.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 192.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 193.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 195.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 194.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.60118
wandb: sub_train_loss 0.03277
wandb:       test_acc 0.726
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run proud-sweep-168 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ddho9jod
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215826-ddho9jod/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zh0yhmsd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215841-zh0yhmsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-169
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zh0yhmsd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.16it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 206.74it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 184.88it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 184.83it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 184.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 181.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 183.50it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 186.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 185.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 181.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 187.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 192.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 196.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 194.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 184.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.79
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.661
wandb: sub_train_loss 0.05176
wandb:       test_acc 0.753
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run lunar-sweep-169 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zh0yhmsd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215841-zh0yhmsd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tnsi8fjg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215856-tnsi8fjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-170
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tnsi8fjg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.69it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.67it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 181.07it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 178.73it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 177.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 180.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 183.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 188.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 191.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 191.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 190.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 188.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 188.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 192.23it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 193.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.777
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.68612
wandb: sub_train_loss 0.04193
wandb:       test_acc 0.783
wandb:      valid_acc 0.756
wandb: 
wandb: üöÄ View run brisk-sweep-170 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tnsi8fjg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215856-tnsi8fjg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zvt6pa0m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215911-zvt6pa0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-171
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zvt6pa0m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.86it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 195.73it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 197.21it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 186.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 180.00it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 182.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 182.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 184.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 186.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 188.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 192.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 193.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 196.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 196.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 191.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.809
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.74705
wandb: sub_train_loss 0.0733
wandb:       test_acc 0.812
wandb:      valid_acc 0.796
wandb: 
wandb: üöÄ View run jolly-sweep-171 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zvt6pa0m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215911-zvt6pa0m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ds9byy4b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215927-ds9byy4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-172
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ds9byy4b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 191.04it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 184.98it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 182.46it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 185.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 185.99it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 182.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 182.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 184.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 185.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 185.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 185.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 185.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 187.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 187.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 186.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.812
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.75148
wandb: sub_train_loss 0.08111
wandb:       test_acc 0.809
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run lunar-sweep-172 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ds9byy4b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215927-ds9byy4b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bx7mgg5o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215943-bx7mgg5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bx7mgg5o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.45it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 171.36it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 174.30it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 178.89it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 182.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 185.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 186.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 189.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 188.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 189.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 185.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 180.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 178.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 176.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 180.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.806
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.77917
wandb: sub_train_loss 0.11753
wandb:       test_acc 0.812
wandb:      valid_acc 0.788
wandb: 
wandb: üöÄ View run gallant-sweep-173 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bx7mgg5o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215943-bx7mgg5o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9wm2oip1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_215958-9wm2oip1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-174
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9wm2oip1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.04it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.58it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 187.70it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 189.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 189.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 189.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 192.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 194.28it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 191.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 185.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 180.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 177.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 176.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 176.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 177.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.794
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.76145
wandb: sub_train_loss 0.09944
wandb:       test_acc 0.786
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run wild-sweep-174 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9wm2oip1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_215958-9wm2oip1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yvfbhhy5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220019-yvfbhhy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-175
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yvfbhhy5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.84it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 182.57it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 177.54it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 172.09it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 172.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 169.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 164.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 165.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 165.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 170.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 167.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 166.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 161.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 164.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 170.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 171.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.816
wandb: best_valid_acc 0.818
wandb:  sub_train_acc 0.79616
wandb: sub_train_loss 0.10971
wandb:       test_acc 0.786
wandb:      valid_acc 0.788
wandb: 
wandb: üöÄ View run absurd-sweep-175 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yvfbhhy5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220019-yvfbhhy5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wts1ia8s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220036-wts1ia8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-176
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wts1ia8s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.45it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.54it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 169.88it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 171.54it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 170.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 157.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 147.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 148.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 155.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 162.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 167.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 170.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 169.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 166.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 166.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 172.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.817
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.8161
wandb: sub_train_loss 0.08739
wandb:       test_acc 0.816
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run decent-sweep-176 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wts1ia8s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220036-wts1ia8s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4couqrb9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220052-4couqrb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-177
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4couqrb9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.65it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.14it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.02it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 148.37it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 148.00it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.25it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 146.77it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 146.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 147.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 142.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 130.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 120.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 123.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 127.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 131.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 133.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 139.21it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 142.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 144.21it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 142.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.529
wandb: best_valid_acc 0.524
wandb:  sub_train_acc 0.17504
wandb: sub_train_loss 7e-05
wandb:       test_acc 0.156
wandb:      valid_acc 0.144
wandb: 
wandb: üöÄ View run fallen-sweep-177 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4couqrb9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220052-4couqrb9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2o5p53cv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220112-2o5p53cv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2o5p53cv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.90it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 141.61it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 139.16it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 140.55it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 139.79it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 138.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 136.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 135.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 134.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 134.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 135.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 139.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 130.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 107.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 95.06it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 91.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 85.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 81.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 79.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 77.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 81.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 82.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 82.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 89.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 107.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.415
wandb: best_valid_acc 0.446
wandb:  sub_train_acc 0.26219
wandb: sub_train_loss 0.0
wandb:       test_acc 0.244
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run playful-sweep-178 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2o5p53cv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220112-2o5p53cv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nyxsf0rp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220128-nyxsf0rp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-179
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nyxsf0rp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.19it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 134.39it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 112.09it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 107.26it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 106.61it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 107.50it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 110.75it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 116.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 113.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 110.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 111.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 120.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 124.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 126.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 128.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 129.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 127.19it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 125.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 124.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 123.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 125.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 129.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.466
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.26773
wandb: sub_train_loss 0.00103
wandb:       test_acc 0.196
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run apricot-sweep-179 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nyxsf0rp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220128-nyxsf0rp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ifw9qarn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220143-ifw9qarn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-180
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ifw9qarn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.23it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 127.19it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 131.45it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.14it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.84it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 137.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 137.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 133.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 115.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 109.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 110.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 112.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 114.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 116.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 121.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 124.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 126.59it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 125.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 124.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 117.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 114.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 116.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 121.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.652
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.47932
wandb: sub_train_loss 0.00072
wandb:       test_acc 0.557
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run true-sweep-180 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ifw9qarn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220143-ifw9qarn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ko3ra75o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220159-ko3ra75o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-181
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ko3ra75o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.53it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.14it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 115.24it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 119.68it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 117.91it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 116.54it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 117.47it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 117.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 120.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 117.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 119.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 127.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 131.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 133.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 132.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 131.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 134.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 136.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 136.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 138.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 137.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 135.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.662
wandb: best_valid_acc 0.624
wandb:  sub_train_acc 0.27548
wandb: sub_train_loss 0.81067
wandb:       test_acc 0.219
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run astral-sweep-181 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ko3ra75o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220159-ko3ra75o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7hut9ozq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220214-7hut9ozq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-182
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7hut9ozq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.39it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.64it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 136.00it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 130.04it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 129.75it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 132.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 134.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 122.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 110.78it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 103.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 96.84it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 104.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 113.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 119.92it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 123.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 125.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 126.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 128.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 131.93it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 134.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 134.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.4723
wandb: sub_train_loss 0.04346
wandb:       test_acc 0.512
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run wild-sweep-182 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7hut9ozq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220214-7hut9ozq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gopladdh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220229-gopladdh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gopladdh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.28it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 123.98it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 130.27it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 136.49it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 122.69it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 123.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 127.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 133.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 135.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 134.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 132.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 130.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 131.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 131.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 126.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 126.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 128.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 126.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 125.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 126.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 125.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.677
wandb: best_valid_acc 0.684
wandb:  sub_train_acc 0.4483
wandb: sub_train_loss 0.74152
wandb:       test_acc 0.463
wandb:      valid_acc 0.456
wandb: 
wandb: üöÄ View run snowy-sweep-183 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gopladdh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220229-gopladdh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ygqgsfoi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220245-ygqgsfoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-184
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ygqgsfoi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.31it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 129.65it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.07it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.71it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 130.91it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 129.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 116.03it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 113.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 114.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 111.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 111.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 113.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 117.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 120.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 121.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 122.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 124.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 124.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 126.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 129.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 131.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 128.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.39032
wandb: sub_train_loss 0.41242
wandb:       test_acc 0.336
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run clean-sweep-184 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ygqgsfoi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220245-ygqgsfoi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6svqo4lb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220301-6svqo4lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-185
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6svqo4lb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.56it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 135.77it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.53it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 136.06it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 116.30it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:02, 104.27it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:02, 101.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 102.21it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 101.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 97.42it/s]  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 94.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 93.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 102.95it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 108.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 113.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 117.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 123.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 130.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 134.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 135.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 138.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 129.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.741
wandb: best_valid_acc 0.718
wandb:  sub_train_acc 0.62112
wandb: sub_train_loss 0.03301
wandb:       test_acc 0.669
wandb:      valid_acc 0.652
wandb: 
wandb: üöÄ View run firm-sweep-185 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6svqo4lb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220301-6svqo4lb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jcywlhdb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220322-jcywlhdb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-186
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jcywlhdb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.11it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 130.10it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 132.45it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 130.25it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 128.59it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 127.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 128.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 124.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 124.31it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 131.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 137.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 141.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 144.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 146.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 148.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 148.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 149.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 147.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 148.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 148.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.757
wandb: best_valid_acc 0.752
wandb:  sub_train_acc 0.51219
wandb: sub_train_loss 0.11712
wandb:       test_acc 0.498
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run fancy-sweep-186 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jcywlhdb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220322-jcywlhdb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 73ry6ry7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220336-73ry6ry7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-187
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/73ry6ry7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.95it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.98it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.56it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.19it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.59it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 133.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 131.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 131.38it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 131.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 131.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 131.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 131.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 132.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 131.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 132.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 129.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 130.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 132.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 130.59it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 126.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.768
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.60303
wandb: sub_train_loss 0.64104
wandb:       test_acc 0.603
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run resilient-sweep-187 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/73ry6ry7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220336-73ry6ry7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nj0ht4cs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220352-nj0ht4cs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nj0ht4cs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 109.45it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.47it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 120.98it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 122.40it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 110.34it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 104.74it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 102.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:02, 98.49it/s]  36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:01, 97.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 95.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 96.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 95.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 90.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 88.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 87.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 87.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 87.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 88.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 85.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:01, 85.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 92.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 98.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 96.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 99.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 104.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 110.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 114.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 100.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.51957
wandb: sub_train_loss 0.60064
wandb:       test_acc 0.487
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run youthful-sweep-188 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nj0ht4cs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220352-nj0ht4cs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: st8x8ytl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220407-st8x8ytl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-189
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/st8x8ytl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.53it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 127.22it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 130.23it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 130.74it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 129.73it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 129.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 129.74it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 131.05it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 126.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 128.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 131.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 132.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 135.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 138.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 141.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 144.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 145.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 145.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 143.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 138.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.787
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.69018
wandb: sub_train_loss 0.26435
wandb:       test_acc 0.709
wandb:      valid_acc 0.682
wandb: 
wandb: üöÄ View run cool-sweep-189 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/st8x8ytl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220407-st8x8ytl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7q4z8a9i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220423-7q4z8a9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-190
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7q4z8a9i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.96it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 128.25it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 132.22it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 132.03it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 123.92it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 122.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 119.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 116.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 124.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 126.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 127.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 117.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 119.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 118.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 114.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 115.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 114.35it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 116.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 118.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 118.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 119.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 116.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 115.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.784
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.48227
wandb: sub_train_loss 0.89653
wandb:       test_acc 0.452
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run whole-sweep-190 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7q4z8a9i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220423-7q4z8a9i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nudxvqig with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220440-nudxvqig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-191
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nudxvqig
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.10it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 113.92it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 119.89it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 128.82it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 131.00it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 134.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 132.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 134.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 137.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 131.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 119.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 123.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 126.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 126.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 126.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 123.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 117.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 124.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 128.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 128.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 129.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.34897
wandb: sub_train_loss 0.98479
wandb:       test_acc 0.364
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run cosmic-sweep-191 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nudxvqig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220440-nudxvqig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pfi8f6l4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220454-pfi8f6l4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-192
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pfi8f6l4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.09it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 144.95it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 142.10it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 142.42it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 146.93it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 149.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 150.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 148.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 147.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 139.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 131.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 134.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 135.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 134.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 130.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 132.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 138.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 143.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 144.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.020 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.756
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.36411
wandb: sub_train_loss 1.13395
wandb:       test_acc 0.361
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run revived-sweep-192 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pfi8f6l4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220454-pfi8f6l4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bldpkr9y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220514-bldpkr9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bldpkr9y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 233.88it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 226.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 244.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 269.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 292.33it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 307.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 289.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.137
wandb: best_valid_acc 0.12
wandb:  sub_train_acc 0.07792
wandb: sub_train_loss 1.85663
wandb:       test_acc 0.077
wandb:      valid_acc 0.072
wandb: 
wandb: üöÄ View run clear-sweep-193 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bldpkr9y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220514-bldpkr9y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nfwsyjr7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220530-nfwsyjr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-194
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nfwsyjr7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 324.69it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 332.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 328.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 324.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 334.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 332.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.15
wandb: best_valid_acc 0.166
wandb:  sub_train_acc 0.16728
wandb: sub_train_loss 1.8591
wandb:       test_acc 0.159
wandb:      valid_acc 0.166
wandb: 
wandb: üöÄ View run avid-sweep-194 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nfwsyjr7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220530-nfwsyjr7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: occeicao with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220544-occeicao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-195
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/occeicao
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 322.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 335.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 329.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 322.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 322.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 326.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.211
wandb: best_valid_acc 0.23
wandb:  sub_train_acc 0.18648
wandb: sub_train_loss 1.86999
wandb:       test_acc 0.194
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run whole-sweep-195 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/occeicao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220544-occeicao/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5t0t1bk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220600-i5t0t1bk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-196
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i5t0t1bk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 339.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 323.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 313.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 319.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 327.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 316.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.131
wandb: best_valid_acc 0.122
wandb:  sub_train_acc 0.11595
wandb: sub_train_loss 1.86349
wandb:       test_acc 0.135
wandb:      valid_acc 0.122
wandb: 
wandb: üöÄ View run cosmic-sweep-196 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i5t0t1bk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220600-i5t0t1bk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ppuaemui with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220617-ppuaemui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-197
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ppuaemui
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.30it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 291.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 302.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 327.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 335.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 341.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 326.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.463
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.41137
wandb: sub_train_loss 1.87359
wandb:       test_acc 0.46
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run chocolate-sweep-197 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ppuaemui
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220617-ppuaemui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ieniedg6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220631-ieniedg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ieniedg6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 312.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 314.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 305.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 300.51it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 292.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 314.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 308.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.23818
wandb: sub_train_loss 1.87354
wandb:       test_acc 0.227
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run giddy-sweep-198 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ieniedg6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220631-ieniedg6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c8milrvc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220643-c8milrvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c8milrvc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 367.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 371.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 373.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 375.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 375.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 373.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.188
wandb: best_valid_acc 0.2
wandb:  sub_train_acc 0.19461
wandb: sub_train_loss 1.87447
wandb:       test_acc 0.189
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run fanciful-sweep-199 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c8milrvc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220643-c8milrvc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hct20li1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220657-hct20li1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hct20li1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 358.03it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 353.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 354.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 316.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 294.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 303.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.249
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.25443
wandb: sub_train_loss 1.87407
wandb:       test_acc 0.243
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run upbeat-sweep-200 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hct20li1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220657-hct20li1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t9sh7hki with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220709-t9sh7hki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t9sh7hki
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 341.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 348.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 349.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 353.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 346.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 347.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.403
wandb: best_valid_acc 0.386
wandb:  sub_train_acc 0.35968
wandb: sub_train_loss 1.87715
wandb:       test_acc 0.403
wandb:      valid_acc 0.386
wandb: 
wandb: üöÄ View run legendary-sweep-201 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t9sh7hki
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220709-t9sh7hki/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v7y03775 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220723-v7y03775
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-202
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/v7y03775
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 256.68it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 243.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 283.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 303.04it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 313.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 315.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 300.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.299
wandb: best_valid_acc 0.302
wandb:  sub_train_acc 0.27696
wandb: sub_train_loss 1.87597
wandb:       test_acc 0.299
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run zesty-sweep-202 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/v7y03775
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220723-v7y03775/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a95ufncg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220739-a95ufncg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a95ufncg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 353.90it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 360.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 362.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 362.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 360.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 360.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.41728
wandb: sub_train_loss 1.88389
wandb:       test_acc 0.422
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run clean-sweep-203 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a95ufncg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220739-a95ufncg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i3fbbvuz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220753-i3fbbvuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-204
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i3fbbvuz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 317.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 303.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 321.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 334.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 341.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 335.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.431
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.43242
wandb: sub_train_loss 1.88231
wandb:       test_acc 0.446
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run crimson-sweep-204 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i3fbbvuz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220753-i3fbbvuz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mythht5z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220809-mythht5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-205
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mythht5z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 331.64it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 337.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 342.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 342.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 346.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 345.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.47
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.476
wandb: sub_train_loss 1.88695
wandb:       test_acc 0.47
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run faithful-sweep-205 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mythht5z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220809-mythht5z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ske9oa1w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220830-ske9oa1w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-206
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ske9oa1w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 291.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 326.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 333.87it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 335.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 337.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 333.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.334
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.33272
wandb: sub_train_loss 1.88646
wandb:       test_acc 0.334
wandb:      valid_acc 0.322
wandb: 
wandb: üöÄ View run denim-sweep-206 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ske9oa1w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220830-ske9oa1w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gtt858vu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220845-gtt858vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-207
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gtt858vu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 301.50it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 318.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 324.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 329.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 334.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 330.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.618
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.64549
wandb: sub_train_loss 1.88776
wandb:       test_acc 0.62
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run light-sweep-207 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gtt858vu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220845-gtt858vu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2a7k6icd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220900-2a7k6icd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-208
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2a7k6icd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 347.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 350.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 349.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 351.45it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 354.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 351.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.633
wandb: best_valid_acc 0.63
wandb:  sub_train_acc 0.65547
wandb: sub_train_loss 1.88733
wandb:       test_acc 0.633
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run polished-sweep-208 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2a7k6icd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220900-2a7k6icd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vm15yu0n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220916-vm15yu0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-209
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vm15yu0n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 255.83it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 242.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 244.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 243.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 249.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 250.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 250.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 248.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.124
wandb: best_valid_acc 0.142
wandb:  sub_train_acc 0.0938
wandb: sub_train_loss 1.73263
wandb:       test_acc 0.117
wandb:      valid_acc 0.122
wandb: 
wandb: üöÄ View run eager-sweep-209 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vm15yu0n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220916-vm15yu0n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 177g05np with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220936-177g05np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-210
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/177g05np
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.86it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 247.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 241.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 244.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 240.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 233.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 239.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 241.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.358
wandb: best_valid_acc 0.382
wandb:  sub_train_acc 0.32238
wandb: sub_train_loss 1.72283
wandb:       test_acc 0.189
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run jumping-sweep-210 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/177g05np
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220936-177g05np/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ex81ruom with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_220957-ex81ruom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-211
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ex81ruom
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 207.71it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 225.23it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 227.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 230.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 229.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 231.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 231.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 236.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 232.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.23006
wandb: sub_train_loss 1.73938
wandb:       test_acc 0.236
wandb:      valid_acc 0.232
wandb: 
wandb: üöÄ View run exalted-sweep-211 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ex81ruom
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_220957-ex81ruom/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hmr4w5zf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221011-hmr4w5zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-212
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hmr4w5zf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 230.64it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 237.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 252.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 258.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 258.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 253.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 250.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 248.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.221
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.18981
wandb: sub_train_loss 1.7488
wandb:       test_acc 0.226
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run visionary-sweep-212 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hmr4w5zf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221011-hmr4w5zf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 50q7yvff with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221023-50q7yvff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-213
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/50q7yvff
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 274.75it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 271.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 266.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 261.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 255.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 245.59it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 235.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 245.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.194
wandb: best_valid_acc 0.198
wandb:  sub_train_acc 0.18095
wandb: sub_train_loss 1.75641
wandb:       test_acc 0.169
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run hearty-sweep-213 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/50q7yvff
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221023-50q7yvff/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g956d5t2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221038-g956d5t2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-214
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g956d5t2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.11it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 255.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 240.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 238.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 237.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 244.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 245.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 245.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.199
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.14365
wandb: sub_train_loss 1.73844
wandb:       test_acc 0.199
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run likely-sweep-214 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g956d5t2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221038-g956d5t2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zsdsqm45 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221053-zsdsqm45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-215
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zsdsqm45
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 275.10it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 277.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 270.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 268.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 265.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 264.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 260.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 265.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.215
wandb: best_valid_acc 0.226
wandb:  sub_train_acc 0.20938
wandb: sub_train_loss 1.78041
wandb:       test_acc 0.216
wandb:      valid_acc 0.226
wandb: 
wandb: üöÄ View run cerulean-sweep-215 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zsdsqm45
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221053-zsdsqm45/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: od8zuywq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221105-od8zuywq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-216
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/od8zuywq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 270.64it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 275.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 281.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 278.49it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 273.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 277.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 278.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.232
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.19092
wandb: sub_train_loss 1.76703
wandb:       test_acc 0.178
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run azure-sweep-216 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/od8zuywq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221105-od8zuywq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n5wz4q3p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221119-n5wz4q3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-217
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/n5wz4q3p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 258.19it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 256.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 257.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 260.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 257.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 253.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 253.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 255.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.386
wandb: best_valid_acc 0.402
wandb:  sub_train_acc 0.30133
wandb: sub_train_loss 1.80755
wandb:       test_acc 0.386
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run eternal-sweep-217 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/n5wz4q3p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221119-n5wz4q3p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: va16azfz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221140-va16azfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/va16azfz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.75it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 211.44it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 214.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 215.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 216.46it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 219.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 225.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 227.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 222.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.405
wandb: best_valid_acc 0.392
wandb:  sub_train_acc 0.27142
wandb: sub_train_loss 1.76256
wandb:       test_acc 0.405
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run light-sweep-218 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/va16azfz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221140-va16azfz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i3lhxpb5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221205-i3lhxpb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-219
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i3lhxpb5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 266.10it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 281.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 286.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 288.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 289.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 285.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 285.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.388
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.31352
wandb: sub_train_loss 1.78413
wandb:       test_acc 0.388
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run unique-sweep-219 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i3lhxpb5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221205-i3lhxpb5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: v8rpoiuy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221220-v8rpoiuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-220
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/v8rpoiuy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 255.59it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 260.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 259.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 260.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 256.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 256.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 258.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 259.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.383
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.35487
wandb: sub_train_loss 1.80226
wandb:       test_acc 0.383
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run woven-sweep-220 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/v8rpoiuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221220-v8rpoiuy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mbjpskep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221236-mbjpskep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-221
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mbjpskep
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 269.43it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 277.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 277.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 274.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 271.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 264.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 244.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 259.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.47
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.44055
wandb: sub_train_loss 1.8006
wandb:       test_acc 0.47
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run rose-sweep-221 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mbjpskep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221236-mbjpskep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hzl6p2r0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221251-hzl6p2r0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hzl6p2r0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 255.20it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 254.46it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 255.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 252.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 251.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 241.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 212.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 231.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.472
wandb: best_valid_acc 0.464
wandb:  sub_train_acc 0.4339
wandb: sub_train_loss 1.81095
wandb:       test_acc 0.476
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run atomic-sweep-222 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hzl6p2r0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221251-hzl6p2r0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wkyku50t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221306-wkyku50t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-223
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wkyku50t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 253.32it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 264.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 260.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 254.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 252.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 252.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 255.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 257.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.722
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.74778
wandb: sub_train_loss 1.79002
wandb:       test_acc 0.725
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run polished-sweep-223 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wkyku50t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221306-wkyku50t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3fb41slc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221322-3fb41slc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-224
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3fb41slc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 275.40it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 279.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 280.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 286.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 287.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 288.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 284.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.565
wandb: best_valid_acc 0.562
wandb:  sub_train_acc 0.59417
wandb: sub_train_loss 1.77405
wandb:       test_acc 0.576
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run faithful-sweep-224 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3fb41slc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221322-3fb41slc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g0we0vws with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221337-g0we0vws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-225
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g0we0vws
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.09it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 190.24it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 193.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 194.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 195.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 196.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 194.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 194.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 191.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.022 MB of 0.023 MB uploadedwandb: - 0.022 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.172
wandb: best_valid_acc 0.18
wandb:  sub_train_acc 0.15583
wandb: sub_train_loss 1.66953
wandb:       test_acc 0.078
wandb:      valid_acc 0.076
wandb: 
wandb: üöÄ View run exalted-sweep-225 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g0we0vws
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221337-g0we0vws/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m0v9tm21 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221353-m0v9tm21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-226
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m0v9tm21
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.61it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 205.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 205.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 202.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 199.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 199.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 201.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 199.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 198.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 200.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.174
wandb: best_valid_acc 0.188
wandb:  sub_train_acc 0.07275
wandb: sub_train_loss 1.57334
wandb:       test_acc 0.065
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run genial-sweep-226 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m0v9tm21
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221353-m0v9tm21/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 09bg88ss with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221408-09bg88ss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-227
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/09bg88ss
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 208.20it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 186.52it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 190.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 197.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 205.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 208.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 208.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 210.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 210.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 206.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.252
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.15953
wandb: sub_train_loss 1.70553
wandb:       test_acc 0.177
wandb:      valid_acc 0.158
wandb: 
wandb: üöÄ View run super-sweep-227 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/09bg88ss
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221408-09bg88ss/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6vp5poew with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221424-6vp5poew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-228
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6vp5poew
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 177.49it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 177.02it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 172.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 183.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 186.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 189.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 189.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 192.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 197.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 202.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.19
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.07275
wandb: sub_train_loss 1.73671
wandb:       test_acc 0.065
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run noble-sweep-228 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6vp5poew
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221424-6vp5poew/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bfw4asv7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221439-bfw4asv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-229
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bfw4asv7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.07it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 184.55it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 183.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 178.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 172.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 169.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 163.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 165.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 168.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 170.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.215
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.1466
wandb: sub_train_loss 1.71687
wandb:       test_acc 0.218
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run honest-sweep-229 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bfw4asv7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221439-bfw4asv7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ik1a4w8p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221454-ik1a4w8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-230
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ik1a4w8p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.24it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 215.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 215.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 217.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 219.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 209.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 208.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 199.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 200.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 206.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.23
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.29948
wandb: sub_train_loss 1.73386
wandb:       test_acc 0.234
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run honest-sweep-230 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ik1a4w8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221454-ik1a4w8p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ra377v85 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221505-ra377v85
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-231
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ra377v85
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 208.70it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 216.58it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 219.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 212.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 206.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 207.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 207.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 207.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 205.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 208.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.068
wandb: best_valid_acc 0.06
wandb:  sub_train_acc 0.07459
wandb: sub_train_loss 1.79011
wandb:       test_acc 0.071
wandb:      valid_acc 0.06
wandb: 
wandb: üöÄ View run robust-sweep-231 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ra377v85
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221505-ra377v85/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 71lzi6oi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221521-71lzi6oi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-232
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/71lzi6oi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.55it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 152.06it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 153.56it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 156.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 159.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 163.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 162.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 169.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 177.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 179.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 182.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.404
wandb:  sub_train_acc 0.24225
wandb: sub_train_loss 1.75549
wandb:       test_acc 0.263
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run stilted-sweep-232 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/71lzi6oi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221521-71lzi6oi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j0eqzl55 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221535-j0eqzl55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-233
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j0eqzl55
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.07it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 193.31it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 194.40it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 186.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 192.21it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 200.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 202.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 201.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 201.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.251
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.19165
wandb: sub_train_loss 1.7453
wandb:       test_acc 0.251
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run lilac-sweep-233 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j0eqzl55
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221535-j0eqzl55/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z0kre1pd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221551-z0kre1pd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-234
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z0kre1pd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.76it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 184.24it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 185.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 192.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 191.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 193.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 170.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 185.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 194.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.124
wandb: best_valid_acc 0.13
wandb:  sub_train_acc 0.20643
wandb: sub_train_loss 1.73826
wandb:       test_acc 0.127
wandb:      valid_acc 0.13
wandb: 
wandb: üöÄ View run sweet-sweep-234 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z0kre1pd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221551-z0kre1pd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8mc5j3up with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221607-8mc5j3up
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-235
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8mc5j3up
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 196.37it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 198.44it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 197.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 198.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 195.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 188.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 185.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 188.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 183.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 176.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.461
wandb: best_valid_acc 0.468
wandb:  sub_train_acc 0.40805
wandb: sub_train_loss 1.75869
wandb:       test_acc 0.441
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run deft-sweep-235 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8mc5j3up
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221607-8mc5j3up/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e6shy45u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221619-e6shy45u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-236
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e6shy45u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.42it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 173.61it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 182.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 184.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 175.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 180.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 178.99it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 163.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 167.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 177.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.424
wandb: best_valid_acc 0.422
wandb:  sub_train_acc 0.40325
wandb: sub_train_loss 1.80584
wandb:       test_acc 0.424
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run comfy-sweep-236 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e6shy45u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221619-e6shy45u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dt966eb3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221633-dt966eb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-237
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dt966eb3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 182.23it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 193.42it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 195.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 135.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 139.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 148.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 160.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 166.09it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 174.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.394
wandb:  sub_train_acc 0.35894
wandb: sub_train_loss 1.79194
wandb:       test_acc 0.343
wandb:      valid_acc 0.334
wandb: 
wandb: üöÄ View run winter-sweep-237 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dt966eb3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221633-dt966eb3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xseig8nd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221648-xseig8nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-238
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xseig8nd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.99it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 184.36it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 160.64it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 162.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 163.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 158.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 155.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 148.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 139.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 134.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 127.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 123.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.526
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.51219
wandb: sub_train_loss 1.78252
wandb:       test_acc 0.533
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run neat-sweep-238 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xseig8nd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221648-xseig8nd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a8hqjb8o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221704-a8hqjb8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-239
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a8hqjb8o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 204.13it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 202.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 193.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 191.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 184.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 180.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 175.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 176.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 180.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 162.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.581
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.49151
wandb: sub_train_loss 1.81814
wandb:       test_acc 0.461
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run dulcet-sweep-239 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a8hqjb8o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221704-a8hqjb8o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vognczx9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221720-vognczx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-240
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vognczx9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 182.93it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.76it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 179.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 176.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 175.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 171.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 172.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 173.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 183.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 193.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.537
wandb: best_valid_acc 0.572
wandb:  sub_train_acc 0.57016
wandb: sub_train_loss 1.76042
wandb:       test_acc 0.537
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run revived-sweep-240 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vognczx9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221720-vognczx9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ovt8wksn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221736-ovt8wksn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-241
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ovt8wksn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 357.69it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 365.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 366.22it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 364.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 354.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 349.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 360.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:00<00:00, 365.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 361.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.201
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.19498
wandb: sub_train_loss 1.81724
wandb:       test_acc 0.201
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run robust-sweep-241 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ovt8wksn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221736-ovt8wksn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ystyubwb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221752-ystyubwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-242
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ystyubwb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 260.33it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 220.46it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 259.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 287.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 316.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 337.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 350.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:00<00:00, 351.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 323.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.223
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.22784
wandb: sub_train_loss 1.81126
wandb:       test_acc 0.217
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run dauntless-sweep-242 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ystyubwb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221752-ystyubwb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lo4mqdyy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221807-lo4mqdyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-243
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lo4mqdyy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 341.55it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 355.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 355.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 355.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 356.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 356.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:00<00:00, 355.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:00<00:00, 356.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 355.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.169
wandb: best_valid_acc 0.174
wandb:  sub_train_acc 0.15657
wandb: sub_train_loss 1.82495
wandb:       test_acc 0.169
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run restful-sweep-243 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lo4mqdyy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221807-lo4mqdyy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3a0kb1fu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221823-3a0kb1fu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-244
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3a0kb1fu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 360.37it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 353.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 350.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 348.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 356.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 364.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 370.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 370.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 362.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.232
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.22157
wandb: sub_train_loss 1.82343
wandb:       test_acc 0.221
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run jumping-sweep-244 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3a0kb1fu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221823-3a0kb1fu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yh37532g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221838-yh37532g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-245
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yh37532g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 364.43it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 370.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 373.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 373.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 363.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 362.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 368.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 370.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.237
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.19572
wandb: sub_train_loss 1.8295
wandb:       test_acc 0.244
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run hopeful-sweep-245 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yh37532g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221838-yh37532g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ug4osjny with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221852-ug4osjny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-246
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ug4osjny
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:00, 370.37it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 358.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 360.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 367.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 371.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 374.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 376.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 371.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.22
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.24889
wandb: sub_train_loss 1.83059
wandb:       test_acc 0.22
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run peach-sweep-246 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ug4osjny
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221852-ug4osjny/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7xlwhkig with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221908-7xlwhkig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-247
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7xlwhkig
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 349.37it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 362.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 356.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 360.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 358.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 349.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 348.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:00<00:00, 348.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 352.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.293
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.24963
wandb: sub_train_loss 1.83787
wandb:       test_acc 0.259
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run swept-sweep-247 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7xlwhkig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221908-7xlwhkig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gc7dj99h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221924-gc7dj99h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-248
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gc7dj99h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 338.40it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 364.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 368.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 369.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 372.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 374.70it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:00<00:00, 374.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 372.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.244
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.24742
wandb: sub_train_loss 1.83869
wandb:       test_acc 0.239
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run scarlet-sweep-248 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gc7dj99h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221924-gc7dj99h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tqdq3fk9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221939-tqdq3fk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tqdq3fk9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 328.85it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:00, 344.83it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 354.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 356.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 356.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 350.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 351.57it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 347.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 350.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.286
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.27105
wandb: sub_train_loss 1.83994
wandb:       test_acc 0.286
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run absurd-sweep-249 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tqdq3fk9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221939-tqdq3fk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ucind8ye with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_221954-ucind8ye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-250
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ucind8ye
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 323.04it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:00, 339.53it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 348.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 348.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 345.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 346.37it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 347.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:00<00:00, 343.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 343.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.429
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.42356
wandb: sub_train_loss 1.84136
wandb:       test_acc 0.43
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run vague-sweep-250 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ucind8ye
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_221954-ucind8ye/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uu4o4gb2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222010-uu4o4gb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-251
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uu4o4gb2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 316.84it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 317.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 316.86it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 318.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 318.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 316.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 313.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:00<00:00, 315.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:00<00:00, 327.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 320.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.486
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.45495
wandb: sub_train_loss 1.84987
wandb:       test_acc 0.485
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run clear-sweep-251 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uu4o4gb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222010-uu4o4gb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ug33ar3o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222031-ug33ar3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-252
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ug33ar3o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 336.93it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 336.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 334.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 335.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 338.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 347.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 347.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:00<00:00, 350.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 346.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.495
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.45864
wandb: sub_train_loss 1.8506
wandb:       test_acc 0.502
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run trim-sweep-252 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ug33ar3o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222031-ug33ar3o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yakqyie4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222045-yakqyie4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-253
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yakqyie4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 329.58it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 338.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 332.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 332.17it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 338.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 340.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 346.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:00<00:00, 352.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 345.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.397
wandb: best_valid_acc 0.374
wandb:  sub_train_acc 0.41581
wandb: sub_train_loss 1.85459
wandb:       test_acc 0.405
wandb:      valid_acc 0.374
wandb: 
wandb: üöÄ View run smooth-sweep-253 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yakqyie4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222045-yakqyie4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9bvpkzf4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222101-9bvpkzf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-254
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9bvpkzf4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 282.62it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 306.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 314.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 325.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 330.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 331.13it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 329.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:00<00:00, 332.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 328.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.384
wandb: best_valid_acc 0.354
wandb:  sub_train_acc 0.38996
wandb: sub_train_loss 1.85422
wandb:       test_acc 0.384
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run solar-sweep-254 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9bvpkzf4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222101-9bvpkzf4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lf8i92jw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222116-lf8i92jw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-255
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lf8i92jw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 333.28it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 336.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 334.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 335.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 341.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 343.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 344.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:00<00:00, 332.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 337.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.654
wandb: best_valid_acc 0.686
wandb:  sub_train_acc 0.63183
wandb: sub_train_loss 1.85666
wandb:       test_acc 0.605
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run firm-sweep-255 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lf8i92jw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222116-lf8i92jw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vk5l72o7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222137-vk5l72o7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-256
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vk5l72o7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 267.19it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 278.66it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 284.29it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 299.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 312.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 322.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:00<00:00, 328.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 321.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:00<00:00, 318.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 311.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.603
wandb: best_valid_acc 0.624
wandb:  sub_train_acc 0.6322
wandb: sub_train_loss 1.85472
wandb:       test_acc 0.603
wandb:      valid_acc 0.624
wandb: 
wandb: üöÄ View run stellar-sweep-256 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vk5l72o7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222137-vk5l72o7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3nj32yl7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222153-3nj32yl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3nj32yl7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 238.70it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 233.67it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 231.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 212.00it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 215.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 215.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 216.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 227.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 238.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 241.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 251.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 257.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 236.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.066
wandb: best_valid_acc 0.064
wandb:  sub_train_acc 0.0757
wandb: sub_train_loss 1.47733
wandb:       test_acc 0.073
wandb:      valid_acc 0.06
wandb: 
wandb: üöÄ View run wise-sweep-257 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3nj32yl7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222153-3nj32yl7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7rzqiyqk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222207-7rzqiyqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-258
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7rzqiyqk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 245.16it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 254.28it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 264.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 268.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 262.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 265.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 260.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 236.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 241.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 252.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 253.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 254.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.324
wandb: best_valid_acc 0.32
wandb:  sub_train_acc 0.11743
wandb: sub_train_loss 1.50106
wandb:       test_acc 0.195
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run cerulean-sweep-258 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7rzqiyqk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222207-7rzqiyqk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8l4n8vgg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222226-8l4n8vgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-259
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8l4n8vgg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 257.70it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 269.83it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 280.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 287.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 290.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 283.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 285.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 286.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 286.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 287.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.198
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.18168
wandb: sub_train_loss 1.5776
wandb:       test_acc 0.184
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run stellar-sweep-259 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8l4n8vgg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222226-8l4n8vgg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p19xaak8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222247-p19xaak8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p19xaak8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 244.97it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 248.04it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 236.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 229.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 232.69it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 220.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 223.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 225.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 230.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 235.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 239.59it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 246.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 235.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.251
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.21455
wandb: sub_train_loss 1.56521
wandb:       test_acc 0.207
wandb:      valid_acc 0.216
wandb: 
wandb: üöÄ View run bumbling-sweep-260 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p19xaak8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222247-p19xaak8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sa6zsxl4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222258-sa6zsxl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-261
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sa6zsxl4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 258.94it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 267.02it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:00, 269.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 274.36it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 270.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 267.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 257.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 252.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 250.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 250.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 248.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 256.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.18
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.22083
wandb: sub_train_loss 1.58304
wandb:       test_acc 0.18
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run wild-sweep-261 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sa6zsxl4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222258-sa6zsxl4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0sjc93yo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222314-0sjc93yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-262
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0sjc93yo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.85it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 250.34it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 245.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 245.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 243.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 245.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 246.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 250.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 252.58it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 253.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 252.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.233
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.23744
wandb: sub_train_loss 1.53773
wandb:       test_acc 0.233
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run wild-sweep-262 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0sjc93yo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222314-0sjc93yo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 629tcxhw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222329-629tcxhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-263
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/629tcxhw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 233.52it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 243.40it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 240.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 219.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 208.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 209.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 211.61it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 222.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 224.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 229.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 230.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 231.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.334
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.26219
wandb: sub_train_loss 1.60355
wandb:       test_acc 0.269
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run swift-sweep-263 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/629tcxhw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222329-629tcxhw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bab5cvf6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222340-bab5cvf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-264
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bab5cvf6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 244.32it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 242.80it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 253.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 263.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 269.40it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 276.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 279.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 282.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 284.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 287.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 275.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.281
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.23301
wandb: sub_train_loss 1.6335
wandb:       test_acc 0.281
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run fresh-sweep-264 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bab5cvf6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222340-bab5cvf6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: syhwmsev with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222355-syhwmsev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-265
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/syhwmsev
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 260.46it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 201.13it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 180.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 190.74it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 182.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 180.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 179.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 181.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 203.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 225.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 234.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 236.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 209.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.225
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.23818
wandb: sub_train_loss 1.67361
wandb:       test_acc 0.225
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run light-sweep-265 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/syhwmsev
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222355-syhwmsev/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wfxm76af with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222410-wfxm76af
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-266
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wfxm76af
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 250.44it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 242.45it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 240.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 231.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 227.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 228.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 225.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 224.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 214.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 211.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 204.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 199.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 217.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.484
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.43095
wandb: sub_train_loss 1.61241
wandb:       test_acc 0.488
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run scarlet-sweep-266 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wfxm76af
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222410-wfxm76af/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qbhthhzd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222425-qbhthhzd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-267
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qbhthhzd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 273.04it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 271.95it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 264.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 264.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 249.01it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 207.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 188.76it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 178.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 175.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 168.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 168.39it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 168.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 179.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 196.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.337
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.6601
wandb:       test_acc 0.337
wandb:      valid_acc 0.35
wandb: 
wandb: üöÄ View run comfy-sweep-267 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qbhthhzd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222425-qbhthhzd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fzp37b9e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222441-fzp37b9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-268
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fzp37b9e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.82it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 276.98it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 265.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 266.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 275.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 250.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 238.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 232.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:00<00:00, 230.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 221.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 211.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 236.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.541
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.43575
wandb: sub_train_loss 1.67978
wandb:       test_acc 0.541
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run winter-sweep-268 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fzp37b9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222441-fzp37b9e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ptzuf0d2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222501-ptzuf0d2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-269
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ptzuf0d2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 269.59it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 258.98it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 256.38it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 251.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 246.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 249.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 243.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 225.63it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 229.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 232.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 236.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 241.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.604
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.59527
wandb: sub_train_loss 1.65399
wandb:       test_acc 0.606
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run proud-sweep-269 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ptzuf0d2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222501-ptzuf0d2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dnxa7nvy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222517-dnxa7nvy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-270
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dnxa7nvy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 263.39it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 249.62it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 253.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 260.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 258.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 254.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 255.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 257.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 258.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 263.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 263.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 259.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.502
wandb:  sub_train_acc 0.48781
wandb: sub_train_loss 1.68775
wandb:       test_acc 0.491
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run swift-sweep-270 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dnxa7nvy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222517-dnxa7nvy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wbd0yh9o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222532-wbd0yh9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-271
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wbd0yh9o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.22it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 275.57it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 273.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 272.27it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 269.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 271.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 269.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 263.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 262.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 260.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 261.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.75
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.75739
wandb: sub_train_loss 1.64645
wandb:       test_acc 0.75
wandb:      valid_acc 0.728
wandb: 
wandb: üöÄ View run glamorous-sweep-271 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wbd0yh9o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222532-wbd0yh9o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fowo9xhr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222548-fowo9xhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-272
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fowo9xhr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.98it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 263.79it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 275.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 281.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 272.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 265.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 258.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 255.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 255.01it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 251.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 258.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.7644
wandb: sub_train_loss 1.61569
wandb:       test_acc 0.753
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run effortless-sweep-272 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fowo9xhr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222548-fowo9xhr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u17k2trw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222603-u17k2trw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-273
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u17k2trw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.23it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.20it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.01it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 148.96it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 152.08it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 156.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 155.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 158.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 162.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 162.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 165.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 158.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 154.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 151.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 152.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 155.50it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 155.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.151
wandb: best_valid_acc 0.17
wandb:  sub_train_acc 0.06647
wandb: sub_train_loss 1.303
wandb:       test_acc 0.064
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run glamorous-sweep-273 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u17k2trw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222603-u17k2trw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 20gfydcn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222618-20gfydcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-274
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/20gfydcn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 197.87it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 201.65it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 206.17it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 200.59it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 196.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 194.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 195.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 195.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 196.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 195.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 193.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 190.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 191.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 191.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 194.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.131
wandb: best_valid_acc 0.126
wandb:  sub_train_acc 0.07275
wandb: sub_train_loss 1.324
wandb:       test_acc 0.075
wandb:      valid_acc 0.068
wandb: 
wandb: üöÄ View run helpful-sweep-274 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/20gfydcn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222618-20gfydcn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jxe367k6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222633-jxe367k6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-275
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxe367k6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 203.87it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 204.67it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 205.40it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 202.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 198.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 202.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 208.63it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 212.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 216.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 216.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 216.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 215.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 216.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 211.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.25
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.0938
wandb: sub_train_loss 1.3594
wandb:       test_acc 0.121
wandb:      valid_acc 0.124
wandb: 
wandb: üöÄ View run celestial-sweep-275 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxe367k6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222633-jxe367k6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l1izydc3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222645-l1izydc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-276
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l1izydc3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 189.26it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 197.22it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 200.48it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 202.86it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 201.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 199.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 196.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 192.04it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 192.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 189.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 183.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 178.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 174.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 174.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 179.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.15
wandb: best_valid_acc 0.164
wandb:  sub_train_acc 0.11928
wandb: sub_train_loss 1.40034
wandb:       test_acc 0.117
wandb:      valid_acc 0.12
wandb: 
wandb: üöÄ View run lucky-sweep-276 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l1izydc3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222645-l1izydc3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g1fzeue4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222659-g1fzeue4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-277
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g1fzeue4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.89it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 190.38it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 194.26it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 196.46it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 193.87it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 190.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 192.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 190.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 189.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 188.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 186.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 185.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 185.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 185.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 188.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.202
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.32533
wandb: sub_train_loss 1.43302
wandb:       test_acc 0.191
wandb:      valid_acc 0.184
wandb: 
wandb: üöÄ View run fanciful-sweep-277 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g1fzeue4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222659-g1fzeue4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xhmhi687 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222714-xhmhi687
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-278
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xhmhi687
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.19it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.73it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 186.08it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 180.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 175.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 167.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 169.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 171.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 172.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 173.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 177.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 178.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 178.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 178.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 175.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 173.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.203
wandb: best_valid_acc 0.23
wandb:  sub_train_acc 0.28287
wandb: sub_train_loss 1.40968
wandb:       test_acc 0.21
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run young-sweep-278 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xhmhi687
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222714-xhmhi687/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qw6l5dih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222730-qw6l5dih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-279
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qw6l5dih
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 188.15it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 191.19it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 182.21it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 184.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 190.70it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 189.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 184.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 181.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 180.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 180.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 163.45it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 145.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 134.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 131.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 128.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 130.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.288
wandb:  sub_train_acc 0.21307
wandb: sub_train_loss 1.53975
wandb:       test_acc 0.241
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run pious-sweep-279 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qw6l5dih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222730-qw6l5dih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r7ivxmlh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222752-r7ivxmlh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-280
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r7ivxmlh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.23it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.51it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 165.98it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 169.12it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 172.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 167.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 167.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 171.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 184.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 194.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 200.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 203.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 203.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 189.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 196.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.27622
wandb: sub_train_loss 1.50354
wandb:       test_acc 0.293
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run ethereal-sweep-280 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r7ivxmlh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222752-r7ivxmlh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9odugzj3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222807-9odugzj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-281
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9odugzj3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.81it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 180.92it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 187.60it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 186.74it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 187.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 180.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 172.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 166.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 170.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 174.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 171.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 171.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 149.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 147.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 148.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 148.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.202
wandb: best_valid_acc 0.222
wandb:  sub_train_acc 0.32681
wandb: sub_train_loss 1.54309
wandb:       test_acc 0.223
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run azure-sweep-281 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9odugzj3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222807-9odugzj3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cgxf346e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222823-cgxf346e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-282
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cgxf346e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.26it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 159.10it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 150.45it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 159.60it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 152.18it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 150.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 150.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 152.69it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 160.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 170.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 174.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 175.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 176.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 176.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 174.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 177.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 177.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.569
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.47674
wandb: sub_train_loss 1.46209
wandb:       test_acc 0.572
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run hopeful-sweep-282 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cgxf346e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222823-cgxf346e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5cvwj3j8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222839-5cvwj3j8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-283
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5cvwj3j8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.34it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.38it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.45it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 181.42it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 184.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 182.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 186.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 190.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 193.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 185.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 192.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 194.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 196.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 202.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 198.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.486
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.43907
wandb: sub_train_loss 1.54639
wandb:       test_acc 0.448
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run balmy-sweep-283 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5cvwj3j8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222839-5cvwj3j8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6ek7e0hb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222853-6ek7e0hb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-284
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6ek7e0hb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.85it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.40it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 177.88it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 179.30it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 176.62it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 178.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 174.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 174.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 185.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 195.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 193.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 192.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 177.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 178.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 180.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.599
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.49926
wandb: sub_train_loss 1.57667
wandb:       test_acc 0.583
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run hopeful-sweep-284 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6ek7e0hb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222853-6ek7e0hb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s8ztozou with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222909-s8ztozou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-285
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8ztozou
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.08it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.02it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 176.47it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 172.95it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 177.20it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 156.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 136.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 136.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 143.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 162.52it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 177.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 186.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 192.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 190.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 191.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.603
wandb: best_valid_acc 0.578
wandb:  sub_train_acc 0.58567
wandb: sub_train_loss 1.52357
wandb:       test_acc 0.603
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run kind-sweep-285 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8ztozou
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222909-s8ztozou/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k80ng69a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222924-k80ng69a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-286
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k80ng69a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 197.45it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 207.51it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 212.95it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 206.27it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 205.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 207.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 208.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 209.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 210.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 205.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 203.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 198.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 193.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 184.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 199.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.605
wandb: best_valid_acc 0.592
wandb:  sub_train_acc 0.58124
wandb: sub_train_loss 1.53463
wandb:       test_acc 0.605
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run expert-sweep-286 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k80ng69a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222924-k80ng69a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 90jcehp5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222935-90jcehp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-287
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/90jcehp5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.81it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 178.38it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.97it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 169.05it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 170.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 180.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 191.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 194.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 198.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 201.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 202.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 201.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 199.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 197.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.635
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.65916
wandb: sub_train_loss 1.4449
wandb:       test_acc 0.635
wandb:      valid_acc 0.656
wandb: 
wandb: üöÄ View run unique-sweep-287 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/90jcehp5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222935-90jcehp5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5v1q3ys7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_222949-5v1q3ys7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-288
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5v1q3ys7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.53it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.51it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 174.69it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 181.84it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 186.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 191.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 189.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 189.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 188.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 188.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 190.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 186.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 185.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 185.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 177.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.498
wandb: best_valid_acc 0.516
wandb:  sub_train_acc 0.53693
wandb: sub_train_loss 1.42476
wandb:       test_acc 0.509
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run restful-sweep-288 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5v1q3ys7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_222949-5v1q3ys7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pl5yx6rq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223005-pl5yx6rq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-289
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pl5yx6rq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 307.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 311.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 315.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 317.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 316.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 317.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 316.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.208
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.1935
wandb: sub_train_loss 1.88441
wandb:       test_acc 0.215
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run graceful-sweep-289 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pl5yx6rq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223005-pl5yx6rq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jsvkhxno with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223020-jsvkhxno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-290
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jsvkhxno
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 232.96it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 245.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 245.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 252.62it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 258.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 268.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 273.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 263.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.178
wandb: best_valid_acc 0.174
wandb:  sub_train_acc 0.17393
wandb: sub_train_loss 1.88406
wandb:       test_acc 0.178
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run rose-sweep-290 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jsvkhxno
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223020-jsvkhxno/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cup6v4h6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223036-cup6v4h6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-291
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cup6v4h6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 259.41it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 268.16it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 261.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 256.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 255.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 258.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 273.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 266.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.207
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.19719
wandb: sub_train_loss 1.89961
wandb:       test_acc 0.21
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run restful-sweep-291 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cup6v4h6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223036-cup6v4h6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gn66qldd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223052-gn66qldd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-292
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gn66qldd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 304.29it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 286.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 280.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 280.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 285.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 285.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 286.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.21
wandb:  sub_train_acc 0.20901
wandb: sub_train_loss 1.90071
wandb:       test_acc 0.214
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run frosty-sweep-292 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gn66qldd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223052-gn66qldd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ryvo0bnv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223106-ryvo0bnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-293
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ryvo0bnv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 271.56it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 282.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 274.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 269.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 272.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 273.45it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 273.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 273.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.314
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.30391
wandb: sub_train_loss 1.90418
wandb:       test_acc 0.317
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run balmy-sweep-293 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ryvo0bnv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223106-ryvo0bnv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7t27zck8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223127-7t27zck8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-294
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7t27zck8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 278.58it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 282.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 278.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 277.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 281.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 283.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 285.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.365
wandb: best_valid_acc 0.358
wandb:  sub_train_acc 0.31942
wandb: sub_train_loss 1.90355
wandb:       test_acc 0.365
wandb:      valid_acc 0.358
wandb: 
wandb: üöÄ View run dauntless-sweep-294 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7t27zck8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223127-7t27zck8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: me806c7f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223143-me806c7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/me806c7f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 297.83it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 285.48it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 290.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 298.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 288.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 299.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 297.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.243
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.24963
wandb: sub_train_loss 1.90901
wandb:       test_acc 0.243
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run treasured-sweep-295 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/me806c7f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223143-me806c7f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 41p0bo0o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223158-41p0bo0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-296
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/41p0bo0o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.21it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 246.71it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 264.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 275.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 270.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 268.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 268.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 264.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.242
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.24631
wandb: sub_train_loss 1.90918
wandb:       test_acc 0.242
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run dry-sweep-296 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/41p0bo0o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223158-41p0bo0o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9fa6woy3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223213-9fa6woy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-297
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fa6woy3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 284.43it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 267.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 252.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 237.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 227.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 232.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 241.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 245.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.35
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.36078
wandb: sub_train_loss 1.9121
wandb:       test_acc 0.353
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run legendary-sweep-297 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9fa6woy3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223213-9fa6woy3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 04xvn6jk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223234-04xvn6jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-298
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/04xvn6jk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 291.76it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 293.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 291.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 288.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 289.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 291.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.408
wandb:  sub_train_acc 0.38626
wandb: sub_train_loss 1.91227
wandb:       test_acc 0.41
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run comfy-sweep-298 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/04xvn6jk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223234-04xvn6jk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5lt0u0zu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223249-5lt0u0zu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-299
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5lt0u0zu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 279.70it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 290.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 300.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 309.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 313.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 316.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 309.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.45
wandb: best_valid_acc 0.408
wandb:  sub_train_acc 0.41987
wandb: sub_train_loss 1.91843
wandb:       test_acc 0.451
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run solar-sweep-299 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5lt0u0zu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223249-5lt0u0zu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o7mcy15a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223304-o7mcy15a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-300
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7mcy15a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 318.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 315.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 303.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 301.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 300.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 293.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 298.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.019 MB of 0.023 MB uploadedwandb: - 0.019 MB of 0.023 MB uploadedwandb: \ 0.019 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.463
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.44793
wandb: sub_train_loss 1.917
wandb:       test_acc 0.463
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run helpful-sweep-300 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7mcy15a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223304-o7mcy15a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5fiqcpa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223322-i5fiqcpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-301
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i5fiqcpa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 274.06it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 272.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 286.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 296.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 295.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 294.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.43
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.41876
wandb: sub_train_loss 1.9205
wandb:       test_acc 0.433
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run vital-sweep-301 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i5fiqcpa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223322-i5fiqcpa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bexu72eu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223338-bexu72eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-302
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bexu72eu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 262.61it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 271.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 275.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 282.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 287.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 293.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 288.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.368
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.37223
wandb: sub_train_loss 1.9204
wandb:       test_acc 0.363
wandb:      valid_acc 0.358
wandb: 
wandb: üöÄ View run wobbly-sweep-302 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bexu72eu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223338-bexu72eu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nssfvueo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223352-nssfvueo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-303
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nssfvueo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.30it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 276.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 287.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 305.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 304.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 298.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 295.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.635
wandb: best_valid_acc 0.66
wandb:  sub_train_acc 0.61558
wandb: sub_train_loss 1.92183
wandb:       test_acc 0.591
wandb:      valid_acc 0.616
wandb: 
wandb: üöÄ View run happy-sweep-303 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nssfvueo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223352-nssfvueo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9ffgfyg6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223408-9ffgfyg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-304
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9ffgfyg6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 303.64it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 297.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 294.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 294.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 294.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 298.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 298.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.591
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.59195
wandb: sub_train_loss 1.92319
wandb:       test_acc 0.586
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run absurd-sweep-304 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9ffgfyg6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223408-9ffgfyg6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jb0b2tw2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223420-jb0b2tw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-305
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jb0b2tw2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 190.71it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 187.29it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 186.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 185.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 186.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 183.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 183.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 186.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 184.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 185.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.221
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.21049
wandb: sub_train_loss 1.70004
wandb:       test_acc 0.221
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run deep-sweep-305 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jb0b2tw2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223420-jb0b2tw2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: squodzu6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223434-squodzu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-306
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/squodzu6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 190.48it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 185.83it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 185.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 185.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 186.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 183.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 181.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 180.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 181.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 185.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.20716
wandb: sub_train_loss 1.70456
wandb:       test_acc 0.222
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run divine-sweep-306 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/squodzu6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223434-squodzu6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2d3grc4f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223450-2d3grc4f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-307
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2d3grc4f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 203.24it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 200.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 203.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 205.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 206.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 202.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 198.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 186.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 163.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.068
wandb: best_valid_acc 0.062
wandb:  sub_train_acc 0.08863
wandb: sub_train_loss 1.73438
wandb:       test_acc 0.068
wandb:      valid_acc 0.062
wandb: 
wandb: üöÄ View run elated-sweep-307 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2d3grc4f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223450-2d3grc4f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7g71pdqj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223510-7g71pdqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-308
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7g71pdqj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.31it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.59it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 170.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 173.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 177.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 178.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 178.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 179.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 179.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 176.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.28323
wandb: sub_train_loss 1.76671
wandb:       test_acc 0.259
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run clear-sweep-308 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7g71pdqj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223510-7g71pdqj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jknw2ium with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223526-jknw2ium
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jknw2ium
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.53it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 147.46it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 137.25it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 136.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 148.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 164.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 174.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 180.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 185.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 190.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.08it/s]
wandb: - 0.000 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.236
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.27216
wandb: sub_train_loss 1.78031
wandb:       test_acc 0.237
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run different-sweep-309 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jknw2ium
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223526-jknw2ium/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 66p1h0tg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223542-66p1h0tg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-310
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/66p1h0tg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.46it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.22it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 149.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 148.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 147.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 147.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 153.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 156.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 160.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 164.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 167.62it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 168.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.219
wandb: best_valid_acc 0.212
wandb:  sub_train_acc 0.25295
wandb: sub_train_loss 1.77147
wandb:       test_acc 0.226
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run fiery-sweep-310 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/66p1h0tg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223542-66p1h0tg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: isuphm40 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223557-isuphm40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-311
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/isuphm40
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 197.30it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 186.00it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 184.93it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 187.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 189.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 190.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 189.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 190.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 191.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 192.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 190.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.015 MB of 0.023 MB uploadedwandb: - 0.015 MB of 0.023 MB uploadedwandb: \ 0.015 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.287
wandb: best_valid_acc 0.294
wandb:  sub_train_acc 0.31352
wandb: sub_train_loss 1.80421
wandb:       test_acc 0.287
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run stilted-sweep-311 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/isuphm40
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223557-isuphm40/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o06ldbff with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223612-o06ldbff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-312
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o06ldbff
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 204.05it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 198.28it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 194.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 194.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 189.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 189.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 188.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 189.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 194.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 193.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.204
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.22341
wandb: sub_train_loss 1.79866
wandb:       test_acc 0.207
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run whole-sweep-312 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o06ldbff
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223612-o06ldbff/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fdulg4oo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223628-fdulg4oo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-313
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdulg4oo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.93it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 180.93it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 175.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 173.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 169.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 163.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 166.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 167.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 171.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 174.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.424
wandb: best_valid_acc 0.432
wandb:  sub_train_acc 0.41544
wandb: sub_train_loss 1.81859
wandb:       test_acc 0.429
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run splendid-sweep-313 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdulg4oo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223628-fdulg4oo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yuv3ahzq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223642-yuv3ahzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-314
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yuv3ahzq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 189.78it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 190.29it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 190.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 190.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 188.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 191.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 193.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 192.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 188.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 185.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.86it/s]
wandb: - 0.000 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.554
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.51883
wandb: sub_train_loss 1.81149
wandb:       test_acc 0.554
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run smart-sweep-314 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yuv3ahzq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223642-yuv3ahzq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ko6ci70s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223654-ko6ci70s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-315
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ko6ci70s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.72it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 152.72it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 155.66it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 158.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 169.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 171.04it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 162.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 163.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 164.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 170.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 171.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.015 MB of 0.023 MB uploadedwandb: - 0.015 MB of 0.023 MB uploadedwandb: \ 0.015 MB of 0.023 MB uploadedwandb: | 0.015 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.47
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.46861
wandb: sub_train_loss 1.83333
wandb:       test_acc 0.471
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run rare-sweep-315 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ko6ci70s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223654-ko6ci70s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fr92fliu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223719-fr92fliu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-316
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fr92fliu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 199.06it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 197.48it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 194.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 198.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 200.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 203.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 204.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 205.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 204.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 201.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.356
wandb: best_valid_acc 0.366
wandb:  sub_train_acc 0.39032
wandb: sub_train_loss 1.8335
wandb:       test_acc 0.357
wandb:      valid_acc 0.366
wandb: 
wandb: üöÄ View run different-sweep-316 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fr92fliu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223719-fr92fliu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ot0lymv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223733-5ot0lymv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-317
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ot0lymv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 199.15it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 204.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 206.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 207.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 207.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 207.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 207.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 208.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 209.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 207.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.377
wandb: best_valid_acc 0.372
wandb:  sub_train_acc 0.39771
wandb: sub_train_loss 1.84941
wandb:       test_acc 0.376
wandb:      valid_acc 0.372
wandb: 
wandb: üöÄ View run wild-sweep-317 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ot0lymv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223733-5ot0lymv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nqjhvd4c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223749-nqjhvd4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-318
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nqjhvd4c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.08it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 176.40it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 179.15it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 170.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 169.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 172.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 166.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 168.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 171.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 170.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.33
wandb: best_valid_acc 0.328
wandb:  sub_train_acc 0.3017
wandb: sub_train_loss 1.83919
wandb:       test_acc 0.288
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run different-sweep-318 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nqjhvd4c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223749-nqjhvd4c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xejrgjec with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223801-xejrgjec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-319
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xejrgjec
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.41it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 188.47it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 187.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 190.98it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 193.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 193.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 191.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 190.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 189.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 185.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.512
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.52437
wandb: sub_train_loss 1.8545
wandb:       test_acc 0.513
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run dazzling-sweep-319 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xejrgjec
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223801-xejrgjec/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qirt3g8t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223814-qirt3g8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-320
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qirt3g8t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.43it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 197.52it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 195.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 196.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 195.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 196.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 197.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 199.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 201.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 199.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.728
wandb:  sub_train_acc 0.70716
wandb: sub_train_loss 1.83821
wandb:       test_acc 0.69
wandb:      valid_acc 0.698
wandb: 
wandb: üöÄ View run morning-sweep-320 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qirt3g8t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223814-qirt3g8t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zxpzj4gk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223826-zxpzj4gk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-321
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zxpzj4gk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.45it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 137.59it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 134.89it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 133.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 135.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 140.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 144.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 147.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 149.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 148.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 150.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 150.88it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 148.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.085
wandb: best_valid_acc 0.08
wandb:  sub_train_acc 0.07386
wandb: sub_train_loss 1.5824
wandb:       test_acc 0.064
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run warm-sweep-321 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zxpzj4gk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223826-zxpzj4gk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dlswcu9t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223841-dlswcu9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-322
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dlswcu9t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.98it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.84it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 152.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 152.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 152.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 151.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 151.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 150.44it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 151.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 149.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 147.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.074
wandb: best_valid_acc 0.072
wandb:  sub_train_acc 0.07164
wandb: sub_train_loss 1.56005
wandb:       test_acc 0.064
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run eager-sweep-322 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dlswcu9t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223841-dlswcu9t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vb272ypc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223856-vb272ypc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-323
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vb272ypc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.53it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.97it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.20it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 147.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 150.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 151.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 150.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 144.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 142.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 142.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 146.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.089
wandb: best_valid_acc 0.088
wandb:  sub_train_acc 0.10487
wandb: sub_train_loss 1.65113
wandb:       test_acc 0.085
wandb:      valid_acc 0.076
wandb: 
wandb: üöÄ View run vibrant-sweep-323 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vb272ypc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223856-vb272ypc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0fhw3kxa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223912-0fhw3kxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-324
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0fhw3kxa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.72it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.91it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 153.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 154.08it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 154.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 154.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 154.62it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 151.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 152.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 152.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 145.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.189
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.20421
wandb: sub_train_loss 1.70287
wandb:       test_acc 0.189
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run sleek-sweep-324 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0fhw3kxa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223912-0fhw3kxa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7tw2rdwu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223928-7tw2rdwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-325
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7tw2rdwu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.95it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.87it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 118.71it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 117.00it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 117.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 118.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 111.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 111.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 114.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 118.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 122.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 126.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 126.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 128.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 125.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.213
wandb: best_valid_acc 0.23
wandb:  sub_train_acc 0.22526
wandb: sub_train_loss 1.70172
wandb:       test_acc 0.215
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run earthy-sweep-325 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7tw2rdwu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223928-7tw2rdwu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yak32rer with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_223949-yak32rer
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-326
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yak32rer
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.61it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 120.83it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 103.46it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 105.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 105.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 107.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 110.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 114.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 119.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 122.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 125.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 127.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 127.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 129.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 132.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 120.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.289
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.31573
wandb: sub_train_loss 1.734
wandb:       test_acc 0.289
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run light-sweep-326 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yak32rer
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_223949-yak32rer/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2x868ryu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224001-2x868ryu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-327
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2x868ryu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 131.35it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 129.77it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.01it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 129.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:01, 119.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 119.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 119.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 125.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 129.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 133.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 135.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 135.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 138.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 142.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.201
wandb: best_valid_acc 0.204
wandb:  sub_train_acc 0.22378
wandb: sub_train_loss 1.71112
wandb:       test_acc 0.202
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run stoic-sweep-327 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2x868ryu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224001-2x868ryu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tfn5t3m7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224016-tfn5t3m7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-328
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tfn5t3m7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.96it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 140.67it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 143.78it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 143.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 140.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 135.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 135.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 135.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 135.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 135.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 135.29it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 134.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 135.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.27474
wandb: sub_train_loss 1.73676
wandb:       test_acc 0.259
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run drawn-sweep-328 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tfn5t3m7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224016-tfn5t3m7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rzunlcjn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224032-rzunlcjn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-329
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rzunlcjn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.69it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 119.24it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 119.30it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 120.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 117.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 117.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 118.52it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 120.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 120.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 118.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 116.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 115.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 114.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 113.59it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 114.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.29616
wandb: sub_train_loss 1.78677
wandb:       test_acc 0.268
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run young-sweep-329 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rzunlcjn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224032-rzunlcjn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e2lylcd2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224053-e2lylcd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-330
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e2lylcd2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 109.43it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 100.46it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 107.71it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 114.62it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 119.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 121.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 124.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 127.17it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 126.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 128.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 129.51it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 130.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 128.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 126.62it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 123.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.279
wandb: best_valid_acc 0.292
wandb:  sub_train_acc 0.3209
wandb: sub_train_loss 1.77011
wandb:       test_acc 0.283
wandb:      valid_acc 0.292
wandb: 
wandb: üöÄ View run stoic-sweep-330 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e2lylcd2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224053-e2lylcd2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ny0s4lb0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224108-ny0s4lb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-331
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ny0s4lb0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.56it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.11it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 150.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 148.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 148.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 148.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 149.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 149.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 147.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 141.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 139.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.592
wandb: best_valid_acc 0.568
wandb:  sub_train_acc 0.56499
wandb: sub_train_loss 1.78969
wandb:       test_acc 0.603
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run sunny-sweep-331 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ny0s4lb0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224108-ny0s4lb0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wh1fe4el with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224128-wh1fe4el
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-332
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wh1fe4el
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.63it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 147.77it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.99it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 145.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 143.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 144.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 144.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 144.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 143.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 144.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 144.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 144.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 144.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.281
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.30096
wandb: sub_train_loss 1.8101
wandb:       test_acc 0.281
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run driven-sweep-332 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wh1fe4el
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224128-wh1fe4el/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p1tvu5us with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224147-p1tvu5us
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-333
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p1tvu5us
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.45it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.00it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 148.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 147.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 145.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 148.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 148.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 146.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 145.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 145.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 145.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 143.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.453
wandb: best_valid_acc 0.434
wandb:  sub_train_acc 0.45901
wandb: sub_train_loss 1.80607
wandb:       test_acc 0.455
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run pretty-sweep-333 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p1tvu5us
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224147-p1tvu5us/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5a0jkm1n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224159-5a0jkm1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-334
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5a0jkm1n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.87it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.23it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 142.65it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 140.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 137.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 135.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 132.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 134.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 136.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 138.75it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 139.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 140.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 140.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.23
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.24298
wandb: sub_train_loss 1.81882
wandb:       test_acc 0.234
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run smart-sweep-334 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5a0jkm1n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224159-5a0jkm1n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f73d3kgk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224218-f73d3kgk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-335
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f73d3kgk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 119.75it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.00it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 119.80it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 121.67it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 122.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 123.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 124.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 125.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 126.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 125.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 125.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 125.82it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 127.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 130.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 131.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.020 MB of 0.023 MB uploadedwandb: | 0.020 MB of 0.023 MB uploadedwandb: / 0.020 MB of 0.023 MB uploadedwandb: - 0.020 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.52
wandb:  sub_train_acc 0.52326
wandb: sub_train_loss 1.83214
wandb:       test_acc 0.498
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run generous-sweep-335 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f73d3kgk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224218-f73d3kgk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5nqb6f0v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224245-5nqb6f0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-336
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5nqb6f0v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.65it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 131.83it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 129.41it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 130.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 131.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 129.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 132.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 130.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 130.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 126.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 124.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 125.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 125.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.268
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.27917
wandb: sub_train_loss 1.81855
wandb:       test_acc 0.268
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run stellar-sweep-336 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5nqb6f0v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224245-5nqb6f0v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: occ4s1w4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224301-occ4s1w4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-337
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/occ4s1w4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 264.43it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 291.52it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 290.22it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 291.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 291.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 292.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 296.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 301.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 303.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 296.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.197
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.19202
wandb: sub_train_loss 1.84897
wandb:       test_acc 0.206
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run devoted-sweep-337 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/occ4s1w4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224301-occ4s1w4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 25awrk4l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224316-25awrk4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-338
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/25awrk4l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 331.34it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 333.40it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 332.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 328.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 326.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 324.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 310.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 293.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:00<00:00, 292.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 309.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.211
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.18648
wandb: sub_train_loss 1.85045
wandb:       test_acc 0.193
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run sandy-sweep-338 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/25awrk4l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224316-25awrk4l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: naqrttw6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224332-naqrttw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-339
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/naqrttw6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 242.88it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 245.18it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 257.57it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 268.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 271.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 275.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 280.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 268.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 263.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 265.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 265.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.2212
wandb: sub_train_loss 1.87455
wandb:       test_acc 0.228
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run amber-sweep-339 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/naqrttw6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224332-naqrttw6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ce48zoh7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224352-ce48zoh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-340
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ce48zoh7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 286.88it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 290.03it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 295.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 297.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 298.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 298.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 297.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 300.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 300.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 298.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.226
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.21566
wandb: sub_train_loss 1.87494
wandb:       test_acc 0.23
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run worldly-sweep-340 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ce48zoh7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224352-ce48zoh7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dgplzyub with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224407-dgplzyub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-341
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dgplzyub
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 298.39it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 293.81it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 281.72it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 273.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 274.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 275.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 275.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 270.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 267.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 271.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 274.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.334
wandb: best_valid_acc 0.362
wandb:  sub_train_acc 0.32607
wandb: sub_train_loss 1.88216
wandb:       test_acc 0.332
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run efficient-sweep-341 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dgplzyub
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224407-dgplzyub/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 89wabhmr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224428-89wabhmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-342
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/89wabhmr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.69it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 288.89it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 294.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 294.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 299.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 297.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 300.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 301.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 292.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 294.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.297
wandb: best_valid_acc 0.318
wandb:  sub_train_acc 0.29431
wandb: sub_train_loss 1.88154
wandb:       test_acc 0.297
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run graceful-sweep-342 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/89wabhmr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224428-89wabhmr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0ogd2o6k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224443-0ogd2o6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-343
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0ogd2o6k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 283.67it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 289.99it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 293.02it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 288.69it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 289.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 286.94it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 284.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 277.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 285.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 289.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.26366
wandb: sub_train_loss 1.89006
wandb:       test_acc 0.247
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run sweet-sweep-343 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0ogd2o6k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224443-0ogd2o6k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s8g2606i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224458-s8g2606i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-344
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8g2606i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 289.56it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 298.51it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 305.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 296.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 286.85it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 280.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 284.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 289.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 290.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 290.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.265
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.27991
wandb: sub_train_loss 1.88908
wandb:       test_acc 0.266
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run devoted-sweep-344 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s8g2606i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224458-s8g2606i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vhhqgqlm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224519-vhhqgqlm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-345
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vhhqgqlm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 286.39it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 290.65it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 287.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 238.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 231.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 237.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 234.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 230.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 246.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 256.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 251.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.42
wandb: best_valid_acc 0.424
wandb:  sub_train_acc 0.41211
wandb: sub_train_loss 1.89453
wandb:       test_acc 0.441
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run hardy-sweep-345 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vhhqgqlm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224519-vhhqgqlm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tzorzqyf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224534-tzorzqyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-346
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tzorzqyf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 312.25it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 311.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 306.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 303.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 309.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 313.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 314.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:00<00:00, 307.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:00<00:00, 307.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 309.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.436
wandb: best_valid_acc 0.414
wandb:  sub_train_acc 0.40325
wandb: sub_train_loss 1.89255
wandb:       test_acc 0.438
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run fluent-sweep-346 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tzorzqyf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224534-tzorzqyf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hf9fhidx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224550-hf9fhidx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-347
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hf9fhidx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 318.78it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 317.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 309.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 310.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 310.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 310.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 307.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 301.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 291.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 301.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.421
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.42097
wandb: sub_train_loss 1.90099
wandb:       test_acc 0.429
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run desert-sweep-347 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hf9fhidx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224550-hf9fhidx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qj02fwj9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224605-qj02fwj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-348
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qj02fwj9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 308.35it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 306.06it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 309.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 318.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 323.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 326.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 329.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 330.54it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:00<00:00, 316.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 319.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.526
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.49926
wandb: sub_train_loss 1.90161
wandb:       test_acc 0.526
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run fragrant-sweep-348 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qj02fwj9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224605-qj02fwj9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2lfpwmto with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224620-2lfpwmto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-349
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2lfpwmto
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 284.18it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 285.44it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 286.84it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 285.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 280.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 274.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 268.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 271.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:00<00:00, 271.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 273.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 275.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.379
wandb: best_valid_acc 0.38
wandb:  sub_train_acc 0.38368
wandb: sub_train_loss 1.90776
wandb:       test_acc 0.382
wandb:      valid_acc 0.36
wandb: 
wandb: üöÄ View run northern-sweep-349 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2lfpwmto
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224620-2lfpwmto/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x7vmw197 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224636-x7vmw197
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-350
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x7vmw197
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 317.64it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 314.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 312.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 308.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 308.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 310.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 310.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 312.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:00<00:00, 312.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 311.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.458
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.41544
wandb: sub_train_loss 1.90632
wandb:       test_acc 0.434
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run wandering-sweep-350 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x7vmw197
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224636-x7vmw197/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k55kwxi7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224652-k55kwxi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-351
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k55kwxi7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 308.02it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:00, 312.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 310.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 314.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 314.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 316.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 318.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:00<00:00, 319.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:00<00:00, 319.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 316.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.662
wandb: best_valid_acc 0.614
wandb:  sub_train_acc 0.65879
wandb: sub_train_loss 1.90941
wandb:       test_acc 0.662
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run vital-sweep-351 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/k55kwxi7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224652-k55kwxi7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q5lpybmv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224706-q5lpybmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-352
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q5lpybmv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 305.79it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 301.21it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 290.47it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 294.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 301.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 307.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 312.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 316.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 314.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 308.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.618
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.62888
wandb: sub_train_loss 1.90867
wandb:       test_acc 0.621
wandb:      valid_acc 0.584
wandb: 
wandb: üöÄ View run lucky-sweep-352 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q5lpybmv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224706-q5lpybmv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d2ik9rnz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224718-d2ik9rnz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-353
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d2ik9rnz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.23it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.44it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 164.82it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 168.44it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 171.59it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 169.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 172.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 170.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 177.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 180.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 186.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 192.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 196.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 198.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 200.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 184.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.23227
wandb: sub_train_loss 1.51353
wandb:       test_acc 0.231
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run toasty-sweep-353 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d2ik9rnz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224718-d2ik9rnz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nbhgado4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224732-nbhgado4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-354
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nbhgado4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.94it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.95it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 161.99it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 170.12it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 175.66it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 177.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 178.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 176.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 177.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 176.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 180.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 177.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 177.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 178.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 181.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 182.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.186
wandb: best_valid_acc 0.194
wandb:  sub_train_acc 0.20162
wandb: sub_train_loss 1.50554
wandb:       test_acc 0.187
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run denim-sweep-354 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nbhgado4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224732-nbhgado4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mgq6sf4w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224758-mgq6sf4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-355
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mgq6sf4w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 154.27it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 107.68it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 113.91it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 127.04it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 142.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 150.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 144.86it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 127.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 124.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 133.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 141.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 142.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 138.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 138.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 149.19it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 152.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 156.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 158.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.173
wandb: best_valid_acc 0.176
wandb:  sub_train_acc 0.1935
wandb: sub_train_loss 1.59499
wandb:       test_acc 0.175
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run twilight-sweep-355 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mgq6sf4w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224758-mgq6sf4w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o63fm077 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224820-o63fm077
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-356
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o63fm077
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.69it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.09it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 159.86it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 146.84it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 160.57it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 170.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 176.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 180.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 183.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 187.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 191.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 194.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 197.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 198.94it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 200.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 184.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.096
wandb: best_valid_acc 0.092
wandb:  sub_train_acc 0.13589
wandb: sub_train_loss 1.57932
wandb:       test_acc 0.097
wandb:      valid_acc 0.092
wandb: 
wandb: üöÄ View run elated-sweep-356 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o63fm077
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224820-o63fm077/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0m9gicgg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224835-0m9gicgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-357
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0m9gicgg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.96it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 193.99it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 192.72it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 191.41it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 192.08it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 196.38it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 198.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 200.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 199.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 201.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 202.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 201.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 200.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 198.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.129
wandb: best_valid_acc 0.122
wandb:  sub_train_acc 0.17024
wandb: sub_train_loss 1.64365
wandb:       test_acc 0.129
wandb:      valid_acc 0.122
wandb: 
wandb: üöÄ View run brisk-sweep-357 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0m9gicgg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224835-0m9gicgg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hfncnnoj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224851-hfncnnoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-358
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hfncnnoj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 205.54it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 198.31it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 189.40it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 188.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 187.33it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 185.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 184.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 185.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 177.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 174.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 175.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 180.14it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 184.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 183.55it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 181.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.261
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.22821
wandb: sub_train_loss 1.64492
wandb:       test_acc 0.183
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run lucky-sweep-358 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hfncnnoj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224851-hfncnnoj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u8b0bzhe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224906-u8b0bzhe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-359
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u8b0bzhe
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 194.15it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 194.07it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 190.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 186.34it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 181.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 179.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 178.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 176.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 177.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 173.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 170.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 175.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 178.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 179.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.205
wandb: best_valid_acc 0.19
wandb:  sub_train_acc 0.22932
wandb: sub_train_loss 1.68805
wandb:       test_acc 0.206
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run worthy-sweep-359 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u8b0bzhe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224906-u8b0bzhe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hiwondwr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224921-hiwondwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-360
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hiwondwr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 201.09it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 199.64it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 196.70it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 199.23it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 202.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 196.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 192.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 191.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 191.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 191.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 191.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 190.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 190.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 190.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.301
wandb: best_valid_acc 0.312
wandb:  sub_train_acc 0.33419
wandb: sub_train_loss 1.69364
wandb:       test_acc 0.287
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run trim-sweep-360 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hiwondwr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224921-hiwondwr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5h8yxnys with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224937-5h8yxnys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-361
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5h8yxnys
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.16it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 190.17it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 193.14it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 191.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 192.62it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 192.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 192.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 188.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 184.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 183.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 186.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 187.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 188.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 189.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 190.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.349
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.37371
wandb: sub_train_loss 1.71622
wandb:       test_acc 0.352
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run spring-sweep-361 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5h8yxnys
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224937-5h8yxnys/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: odw5dqu2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_224952-odw5dqu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-362
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/odw5dqu2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 201.57it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 205.06it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 204.99it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 205.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 206.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 204.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 201.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 199.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 198.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 196.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 198.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 195.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 190.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 186.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 196.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.536
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.49446
wandb: sub_train_loss 1.70763
wandb:       test_acc 0.538
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run astral-sweep-362 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/odw5dqu2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_224952-odw5dqu2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qxqkmnep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225004-qxqkmnep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-363
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qxqkmnep
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.33it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 199.88it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 201.31it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 200.77it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 194.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 190.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 191.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 192.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 181.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 183.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 180.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 173.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 166.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 164.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 167.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.392
wandb:  sub_train_acc 0.40251
wandb: sub_train_loss 1.75969
wandb:       test_acc 0.411
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run comic-sweep-363 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qxqkmnep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225004-qxqkmnep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yj8auity with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225018-yj8auity
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-364
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yj8auity
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 189.91it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 176.90it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 176.87it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 185.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 191.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 194.14it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 198.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 198.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 195.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 191.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 187.08it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 183.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 181.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 181.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 181.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.575
wandb: best_valid_acc 0.558
wandb:  sub_train_acc 0.55761
wandb: sub_train_loss 1.74804
wandb:       test_acc 0.576
wandb:      valid_acc 0.558
wandb: 
wandb: üöÄ View run absurd-sweep-364 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yj8auity
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225018-yj8auity/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8rwr3fbn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225033-8rwr3fbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8rwr3fbn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.51it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 178.02it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 182.18it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 184.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 191.03it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 197.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 198.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 201.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 203.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 201.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 195.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 186.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 178.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 176.59it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 176.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.382
wandb: best_valid_acc 0.38
wandb:  sub_train_acc 0.39549
wandb: sub_train_loss 1.76266
wandb:       test_acc 0.391
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run desert-sweep-365 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8rwr3fbn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225033-8rwr3fbn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uajtdej6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225049-uajtdej6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uajtdej6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.81it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 198.35it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 201.93it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 204.32it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 205.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 206.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 205.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 206.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 207.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 207.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 205.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 198.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 193.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 191.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 199.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.455
wandb: best_valid_acc 0.396
wandb:  sub_train_acc 0.43427
wandb: sub_train_loss 1.77135
wandb:       test_acc 0.455
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run solar-sweep-366 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uajtdej6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225049-uajtdej6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cs489pi2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225103-cs489pi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-367
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cs489pi2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.26it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 154.24it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.98it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.88it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 163.60it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 168.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 173.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 177.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 180.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 182.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 186.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 191.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 190.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 185.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 182.61it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 184.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.689
wandb: best_valid_acc 0.708
wandb:  sub_train_acc 0.70975
wandb: sub_train_loss 1.76551
wandb:       test_acc 0.689
wandb:      valid_acc 0.706
wandb: 
wandb: üöÄ View run denim-sweep-367 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cs489pi2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225103-cs489pi2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i1ty22gb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225119-i1ty22gb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-368
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1ty22gb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 190.08it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 187.28it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 182.40it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 181.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 181.07it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 182.31it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 178.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 175.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 173.33it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 174.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 176.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 177.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 177.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 176.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 179.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.775
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.78914
wandb: sub_train_loss 1.76182
wandb:       test_acc 0.777
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run frosty-sweep-368 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1ty22gb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225119-i1ty22gb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: na5xiump with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225131-na5xiump
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-369
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na5xiump
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.18it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.40it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 133.16it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 134.70it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 135.61it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 134.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 133.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 132.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 129.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 128.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 130.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 132.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 132.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 132.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 131.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 132.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 131.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 133.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 136.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 137.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 136.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.097
wandb: best_valid_acc 0.096
wandb:  sub_train_acc 0.1226
wandb: sub_train_loss 1.14809
wandb:       test_acc 0.097
wandb:      valid_acc 0.096
wandb: 
wandb: üöÄ View run polished-sweep-369 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na5xiump
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225131-na5xiump/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wjdvgem9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225144-wjdvgem9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-370
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wjdvgem9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 103.70it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 106.03it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 108.93it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:02, 112.18it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 119.09it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 122.41it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 125.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 126.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 127.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 125.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 124.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 118.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 124.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 129.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 134.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 138.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 140.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 141.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 142.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 142.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 143.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.188
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.15547
wandb: sub_train_loss 1.10576
wandb:       test_acc 0.137
wandb:      valid_acc 0.136
wandb: 
wandb: üöÄ View run genial-sweep-370 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wjdvgem9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225144-wjdvgem9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1s468b7k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225156-1s468b7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-371
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1s468b7k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.58it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 143.76it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 142.71it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 142.55it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 142.67it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 141.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 139.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 138.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 137.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 139.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 137.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 130.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 126.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 127.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 130.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 131.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 129.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 131.27it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 130.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.078
wandb: best_valid_acc 0.074
wandb:  sub_train_acc 0.10155
wandb: sub_train_loss 1.3425
wandb:       test_acc 0.067
wandb:      valid_acc 0.062
wandb: 
wandb: üöÄ View run tough-sweep-371 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1s468b7k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225156-1s468b7k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pzehsen7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225211-pzehsen7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-372
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pzehsen7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.19it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.58it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.82it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.18it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 144.06it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 144.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 145.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 145.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 145.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 145.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 146.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 146.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 145.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 145.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 145.75it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 146.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 146.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 146.02it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 145.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.186
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.18095
wandb: sub_train_loss 1.3558
wandb:       test_acc 0.133
wandb:      valid_acc 0.126
wandb: 
wandb: üöÄ View run cool-sweep-372 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pzehsen7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225211-pzehsen7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r3r7dze7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225226-r3r7dze7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-373
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r3r7dze7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.67it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.97it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.39it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 151.96it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 154.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 155.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 154.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 154.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 154.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 152.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 140.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 125.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 125.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 126.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 123.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 126.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 130.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 131.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 132.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 133.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.244
wandb: best_valid_acc 0.258
wandb:  sub_train_acc 0.26477
wandb: sub_train_loss 1.43418
wandb:       test_acc 0.246
wandb:      valid_acc 0.258
wandb: 
wandb: üöÄ View run cerulean-sweep-373 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r3r7dze7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225226-r3r7dze7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: brtsn6er with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225242-brtsn6er
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-374
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/brtsn6er
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.70it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.63it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 133.90it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 135.26it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 135.96it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 135.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 132.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 133.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 133.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 133.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 131.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 130.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 132.15it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 133.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 136.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 138.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 139.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 142.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 143.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 144.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.198
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.25739
wandb: sub_train_loss 1.48808
wandb:       test_acc 0.198
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run copper-sweep-374 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/brtsn6er
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225242-brtsn6er/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 33undn8m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225257-33undn8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-375
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33undn8m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.67it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 134.89it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 138.30it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 135.47it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 130.14it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 128.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 127.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 129.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 130.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 135.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 138.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 142.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 145.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 147.88it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 149.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 150.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 151.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 151.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 151.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 150.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.239
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.25997
wandb: sub_train_loss 1.51196
wandb:       test_acc 0.239
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run splendid-sweep-375 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/33undn8m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225257-33undn8m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pwie7rbv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225312-pwie7rbv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-376
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pwie7rbv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.78it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 121.61it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 121.19it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 122.19it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 131.36it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 138.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 142.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 139.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 139.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 141.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 140.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 137.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 137.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 136.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 135.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 132.46it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 131.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 134.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 137.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 138.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.233
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.26662
wandb: sub_train_loss 1.51109
wandb:       test_acc 0.237
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run lunar-sweep-376 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pwie7rbv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225312-pwie7rbv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tuvzgphz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225327-tuvzgphz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-377
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tuvzgphz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.61it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 138.17it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 134.59it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 134.63it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 134.59it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 135.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 133.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 134.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 132.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 134.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 133.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 134.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 131.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 131.55it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 136.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 138.52it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 137.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 136.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 136.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 134.49it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 133.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 134.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.544
wandb: best_valid_acc 0.548
wandb:  sub_train_acc 0.52659
wandb: sub_train_loss 1.55824
wandb:       test_acc 0.572
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run azure-sweep-377 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tuvzgphz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225327-tuvzgphz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i1oln690 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225343-i1oln690
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-378
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1oln690
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.71it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.08it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 135.04it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 136.71it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 140.86it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 141.23it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 141.50it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 139.81it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 134.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 124.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 113.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 114.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 117.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 118.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 119.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 124.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 126.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 129.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 131.95it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 131.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 132.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.554
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.52326
wandb: sub_train_loss 1.5478
wandb:       test_acc 0.553
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run gallant-sweep-378 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i1oln690
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225343-i1oln690/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c7ladqac with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225358-c7ladqac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-379
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c7ladqac
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.98it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.28it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.92it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.55it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 144.48it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 144.33it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 142.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 143.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 144.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 143.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 139.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 140.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 140.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 140.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 138.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 136.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 135.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 135.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 134.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.556
wandb: best_valid_acc 0.54
wandb:  sub_train_acc 0.52659
wandb: sub_train_loss 1.62695
wandb:       test_acc 0.557
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run fallen-sweep-379 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c7ladqac
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225358-c7ladqac/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rd1g1z7z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225414-rd1g1z7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-380
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rd1g1z7z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.86it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 137.92it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 139.12it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 140.90it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 135.11it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 129.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 129.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 127.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 125.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 130.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 132.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 131.88it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 132.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 132.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 133.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 133.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 133.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 133.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 135.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 132.67it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 133.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.409
wandb: best_valid_acc 0.402
wandb:  sub_train_acc 0.41765
wandb: sub_train_loss 1.6083
wandb:       test_acc 0.409
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run sleek-sweep-380 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rd1g1z7z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225414-rd1g1z7z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 87a83bqu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225429-87a83bqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-381
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/87a83bqu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.00it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 121.53it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 120.91it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.96it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 128.83it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 127.58it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 121.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 122.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 123.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 130.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 134.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 136.94it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 137.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 138.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 139.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 140.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 144.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 147.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 148.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 146.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.544
wandb: best_valid_acc 0.53
wandb:  sub_train_acc 0.52991
wandb: sub_train_loss 1.6695
wandb:       test_acc 0.544
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run crisp-sweep-381 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/87a83bqu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225429-87a83bqu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ij88ziev with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225444-ij88ziev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-382
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ij88ziev
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.30it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 128.68it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.24it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.47it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 125.83it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 128.35it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 131.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 134.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 137.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 138.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 140.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 142.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 140.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 134.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 128.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 125.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 123.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 120.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 117.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 116.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 116.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.484
wandb: best_valid_acc 0.464
wandb:  sub_train_acc 0.49557
wandb: sub_train_loss 1.63966
wandb:       test_acc 0.484
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run bright-sweep-382 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ij88ziev
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225444-ij88ziev/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r694lwwv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225500-r694lwwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-383
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r694lwwv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.42it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.30it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 133.47it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 132.86it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 134.40it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 136.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 135.12it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 131.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 125.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 120.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 117.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 119.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 120.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 121.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 123.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 124.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 128.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 129.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 129.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 126.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 127.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.789
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.7921
wandb: sub_train_loss 1.68204
wandb:       test_acc 0.789
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run flowing-sweep-383 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r694lwwv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225500-r694lwwv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oyugwm1x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225516-oyugwm1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oyugwm1x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.94it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.35it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.95it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.45it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 143.34it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 146.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 147.24it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 148.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 148.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 146.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 143.21it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 139.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 140.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 141.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 142.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 145.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 147.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 147.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 145.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.681
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.70716
wandb: sub_train_loss 1.63932
wandb:       test_acc 0.683
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run good-sweep-384 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oyugwm1x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225516-oyugwm1x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z9qepsb7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225531-z9qepsb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-385
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z9qepsb7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 330.22it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 329.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 329.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 333.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 325.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 327.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.217
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.20347
wandb: sub_train_loss 1.19677
wandb:       test_acc 0.194
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run genial-sweep-385 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z9qepsb7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225531-z9qepsb7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: is20vbnr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225547-is20vbnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-386
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/is20vbnr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 341.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 342.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 343.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 345.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 348.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 346.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.356
wandb: best_valid_acc 0.364
wandb:  sub_train_acc 0.19165
wandb: sub_train_loss 1.19908
wandb:       test_acc 0.187
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run firm-sweep-386 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/is20vbnr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225547-is20vbnr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g0o8i5yx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225602-g0o8i5yx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-387
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g0o8i5yx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 359.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 360.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 363.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 360.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 359.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 359.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.243
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.24668
wandb: sub_train_loss 1.25341
wandb:       test_acc 0.248
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run hopeful-sweep-387 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g0o8i5yx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225602-g0o8i5yx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mhudwuip with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225613-mhudwuip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-388
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mhudwuip
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 374.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 368.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 369.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 373.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 375.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 373.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.22
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.21861
wandb: sub_train_loss 1.2508
wandb:       test_acc 0.225
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run unique-sweep-388 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mhudwuip
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225613-mhudwuip/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tt0or3hv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225628-tt0or3hv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-389
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tt0or3hv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 348.11it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 347.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 350.21it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 351.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 351.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 351.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.34
wandb: best_valid_acc 0.33
wandb:  sub_train_acc 0.33419
wandb: sub_train_loss 1.2971
wandb:       test_acc 0.314
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run fragrant-sweep-389 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tt0or3hv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225628-tt0or3hv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bxf1o53g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225643-bxf1o53g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-390
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bxf1o53g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 343.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 340.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 346.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 354.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 360.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 354.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.3
wandb: best_valid_acc 0.326
wandb:  sub_train_acc 0.33346
wandb: sub_train_loss 1.29658
wandb:       test_acc 0.293
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run fresh-sweep-390 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bxf1o53g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225643-bxf1o53g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mpbj2wlz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225704-mpbj2wlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-391
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mpbj2wlz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 258.45it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 308.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 334.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 334.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 337.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 328.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.385
wandb: best_valid_acc 0.382
wandb:  sub_train_acc 0.31056
wandb: sub_train_loss 1.32688
wandb:       test_acc 0.31
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run gentle-sweep-391 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mpbj2wlz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225704-mpbj2wlz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r37xcxiw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225721-r37xcxiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-392
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r37xcxiw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 322.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 336.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 333.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 298.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 281.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 292.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 300.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.312
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.29874
wandb: sub_train_loss 1.3263
wandb:       test_acc 0.301
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run morning-sweep-392 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r37xcxiw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225721-r37xcxiw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ycs2qwms with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225736-ycs2qwms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-393
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ycs2qwms
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 338.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 303.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 290.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 311.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 319.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 316.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.487
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.45126
wandb: sub_train_loss 1.34873
wandb:       test_acc 0.482
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run woven-sweep-393 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ycs2qwms
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225736-ycs2qwms/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rjkg7qk8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225752-rjkg7qk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-394
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rjkg7qk8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 359.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 359.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 354.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 351.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 340.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 346.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.496
wandb:  sub_train_acc 0.46677
wandb: sub_train_loss 1.34871
wandb:       test_acc 0.493
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run bumbling-sweep-394 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rjkg7qk8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225752-rjkg7qk8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bmpmwj2q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225807-bmpmwj2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-395
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bmpmwj2q
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 343.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 329.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 325.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 331.79it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 329.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 329.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.533
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.51108
wandb: sub_train_loss 1.39125
wandb:       test_acc 0.532
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run crimson-sweep-395 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bmpmwj2q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225807-bmpmwj2q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d5grgduo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225822-d5grgduo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-396
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d5grgduo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 319.82it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 334.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 325.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 321.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 322.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 327.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.538
wandb: best_valid_acc 0.534
wandb:  sub_train_acc 0.52105
wandb: sub_train_loss 1.39173
wandb:       test_acc 0.543
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run ethereal-sweep-396 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d5grgduo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225822-d5grgduo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kaqlz6q4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225838-kaqlz6q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-397
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kaqlz6q4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 332.20it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 331.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 322.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 319.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 320.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 322.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.632
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.61041
wandb: sub_train_loss 1.40161
wandb:       test_acc 0.632
wandb:      valid_acc 0.644
wandb: 
wandb: üöÄ View run soft-sweep-397 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kaqlz6q4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225838-kaqlz6q4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vskdtcl2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225858-vskdtcl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-398
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vskdtcl2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 334.06it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 345.50it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 348.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 351.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 351.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 351.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.638
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.63626
wandb: sub_train_loss 1.40166
wandb:       test_acc 0.641
wandb:      valid_acc 0.642
wandb: 
wandb: üöÄ View run dry-sweep-398 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vskdtcl2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225858-vskdtcl2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oof0ng58 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225919-oof0ng58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-399
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oof0ng58
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 319.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 329.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 316.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 316.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 319.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 324.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 322.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.70716
wandb: sub_train_loss 1.40018
wandb:       test_acc 0.685
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run youthful-sweep-399 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oof0ng58
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225919-oof0ng58/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o7lwey1e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225934-o7lwey1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-400
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7lwey1e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 335.84it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 343.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 347.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 350.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 353.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 350.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.713
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.68944
wandb: sub_train_loss 1.39915
wandb:       test_acc 0.667
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run unique-sweep-400 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7lwey1e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225934-o7lwey1e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: csbu85dz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_225945-csbu85dz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-401
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/csbu85dz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.80it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 217.85it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 227.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 238.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 240.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 249.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 260.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 248.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.217
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.36854
wandb: sub_train_loss 0.00444
wandb:       test_acc 0.221
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run swift-sweep-401 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/csbu85dz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_225945-csbu85dz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7o4nfsq9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230000-7o4nfsq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-402
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7o4nfsq9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 249.71it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 247.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 250.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 260.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 264.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 264.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 260.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 257.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.212
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.31684
wandb: sub_train_loss 0.01083
wandb:       test_acc 0.212
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run classic-sweep-402 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7o4nfsq9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230000-7o4nfsq9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d8gup0mu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230021-d8gup0mu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-403
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d8gup0mu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 227.22it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 231.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 232.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 238.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 241.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 245.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 247.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 246.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.476
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.33456
wandb: sub_train_loss 0.00295
wandb:       test_acc 0.475
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run grateful-sweep-403 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d8gup0mu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230021-d8gup0mu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gmzh8hkb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230032-gmzh8hkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-404
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gmzh8hkb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 222.22it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 234.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 246.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 244.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 236.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 235.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 237.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 236.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 237.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.519
wandb: best_valid_acc 0.522
wandb:  sub_train_acc 0.31795
wandb: sub_train_loss 0.004
wandb:       test_acc 0.521
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run flowing-sweep-404 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gmzh8hkb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230032-gmzh8hkb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dawoprmy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230047-dawoprmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-405
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dawoprmy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.11it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 243.02it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 244.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 230.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 216.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 214.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 212.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 233.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 228.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.618
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.36854
wandb: sub_train_loss 0.00331
wandb:       test_acc 0.565
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run soft-sweep-405 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dawoprmy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230047-dawoprmy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d3qg141l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230058-d3qg141l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-406
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d3qg141l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 264.36it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 269.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 265.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 263.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 260.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 260.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 253.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 258.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.571
wandb: best_valid_acc 0.59
wandb:  sub_train_acc 0.38959
wandb: sub_train_loss 0.00243
wandb:       test_acc 0.527
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run youthful-sweep-406 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/d3qg141l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230058-d3qg141l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8o8hnwkz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230113-8o8hnwkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-407
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8o8hnwkz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 250.52it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 255.86it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 258.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 255.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 243.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 246.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 244.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 246.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.683
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.42134
wandb: sub_train_loss 0.00122
wandb:       test_acc 0.577
wandb:      valid_acc 0.566
wandb: 
wandb: üöÄ View run deep-sweep-407 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8o8hnwkz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230113-8o8hnwkz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r7qcnudu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230128-r7qcnudu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-408
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r7qcnudu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 233.57it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 225.40it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 223.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 230.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 237.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 245.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 249.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 241.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.648
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.41691
wandb: sub_train_loss 0.00121
wandb:       test_acc 0.596
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run faithful-sweep-408 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r7qcnudu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230128-r7qcnudu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qtbojhfi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230143-qtbojhfi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-409
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qtbojhfi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 215.70it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 233.07it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 243.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 242.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 240.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 241.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 242.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 243.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 240.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.73
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.58161
wandb: sub_train_loss 0.00235
wandb:       test_acc 0.73
wandb:      valid_acc 0.72
wandb: 
wandb: üöÄ View run winter-sweep-409 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qtbojhfi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230143-qtbojhfi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9frm4gyk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230159-9frm4gyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-410
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9frm4gyk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 241.07it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 241.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 247.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 250.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 254.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 250.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 251.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 251.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.732
wandb:  sub_train_acc 0.56832
wandb: sub_train_loss 0.00149
wandb:       test_acc 0.73
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run lively-sweep-410 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9frm4gyk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230159-9frm4gyk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nggadeep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230220-nggadeep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-411
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nggadeep
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 247.62it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 251.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 250.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 248.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 254.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 255.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 257.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 243.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.748
wandb:  sub_train_acc 0.69609
wandb: sub_train_loss 0.00097
wandb:       test_acc 0.764
wandb:      valid_acc 0.74
wandb: 
wandb: üöÄ View run jolly-sweep-411 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nggadeep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230220-nggadeep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6qvnz8we with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230235-6qvnz8we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-412
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6qvnz8we
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 232.71it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 249.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 251.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 248.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 242.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 185.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 174.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 181.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 202.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.777
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.69645
wandb: sub_train_loss 0.001
wandb:       test_acc 0.766
wandb:      valid_acc 0.752
wandb: 
wandb: üöÄ View run glamorous-sweep-412 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6qvnz8we
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230235-6qvnz8we/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1r7m1ni9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230250-1r7m1ni9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-413
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1r7m1ni9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 252.13it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 249.01it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 254.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 249.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 235.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 224.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 232.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 239.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.786
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.74114
wandb: sub_train_loss 0.0006
wandb:       test_acc 0.774
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run giddy-sweep-413 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1r7m1ni9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230250-1r7m1ni9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fbvg2sti with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230306-fbvg2sti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-414
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fbvg2sti
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 255.85it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 248.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 235.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 231.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 208.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 203.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 196.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 197.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 209.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.72747
wandb: sub_train_loss 0.00083
wandb:       test_acc 0.77
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run driven-sweep-414 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fbvg2sti
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230306-fbvg2sti/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7ejc2xi6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230321-7ejc2xi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-415
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7ejc2xi6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 242.12it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 239.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 244.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 247.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 250.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 252.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 256.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 252.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.787
wandb: best_valid_acc 0.782
wandb:  sub_train_acc 0.78397
wandb: sub_train_loss 0.00042
wandb:       test_acc 0.768
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run peach-sweep-415 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7ejc2xi6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230321-7ejc2xi6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7c2yfl8k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230344-7c2yfl8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-416
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7c2yfl8k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 230.62it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 238.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 242.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 246.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 254.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 260.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 265.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 257.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.765
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.78656
wandb: sub_train_loss 0.0002
wandb:       test_acc 0.77
wandb:      valid_acc 0.766
wandb: 
wandb: üöÄ View run copper-sweep-416 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7c2yfl8k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230344-7c2yfl8k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5yn5vmjc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230358-5yn5vmjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-417
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5yn5vmjc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.91it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.82it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 192.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 195.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 197.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 198.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 199.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 200.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:00<00:00, 191.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 191.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.32
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.12703
wandb: sub_train_loss 8e-05
wandb:       test_acc 0.183
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run clear-sweep-417 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5yn5vmjc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230358-5yn5vmjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 29cbzack with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230414-29cbzack
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-418
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/29cbzack
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 172.83it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.29it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 196.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 199.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 199.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 197.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 190.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 191.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 194.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 194.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.296
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.18095
wandb: sub_train_loss 0.00026
wandb:       test_acc 0.133
wandb:      valid_acc 0.136
wandb: 
wandb: üöÄ View run golden-sweep-418 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/29cbzack
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230414-29cbzack/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zyh9jfx4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230429-zyh9jfx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-419
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zyh9jfx4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 214.15it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 216.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 210.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 209.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 211.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 205.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 204.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 202.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 196.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 203.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.576
wandb: best_valid_acc 0.556
wandb:  sub_train_acc 0.2404
wandb: sub_train_loss 2e-05
wandb:       test_acc 0.218
wandb:      valid_acc 0.198
wandb: 
wandb: üöÄ View run mild-sweep-419 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zyh9jfx4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230429-zyh9jfx4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: neiflzz5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230449-neiflzz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-420
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/neiflzz5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 175.14it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 178.39it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 174.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 178.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 191.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 199.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 204.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 201.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 205.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.369
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.27105
wandb: sub_train_loss 5e-05
wandb:       test_acc 0.305
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run classic-sweep-420 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/neiflzz5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230449-neiflzz5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bf32fxiv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230502-bf32fxiv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-421
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bf32fxiv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.90it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 206.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 198.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 197.48it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 197.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 197.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 196.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 197.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 195.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.557
wandb: best_valid_acc 0.566
wandb:  sub_train_acc 0.41285
wandb: sub_train_loss 0.00161
wandb:       test_acc 0.379
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run vague-sweep-421 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bf32fxiv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230502-bf32fxiv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2cy2axbp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230517-2cy2axbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-422
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2cy2axbp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.05it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 222.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 209.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 214.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 212.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 207.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 178.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 165.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 164.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.595
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.351
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run unique-sweep-422 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2cy2axbp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230517-2cy2axbp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p36z7jed with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230532-p36z7jed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-423
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p36z7jed
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 208.62it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 214.24it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 204.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 204.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 204.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 190.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 189.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 192.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 199.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.657
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.33973
wandb: sub_train_loss 0.0002
wandb:       test_acc 0.52
wandb:      valid_acc 0.562
wandb: 
wandb: üöÄ View run distinctive-sweep-423 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p36z7jed
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230532-p36z7jed/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jq2np79p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230548-jq2np79p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-424
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jq2np79p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 198.65it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 198.24it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 178.04it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 181.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 185.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 187.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 145.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 129.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 125.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 121.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.678
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.41211
wandb: sub_train_loss 0.02534
wandb:       test_acc 0.564
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run brisk-sweep-424 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jq2np79p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230548-jq2np79p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jxe1v6m7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230603-jxe1v6m7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-425
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxe1v6m7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 181.66it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 192.70it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 198.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 200.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 185.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 183.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 179.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 180.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 181.02it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 180.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.695
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.50037
wandb: sub_train_loss 0.01383
wandb:       test_acc 0.55
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run rare-sweep-425 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxe1v6m7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230603-jxe1v6m7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xfv0t5nh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230618-xfv0t5nh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-426
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfv0t5nh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 186.11it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 175.78it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 180.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 182.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 183.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 172.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 159.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 147.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 150.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 151.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 154.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 162.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.55613
wandb: sub_train_loss 0.48493
wandb:       test_acc 0.618
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run generous-sweep-426 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfv0t5nh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230618-xfv0t5nh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qcpa8oqq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230634-qcpa8oqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-427
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qcpa8oqq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 182.61it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.93it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 185.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 190.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 192.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 192.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 196.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 200.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 203.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 197.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.76
wandb:  sub_train_acc 0.37297
wandb: sub_train_loss 1.19117
wandb:       test_acc 0.357
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run feasible-sweep-427 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qcpa8oqq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230634-qcpa8oqq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mzmkwyp3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230649-mzmkwyp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-428
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mzmkwyp3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.80it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 210.14it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 209.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 204.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 202.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 203.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 205.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 205.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 205.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.673
wandb: best_valid_acc 0.698
wandb:  sub_train_acc 0.48486
wandb: sub_train_loss 0.27239
wandb:       test_acc 0.505
wandb:      valid_acc 0.5
wandb: 
wandb: üöÄ View run leafy-sweep-428 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mzmkwyp3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230649-mzmkwyp3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xdjm8o7h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230704-xdjm8o7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-429
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xdjm8o7h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.83it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 178.76it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 164.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 167.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 173.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 179.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 175.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 174.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 182.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 145.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 159.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.749
wandb: best_valid_acc 0.738
wandb:  sub_train_acc 0.45199
wandb: sub_train_loss 1.16879
wandb:       test_acc 0.438
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run good-sweep-429 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xdjm8o7h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230704-xdjm8o7h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u9lvtzao with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230722-u9lvtzao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-430
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u9lvtzao
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.18it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 188.32it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 179.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 173.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 143.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 157.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 171.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 173.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 177.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 173.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.736
wandb:  sub_train_acc 0.67356
wandb: sub_train_loss 0.43992
wandb:       test_acc 0.688
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run olive-sweep-430 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u9lvtzao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230722-u9lvtzao/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w2gq4cb5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230744-w2gq4cb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-431
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w2gq4cb5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.04it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.76it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 181.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 187.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 173.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 172.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 165.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 157.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 155.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 159.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 165.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.782
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.57459
wandb: sub_train_loss 0.34032
wandb:       test_acc 0.545
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run helpful-sweep-431 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w2gq4cb5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230744-w2gq4cb5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m3pgob16 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230759-m3pgob16
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-432
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m3pgob16
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 176.43it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 179.14it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 184.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 188.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 188.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 186.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 186.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 187.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 190.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 194.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.66322
wandb: sub_train_loss 0.09581
wandb:       test_acc 0.64
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run earnest-sweep-432 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m3pgob16
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230759-m3pgob16/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ofopx56k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230814-ofopx56k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-433
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ofopx56k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 307.02it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:00, 312.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 307.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 321.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 329.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 334.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 339.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:00<00:00, 345.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 335.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.177
wandb: best_valid_acc 0.202
wandb:  sub_train_acc 0.1743
wandb: sub_train_loss 0.89599
wandb:       test_acc 0.168
wandb:      valid_acc 0.17
wandb: 
wandb: üöÄ View run prime-sweep-433 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ofopx56k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230814-ofopx56k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y63h3xm2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230830-y63h3xm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-434
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y63h3xm2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 355.83it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 309.66it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 273.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 272.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 285.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 304.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:00<00:00, 316.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 324.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 312.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.206
wandb: best_valid_acc 0.22
wandb:  sub_train_acc 0.17467
wandb: sub_train_loss 0.89674
wandb:       test_acc 0.167
wandb:      valid_acc 0.168
wandb: 
wandb: üöÄ View run azure-sweep-434 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y63h3xm2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230830-y63h3xm2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bsrc6z8k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230845-bsrc6z8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-435
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bsrc6z8k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 336.35it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:00, 344.05it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 349.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 342.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 346.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:00<00:00, 351.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:00<00:00, 345.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:00<00:00, 346.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 346.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.232
wandb: best_valid_acc 0.24
wandb:  sub_train_acc 0.18722
wandb: sub_train_loss 0.96257
wandb:       test_acc 0.206
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run divine-sweep-435 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bsrc6z8k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230845-bsrc6z8k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: axq6ky4l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230900-axq6ky4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-436
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/axq6ky4l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 324.77it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 337.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 325.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 314.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 299.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 307.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 312.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 326.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 322.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.229
wandb: best_valid_acc 0.26
wandb:  sub_train_acc 0.20827
wandb: sub_train_loss 0.96214
wandb:       test_acc 0.227
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run comfy-sweep-436 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/axq6ky4l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230900-axq6ky4l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yndgw5u5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230915-yndgw5u5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-437
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yndgw5u5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 354.86it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 362.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 369.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 374.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 376.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 378.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:00<00:00, 378.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 369.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.396
wandb: best_valid_acc 0.4
wandb:  sub_train_acc 0.2644
wandb: sub_train_loss 1.01659
wandb:       test_acc 0.264
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run scarlet-sweep-437 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yndgw5u5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230915-yndgw5u5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qncyjl1l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230927-qncyjl1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-438
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qncyjl1l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 333.35it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 347.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 353.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 354.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 361.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 365.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 354.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:00<00:00, 352.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 354.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.321
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.27917
wandb: sub_train_loss 1.01688
wandb:       test_acc 0.272
wandb:      valid_acc 0.284
wandb: 
wandb: üöÄ View run driven-sweep-438 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qncyjl1l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230927-qncyjl1l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c2u9j6ep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230941-c2u9j6ep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-439
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c2u9j6ep
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 342.95it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 366.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 371.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 376.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 376.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 376.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 376.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 372.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.333
wandb: best_valid_acc 0.352
wandb:  sub_train_acc 0.30724
wandb: sub_train_loss 1.05238
wandb:       test_acc 0.32
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run lemon-sweep-439 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c2u9j6ep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230941-c2u9j6ep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a6ayn9wd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_230956-a6ayn9wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a6ayn9wd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 334.63it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 348.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 348.46it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 347.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 352.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 358.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:00<00:00, 361.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:00<00:00, 360.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 356.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.323
wandb: best_valid_acc 0.334
wandb:  sub_train_acc 0.30539
wandb: sub_train_loss 1.05215
wandb:       test_acc 0.316
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run noble-sweep-440 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a6ayn9wd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_230956-a6ayn9wd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uf8v2349 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231018-uf8v2349
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-441
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uf8v2349
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 326.81it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 360.51it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 370.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 370.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 368.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 367.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 370.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 372.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 368.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.5
wandb: best_valid_acc 0.484
wandb:  sub_train_acc 0.44535
wandb: sub_train_loss 1.08466
wandb:       test_acc 0.492
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run swift-sweep-441 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uf8v2349
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231018-uf8v2349/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pshdx75l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231031-pshdx75l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-442
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pshdx75l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 339.37it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 352.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 320.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 299.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 291.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 291.31it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 296.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 301.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 318.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 309.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.496
wandb: best_valid_acc 0.492
wandb:  sub_train_acc 0.44424
wandb: sub_train_loss 1.08507
wandb:       test_acc 0.493
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run fluent-sweep-442 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pshdx75l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231031-pshdx75l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nd9vuxy2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231053-nd9vuxy2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-443
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nd9vuxy2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 361.05it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:00, 372.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 372.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 378.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 378.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 373.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 371.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 370.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.54136
wandb: sub_train_loss 1.13156
wandb:       test_acc 0.571
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run magic-sweep-443 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nd9vuxy2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231053-nd9vuxy2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bspoj1iu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231108-bspoj1iu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-444
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bspoj1iu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 353.94it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 347.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 348.53it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 356.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 338.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 341.54it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 344.04it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:00<00:00, 342.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 344.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.54
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.51329
wandb: sub_train_loss 1.13032
wandb:       test_acc 0.55
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run genial-sweep-444 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bspoj1iu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231108-bspoj1iu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: te2jireu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231123-te2jireu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-445
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/te2jireu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 306.75it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:00, 311.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 316.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 314.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 316.82it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 314.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 317.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:00<00:00, 314.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:00<00:00, 326.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 319.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.67
wandb: best_valid_acc 0.67
wandb:  sub_train_acc 0.66691
wandb: sub_train_loss 1.14371
wandb:       test_acc 0.673
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run dauntless-sweep-445 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/te2jireu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231123-te2jireu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bj0jzuca with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231144-bj0jzuca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-446
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bj0jzuca
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 275.44it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 293.04it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 313.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 322.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 320.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 303.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 311.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:00<00:00, 323.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:00<00:00, 330.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 318.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.68833
wandb: sub_train_loss 1.14334
wandb:       test_acc 0.693
wandb:      valid_acc 0.682
wandb: 
wandb: üöÄ View run super-sweep-446 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bj0jzuca
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231144-bj0jzuca/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2acuzs4j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231159-2acuzs4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-447
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2acuzs4j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 346.37it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 352.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 356.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 359.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 361.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 362.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 363.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:00<00:00, 364.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 360.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.70901
wandb: sub_train_loss 1.13947
wandb:       test_acc 0.684
wandb:      valid_acc 0.688
wandb: 
wandb: üöÄ View run usual-sweep-447 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2acuzs4j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231159-2acuzs4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0go7tksu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231210-0go7tksu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-448
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0go7tksu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 234.31it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 269.51it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 294.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 310.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 325.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 336.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 343.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:00<00:00, 347.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 329.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.707
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.7223
wandb: sub_train_loss 1.13976
wandb:       test_acc 0.697
wandb:      valid_acc 0.718
wandb: 
wandb: üöÄ View run still-sweep-448 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0go7tksu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231210-0go7tksu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tbdb2vi1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231225-tbdb2vi1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-449
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tbdb2vi1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 229.06it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 217.92it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 219.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 236.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 243.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 245.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 257.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 268.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 277.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 283.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 284.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 262.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.221
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.37334
wandb: sub_train_loss 0.0
wandb:       test_acc 0.224
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run kind-sweep-449 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tbdb2vi1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231225-tbdb2vi1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: na6g08f9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231239-na6g08f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-450
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na6g08f9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 275.85it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 275.03it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 280.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 281.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 282.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 284.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 283.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 284.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 284.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 278.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 280.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.2
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.36263
wandb: sub_train_loss 0.0
wandb:       test_acc 0.197
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run gallant-sweep-450 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na6g08f9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231239-na6g08f9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o7yxl7ok with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231255-o7yxl7ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-451
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7yxl7ok
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 206.64it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 210.67it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 222.94it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 240.96it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 254.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 261.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 269.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 276.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:00<00:00, 272.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 265.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 260.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 255.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.523
wandb: best_valid_acc 0.52
wandb:  sub_train_acc 0.33641
wandb: sub_train_loss 0.0
wandb:       test_acc 0.525
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run happy-sweep-451 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o7yxl7ok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231255-o7yxl7ok/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o0k6xopi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231311-o0k6xopi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-452
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o0k6xopi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 224.98it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 230.17it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 242.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 239.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 235.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 237.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 243.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 246.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:00<00:00, 242.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 217.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 190.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 185.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.486
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.35192
wandb: sub_train_loss 0.0
wandb:       test_acc 0.424
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run comic-sweep-452 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o0k6xopi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231311-o0k6xopi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hrvxngz7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231332-hrvxngz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-453
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hrvxngz7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 208.38it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 215.28it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 207.48it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 199.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 190.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 192.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 199.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 204.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 208.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 215.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 203.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 202.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 205.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 203.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.63
wandb: best_valid_acc 0.636
wandb:  sub_train_acc 0.42134
wandb: sub_train_loss 0.0
wandb:       test_acc 0.589
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run brisk-sweep-453 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hrvxngz7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231332-hrvxngz7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9bnkdtwh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231346-9bnkdtwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-454
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9bnkdtwh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.05it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 240.54it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 244.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 239.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 238.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 233.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 232.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 241.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 251.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 252.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 255.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 246.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.57
wandb: best_valid_acc 0.596
wandb:  sub_train_acc 0.39993
wandb: sub_train_loss 0.0
wandb:       test_acc 0.46
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run fearless-sweep-454 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9bnkdtwh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231346-9bnkdtwh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 944ya39l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231407-944ya39l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-455
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/944ya39l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 225.27it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 217.77it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 221.44it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 222.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 221.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 221.62it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 219.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 222.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 234.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 246.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 255.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 258.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 237.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.669
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.47157
wandb: sub_train_loss 0.0
wandb:       test_acc 0.589
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run noble-sweep-455 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/944ya39l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231407-944ya39l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 35en514e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231428-35en514e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-456
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/35en514e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 200.95it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 201.68it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 194.46it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 184.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 195.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 203.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 211.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 211.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 206.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 204.85it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 220.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 230.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 235.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.68
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.45236
wandb: sub_train_loss 0.0
wandb:       test_acc 0.628
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run leafy-sweep-456 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/35en514e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231428-35en514e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ci7x0c60 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231447-ci7x0c60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-457
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ci7x0c60
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 168.23it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.04it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 149.27it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 142.35it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 143.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 146.45it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 156.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 164.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 159.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 159.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 167.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 165.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 175.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 178.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 172.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 174.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.734
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.56795
wandb: sub_train_loss 1e-05
wandb:       test_acc 0.721
wandb:      valid_acc 0.718
wandb: 
wandb: üöÄ View run gallant-sweep-457 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ci7x0c60
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231447-ci7x0c60/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j861yotm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231501-j861yotm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-458
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j861yotm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 238.62it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 253.76it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 260.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 260.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 263.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 267.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 266.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 263.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 262.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 262.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 262.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 261.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.74
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.58752
wandb: sub_train_loss 0.0
wandb:       test_acc 0.724
wandb:      valid_acc 0.734
wandb: 
wandb: üöÄ View run wild-sweep-458 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j861yotm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231501-j861yotm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j5iyyarp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231517-j5iyyarp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-459
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j5iyyarp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.73it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:00, 261.56it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:00, 260.56it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 263.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 264.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 265.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 263.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 265.36it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 261.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 257.65it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 258.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 261.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.781
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.68648
wandb: sub_train_loss 0.0
wandb:       test_acc 0.773
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run toasty-sweep-459 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j5iyyarp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231517-j5iyyarp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 19ayavsj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231537-19ayavsj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-460
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/19ayavsj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 238.46it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 249.42it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 256.18it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 257.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 258.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 259.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 260.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 264.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 275.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 277.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 281.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 267.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.786
wandb: best_valid_acc 0.77
wandb:  sub_train_acc 0.69904
wandb: sub_train_loss 0.0
wandb:       test_acc 0.781
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run pious-sweep-460 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/19ayavsj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231537-19ayavsj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t4jsa03k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231553-t4jsa03k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-461
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t4jsa03k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 248.52it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 252.12it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 254.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:00, 258.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 259.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 262.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 268.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 274.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:00<00:00, 278.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 278.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 270.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.789
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.75074
wandb: sub_train_loss 0.0
wandb:       test_acc 0.782
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run fresh-sweep-461 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t4jsa03k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231553-t4jsa03k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ime7pnjh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231609-ime7pnjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-462
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ime7pnjh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 245.27it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 251.53it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 253.23it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 252.33it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 259.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 262.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 268.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 272.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 275.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 278.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 268.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.73412
wandb: sub_train_loss 0.0
wandb:       test_acc 0.773
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run hardy-sweep-462 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ime7pnjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231609-ime7pnjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: aj462tmy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231629-aj462tmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-463
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/aj462tmy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 241.24it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 239.27it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 229.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 228.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 228.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 232.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 232.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 231.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 231.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 237.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 236.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 236.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 234.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.79
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.79136
wandb: sub_train_loss 0.0
wandb:       test_acc 0.784
wandb:      valid_acc 0.774
wandb: 
wandb: üöÄ View run devoted-sweep-463 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/aj462tmy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231629-aj462tmy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vsuzuc8p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231644-vsuzuc8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-464
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vsuzuc8p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 257.95it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 249.87it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 252.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 257.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 267.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 270.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 272.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 272.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 270.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 269.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 267.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.777
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.7825
wandb: sub_train_loss 0.0
wandb:       test_acc 0.768
wandb:      valid_acc 0.764
wandb: 
wandb: üöÄ View run peach-sweep-464 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vsuzuc8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231644-vsuzuc8p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9atelkdw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231700-9atelkdw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-465
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9atelkdw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 202.90it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 205.08it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 202.58it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 203.27it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 202.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 196.64it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 193.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 188.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 181.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 184.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 186.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 186.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 190.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 194.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.22563
wandb: sub_train_loss 0.0
wandb:       test_acc 0.145
wandb:      valid_acc 0.136
wandb: 
wandb: üöÄ View run distinctive-sweep-465 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9atelkdw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231700-9atelkdw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u9ge7bau with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231722-u9ge7bau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-466
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u9ge7bau
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.10it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 183.58it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 174.40it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 173.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 170.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 177.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 157.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 165.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 180.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 189.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 196.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 200.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 201.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 199.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.262
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.28693
wandb: sub_train_loss 0.0
wandb:       test_acc 0.24
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run stellar-sweep-466 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u9ge7bau
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231722-u9ge7bau/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jduo8iqq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231737-jduo8iqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-467
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jduo8iqq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 197.36it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 202.34it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 195.51it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 186.23it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 185.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 183.36it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 184.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 182.36it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 184.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 190.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 190.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 188.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 189.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 187.45it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 187.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.604
wandb: best_valid_acc 0.614
wandb:  sub_train_acc 0.23191
wandb: sub_train_loss 0.0
wandb:       test_acc 0.27
wandb:      valid_acc 0.304
wandb: 
wandb: üöÄ View run crisp-sweep-467 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jduo8iqq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231737-jduo8iqq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2l9zpqh9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231753-2l9zpqh9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-468
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2l9zpqh9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.62it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.49it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 171.78it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 174.75it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 181.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 188.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 195.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 195.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 196.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 198.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 199.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 199.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 198.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 197.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 197.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.558
wandb: best_valid_acc 0.538
wandb:  sub_train_acc 0.27622
wandb: sub_train_loss 0.0
wandb:       test_acc 0.418
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run fresh-sweep-468 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2l9zpqh9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231753-2l9zpqh9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t7m710uz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231808-t7m710uz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-469
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t7m710uz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.00it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 165.39it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 156.97it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 165.37it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 179.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 188.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 186.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 188.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 195.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 198.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 203.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 207.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 207.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 203.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.542
wandb:  sub_train_acc 0.30281
wandb: sub_train_loss 0.0
wandb:       test_acc 0.405
wandb:      valid_acc 0.406
wandb: 
wandb: üöÄ View run stellar-sweep-469 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/t7m710uz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231808-t7m710uz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o9x9nka2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231823-o9x9nka2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-470
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o9x9nka2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 212.62it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 206.39it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 197.22it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 198.99it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 201.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 203.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 207.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 207.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 207.27it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 204.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 192.32it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 190.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 189.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 189.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.641
wandb: best_valid_acc 0.658
wandb:  sub_train_acc 0.42984
wandb: sub_train_loss 0.0
wandb:       test_acc 0.492
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run glorious-sweep-470 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o9x9nka2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231823-o9x9nka2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xk92t3ki with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231845-xk92t3ki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-471
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xk92t3ki
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 103.01it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 109.81it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 110.77it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 115.56it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 115.47it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 112.78it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 117.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 123.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 125.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 127.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 133.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 141.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 147.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 149.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 156.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 158.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 161.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 162.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 155.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 156.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.651
wandb: best_valid_acc 0.668
wandb:  sub_train_acc 0.32312
wandb: sub_train_loss 0.05678
wandb:       test_acc 0.352
wandb:      valid_acc 0.37
wandb: 
wandb: üöÄ View run twilight-sweep-471 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xk92t3ki
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231845-xk92t3ki/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 673puaja with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231900-673puaja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-472
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/673puaja
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 205.36it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 212.88it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 212.03it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 214.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 213.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 208.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 210.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 214.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 217.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 216.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 217.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 218.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 218.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 214.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.699
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.36411
wandb: sub_train_loss 0.11008
wandb:       test_acc 0.432
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run fancy-sweep-472 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/673puaja
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231900-673puaja/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8b4685ka with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231911-8b4685ka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-473
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8b4685ka
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.28it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 186.70it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 175.59it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 171.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 173.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 179.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 180.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 185.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 190.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 191.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 191.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 190.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 189.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 191.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 191.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.44682
wandb: sub_train_loss 0.01944
wandb:       test_acc 0.52
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run vital-sweep-473 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8b4685ka
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231911-8b4685ka/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ucqwx4l8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231926-ucqwx4l8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-474
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ucqwx4l8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.88it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.19it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 175.01it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 170.96it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 170.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 160.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 164.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 171.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 176.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 181.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 183.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 185.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 179.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 178.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 178.20it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 173.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.718
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.38146
wandb: sub_train_loss 0.01836
wandb:       test_acc 0.438
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run glad-sweep-474 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ucqwx4l8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231926-ucqwx4l8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z11s66z7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231941-z11s66z7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-475
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z11s66z7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.76it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 180.99it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.11it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 181.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 175.44it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 173.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 171.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 172.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 174.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 175.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 176.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 177.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 175.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 177.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 180.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 181.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.75
wandb:  sub_train_acc 0.51883
wandb: sub_train_loss 0.57722
wandb:       test_acc 0.553
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run volcanic-sweep-475 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z11s66z7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231941-z11s66z7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4yf25qzt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_231956-4yf25qzt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-476
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4yf25qzt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.41it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 190.17it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 192.62it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.68it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 191.52it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 184.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 177.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 181.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 186.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 191.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 191.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 190.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 189.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 196.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.789
wandb: best_valid_acc 0.754
wandb:  sub_train_acc 0.58936
wandb: sub_train_loss 0.15229
wandb:       test_acc 0.622
wandb:      valid_acc 0.644
wandb: 
wandb: üöÄ View run deft-sweep-476 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4yf25qzt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_231956-4yf25qzt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zsowwulg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232008-zsowwulg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-477
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zsowwulg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.09it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 141.76it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 137.72it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 142.05it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 133.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 143.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 150.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:01, 155.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 154.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 153.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 148.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 142.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 154.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 167.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 179.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 190.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 198.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.794
wandb: best_valid_acc 0.766
wandb:  sub_train_acc 0.51957
wandb: sub_train_loss 0.21635
wandb:       test_acc 0.525
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run atomic-sweep-477 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zsowwulg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232008-zsowwulg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x2yxqu2w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232022-x2yxqu2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-478
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x2yxqu2w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.18it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.07it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 146.20it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 135.94it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 140.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 153.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 169.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 179.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 187.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 189.60it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 191.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 192.03it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 191.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 186.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 182.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.58567
wandb: sub_train_loss 0.0091
wandb:       test_acc 0.601
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run sparkling-sweep-478 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x2yxqu2w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232022-x2yxqu2w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2b4wmqz9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232038-2b4wmqz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-479
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2b4wmqz9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.12it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 163.09it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 160.93it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 163.19it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 153.31it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 156.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 156.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 159.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 167.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 175.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 178.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 178.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 181.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 183.22it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 185.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 186.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.754
wandb: best_valid_acc 0.768
wandb:  sub_train_acc 0.70015
wandb: sub_train_loss 0.31805
wandb:       test_acc 0.693
wandb:      valid_acc 0.662
wandb: 
wandb: üöÄ View run copper-sweep-479 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2b4wmqz9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232038-2b4wmqz9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3dc01r10 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232053-3dc01r10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-480
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3dc01r10
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.64it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 189.21it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 192.73it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 192.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 194.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 191.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 190.70it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 193.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 196.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 202.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 204.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 207.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 207.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 207.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 197.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.788
wandb: best_valid_acc 0.792
wandb:  sub_train_acc 0.66581
wandb: sub_train_loss 0.18028
wandb:       test_acc 0.659
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run cerulean-sweep-480 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3dc01r10
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232053-3dc01r10/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gpkbjh5d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232113-gpkbjh5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-481
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gpkbjh5d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 210.88it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 228.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 236.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 240.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 217.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 214.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 216.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 219.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 221.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.226
wandb:  sub_train_acc 0.19461
wandb: sub_train_loss 1.40386
wandb:       test_acc 0.206
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run grateful-sweep-481 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gpkbjh5d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232113-gpkbjh5d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7tewrc2y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232129-7tewrc2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-482
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7tewrc2y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.82it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 195.34it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 229.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 229.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 247.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 260.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 276.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 255.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.216
wandb: best_valid_acc 0.222
wandb:  sub_train_acc 0.19387
wandb: sub_train_loss 1.40694
wandb:       test_acc 0.204
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run pleasant-sweep-482 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7tewrc2y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232129-7tewrc2y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 14w3e187 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232144-14w3e187
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-483
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/14w3e187
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 229.08it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 246.34it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 269.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 279.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 288.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 293.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 285.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.227
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.22009
wandb: sub_train_loss 1.53655
wandb:       test_acc 0.211
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run autumn-sweep-483 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/14w3e187
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232144-14w3e187/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7xcewdkm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232205-7xcewdkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-484
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7xcewdkm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 239.31it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 235.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 235.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 248.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 260.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 257.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 247.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 245.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.221
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.21972
wandb: sub_train_loss 1.53423
wandb:       test_acc 0.211
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run avid-sweep-484 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7xcewdkm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232205-7xcewdkm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ou7fvu2y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232220-ou7fvu2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-485
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ou7fvu2y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 264.78it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 277.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 282.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 277.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 266.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 265.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 273.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 272.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.297
wandb: best_valid_acc 0.32
wandb:  sub_train_acc 0.28693
wandb: sub_train_loss 1.58112
wandb:       test_acc 0.266
wandb:      valid_acc 0.294
wandb: 
wandb: üöÄ View run vocal-sweep-485 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ou7fvu2y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232220-ou7fvu2y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kl2s34f4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232240-kl2s34f4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-486
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kl2s34f4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 281.72it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 277.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 276.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 273.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 274.10it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 271.64it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 272.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 274.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.307
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.28619
wandb: sub_train_loss 1.58142
wandb:       test_acc 0.27
wandb:      valid_acc 0.296
wandb: 
wandb: üöÄ View run serene-sweep-486 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kl2s34f4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232240-kl2s34f4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cji9gup3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232256-cji9gup3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-487
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cji9gup3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 246.03it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 252.00it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 256.23it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 264.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 262.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 261.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 263.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.2788
wandb: sub_train_loss 1.62037
wandb:       test_acc 0.272
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run vocal-sweep-487 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/cji9gup3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232256-cji9gup3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wenj5g8m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232311-wenj5g8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-488
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wenj5g8m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 278.03it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 291.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 291.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 287.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 280.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 273.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 280.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.259
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.28508
wandb: sub_train_loss 1.61954
wandb:       test_acc 0.266
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run treasured-sweep-488 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wenj5g8m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232311-wenj5g8m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vdingz5k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232326-vdingz5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-489
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vdingz5k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 300.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 310.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 309.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 305.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 310.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 312.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 310.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.021 MB of 0.023 MB uploadedwandb: \ 0.021 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.474
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.44165
wandb: sub_train_loss 1.64769
wandb:       test_acc 0.455
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run neat-sweep-489 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vdingz5k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232326-vdingz5k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nozv6hmb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232342-nozv6hmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-490
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nozv6hmb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 293.79it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 300.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 303.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 308.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 308.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 297.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 300.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.492
wandb: best_valid_acc 0.49
wandb:  sub_train_acc 0.45864
wandb: sub_train_loss 1.6453
wandb:       test_acc 0.475
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run northern-sweep-490 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nozv6hmb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232342-nozv6hmb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5msellbo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232358-5msellbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-491
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5msellbo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 295.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 310.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 298.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 297.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 288.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 287.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 288.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.52548
wandb: sub_train_loss 1.69555
wandb:       test_acc 0.55
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run dainty-sweep-491 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5msellbo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232358-5msellbo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7oz0ao34 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232412-7oz0ao34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-492
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7oz0ao34
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 286.57it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 293.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 293.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 293.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 290.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 290.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.572
wandb: best_valid_acc 0.552
wandb:  sub_train_acc 0.52105
wandb: sub_train_loss 1.6949
wandb:       test_acc 0.542
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run fancy-sweep-492 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7oz0ao34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232412-7oz0ao34/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fyyr70g4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232428-fyyr70g4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-493
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fyyr70g4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 297.68it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 305.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 307.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 305.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 310.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 289.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 295.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.529
wandb: best_valid_acc 0.488
wandb:  sub_train_acc 0.51699
wandb: sub_train_loss 1.71316
wandb:       test_acc 0.532
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run confused-sweep-493 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fyyr70g4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232428-fyyr70g4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iklg5eqp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232443-iklg5eqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-494
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iklg5eqp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.93it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 215.01it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 219.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 236.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 250.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 249.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 256.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 247.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.524
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.51292
wandb: sub_train_loss 1.71154
wandb:       test_acc 0.524
wandb:      valid_acc 0.478
wandb: 
wandb: üöÄ View run zesty-sweep-494 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iklg5eqp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232443-iklg5eqp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ylse994f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232459-ylse994f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-495
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ylse994f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 299.69it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 304.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 307.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 303.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 281.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 274.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 282.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.691
wandb: best_valid_acc 0.696
wandb:  sub_train_acc 0.66654
wandb: sub_train_loss 1.71739
wandb:       test_acc 0.659
wandb:      valid_acc 0.654
wandb: 
wandb: üöÄ View run resilient-sweep-495 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ylse994f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232459-ylse994f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: upty01wc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232520-upty01wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-496
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/upty01wc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 268.02it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 264.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 267.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 267.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 273.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 269.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 261.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 264.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.647
wandb: best_valid_acc 0.672
wandb:  sub_train_acc 0.55096
wandb: sub_train_loss 1.71866
wandb:       test_acc 0.525
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run glowing-sweep-496 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/upty01wc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232520-upty01wc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ka82d0cu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232536-ka82d0cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-497
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ka82d0cu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.52it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 143.75it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.94it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 156.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 158.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 168.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 171.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 176.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 178.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 178.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 182.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.329
wandb: best_valid_acc 0.338
wandb:  sub_train_acc 0.29838
wandb: sub_train_loss 0.00038
wandb:       test_acc 0.329
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run iconic-sweep-497 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ka82d0cu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232536-ka82d0cu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lgkx5lzj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232553-lgkx5lzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-498
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lgkx5lzj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.10it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 188.34it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 188.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 185.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 185.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 186.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 186.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 189.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 191.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 192.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.304
wandb: best_valid_acc 0.308
wandb:  sub_train_acc 0.29062
wandb: sub_train_loss 0.00055
wandb:       test_acc 0.305
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run icy-sweep-498 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lgkx5lzj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232553-lgkx5lzj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ihg1kdpe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232608-ihg1kdpe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-499
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ihg1kdpe
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.03it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.32it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 165.11it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 163.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 165.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 168.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 177.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 183.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 184.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 188.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.651
wandb: best_valid_acc 0.632
wandb:  sub_train_acc 0.47932
wandb: sub_train_loss 0.00469
wandb:       test_acc 0.651
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run noble-sweep-499 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ihg1kdpe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232608-ihg1kdpe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jxg9i1xf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232629-jxg9i1xf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-500
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxg9i1xf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.90it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 170.68it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 175.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 172.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 176.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 157.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 148.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 140.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 143.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 156.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 164.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 160.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.45827
wandb: sub_train_loss 0.0052
wandb:       test_acc 0.58
wandb:      valid_acc 0.6
wandb: 
wandb: üöÄ View run celestial-sweep-500 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxg9i1xf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232629-jxg9i1xf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: su47tuf1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232649-su47tuf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-501
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/su47tuf1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.11it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 199.82it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 202.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 203.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 201.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 200.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 191.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 161.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 157.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.55871
wandb: sub_train_loss 0.03157
wandb:       test_acc 0.673
wandb:      valid_acc 0.668
wandb: 
wandb: üöÄ View run winter-sweep-501 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/su47tuf1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232649-su47tuf1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5jaxq4hy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232710-5jaxq4hy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-502
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5jaxq4hy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.30it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 168.72it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 170.48it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 173.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 174.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 175.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 174.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 173.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 172.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 172.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 171.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.718
wandb:  sub_train_acc 0.54505
wandb: sub_train_loss 0.02637
wandb:       test_acc 0.677
wandb:      valid_acc 0.676
wandb: 
wandb: üöÄ View run sage-sweep-502 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5jaxq4hy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232710-5jaxq4hy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f7il31cw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232725-f7il31cw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-503
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f7il31cw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 168.53it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 170.05it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 170.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 170.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 173.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 173.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 173.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 172.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 169.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 172.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 175.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.704
wandb: best_valid_acc 0.708
wandb:  sub_train_acc 0.5949
wandb: sub_train_loss 0.05424
wandb:       test_acc 0.713
wandb:      valid_acc 0.696
wandb: 
wandb: üöÄ View run solar-sweep-503 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f7il31cw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232725-f7il31cw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kb27kxi3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232740-kb27kxi3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-504
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kb27kxi3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 167.53it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.26it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 177.09it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 173.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 171.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 169.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 169.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 162.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 163.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 169.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.726
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.60746
wandb: sub_train_loss 0.04661
wandb:       test_acc 0.722
wandb:      valid_acc 0.698
wandb: 
wandb: üöÄ View run gallant-sweep-504 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kb27kxi3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232740-kb27kxi3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xsq7iug2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232756-xsq7iug2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-505
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xsq7iug2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.09it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.50it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 192.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 193.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 187.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 184.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 182.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 185.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 186.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 187.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.774
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.67762
wandb: sub_train_loss 0.08041
wandb:       test_acc 0.765
wandb:      valid_acc 0.736
wandb: 
wandb: üöÄ View run whole-sweep-505 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xsq7iug2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232756-xsq7iug2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j0z14jxx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232811-j0z14jxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-506
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j0z14jxx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.62it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 136.90it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 133.85it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 137.06it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 143.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 146.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 154.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 162.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 176.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 183.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 188.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.778
wandb: best_valid_acc 0.786
wandb:  sub_train_acc 0.67319
wandb: sub_train_loss 0.08049
wandb:       test_acc 0.779
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run smooth-sweep-506 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j0z14jxx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232811-j0z14jxx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h7eprbjm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232826-h7eprbjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-507
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h7eprbjm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.69it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.75it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 169.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 167.66it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 173.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 168.81it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 171.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 172.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 175.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.807
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.73117
wandb: sub_train_loss 0.11498
wandb:       test_acc 0.804
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run jolly-sweep-507 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h7eprbjm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232826-h7eprbjm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jiruw0yq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232842-jiruw0yq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-508
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jiruw0yq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.70it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 196.18it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 197.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 197.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 193.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 191.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 188.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 177.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 173.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 175.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 183.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.799
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.74188
wandb: sub_train_loss 0.12442
wandb:       test_acc 0.799
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run silvery-sweep-508 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jiruw0yq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232842-jiruw0yq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g5lxg38b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232857-g5lxg38b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-509
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g5lxg38b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 169.63it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 180.25it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 184.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 188.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 191.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 193.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 194.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 189.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 190.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 191.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 189.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.816
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.78434
wandb: sub_train_loss 0.15741
wandb:       test_acc 0.816
wandb:      valid_acc 0.8
wandb: 
wandb: üöÄ View run prime-sweep-509 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g5lxg38b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232857-g5lxg38b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f5ds2moz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232912-f5ds2moz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-510
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f5ds2moz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.55it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 188.40it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 184.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 184.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 186.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 187.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 186.98it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 186.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 181.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 170.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.811
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.76957
wandb: sub_train_loss 0.14864
wandb:       test_acc 0.801
wandb:      valid_acc 0.792
wandb: 
wandb: üöÄ View run electric-sweep-510 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f5ds2moz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232912-f5ds2moz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q8g28znz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232927-q8g28znz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-511
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q8g28znz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 170.76it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 172.29it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 175.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 176.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 177.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 177.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 175.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 175.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 175.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 174.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.805
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.78434
wandb: sub_train_loss 0.15951
wandb:       test_acc 0.774
wandb:      valid_acc 0.768
wandb: 
wandb: üöÄ View run silver-sweep-511 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q8g28znz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232927-q8g28znz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ui418gzx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232943-ui418gzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-512
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ui418gzx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.46it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 198.70it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 197.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 198.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 197.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 198.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 197.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 194.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 197.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.821
wandb: best_valid_acc 0.802
wandb:  sub_train_acc 0.81056
wandb: sub_train_loss 0.13842
wandb:       test_acc 0.801
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run comic-sweep-512 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ui418gzx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232943-ui418gzx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sp896ceu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_232959-sp896ceu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-513
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sp896ceu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.07it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 124.46it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 122.89it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.86it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 121.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 123.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 128.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 130.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 131.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 131.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 132.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 132.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 131.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.395
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.12666
wandb: sub_train_loss 0.00028
wandb:       test_acc 0.114
wandb:      valid_acc 0.084
wandb: 
wandb: üöÄ View run silvery-sweep-513 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sp896ceu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_232959-sp896ceu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gnrwnufv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233014-gnrwnufv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-514
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gnrwnufv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.75it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.85it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 110.34it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 110.72it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 118.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 123.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 125.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 130.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 129.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 130.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 128.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 126.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 126.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 123.11it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 118.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.555
wandb: best_valid_acc 0.56
wandb:  sub_train_acc 0.21233
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.211
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run blooming-sweep-514 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gnrwnufv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233014-gnrwnufv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hye9704d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233029-hye9704d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-515
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hye9704d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.17it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.49it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 149.65it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 145.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 135.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 128.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 126.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 125.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 118.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 118.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 118.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 119.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 124.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 119.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.69
wandb:  sub_train_acc 0.44018
wandb: sub_train_loss 0.00105
wandb:       test_acc 0.488
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run logical-sweep-515 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hye9704d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233029-hye9704d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2x2tpz5q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233044-2x2tpz5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-516
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2x2tpz5q
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.14it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 140.95it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 141.93it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 141.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 142.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 143.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 138.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 140.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 139.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 135.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 132.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 128.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 123.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.579
wandb: best_valid_acc 0.588
wandb:  sub_train_acc 0.36337
wandb: sub_train_loss 0.0
wandb:       test_acc 0.426
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run usual-sweep-516 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2x2tpz5q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233044-2x2tpz5q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g9pwnxjm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233100-g9pwnxjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-517
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g9pwnxjm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.48it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.86it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 121.58it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 121.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 124.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 132.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 139.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 144.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 145.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 145.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 142.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 141.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 138.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 135.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.629
wandb: best_valid_acc 0.616
wandb:  sub_train_acc 0.39919
wandb: sub_train_loss 0.04877
wandb:       test_acc 0.37
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run colorful-sweep-517 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g9pwnxjm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233100-g9pwnxjm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6cby7u3c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233117-6cby7u3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-518
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6cby7u3c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.87it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 119.15it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 98.05it/s]  24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 101.39it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 109.08it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 113.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 120.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 125.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 128.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 132.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 134.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 133.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 130.76it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 128.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 127.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.717
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.5192
wandb: sub_train_loss 0.51293
wandb:       test_acc 0.558
wandb:      valid_acc 0.536
wandb: 
wandb: üöÄ View run sparkling-sweep-518 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6cby7u3c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233117-6cby7u3c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8kgw423k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233130-8kgw423k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-519
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8kgw423k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.86it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.62it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 126.48it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.77it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 122.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 123.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 123.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 126.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 129.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 128.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 124.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 126.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 130.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 132.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.698
wandb: best_valid_acc 0.722
wandb:  sub_train_acc 0.54394
wandb: sub_train_loss 0.25502
wandb:       test_acc 0.544
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run dulcet-sweep-519 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8kgw423k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233130-8kgw423k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c6hxg7fi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233146-c6hxg7fi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-520
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c6hxg7fi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 110.29it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 113.21it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 118.17it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 120.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 123.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 121.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 124.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 124.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 115.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 113.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 113.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 112.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 111.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 111.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 113.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.715
wandb: best_valid_acc 0.73
wandb:  sub_train_acc 0.45162
wandb: sub_train_loss 0.03343
wandb:       test_acc 0.472
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run smooth-sweep-520 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c6hxg7fi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233146-c6hxg7fi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sf1somnm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233202-sf1somnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-521
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sf1somnm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.15it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 147.85it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.14it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 137.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 134.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 136.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 137.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 136.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 132.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 129.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 133.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 133.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 136.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.739
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.56869
wandb: sub_train_loss 0.4698
wandb:       test_acc 0.597
wandb:      valid_acc 0.568
wandb: 
wandb: üöÄ View run sunny-sweep-521 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sf1somnm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233202-sf1somnm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z5hfhrxk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233217-z5hfhrxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-522
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z5hfhrxk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.41it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 134.29it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 131.03it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 134.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 136.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 135.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 135.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 135.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 132.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 132.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 132.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 132.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 132.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 133.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.744
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.52991
wandb: sub_train_loss 0.22958
wandb:       test_acc 0.594
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run autumn-sweep-522 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z5hfhrxk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233217-z5hfhrxk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g16ar0vf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233232-g16ar0vf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-523
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g16ar0vf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.29it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 139.01it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 140.70it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 141.46it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 140.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 136.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 133.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 132.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 136.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 136.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 138.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 140.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 141.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.777
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.57644
wandb: sub_train_loss 0.61128
wandb:       test_acc 0.541
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run magic-sweep-523 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g16ar0vf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233232-g16ar0vf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o95qierg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233244-o95qierg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-524
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o95qierg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.94it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.24it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 135.99it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 138.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 141.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 142.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 143.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 142.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 137.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 137.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 137.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 137.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 132.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 130.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.799
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.41913
wandb: sub_train_loss 0.96303
wandb:       test_acc 0.407
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run sunny-sweep-524 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o95qierg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233244-o95qierg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6grr7uq4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233258-6grr7uq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-525
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6grr7uq4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 143.18it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.48it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.58it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 141.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 127.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 122.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 117.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 116.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 115.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 115.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 116.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 119.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 122.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 118.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.72267
wandb: sub_train_loss 0.70776
wandb:       test_acc 0.731
wandb:      valid_acc 0.704
wandb: 
wandb: üöÄ View run avid-sweep-525 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6grr7uq4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233258-6grr7uq4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1kxgex4a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233313-1kxgex4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-526
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1kxgex4a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.70it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.96it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 129.22it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 131.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 135.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 137.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 137.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 137.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 137.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 138.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 137.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 135.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 131.55it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 128.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.798
wandb: best_valid_acc 0.796
wandb:  sub_train_acc 0.45606
wandb: sub_train_loss 1.72375
wandb:       test_acc 0.472
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run copper-sweep-526 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1kxgex4a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233313-1kxgex4a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tg88l7is with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233328-tg88l7is
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-527
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tg88l7is
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.89it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 130.75it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 128.54it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 127.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 127.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 126.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 129.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 131.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 132.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 134.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 133.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 132.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 134.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 136.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.8
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.49188
wandb: sub_train_loss 1.39252
wandb:       test_acc 0.467
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run eager-sweep-527 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tg88l7is
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233328-tg88l7is/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ug69cl9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233340-5ug69cl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-528
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ug69cl9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.37it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 138.67it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 136.96it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 136.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 136.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 139.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 140.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 142.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 144.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 140.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 137.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 136.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 135.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.796
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.50148
wandb: sub_train_loss 1.42796
wandb:       test_acc 0.447
wandb:      valid_acc 0.448
wandb: 
wandb: üöÄ View run bright-sweep-528 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ug69cl9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233340-5ug69cl9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fdxgk0n3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233354-fdxgk0n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-529
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdxgk0n3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 282.99it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 282.28it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 279.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 273.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 281.85it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 284.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 281.38it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 282.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 281.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 278.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 280.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.222
wandb:  sub_train_acc 0.18427
wandb: sub_train_loss 1.16485
wandb:       test_acc 0.19
wandb:      valid_acc 0.186
wandb: 
wandb: üöÄ View run wobbly-sweep-529 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fdxgk0n3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233354-fdxgk0n3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 10ywmptu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233409-10ywmptu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-530
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/10ywmptu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 194.55it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 210.21it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 224.67it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 238.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 251.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 261.75it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 262.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 249.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 236.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 235.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 234.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 238.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.214
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.18316
wandb: sub_train_loss 1.16455
wandb:       test_acc 0.19
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run easy-sweep-530 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/10ywmptu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233409-10ywmptu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sdkpx7hj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233425-sdkpx7hj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-531
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sdkpx7hj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 249.69it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 270.85it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 275.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 279.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 288.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 296.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 300.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 300.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 301.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 303.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 294.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.233
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.18205
wandb: sub_train_loss 1.34559
wandb:       test_acc 0.168
wandb:      valid_acc 0.156
wandb: 
wandb: üöÄ View run prime-sweep-531 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sdkpx7hj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233425-sdkpx7hj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1j9coogk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233442-1j9coogk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-532
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1j9coogk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 272.01it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:00, 278.46it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 289.75it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 295.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 279.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 263.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 270.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 271.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:00<00:00, 272.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 275.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.18944
wandb: sub_train_loss 1.34573
wandb:       test_acc 0.173
wandb:      valid_acc 0.16
wandb: 
wandb: üöÄ View run trim-sweep-532 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1j9coogk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233442-1j9coogk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pq067fg4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233456-pq067fg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-533
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pq067fg4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 279.63it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 291.58it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 276.83it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 278.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 277.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 279.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 284.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 272.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 273.49it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 283.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 280.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.301
wandb: best_valid_acc 0.326
wandb:  sub_train_acc 0.25406
wandb: sub_train_loss 1.41274
wandb:       test_acc 0.238
wandb:      valid_acc 0.248
wandb: 
wandb: üöÄ View run ruby-sweep-533 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pq067fg4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233456-pq067fg4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: la6l1nh6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233517-la6l1nh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-534
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/la6l1nh6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 260.50it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 262.51it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 277.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 283.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 283.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 281.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 281.31it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 281.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 286.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 292.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.322
wandb: best_valid_acc 0.35
wandb:  sub_train_acc 0.25295
wandb: sub_train_loss 1.41264
wandb:       test_acc 0.235
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run glowing-sweep-534 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/la6l1nh6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233517-la6l1nh6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q0doo95k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233531-q0doo95k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-535
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q0doo95k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 281.40it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 288.53it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 295.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 296.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 284.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 282.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 285.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 290.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:00<00:00, 291.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 285.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.267
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.28028
wandb: sub_train_loss 1.46603
wandb:       test_acc 0.268
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run whole-sweep-535 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q0doo95k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233531-q0doo95k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 65qyp0eh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233547-65qyp0eh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-536
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/65qyp0eh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 286.45it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:00, 293.00it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 299.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 300.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 302.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 300.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 298.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 292.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:00<00:00, 285.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 289.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.266
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.27733
wandb: sub_train_loss 1.46629
wandb:       test_acc 0.255
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run winter-sweep-536 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/65qyp0eh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233547-65qyp0eh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rej67v8x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233603-rej67v8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-537
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rej67v8x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 285.79it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 298.08it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 310.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 317.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 316.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 316.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:00<00:00, 315.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 314.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 302.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 306.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.486
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.44904
wandb: sub_train_loss 1.50899
wandb:       test_acc 0.477
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run dandy-sweep-537 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rej67v8x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233603-rej67v8x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3eql743g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233617-3eql743g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-538
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3eql743g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 314.33it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:00, 323.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 325.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 325.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 317.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 321.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:00<00:00, 319.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:00<00:00, 321.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:00<00:00, 322.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 321.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.479
wandb: best_valid_acc 0.476
wandb:  sub_train_acc 0.45089
wandb: sub_train_loss 1.50801
wandb:       test_acc 0.482
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run crimson-sweep-538 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3eql743g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233617-3eql743g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: frwow9py with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233633-frwow9py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-539
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/frwow9py
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 318.41it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:00, 320.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 319.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 318.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 321.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 321.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 318.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 315.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:00<00:00, 312.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 315.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.46603
wandb: sub_train_loss 1.57071
wandb:       test_acc 0.463
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run wild-sweep-539 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/frwow9py
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233633-frwow9py/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o4416qu9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233649-o4416qu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-540
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o4416qu9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 281.67it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 293.49it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 296.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 297.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 297.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 298.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 291.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 285.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:00<00:00, 260.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 253.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.577
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.46861
wandb: sub_train_loss 1.57017
wandb:       test_acc 0.469
wandb:      valid_acc 0.468
wandb: 
wandb: üöÄ View run sleek-sweep-540 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o4416qu9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233649-o4416qu9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ynw5j1e2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233704-ynw5j1e2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-541
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ynw5j1e2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 253.67it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 256.58it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 252.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 256.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 260.70it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 264.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 271.91it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 279.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 277.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 281.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 272.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.723
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.68242
wandb: sub_train_loss 1.59355
wandb:       test_acc 0.671
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run playful-sweep-541 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ynw5j1e2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233704-ynw5j1e2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pu8bibpt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233719-pu8bibpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-542
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pu8bibpt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.38it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 161.04it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 158.18it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 156.45it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 150.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 156.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 147.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 149.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 158.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 172.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 201.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 228.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 239.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 252.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 195.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.719
wandb: best_valid_acc 0.716
wandb:  sub_train_acc 0.66433
wandb: sub_train_loss 1.59313
wandb:       test_acc 0.668
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run quiet-sweep-542 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pu8bibpt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233719-pu8bibpt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jxl8q2ul with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233735-jxl8q2ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-543
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxl8q2ul
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 293.69it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 288.58it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 290.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 291.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 293.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 290.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 290.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 288.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 285.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 282.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.743
wandb: best_valid_acc 0.734
wandb:  sub_train_acc 0.65251
wandb: sub_train_loss 1.60009
wandb:       test_acc 0.671
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run earnest-sweep-543 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jxl8q2ul
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233735-jxl8q2ul/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: njhxdhm5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233755-njhxdhm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-544
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/njhxdhm5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 28/300 [00:00<00:00, 273.17it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:00, 276.89it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 287.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 281.63it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 277.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 270.25it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 270.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 277.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:00<00:00, 273.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 277.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.686
wandb: best_valid_acc 0.662
wandb:  sub_train_acc 0.67061
wandb: sub_train_loss 1.59891
wandb:       test_acc 0.681
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run comic-sweep-544 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/njhxdhm5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233755-njhxdhm5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x1z8a1qd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233808-x1z8a1qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-545
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x1z8a1qd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.65it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.63it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 179.10it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 179.05it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 181.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 188.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 191.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 188.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 186.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 186.45it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 191.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 192.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 191.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 192.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 191.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.28
wandb: best_valid_acc 0.286
wandb:  sub_train_acc 0.28213
wandb: sub_train_loss 0.0
wandb:       test_acc 0.28
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run misunderstood-sweep-545 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x1z8a1qd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233808-x1z8a1qd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8ttounmk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233823-8ttounmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-546
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8ttounmk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 183.62it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 181.04it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 182.58it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 185.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 192.74it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 197.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 202.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 206.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 207.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 208.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 208.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 207.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 205.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 200.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 199.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.303
wandb: best_valid_acc 0.298
wandb:  sub_train_acc 0.28545
wandb: sub_train_loss 0.0
wandb:       test_acc 0.304
wandb:      valid_acc 0.298
wandb: 
wandb: üöÄ View run upbeat-sweep-546 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8ttounmk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233823-8ttounmk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c15hveih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233839-c15hveih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-547
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c15hveih
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.87it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 184.31it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 191.25it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 197.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 198.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 198.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 190.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 188.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 192.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 197.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 193.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 176.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 174.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 182.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.55
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.36595
wandb: sub_train_loss 0.00108
wandb:       test_acc 0.408
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run sandy-sweep-547 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c15hveih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233839-c15hveih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mj1d0gyj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233856-mj1d0gyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-548
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mj1d0gyj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.90it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 188.77it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 188.19it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 185.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 185.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 184.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 184.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 184.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 185.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 187.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 189.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 192.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 192.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 191.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 186.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.675
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.42393
wandb: sub_train_loss 0.00039
wandb:       test_acc 0.518
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run fiery-sweep-548 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mj1d0gyj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233856-mj1d0gyj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6ddd0n05 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233911-6ddd0n05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-549
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6ddd0n05
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 166.18it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 167.14it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 173.54it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 173.91it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 178.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 178.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 176.86it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 181.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 184.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 186.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 188.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 185.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 185.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 185.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 186.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.721
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.51588
wandb: sub_train_loss 0.00827
wandb:       test_acc 0.639
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run lemon-sweep-549 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6ddd0n05
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233911-6ddd0n05/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h4ouhhui with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233928-h4ouhhui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-550
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h4ouhhui
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.16it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.71it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 176.15it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 175.61it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 176.07it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 178.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 185.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 190.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 194.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 196.45it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 198.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 195.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 194.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 195.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 195.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.682
wandb: best_valid_acc 0.688
wandb:  sub_train_acc 0.53176
wandb: sub_train_loss 0.01012
wandb:       test_acc 0.656
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run clear-sweep-550 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h4ouhhui
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233928-h4ouhhui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uio0d4nc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_233950-uio0d4nc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-551
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uio0d4nc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.63it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 181.77it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 184.87it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 186.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 188.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 189.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 190.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 190.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 179.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 178.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 173.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 176.47it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 174.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 169.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 175.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.022 MB of 0.023 MB uploadedwandb: / 0.022 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.711
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.58013
wandb: sub_train_loss 0.00736
wandb:       test_acc 0.669
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run sage-sweep-551 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uio0d4nc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_233950-uio0d4nc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: amlj0ge8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234002-amlj0ge8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-552
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/amlj0ge8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.94it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 162.18it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 166.57it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 170.89it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 177.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 180.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 181.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 176.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 177.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 179.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 181.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 182.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 183.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 186.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 186.84it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 185.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.737
wandb: best_valid_acc 0.726
wandb:  sub_train_acc 0.57349
wandb: sub_train_loss 0.00972
wandb:       test_acc 0.653
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run flowing-sweep-552 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/amlj0ge8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234002-amlj0ge8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oguy7a2g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234022-oguy7a2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-553
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oguy7a2g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 199.91it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 195.48it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 194.04it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 192.90it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 190.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 186.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 185.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 187.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 187.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 187.09it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 185.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 184.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 181.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 185.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 189.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.781
wandb: best_valid_acc 0.758
wandb:  sub_train_acc 0.66137
wandb: sub_train_loss 0.01522
wandb:       test_acc 0.743
wandb:      valid_acc 0.752
wandb: 
wandb: üöÄ View run sparkling-sweep-553 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oguy7a2g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234022-oguy7a2g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w1xhcov7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234043-w1xhcov7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-554
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w1xhcov7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.24it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 169.60it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 168.31it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 171.94it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 171.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 172.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 173.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 174.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 178.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 182.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 182.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 183.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 185.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 187.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 188.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 185.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.785
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.66396
wandb: sub_train_loss 0.00511
wandb:       test_acc 0.768
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run vivid-sweep-554 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w1xhcov7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234043-w1xhcov7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4vzoi8ps with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234057-4vzoi8ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-555
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4vzoi8ps
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 169.81it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 172.75it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 169.98it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 165.56it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 161.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 158.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 159.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 169.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 177.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 182.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 187.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 187.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 188.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 189.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 186.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 182.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.795
wandb: best_valid_acc 0.78
wandb:  sub_train_acc 0.74298
wandb: sub_train_loss 0.02644
wandb:       test_acc 0.793
wandb:      valid_acc 0.78
wandb: 
wandb: üöÄ View run northern-sweep-555 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4vzoi8ps
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234057-4vzoi8ps/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sfakxww9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234119-sfakxww9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-556
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sfakxww9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 196.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.99it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 190.59it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 193.88it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 196.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 195.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 197.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 200.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 199.64it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 199.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 194.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 186.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 183.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 182.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.816
wandb: best_valid_acc 0.798
wandb:  sub_train_acc 0.73892
wandb: sub_train_loss 0.01411
wandb:       test_acc 0.806
wandb:      valid_acc 0.782
wandb: 
wandb: üöÄ View run pleasant-sweep-556 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sfakxww9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234119-sfakxww9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zd7bhn39 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234137-zd7bhn39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-557
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zd7bhn39
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.01it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.17it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 157.43it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 154.53it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 147.95it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 146.98it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 144.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 141.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 139.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 138.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 135.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 137.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 142.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 140.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 132.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 128.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 130.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 131.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 135.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 135.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.811
wandb: best_valid_acc 0.8
wandb:  sub_train_acc 0.77511
wandb: sub_train_loss 0.02427
wandb:       test_acc 0.809
wandb:      valid_acc 0.778
wandb: 
wandb: üöÄ View run lucky-sweep-557 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zd7bhn39
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234137-zd7bhn39/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1lewz7hj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234153-1lewz7hj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-558
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1lewz7hj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.77it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 158.24it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 176.24it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 175.84it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 180.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 179.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 184.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 186.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 190.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 191.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 189.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 185.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 182.27it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 173.48it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 172.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.813
wandb: best_valid_acc 0.806
wandb:  sub_train_acc 0.6562
wandb: sub_train_loss 0.12722
wandb:       test_acc 0.652
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run elated-sweep-558 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1lewz7hj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234153-1lewz7hj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: di17uiyj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234215-di17uiyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-559
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/di17uiyj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.96it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 144.51it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 144.38it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 143.78it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 151.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 162.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 169.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 173.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 176.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 174.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 180.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 184.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 188.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 189.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 191.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 193.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.819
wandb: best_valid_acc 0.818
wandb:  sub_train_acc 0.80133
wandb: sub_train_loss 0.0435
wandb:       test_acc 0.781
wandb:      valid_acc 0.778
wandb: 
wandb: üöÄ View run grateful-sweep-559 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/di17uiyj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234215-di17uiyj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mg6cieme with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234228-mg6cieme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-560
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mg6cieme
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.35it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 148.53it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 149.70it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 153.61it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 154.94it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 151.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 151.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 155.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 158.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 157.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 154.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 154.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 157.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 158.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 162.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 169.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 172.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.815
wandb: best_valid_acc 0.804
wandb:  sub_train_acc 0.79357
wandb: sub_train_loss 0.0281
wandb:       test_acc 0.779
wandb:      valid_acc 0.772
wandb: 
wandb: üöÄ View run revived-sweep-560 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mg6cieme
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234228-mg6cieme/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ikus4hdc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234252-ikus4hdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-561
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ikus4hdc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.62it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.83it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.21it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 147.99it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 149.13it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 150.11it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 147.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 135.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 129.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 131.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 130.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 130.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 130.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 128.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 124.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 125.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 123.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 125.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 128.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 131.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.428
wandb: best_valid_acc 0.472
wandb:  sub_train_acc 0.20679
wandb: sub_train_loss 0.0
wandb:       test_acc 0.179
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run different-sweep-561 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ikus4hdc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234252-ikus4hdc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4izi9q84 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234308-4izi9q84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-562
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4izi9q84
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 137.15it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 126.90it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 127.41it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 131.35it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 133.50it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 133.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 129.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 136.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 137.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 139.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 140.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 141.23it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 141.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 140.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 143.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 146.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 147.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 147.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 148.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 145.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.485
wandb: best_valid_acc 0.526
wandb:  sub_train_acc 0.11152
wandb: sub_train_loss 0.0
wandb:       test_acc 0.073
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run chocolate-sweep-562 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4izi9q84
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234308-4izi9q84/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zzj8fx5w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234323-zzj8fx5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-563
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zzj8fx5w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.86it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 117.02it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.96it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 125.91it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 128.22it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 130.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 137.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 139.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 141.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 140.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 137.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 137.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 132.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 128.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 124.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 122.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 121.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 123.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 127.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 129.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 130.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.662
wandb: best_valid_acc 0.644
wandb:  sub_train_acc 0.35931
wandb: sub_train_loss 0.0
wandb:       test_acc 0.338
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run stellar-sweep-563 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zzj8fx5w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234323-zzj8fx5w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 16gvpf2o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234338-16gvpf2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-564
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/16gvpf2o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 122.03it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 127.19it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.29it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.71it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 130.21it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 127.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 119.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 120.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 119.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 125.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 127.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 127.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 129.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 130.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 132.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 132.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 132.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 134.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 136.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 137.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 137.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 130.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.475
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.16507
wandb: sub_train_loss 3e-05
wandb:       test_acc 0.116
wandb:      valid_acc 0.092
wandb: 
wandb: üöÄ View run youthful-sweep-564 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/16gvpf2o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234338-16gvpf2o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7s8h3vuk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234354-7s8h3vuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-565
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7s8h3vuk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.71it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.48it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.14it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 132.20it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 131.45it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 130.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 127.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 128.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 128.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 119.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 120.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 124.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 123.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 114.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 116.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 119.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 122.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 121.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 119.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 118.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 118.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 120.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.672
wandb: best_valid_acc 0.652
wandb:  sub_train_acc 0.45089
wandb: sub_train_loss 0.58458
wandb:       test_acc 0.422
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run radiant-sweep-565 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7s8h3vuk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234354-7s8h3vuk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8b7nghpv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234409-8b7nghpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-566
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8b7nghpv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 8/300 [00:00<00:03, 78.71it/s]  6%|‚ñå         | 17/300 [00:00<00:03, 80.68it/s]  9%|‚ñä         | 26/300 [00:00<00:03, 79.39it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 92.30it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 99.82it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 104.29it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 105.86it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 105.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 111.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 120.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 127.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 133.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 137.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 139.44it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 138.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 137.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 138.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 136.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 137.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 137.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 141.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 143.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 126.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.732
wandb: best_valid_acc 0.712
wandb:  sub_train_acc 0.44313
wandb: sub_train_loss 0.58642
wandb:       test_acc 0.529
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run warm-sweep-566 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8b7nghpv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234409-8b7nghpv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5mgf88jb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234424-5mgf88jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-567
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5mgf88jb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.86it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.83it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.04it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.30it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 134.05it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 136.73it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 137.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 139.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 139.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 129.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 130.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 130.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 120.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 120.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 121.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 121.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 120.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 123.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 124.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 127.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 129.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.675
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.33936
wandb: sub_train_loss 0.66191
wandb:       test_acc 0.303
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run brisk-sweep-567 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5mgf88jb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234424-5mgf88jb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ftl7uvs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234439-3ftl7uvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-568
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3ftl7uvs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 129.39it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 130.47it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 129.47it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 133.45it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 136.31it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 127.99it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 135.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 140.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 143.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 145.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 143.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 142.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 138.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 136.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 136.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 134.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 131.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 129.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 128.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 126.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 134.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.694
wandb: best_valid_acc 0.702
wandb:  sub_train_acc 0.54247
wandb: sub_train_loss 0.22682
wandb:       test_acc 0.594
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run hardy-sweep-568 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3ftl7uvs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234439-3ftl7uvs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mmw0s19z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234455-mmw0s19z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-569
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mmw0s19z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 107.60it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 115.81it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 116.89it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 109.10it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 111.77it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 113.30it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 108.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 114.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 118.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 123.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 126.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 128.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 131.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 133.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 134.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 135.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 134.08it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 131.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 132.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 132.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 134.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 134.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 126.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.766
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.37371
wandb: sub_train_loss 0.34404
wandb:       test_acc 0.298
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run whole-sweep-569 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mmw0s19z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234455-mmw0s19z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dkf7t46y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234514-dkf7t46y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-570
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dkf7t46y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.34it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 123.56it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 120.79it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 120.07it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 117.64it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 117.50it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 117.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 117.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 118.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 125.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 130.16it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 129.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 129.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 130.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 129.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 126.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 129.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 130.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 131.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 130.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 130.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 131.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 126.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.731
wandb: best_valid_acc 0.706
wandb:  sub_train_acc 0.44535
wandb: sub_train_loss 0.36453
wandb:       test_acc 0.463
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run divine-sweep-570 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dkf7t46y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234514-dkf7t46y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7r69roye with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234531-7r69roye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-571
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7r69roye
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.97it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.97it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.95it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 148.62it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 150.27it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 150.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 150.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 149.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 147.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 148.09it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 147.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 147.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 147.54it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 147.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 146.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 142.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 140.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 134.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 133.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.74
wandb:  sub_train_acc 0.5901
wandb: sub_train_loss 0.1895
wandb:       test_acc 0.594
wandb:      valid_acc 0.624
wandb: 
wandb: üöÄ View run decent-sweep-571 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7r69roye
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234531-7r69roye/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: agsrg946 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234547-agsrg946
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-572
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/agsrg946
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.77it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.13it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.11it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 148.99it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 149.58it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 148.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 149.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 149.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:01, 149.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 149.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 137.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 124.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 122.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 120.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 121.92it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 122.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 126.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 117.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 109.95it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 107.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 109.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÖ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.746
wandb:  sub_train_acc 0.56019
wandb: sub_train_loss 0.57517
wandb:       test_acc 0.572
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run devoted-sweep-572 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/agsrg946
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234547-agsrg946/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8eh59qjc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234603-8eh59qjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-573
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8eh59qjc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 134.98it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 139.71it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.27it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 119.71it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 111.83it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 108.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 114.68it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 121.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:01<00:01, 128.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 132.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 134.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 132.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 130.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 129.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 130.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 125.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 117.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 113.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 108.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 109.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 117.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.783
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.55761
wandb: sub_train_loss 0.40932
wandb:       test_acc 0.541
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run golden-sweep-573 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8eh59qjc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234603-8eh59qjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kmvm47u1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234621-kmvm47u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-574
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kmvm47u1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.36it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 119.85it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 114.23it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 115.12it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 117.81it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 119.59it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 121.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 124.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 126.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 128.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 126.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 127.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 126.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 124.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 124.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 123.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 122.98it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 122.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 119.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 118.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 118.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 114.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 104.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.808
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.40547
wandb: sub_train_loss 0.7422
wandb:       test_acc 0.42
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run curious-sweep-574 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/kmvm47u1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234621-kmvm47u1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sje9cgaj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234637-sje9cgaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-575
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sje9cgaj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.12it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.49it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 106.27it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 112.13it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 114.12it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 121.39it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 125.59it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 128.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 127.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 127.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 128.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 126.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 128.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 135.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 139.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 142.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 144.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 140.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 139.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 138.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 136.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.79
wandb: best_valid_acc 0.788
wandb:  sub_train_acc 0.64623
wandb: sub_train_loss 0.60286
wandb:       test_acc 0.648
wandb:      valid_acc 0.614
wandb: 
wandb: üöÄ View run curious-sweep-575 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/sje9cgaj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234637-sje9cgaj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oyqtk95c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234652-oyqtk95c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-576
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oyqtk95c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.45it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 134.96it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 133.28it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 134.07it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 135.47it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 139.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 138.97it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 137.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 137.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 140.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 141.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 137.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 140.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 137.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 133.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 110.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 96.60it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 95.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 95.75it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 96.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 97.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 96.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.803
wandb: best_valid_acc 0.794
wandb:  sub_train_acc 0.67097
wandb: sub_train_loss 0.46922
wandb:       test_acc 0.656
wandb:      valid_acc 0.648
wandb: 
wandb: üöÄ View run amber-sweep-576 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/oyqtk95c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234652-oyqtk95c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9j35vgoi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234707-9j35vgoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-577
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9j35vgoi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 326.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 342.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 346.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 350.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 351.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 349.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.203
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.20606
wandb: sub_train_loss 1.8562
wandb:       test_acc 0.201
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run different-sweep-577 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9j35vgoi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234707-9j35vgoi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4ygkb5vk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234722-4ygkb5vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-578
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4ygkb5vk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 368.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 376.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 374.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 369.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 367.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 369.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.125
wandb: best_valid_acc 0.14
wandb:  sub_train_acc 0.12297
wandb: sub_train_loss 1.86189
wandb:       test_acc 0.125
wandb:      valid_acc 0.14
wandb: 
wandb: üöÄ View run good-sweep-578 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4ygkb5vk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234722-4ygkb5vk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7ilmxqyu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234738-7ilmxqyu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-579
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7ilmxqyu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 344.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 355.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 357.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 355.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 351.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 351.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.283
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.19682
wandb: sub_train_loss 1.86935
wandb:       test_acc 0.189
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run legendary-sweep-579 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/7ilmxqyu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234738-7ilmxqyu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g9pq31dd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234753-g9pq31dd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-580
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g9pq31dd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:00, 330.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 346.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 349.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 354.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 357.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 353.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.174
wandb: best_valid_acc 0.204
wandb:  sub_train_acc 0.17541
wandb: sub_train_loss 1.8701
wandb:       test_acc 0.161
wandb:      valid_acc 0.18
wandb: 
wandb: üöÄ View run charmed-sweep-580 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g9pq31dd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234753-g9pq31dd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: begl38sa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234815-begl38sa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-581
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/begl38sa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 351.63it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 361.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 365.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 364.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 369.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 366.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.198
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.20679
wandb: sub_train_loss 1.87399
wandb:       test_acc 0.198
wandb:      valid_acc 0.218
wandb: 
wandb: üöÄ View run dutiful-sweep-581 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/begl38sa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234815-begl38sa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l0rqggmk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234831-l0rqggmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-582
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l0rqggmk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 325.21it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 330.01it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 333.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 323.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 305.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 304.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 313.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.214
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.22858
wandb: sub_train_loss 1.87268
wandb:       test_acc 0.214
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run cosmic-sweep-582 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l0rqggmk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234831-l0rqggmk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rrd814w5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234851-rrd814w5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-583
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rrd814w5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 326.23it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 353.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 357.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 362.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 364.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 360.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.258
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.26957
wandb: sub_train_loss 1.87568
wandb:       test_acc 0.259
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run exalted-sweep-583 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rrd814w5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234851-rrd814w5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c079fpty with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234913-c079fpty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-584
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c079fpty
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 340.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 340.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 299.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 294.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 293.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 277.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 289.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.25
wandb: best_valid_acc 0.264
wandb:  sub_train_acc 0.26366
wandb: sub_train_loss 1.87775
wandb:       test_acc 0.25
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run stilted-sweep-584 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/c079fpty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234913-c079fpty/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1k358ro9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234927-1k358ro9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-585
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1k358ro9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 368.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 368.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 359.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 329.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 304.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 315.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.422
wandb: best_valid_acc 0.404
wandb:  sub_train_acc 0.40583
wandb: sub_train_loss 1.87871
wandb:       test_acc 0.422
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run misunderstood-sweep-585 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1k358ro9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234927-1k358ro9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r3tiexv5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234943-r3tiexv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-586
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r3tiexv5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 315.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 304.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 309.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 268.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 251.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 267.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 277.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.442
wandb: best_valid_acc 0.458
wandb:  sub_train_acc 0.43058
wandb: sub_train_loss 1.87768
wandb:       test_acc 0.446
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run likely-sweep-586 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r3tiexv5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234943-r3tiexv5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bvsssenh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_234958-bvsssenh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-587
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bvsssenh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 366.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 363.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 309.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 319.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 320.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 326.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.337
wandb: best_valid_acc 0.332
wandb:  sub_train_acc 0.32681
wandb: sub_train_loss 1.88294
wandb:       test_acc 0.337
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run dashing-sweep-587 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bvsssenh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_234958-bvsssenh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ijl7gvqd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235019-ijl7gvqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-588
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ijl7gvqd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 289.06it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 299.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 312.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 310.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 307.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 308.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 308.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.482
wandb:  sub_train_acc 0.48486
wandb: sub_train_loss 1.88485
wandb:       test_acc 0.502
wandb:      valid_acc 0.482
wandb: 
wandb: üöÄ View run earthy-sweep-588 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ijl7gvqd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235019-ijl7gvqd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ndmj89rm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235034-ndmj89rm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-589
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ndmj89rm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 362.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 364.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 368.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 371.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 364.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 366.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.485
wandb: best_valid_acc 0.48
wandb:  sub_train_acc 0.48154
wandb: sub_train_loss 1.88545
wandb:       test_acc 0.483
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run curious-sweep-589 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ndmj89rm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235034-ndmj89rm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6b1luc2n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235049-6b1luc2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-590
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6b1luc2n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 315.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 324.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 335.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 346.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 347.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 343.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.329
wandb: best_valid_acc 0.33
wandb:  sub_train_acc 0.3534
wandb: sub_train_loss 1.88767
wandb:       test_acc 0.336
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run swept-sweep-590 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6b1luc2n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235049-6b1luc2n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zxjc7o80 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235105-zxjc7o80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-591
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zxjc7o80
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 343.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 339.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 330.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 332.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 335.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 337.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.658
wandb: best_valid_acc 0.682
wandb:  sub_train_acc 0.68131
wandb: sub_train_loss 1.88776
wandb:       test_acc 0.649
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run quiet-sweep-591 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/zxjc7o80
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235105-zxjc7o80/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yxumci5o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235120-yxumci5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-592
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yxumci5o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 314.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 307.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 304.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 304.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 302.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 296.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 299.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.617
wandb: best_valid_acc 0.634
wandb:  sub_train_acc 0.65288
wandb: sub_train_loss 1.88772
wandb:       test_acc 0.625
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run bumbling-sweep-592 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yxumci5o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235120-yxumci5o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w57i60pu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235132-w57i60pu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-593
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w57i60pu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 256.91it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 264.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 268.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 262.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 258.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:00<00:00, 261.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 267.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 260.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.19
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.17725
wandb: sub_train_loss 1.61969
wandb:       test_acc 0.188
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run eager-sweep-593 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w57i60pu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235132-w57i60pu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: au1xjfwj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235146-au1xjfwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-594
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/au1xjfwj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 210.96it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 206.49it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 197.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 204.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 207.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 215.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 225.68it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 229.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 207.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.224
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.17541
wandb: sub_train_loss 1.58455
wandb:       test_acc 0.193
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run resilient-sweep-594 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/au1xjfwj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235146-au1xjfwj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 57vakfvi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235201-57vakfvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-595
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/57vakfvi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.18it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.11it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 177.97it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 185.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 196.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 202.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 219.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 229.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 237.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 213.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.198
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.19719
wandb: sub_train_loss 1.61933
wandb:       test_acc 0.169
wandb:      valid_acc 0.16
wandb: 
wandb: üöÄ View run royal-sweep-595 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/57vakfvi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235201-57vakfvi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lxm4fkiq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235217-lxm4fkiq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-596
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lxm4fkiq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 261.32it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 269.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 270.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 273.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 277.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 271.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 269.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 270.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.079
wandb: best_valid_acc 0.066
wandb:  sub_train_acc 0.08641
wandb: sub_train_loss 1.66923
wandb:       test_acc 0.084
wandb:      valid_acc 0.066
wandb: 
wandb: üöÄ View run quiet-sweep-596 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lxm4fkiq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235217-lxm4fkiq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ew9iiig with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235232-5ew9iiig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-597
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ew9iiig
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 267.57it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 268.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 269.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 261.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 245.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 238.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 247.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 252.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.388
wandb: best_valid_acc 0.366
wandb:  sub_train_acc 0.37149
wandb: sub_train_loss 1.64168
wandb:       test_acc 0.318
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run peach-sweep-597 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ew9iiig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235232-5ew9iiig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f73f9egb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235248-f73f9egb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-598
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f73f9egb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 262.65it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 241.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 222.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 208.44it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 195.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 197.72it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 202.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 209.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 213.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.238
wandb: best_valid_acc 0.256
wandb:  sub_train_acc 0.22895
wandb: sub_train_loss 1.65881
wandb:       test_acc 0.203
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run dashing-sweep-598 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f73f9egb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235248-f73f9egb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3ma17b99 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235303-3ma17b99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-599
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3ma17b99
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 251.99it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 262.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 267.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 266.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 264.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 262.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 259.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.276
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.23043
wandb: sub_train_loss 1.67489
wandb:       test_acc 0.278
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run wild-sweep-599 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3ma17b99
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235303-3ma17b99/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: boyrar1r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235318-boyrar1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-600
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/boyrar1r
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 235.47it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 232.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 231.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 237.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 243.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 230.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 226.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 221.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 227.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.324
wandb:  sub_train_acc 0.23117
wandb: sub_train_loss 1.67677
wandb:       test_acc 0.294
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run flowing-sweep-600 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/boyrar1r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235318-boyrar1r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ye933r20 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235339-ye933r20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-601
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ye933r20
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 259.76it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 266.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 268.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 269.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 266.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 258.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 257.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 261.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.523
wandb: best_valid_acc 0.532
wandb:  sub_train_acc 0.38737
wandb: sub_train_loss 1.6589
wandb:       test_acc 0.529
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run dark-sweep-601 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ye933r20
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235339-ye933r20/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3f0n0hc9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235355-3f0n0hc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-602
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3f0n0hc9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 264.47it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 271.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 274.37it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 275.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 275.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 279.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 279.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 276.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.468
wandb: best_valid_acc 0.496
wandb:  sub_train_acc 0.43907
wandb: sub_train_loss 1.66477
wandb:       test_acc 0.468
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run deep-sweep-602 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3f0n0hc9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235355-3f0n0hc9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9txpw9vy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235410-9txpw9vy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-603
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9txpw9vy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 225.35it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 214.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 210.66it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 204.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 197.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 198.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 201.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 206.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 219.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 210.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.593
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.51957
wandb: sub_train_loss 1.72007
wandb:       test_acc 0.593
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run dainty-sweep-603 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9txpw9vy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235410-9txpw9vy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yaajy8lb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235425-yaajy8lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-604
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yaajy8lb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 281.11it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 278.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 269.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 267.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 259.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 252.36it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 250.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 257.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.526
wandb: best_valid_acc 0.532
wandb:  sub_train_acc 0.44424
wandb: sub_train_loss 1.70929
wandb:       test_acc 0.526
wandb:      valid_acc 0.532
wandb: 
wandb: üöÄ View run twilight-sweep-604 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yaajy8lb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235425-yaajy8lb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xdczu12r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235446-xdczu12r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-605
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xdczu12r
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 245.77it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 254.74it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 247.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 232.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 222.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 217.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 215.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 229.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 229.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.626
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.60229
wandb: sub_train_loss 1.6948
wandb:       test_acc 0.629
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run wobbly-sweep-605 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xdczu12r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235446-xdczu12r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ticjnij with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235501-5ticjnij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-606
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ticjnij
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 260.43it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 263.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 262.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 259.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 249.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 239.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 235.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 245.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.614
wandb: best_valid_acc 0.6
wandb:  sub_train_acc 0.58826
wandb: sub_train_loss 1.69643
wandb:       test_acc 0.614
wandb:      valid_acc 0.6
wandb: 
wandb: üöÄ View run comic-sweep-606 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5ticjnij
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235501-5ticjnij/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j19chedf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235520-j19chedf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-607
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j19chedf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 284.79it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 283.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 269.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 260.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 268.10it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 262.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 258.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 264.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.72
wandb:  sub_train_acc 0.74926
wandb: sub_train_loss 1.68505
wandb:       test_acc 0.745
wandb:      valid_acc 0.716
wandb: 
wandb: üöÄ View run vibrant-sweep-607 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/j19chedf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235520-j19chedf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xmgg3fd5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235531-xmgg3fd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-608
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xmgg3fd5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 263.56it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 267.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 263.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 261.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 262.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 266.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 272.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 268.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.747
wandb: best_valid_acc 0.744
wandb:  sub_train_acc 0.7644
wandb: sub_train_loss 1.68099
wandb:       test_acc 0.752
wandb:      valid_acc 0.742
wandb: 
wandb: üöÄ View run golden-sweep-608 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xmgg3fd5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235531-xmgg3fd5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2m6ikn6e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235546-2m6ikn6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-609
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2m6ikn6e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 212.01it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 216.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 211.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 212.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 213.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 213.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 215.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 215.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 219.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.131
wandb: best_valid_acc 0.146
wandb:  sub_train_acc 0.06832
wandb: sub_train_loss 1.30619
wandb:       test_acc 0.064
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run robust-sweep-609 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2m6ikn6e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235546-2m6ikn6e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gldceqdt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235602-gldceqdt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-610
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gldceqdt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 200.32it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 202.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 197.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 195.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 196.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 208.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 213.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 215.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 216.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 209.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.06684
wandb: sub_train_loss 1.27055
wandb:       test_acc 0.064
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run absurd-sweep-610 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gldceqdt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235602-gldceqdt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vgalgtrk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235617-vgalgtrk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-611
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vgalgtrk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.14it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 169.18it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 162.71it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 182.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 196.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 203.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 208.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 212.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 215.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 201.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.187
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.07164
wandb: sub_train_loss 1.46249
wandb:       test_acc 0.067
wandb:      valid_acc 0.058
wandb: 
wandb: üöÄ View run electric-sweep-611 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vgalgtrk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235617-vgalgtrk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wvwienth with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235632-wvwienth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-612
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wvwienth
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 212.03it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 214.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 211.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 203.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 203.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 206.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 210.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 213.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 216.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 211.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.184
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.07386
wandb: sub_train_loss 1.43522
wandb:       test_acc 0.067
wandb:      valid_acc 0.06
wandb: 
wandb: üöÄ View run fluent-sweep-612 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wvwienth
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235632-wvwienth/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5rnewr7g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235648-5rnewr7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-613
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5rnewr7g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.86it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 196.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 198.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 200.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 200.97it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 199.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 199.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 201.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 201.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 200.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.203
wandb: best_valid_acc 0.192
wandb:  sub_train_acc 0.33087
wandb: sub_train_loss 1.49982
wandb:       test_acc 0.203
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run ethereal-sweep-613 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5rnewr7g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235648-5rnewr7g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xfugy0oe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235703-xfugy0oe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-614
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfugy0oe
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.54it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 167.93it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 166.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 165.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 164.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 163.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 166.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 174.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 175.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 176.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 166.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.197
wandb: best_valid_acc 0.214
wandb:  sub_train_acc 0.15694
wandb: sub_train_loss 1.48938
wandb:       test_acc 0.199
wandb:      valid_acc 0.214
wandb: 
wandb: üöÄ View run wild-sweep-614 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xfugy0oe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235703-xfugy0oe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y73q89o6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235719-y73q89o6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-615
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y73q89o6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.85it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 211.00it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 212.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 214.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 215.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 214.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 215.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:00<00:00, 211.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 204.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 209.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.245
wandb: best_valid_acc 0.254
wandb:  sub_train_acc 0.20052
wandb: sub_train_loss 1.52571
wandb:       test_acc 0.256
wandb:      valid_acc 0.252
wandb: 
wandb: üöÄ View run chocolate-sweep-615 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y73q89o6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235719-y73q89o6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2fml08hv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235733-2fml08hv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-616
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2fml08hv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 195.71it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 207.03it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 214.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 217.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 216.55it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 218.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 218.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 216.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 216.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.25775
wandb: sub_train_loss 1.50188
wandb:       test_acc 0.276
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run rosy-sweep-616 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/2fml08hv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235733-2fml08hv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ai98ty00 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235749-ai98ty00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-617
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ai98ty00
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.57it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 201.06it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 168.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 163.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 179.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 189.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 188.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 193.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 196.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.5
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.37149
wandb: sub_train_loss 1.5513
wandb:       test_acc 0.487
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run visionary-sweep-617 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ai98ty00
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235749-ai98ty00/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jebl1mp1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235805-jebl1mp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-618
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jebl1mp1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.37it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 194.20it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 190.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 183.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 178.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 175.39it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 172.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 170.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 170.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 181.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.457
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.41137
wandb: sub_train_loss 1.51107
wandb:       test_acc 0.457
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run robust-sweep-618 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jebl1mp1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235805-jebl1mp1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1q3xri08 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235821-1q3xri08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-619
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1q3xri08
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 169.78it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 178.37it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 178.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 182.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 191.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 199.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 205.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 193.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 193.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 192.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.566
wandb: best_valid_acc 0.55
wandb:  sub_train_acc 0.45236
wandb: sub_train_loss 1.61464
wandb:       test_acc 0.568
wandb:      valid_acc 0.55
wandb: 
wandb: üöÄ View run sleek-sweep-619 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1q3xri08
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235821-1q3xri08/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yr85krwm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235833-yr85krwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-620
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yr85krwm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.95it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 208.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 206.38it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 205.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 205.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 206.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 204.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 205.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:00<00:00, 202.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.596
wandb: best_valid_acc 0.586
wandb:  sub_train_acc 0.54985
wandb: sub_train_loss 1.54649
wandb:       test_acc 0.591
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run celestial-sweep-620 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yr85krwm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235833-yr85krwm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: udyo8b9l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235848-udyo8b9l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-621
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/udyo8b9l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.78it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 199.91it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 189.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 187.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 182.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 180.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 178.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 180.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 184.67it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 187.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.538
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.50295
wandb: sub_train_loss 1.62349
wandb:       test_acc 0.538
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run confused-sweep-621 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/udyo8b9l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235848-udyo8b9l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pxty5ijw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235903-pxty5ijw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-622
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pxty5ijw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 191.67it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 191.41it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 184.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 183.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 183.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 182.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 178.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 173.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 171.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 175.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.496
wandb:  sub_train_acc 0.51662
wandb: sub_train_loss 1.52769
wandb:       test_acc 0.514
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run graceful-sweep-622 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pxty5ijw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235903-pxty5ijw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iy23kk23 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235918-iy23kk23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-623
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iy23kk23
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 201.40it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 187.28it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 183.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 167.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 155.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 153.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 164.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 163.14it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 167.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 168.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.767
wandb: best_valid_acc 0.756
wandb:  sub_train_acc 0.76846
wandb: sub_train_loss 1.49512
wandb:       test_acc 0.762
wandb:      valid_acc 0.746
wandb: 
wandb: üöÄ View run trim-sweep-623 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iy23kk23
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235918-iy23kk23/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tyvk2ly8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235930-tyvk2ly8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-624
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tyvk2ly8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.69it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 149.46it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 128.17it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 125.78it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 125.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 129.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 133.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 137.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 138.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 145.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 152.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 164.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.779
wandb: best_valid_acc 0.8
wandb:  sub_train_acc 0.73966
wandb: sub_train_loss 1.48617
wandb:       test_acc 0.711
wandb:      valid_acc 0.73
wandb: 
wandb: üöÄ View run icy-sweep-624 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tyvk2ly8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235930-tyvk2ly8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tuprd3kd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235944-tuprd3kd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-625
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tuprd3kd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 305.50it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 305.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 317.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 325.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 331.81it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 337.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:00<00:00, 346.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:00<00:00, 351.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 339.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.184
wandb: best_valid_acc 0.214
wandb:  sub_train_acc 0.1935
wandb: sub_train_loss 1.8048
wandb:       test_acc 0.193
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run lively-sweep-625 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tuprd3kd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235944-tuprd3kd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u7cm7qd2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240828_235959-u7cm7qd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-626
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u7cm7qd2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:00, 362.52it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 361.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 360.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 361.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 349.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 350.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 358.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:00<00:00, 350.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 354.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.271
wandb: best_valid_acc 0.288
wandb:  sub_train_acc 0.22083
wandb: sub_train_loss 1.80926
wandb:       test_acc 0.219
wandb:      valid_acc 0.242
wandb: 
wandb: üöÄ View run stilted-sweep-626 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/u7cm7qd2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240828_235959-u7cm7qd2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xj2b8qri with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000022-xj2b8qri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-627
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xj2b8qri
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 287.63it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:00, 313.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 325.30it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 334.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 344.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 352.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 355.60it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:00<00:00, 357.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 345.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.185
wandb: best_valid_acc 0.204
wandb:  sub_train_acc 0.16691
wandb: sub_train_loss 1.82777
wandb:       test_acc 0.185
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run chocolate-sweep-627 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xj2b8qri
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000022-xj2b8qri/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: feim8q1g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000036-feim8q1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-628
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/feim8q1g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 312.12it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 313.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 311.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 320.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 301.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 303.50it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 315.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 325.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 333.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 320.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.237
wandb: best_valid_acc 0.224
wandb:  sub_train_acc 0.18538
wandb: sub_train_loss 1.82244
wandb:       test_acc 0.198
wandb:      valid_acc 0.204
wandb: 
wandb: üöÄ View run absurd-sweep-628 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/feim8q1g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000036-feim8q1g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3c7uq0hd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000058-3c7uq0hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-629
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3c7uq0hd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 346.78it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 356.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 354.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 352.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 351.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 355.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 358.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:00<00:00, 359.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 356.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.254
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.24926
wandb: sub_train_loss 1.83074
wandb:       test_acc 0.265
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run fearless-sweep-629 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3c7uq0hd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000058-3c7uq0hd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6k3aobuh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000113-6k3aobuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-630
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6k3aobuh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 342.81it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:00, 345.64it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 349.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 351.93it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 351.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 352.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:00<00:00, 353.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:00<00:00, 346.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 348.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.302
wandb:  sub_train_acc 0.29838
wandb: sub_train_loss 1.83041
wandb:       test_acc 0.294
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run ethereal-sweep-630 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6k3aobuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000113-6k3aobuh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bq4avtc4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000129-bq4avtc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-631
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bq4avtc4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 328.35it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:00, 329.86it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 332.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 336.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 341.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 346.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 347.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:00<00:00, 341.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 340.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.295
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.27622
wandb: sub_train_loss 1.83824
wandb:       test_acc 0.295
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run misty-sweep-631 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bq4avtc4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000129-bq4avtc4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1427c5g8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000144-1427c5g8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-632
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1427c5g8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 328.16it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:00, 326.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 328.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 332.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 334.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 334.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 328.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:00<00:00, 322.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 324.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.214
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.20975
wandb: sub_train_loss 1.83836
wandb:       test_acc 0.214
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run glamorous-sweep-632 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1427c5g8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000144-1427c5g8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e8zzwvpo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000156-e8zzwvpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-633
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e8zzwvpo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:00, 329.20it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 331.20it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 328.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 328.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 326.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 322.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:00<00:00, 326.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:00<00:00, 333.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 331.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.444
wandb: best_valid_acc 0.462
wandb:  sub_train_acc 0.41285
wandb: sub_train_loss 1.84195
wandb:       test_acc 0.448
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run proud-sweep-633 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e8zzwvpo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000156-e8zzwvpo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g3ecnxxr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000215-g3ecnxxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-634
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g3ecnxxr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 33/300 [00:00<00:00, 327.89it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:00, 340.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 341.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 329.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 332.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 332.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:00<00:00, 335.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:00<00:00, 327.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 332.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.34
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.31647
wandb: sub_train_loss 1.84124
wandb:       test_acc 0.34
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run icy-sweep-634 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/g3ecnxxr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000215-g3ecnxxr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3okxblpc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000230-3okxblpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-635
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3okxblpc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 353.34it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 351.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 347.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 345.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 354.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 361.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 364.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:00<00:00, 366.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 359.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.516
wandb: best_valid_acc 0.486
wandb:  sub_train_acc 0.48523
wandb: sub_train_loss 1.84955
wandb:       test_acc 0.519
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run sparkling-sweep-635 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3okxblpc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000230-3okxblpc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xq0ert4z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000252-xq0ert4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-636
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xq0ert4z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 316.79it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 299.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:00, 321.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 329.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 338.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 338.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 333.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:00<00:00, 335.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 333.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.511
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.49594
wandb: sub_train_loss 1.85033
wandb:       test_acc 0.52
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run devout-sweep-636 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xq0ert4z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000252-xq0ert4z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w5kifolv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000307-w5kifolv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-637
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w5kifolv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 298.67it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 287.18it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 292.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 295.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 292.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 292.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 293.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:00<00:00, 295.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:00<00:00, 304.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 302.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.413
wandb: best_valid_acc 0.436
wandb:  sub_train_acc 0.42614
wandb: sub_train_loss 1.85484
wandb:       test_acc 0.434
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run fast-sweep-637 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w5kifolv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000307-w5kifolv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: na6h80jc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000328-na6h80jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-638
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na6h80jc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:00, 358.26it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 351.93it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 352.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 355.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 355.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 354.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:00<00:00, 349.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:00<00:00, 349.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 352.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.479
wandb: best_valid_acc 0.472
wandb:  sub_train_acc 0.48264
wandb: sub_train_loss 1.85408
wandb:       test_acc 0.479
wandb:      valid_acc 0.472
wandb: 
wandb: üöÄ View run fresh-sweep-638 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/na6h80jc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000328-na6h80jc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wh9ofbx3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000344-wh9ofbx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-639
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wh9ofbx3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:00, 345.75it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 349.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:00, 339.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 338.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 336.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 344.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:00<00:00, 349.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:00<00:00, 354.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 347.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.656
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.67541
wandb: sub_train_loss 1.85581
wandb:       test_acc 0.661
wandb:      valid_acc 0.656
wandb: 
wandb: üöÄ View run denim-sweep-639 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wh9ofbx3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000344-wh9ofbx3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wrmhqkix with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000358-wrmhqkix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-640
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wrmhqkix
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 300.35it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 276.73it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 275.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 274.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 283.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 293.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:00<00:00, 301.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:00<00:00, 307.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:00<00:00, 313.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 300.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.638
wandb: best_valid_acc 0.666
wandb:  sub_train_acc 0.6562
wandb: sub_train_loss 1.85504
wandb:       test_acc 0.612
wandb:      valid_acc 0.658
wandb: 
wandb: üöÄ View run good-sweep-640 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wrmhqkix
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000358-wrmhqkix/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o1ta9oig with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000422-o1ta9oig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-641
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o1ta9oig
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 282.77it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 283.31it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 283.19it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 282.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 279.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 275.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 271.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:00<00:00, 263.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:00<00:00, 258.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 257.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 267.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.191
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.12223
wandb: sub_train_loss 1.28412
wandb:       test_acc 0.154
wandb:      valid_acc 0.158
wandb: 
wandb: üöÄ View run snowy-sweep-641 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/o1ta9oig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000422-o1ta9oig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rfg3cy13 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000438-rfg3cy13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-642
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rfg3cy13
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 265.08it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 246.75it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:00, 226.55it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 237.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 240.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 243.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 242.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 245.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 249.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 253.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 253.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 246.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.14
wandb: best_valid_acc 0.128
wandb:  sub_train_acc 0.08309
wandb: sub_train_loss 1.26863
wandb:       test_acc 0.106
wandb:      valid_acc 0.1
wandb: 
wandb: üöÄ View run glorious-sweep-642 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rfg3cy13
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000438-rfg3cy13/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rsszfpwn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000452-rsszfpwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-643
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rsszfpwn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 249.96it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 211.44it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 220.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 232.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 239.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 241.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 243.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 248.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 255.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 256.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 255.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 243.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.319
wandb: best_valid_acc 0.316
wandb:  sub_train_acc 0.13257
wandb: sub_train_loss 1.30167
wandb:       test_acc 0.185
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run gentle-sweep-643 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rsszfpwn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000452-rsszfpwn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pk4hqwk9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000508-pk4hqwk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-644
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pk4hqwk9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 245.19it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 236.60it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 231.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 230.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 227.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 228.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 221.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 223.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 229.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 235.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 236.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 236.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 231.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.256
wandb: best_valid_acc 0.26
wandb:  sub_train_acc 0.15325
wandb: sub_train_loss 1.39107
wandb:       test_acc 0.157
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run pious-sweep-644 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pk4hqwk9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000508-pk4hqwk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: slk4720w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000529-slk4720w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-645
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/slk4720w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 246.96it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:00, 250.72it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 247.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 245.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 243.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 241.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 241.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:00<00:00, 240.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 238.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 238.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 240.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 241.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.257
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.24668
wandb: sub_train_loss 1.3032
wandb:       test_acc 0.257
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run worldly-sweep-645 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/slk4720w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000529-slk4720w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iugo5naf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000543-iugo5naf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-646
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iugo5naf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 257.28it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 265.00it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 265.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:00, 260.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 255.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 256.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 259.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 263.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 259.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 255.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 255.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 258.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.248
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.31278
wandb: sub_train_loss 1.35077
wandb:       test_acc 0.248
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run soft-sweep-646 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iugo5naf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000543-iugo5naf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ips6ao2k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000559-ips6ao2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-647
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ips6ao2k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñâ         | 29/300 [00:00<00:00, 285.93it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:00, 285.43it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:00, 279.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 278.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 278.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 276.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 277.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 268.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 256.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 252.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 264.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.317
wandb: best_valid_acc 0.346
wandb:  sub_train_acc 0.28804
wandb: sub_train_loss 1.38039
wandb:       test_acc 0.318
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run cool-sweep-647 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ips6ao2k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000559-ips6ao2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: arkl5j88 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000615-arkl5j88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-648
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/arkl5j88
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 290.86it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 287.12it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 277.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 279.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 280.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 282.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 278.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:00<00:00, 277.19it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 276.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 271.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.356
wandb: best_valid_acc 0.376
wandb:  sub_train_acc 0.30798
wandb: sub_train_loss 1.37394
wandb:       test_acc 0.356
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run solar-sweep-648 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/arkl5j88
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000615-arkl5j88/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yh7q9si2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000629-yh7q9si2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-649
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yh7q9si2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 258.63it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 250.05it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:00, 245.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 244.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 242.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 247.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 251.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 257.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 261.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 267.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 268.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 257.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.488
wandb: best_valid_acc 0.498
wandb:  sub_train_acc 0.35968
wandb: sub_train_loss 1.42396
wandb:       test_acc 0.491
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run honest-sweep-649 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/yh7q9si2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000629-yh7q9si2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ndf2rey8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000645-ndf2rey8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-650
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ndf2rey8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 244.77it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 268.33it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 275.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 275.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 272.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 275.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 273.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:00<00:00, 276.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 279.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 280.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.504
wandb: best_valid_acc 0.508
wandb:  sub_train_acc 0.48191
wandb: sub_train_loss 1.45098
wandb:       test_acc 0.504
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run soft-sweep-650 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ndf2rey8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000645-ndf2rey8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tbubv4hz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000706-tbubv4hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-651
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tbubv4hz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 267.31it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:00, 279.76it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:00, 276.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:00, 274.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 277.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 279.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:00<00:00, 276.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:00<00:00, 274.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:00<00:00, 267.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 263.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 269.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.574
wandb: best_valid_acc 0.564
wandb:  sub_train_acc 0.52474
wandb: sub_train_loss 1.48574
wandb:       test_acc 0.575
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run volcanic-sweep-651 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tbubv4hz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000706-tbubv4hz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 92rv0gky with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000721-92rv0gky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-652
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/92rv0gky
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.34it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 237.29it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 244.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 246.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 249.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 256.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 252.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 250.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:00<00:00, 247.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 249.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 251.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 249.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.54
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.48264
wandb: sub_train_loss 1.43615
wandb:       test_acc 0.546
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run volcanic-sweep-652 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/92rv0gky
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000721-92rv0gky/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 69gm9jcp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000737-69gm9jcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-653
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/69gm9jcp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 234.61it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 233.01it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:00, 241.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:00, 240.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:00, 241.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 242.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 239.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 249.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 257.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 262.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 267.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 252.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.631
wandb: best_valid_acc 0.61
wandb:  sub_train_acc 0.6178
wandb: sub_train_loss 1.46526
wandb:       test_acc 0.631
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run devout-sweep-653 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/69gm9jcp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000737-69gm9jcp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bn17qgaj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000757-bn17qgaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-654
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bn17qgaj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 263.28it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 268.08it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:00, 263.31it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 261.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 258.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 255.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 250.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 251.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:00<00:00, 251.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 239.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 197.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 232.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.627
wandb: best_valid_acc 0.626
wandb:  sub_train_acc 0.60746
wandb: sub_train_loss 1.45798
wandb:       test_acc 0.627
wandb:      valid_acc 0.626
wandb: 
wandb: üöÄ View run usual-sweep-654 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bn17qgaj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000757-bn17qgaj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: l9v5pi09 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000821-l9v5pi09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-655
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l9v5pi09
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 255.68it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:00, 249.31it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 243.69it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:00, 242.93it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 236.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 240.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 244.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:00<00:00, 250.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:00<00:00, 251.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 256.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 266.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 253.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.766
wandb: best_valid_acc 0.778
wandb:  sub_train_acc 0.78471
wandb: sub_train_loss 1.4078
wandb:       test_acc 0.771
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run helpful-sweep-655 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l9v5pi09
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000821-l9v5pi09/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: erfwe91o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000837-erfwe91o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-656
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/erfwe91o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 251.54it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 246.04it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:00, 235.09it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:00, 225.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 214.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 215.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 216.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 223.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 222.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 217.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 216.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 214.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.755
wandb: best_valid_acc 0.784
wandb:  sub_train_acc 0.78287
wandb: sub_train_loss 1.40836
wandb:       test_acc 0.758
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run logical-sweep-656 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/erfwe91o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000837-erfwe91o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 06guxiu2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000853-06guxiu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-657
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/06guxiu2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 213.45it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.78it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 216.38it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 215.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 212.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 207.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 203.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 203.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 205.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 207.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 209.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 207.94it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 203.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 206.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.17356
wandb: sub_train_loss 0.8687
wandb:       test_acc 0.1
wandb:      valid_acc 0.098
wandb: 
wandb: üöÄ View run generous-sweep-657 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/06guxiu2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000853-06guxiu2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5xtywqb9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000907-5xtywqb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-658
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5xtywqb9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.70it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 180.97it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 173.33it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 165.42it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 169.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 173.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 171.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 173.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 180.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 186.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 187.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 188.88it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 193.03it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 192.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 184.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.176
wandb: best_valid_acc 0.206
wandb:  sub_train_acc 0.12666
wandb: sub_train_loss 0.89311
wandb:       test_acc 0.115
wandb:      valid_acc 0.114
wandb: 
wandb: üöÄ View run bright-sweep-658 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5xtywqb9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000907-5xtywqb9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fc2flwas with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000923-fc2flwas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-659
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fc2flwas
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.73it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 199.65it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 198.62it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 192.27it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 179.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 166.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 162.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 163.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 166.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 169.07it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 169.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 171.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 180.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 188.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 191.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.222
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.33641
wandb: sub_train_loss 0.98685
wandb:       test_acc 0.204
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run curious-sweep-659 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fc2flwas
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000923-fc2flwas/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q42rt2t4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000938-q42rt2t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-660
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q42rt2t4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.06it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 154.78it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 164.52it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 169.81it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 173.72it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 171.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 177.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 180.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 176.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 173.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 172.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 174.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 166.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 153.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 149.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 150.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.249
wandb: best_valid_acc 0.244
wandb:  sub_train_acc 0.22821
wandb: sub_train_loss 0.94271
wandb:       test_acc 0.249
wandb:      valid_acc 0.244
wandb: 
wandb: üöÄ View run icy-sweep-660 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/q42rt2t4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000938-q42rt2t4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tb5oaduw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_000954-tb5oaduw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-661
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tb5oaduw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 194.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 196.73it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 195.88it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 194.02it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 196.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 192.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 191.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 190.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 186.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 186.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 184.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 182.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 174.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 163.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 156.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.271
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.34564
wandb: sub_train_loss 1.04889
wandb:       test_acc 0.271
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run amber-sweep-661 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tb5oaduw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_000954-tb5oaduw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lvxlea5s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001010-lvxlea5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-662
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lvxlea5s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.29it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 170.83it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 177.57it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 174.65it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 178.62it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 176.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 171.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 161.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 168.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 172.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 173.97it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 176.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 176.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 176.09it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 173.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 175.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.261
wandb: best_valid_acc 0.27
wandb:  sub_train_acc 0.37075
wandb: sub_train_loss 0.99568
wandb:       test_acc 0.261
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run crisp-sweep-662 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/lvxlea5s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001010-lvxlea5s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ao1f6xjc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001027-ao1f6xjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-663
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ao1f6xjc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 191.24it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 189.49it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 196.43it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 199.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:00, 201.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:00, 201.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 203.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 197.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 195.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 195.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 196.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 197.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 196.48it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 195.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 196.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.426
wandb:  sub_train_acc 0.29653
wandb: sub_train_loss 0.94364
wandb:       test_acc 0.419
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run frosty-sweep-663 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ao1f6xjc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001027-ao1f6xjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ws9avh2b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001048-ws9avh2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-664
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ws9avh2b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.82it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 175.52it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 176.93it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 180.96it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 181.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 177.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 172.17it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 166.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 166.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 168.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 173.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 180.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 184.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 187.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 190.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 179.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.36
wandb: best_valid_acc 0.39
wandb:  sub_train_acc 0.2921
wandb: sub_train_loss 0.93964
wandb:       test_acc 0.36
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run smooth-sweep-664 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ws9avh2b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001048-ws9avh2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rfq5uxnd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001102-rfq5uxnd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-665
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rfq5uxnd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.32it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 183.75it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 171.85it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 172.74it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 181.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 187.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 192.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 193.49it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 195.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 197.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 186.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 192.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 193.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 200.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.594
wandb: best_valid_acc 0.546
wandb:  sub_train_acc 0.41507
wandb: sub_train_loss 0.97644
wandb:       test_acc 0.595
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run clean-sweep-665 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rfq5uxnd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001102-rfq5uxnd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mavzwo0m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001117-mavzwo0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-666
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mavzwo0m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 204.82it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 188.78it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 164.70it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 150.04it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 130.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 126.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 137.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 153.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 165.51it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 172.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 170.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 165.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 163.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 155.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 154.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 158.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 157.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.543
wandb: best_valid_acc 0.52
wandb:  sub_train_acc 0.46713
wandb: sub_train_loss 1.01105
wandb:       test_acc 0.543
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run sunny-sweep-666 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mavzwo0m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001117-mavzwo0m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tcdakl5b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001132-tcdakl5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-667
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tcdakl5b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.81it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.89it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.14it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 181.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 170.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 166.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 170.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 173.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 173.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 175.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 182.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 181.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 182.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 153.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 136.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 126.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.604
wandb: best_valid_acc 0.606
wandb:  sub_train_acc 0.58013
wandb: sub_train_loss 0.81832
wandb:       test_acc 0.614
wandb:      valid_acc 0.604
wandb: 
wandb: üöÄ View run cerulean-sweep-667 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tcdakl5b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001132-tcdakl5b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tfbqv0hi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001148-tfbqv0hi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-668
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tfbqv0hi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 176.24it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 173.52it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 174.16it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 162.17it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 179.22it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 189.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 195.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 199.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 204.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 206.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 198.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 195.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 196.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 198.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.616
wandb: best_valid_acc 0.594
wandb:  sub_train_acc 0.55835
wandb: sub_train_loss 0.86139
wandb:       test_acc 0.616
wandb:      valid_acc 0.594
wandb: 
wandb: üöÄ View run noble-sweep-668 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tfbqv0hi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001148-tfbqv0hi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iagx0h7p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001203-iagx0h7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-669
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iagx0h7p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.33it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 160.10it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 168.57it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 176.75it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 182.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 188.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 193.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 196.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 198.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 187.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 181.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 177.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 174.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 162.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 144.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 137.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.705
wandb: best_valid_acc 0.692
wandb:  sub_train_acc 0.68538
wandb: sub_train_loss 0.9332
wandb:       test_acc 0.705
wandb:      valid_acc 0.692
wandb: 
wandb: üöÄ View run cool-sweep-669 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/iagx0h7p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001203-iagx0h7p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s0p1qvya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001214-s0p1qvya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-670
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s0p1qvya
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 127.41it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 119.78it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 117.46it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 129.44it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 160.60it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 180.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 188.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 188.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 189.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 191.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 181.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 188.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 194.71it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 187.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 189.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.71
wandb: best_valid_acc 0.71
wandb:  sub_train_acc 0.70089
wandb: sub_train_loss 0.94139
wandb:       test_acc 0.713
wandb:      valid_acc 0.708
wandb: 
wandb: üöÄ View run effortless-sweep-670 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s0p1qvya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001214-s0p1qvya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6zfwgs23 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001229-6zfwgs23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-671
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6zfwgs23
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.57it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 187.65it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 183.08it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 190.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 183.99it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 178.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 167.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 173.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 174.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 182.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 187.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 192.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 194.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 194.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 176.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.773
wandb: best_valid_acc 0.764
wandb:  sub_train_acc 0.78508
wandb: sub_train_loss 0.71502
wandb:       test_acc 0.769
wandb:      valid_acc 0.75
wandb: 
wandb: üöÄ View run splendid-sweep-671 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6zfwgs23
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001229-6zfwgs23/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hwvbc6jk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001251-hwvbc6jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-672
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwvbc6jk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 198.71it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 197.25it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 196.74it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 200.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 191.88it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 185.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 186.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 183.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 184.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 185.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 191.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 195.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 189.63it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 189.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 190.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.753
wandb: best_valid_acc 0.774
wandb:  sub_train_acc 0.80465
wandb: sub_train_loss 0.64787
wandb:       test_acc 0.791
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run daily-sweep-672 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwvbc6jk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001251-hwvbc6jk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: to8690sd with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001311-to8690sd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-673
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/to8690sd
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 305.25it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 275.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 276.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 284.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 292.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 296.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 291.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.217
wandb: best_valid_acc 0.238
wandb:  sub_train_acc 0.19719
wandb: sub_train_loss 1.88228
wandb:       test_acc 0.217
wandb:      valid_acc 0.238
wandb: 
wandb: üöÄ View run elated-sweep-673 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/to8690sd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001311-to8690sd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 18j7d9re with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001326-18j7d9re
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-674
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/18j7d9re
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 212.75it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 237.46it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 243.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 250.46it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 250.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 255.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 251.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 246.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.206
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.19424
wandb: sub_train_loss 1.88275
wandb:       test_acc 0.206
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run frosty-sweep-674 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/18j7d9re
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001326-18j7d9re/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1pkozkxs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001342-1pkozkxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-675
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1pkozkxs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:00, 262.17it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 270.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 270.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 268.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 279.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 287.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 281.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.2
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.19387
wandb: sub_train_loss 1.89929
wandb:       test_acc 0.201
wandb:      valid_acc 0.206
wandb: 
wandb: üöÄ View run rare-sweep-675 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1pkozkxs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001342-1pkozkxs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: izj0yuat with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001357-izj0yuat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-676
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/izj0yuat
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:00, 326.60it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 329.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 330.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 331.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 333.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 332.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.218
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.20384
wandb: sub_train_loss 1.90061
wandb:       test_acc 0.218
wandb:      valid_acc 0.232
wandb: 
wandb: üöÄ View run denim-sweep-676 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/izj0yuat
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001357-izj0yuat/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xv5z3u7f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001409-xv5z3u7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-677
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xv5z3u7f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 310.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 311.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 311.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 309.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 311.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 311.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 311.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.292
wandb: best_valid_acc 0.29
wandb:  sub_train_acc 0.27179
wandb: sub_train_loss 1.90426
wandb:       test_acc 0.292
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run pretty-sweep-677 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xv5z3u7f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001409-xv5z3u7f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9709ojgk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001422-9709ojgk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-678
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9709ojgk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 294.25it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 299.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 299.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 295.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 297.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 298.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 298.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.274
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.26329
wandb: sub_train_loss 1.90444
wandb:       test_acc 0.276
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run apricot-sweep-678 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9709ojgk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001422-9709ojgk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6809i7da with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001434-6809i7da
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-679
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6809i7da
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 306.67it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 298.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 296.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 299.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 301.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 307.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 303.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.231
wandb: best_valid_acc 0.25
wandb:  sub_train_acc 0.24742
wandb: sub_train_loss 1.91057
wandb:       test_acc 0.231
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run stilted-sweep-679 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6809i7da
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001434-6809i7da/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8kuzz2ei with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001449-8kuzz2ei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-680
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8kuzz2ei
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:00, 304.31it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 306.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 307.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 307.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 305.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 306.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 304.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.214
wandb: best_valid_acc 0.234
wandb:  sub_train_acc 0.23781
wandb: sub_train_loss 1.90892
wandb:       test_acc 0.214
wandb:      valid_acc 0.234
wandb: 
wandb: üöÄ View run dry-sweep-680 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8kuzz2ei
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001449-8kuzz2ei/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: tdy6h4tu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001509-tdy6h4tu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-681
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tdy6h4tu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 282.48it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 282.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 297.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 287.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 281.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 276.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 280.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.391
wandb: best_valid_acc 0.402
wandb:  sub_train_acc 0.39697
wandb: sub_train_loss 1.91078
wandb:       test_acc 0.391
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run visionary-sweep-681 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/tdy6h4tu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001509-tdy6h4tu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1cl8cksv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001524-1cl8cksv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-682
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1cl8cksv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:00, 278.36it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 282.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 287.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 288.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 291.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 294.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 290.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.417
wandb: best_valid_acc 0.42
wandb:  sub_train_acc 0.3966
wandb: sub_train_loss 1.91132
wandb:       test_acc 0.417
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run denim-sweep-682 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1cl8cksv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001524-1cl8cksv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h9z7sna4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001540-h9z7sna4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-683
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h9z7sna4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:00, 319.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 319.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 320.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 323.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 323.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 322.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 322.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.48
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.45495
wandb: sub_train_loss 1.91681
wandb:       test_acc 0.487
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run vivid-sweep-683 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h9z7sna4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001540-h9z7sna4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: axx1yhhj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001551-axx1yhhj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-684
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/axx1yhhj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:00, 257.42it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:00, 253.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 253.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 258.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 259.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 264.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:00<00:00, 277.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 267.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.441
wandb: best_valid_acc 0.44
wandb:  sub_train_acc 0.43205
wandb: sub_train_loss 1.91712
wandb:       test_acc 0.441
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run spring-sweep-684 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/axx1yhhj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001551-axx1yhhj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hrxykb37 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001605-hrxykb37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-685
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hrxykb37
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.03it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 186.77it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 194.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 201.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 211.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 224.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 234.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 240.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 225.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.381
wandb: best_valid_acc 0.346
wandb:  sub_train_acc 0.37518
wandb: sub_train_loss 1.92082
wandb:       test_acc 0.382
wandb:      valid_acc 0.344
wandb: 
wandb: üöÄ View run royal-sweep-685 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hrxykb37
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001605-hrxykb37/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fir9fy5m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001621-fir9fy5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-686
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fir9fy5m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 289.27it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 286.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 278.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 263.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 263.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 262.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:00<00:00, 262.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 266.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.434
wandb: best_valid_acc 0.44
wandb:  sub_train_acc 0.4435
wandb: sub_train_loss 1.92067
wandb:       test_acc 0.437
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run smooth-sweep-686 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fir9fy5m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001621-fir9fy5m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hwag4ibj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001636-hwag4ibj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-687
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwag4ibj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:00, 286.05it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 266.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 282.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 277.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 274.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 269.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 272.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.59
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.55724
wandb: sub_train_loss 1.92245
wandb:       test_acc 0.546
wandb:      valid_acc 0.528
wandb: 
wandb: üöÄ View run copper-sweep-687 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/hwag4ibj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001636-hwag4ibj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4b5zeesu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001652-4b5zeesu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-688
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4b5zeesu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:00, 297.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 312.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 312.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 308.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 312.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 313.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 311.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.578
wandb: best_valid_acc 0.58
wandb:  sub_train_acc 0.60303
wandb: sub_train_loss 1.92164
wandb:       test_acc 0.581
wandb:      valid_acc 0.576
wandb: 
wandb: üöÄ View run effortless-sweep-688 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4b5zeesu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001652-4b5zeesu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6y5z7o74 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001706-6y5z7o74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-689
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6y5z7o74
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.16it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.37it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.11it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 176.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 176.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 172.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 173.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 177.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 181.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.152
wandb: best_valid_acc 0.158
wandb:  sub_train_acc 0.17393
wandb: sub_train_loss 1.56965
wandb:       test_acc 0.158
wandb:      valid_acc 0.154
wandb: 
wandb: üöÄ View run unique-sweep-689 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/6y5z7o74
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001706-6y5z7o74/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b2f0u4bl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001722-b2f0u4bl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-690
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/b2f0u4bl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 177.90it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 176.11it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 174.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 169.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 167.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 166.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 166.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 176.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.234
wandb: best_valid_acc 0.218
wandb:  sub_train_acc 0.14069
wandb: sub_train_loss 1.57633
wandb:       test_acc 0.113
wandb:      valid_acc 0.12
wandb: 
wandb: üöÄ View run apricot-sweep-690 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/b2f0u4bl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001722-b2f0u4bl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rm7h2ezr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001744-rm7h2ezr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-691
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rm7h2ezr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.40it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 190.27it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 194.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 196.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 198.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 199.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 200.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 200.79it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 198.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 198.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.254
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.25812
wandb: sub_train_loss 1.65344
wandb:       test_acc 0.258
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run vibrant-sweep-691 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/rm7h2ezr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001744-rm7h2ezr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1cw8e995 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001758-1cw8e995
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-692
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1cw8e995
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 185.24it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 194.84it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 198.47it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 201.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 204.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 204.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 206.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 206.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 205.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 202.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.177
wandb: best_valid_acc 0.174
wandb:  sub_train_acc 0.19535
wandb: sub_train_loss 1.66103
wandb:       test_acc 0.179
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run peach-sweep-692 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1cw8e995
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001758-1cw8e995/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8xx7fn4d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001810-8xx7fn4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-693
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8xx7fn4d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 185.73it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 183.13it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 181.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 180.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 170.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 164.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 164.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 163.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 167.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 172.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.336
wandb: best_valid_acc 0.336
wandb:  sub_train_acc 0.34084
wandb: sub_train_loss 1.70349
wandb:       test_acc 0.336
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run graceful-sweep-693 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8xx7fn4d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001810-8xx7fn4d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3cf4zq6w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001825-3cf4zq6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-694
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3cf4zq6w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.15it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 162.47it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 161.83it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 165.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 166.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 167.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 166.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 168.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 168.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 168.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 163.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 165.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.439
wandb: best_valid_acc 0.418
wandb:  sub_train_acc 0.42541
wandb: sub_train_loss 1.69071
wandb:       test_acc 0.451
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run sage-sweep-694 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/3cf4zq6w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001825-3cf4zq6w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4qw3007c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001839-4qw3007c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-695
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4qw3007c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.81it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.61it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 191.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 189.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 189.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 185.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 184.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 183.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 184.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 185.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.304
wandb: best_valid_acc 0.306
wandb:  sub_train_acc 0.32829
wandb: sub_train_loss 1.72243
wandb:       test_acc 0.3
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run fresh-sweep-695 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4qw3007c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001839-4qw3007c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: diyxjawk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001852-diyxjawk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-696
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/diyxjawk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.10it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.51it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 158.13it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 161.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 155.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 152.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 150.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 151.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 150.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 150.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 160.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.411
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.40288
wandb: sub_train_loss 1.72475
wandb:       test_acc 0.417
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run floral-sweep-696 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/diyxjawk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001852-diyxjawk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gjotjdiv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001906-gjotjdiv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-697
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gjotjdiv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.97it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 162.00it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 157.79it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 158.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 160.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 162.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 162.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 165.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 169.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 169.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 169.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 164.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.559
wandb: best_valid_acc 0.554
wandb:  sub_train_acc 0.52917
wandb: sub_train_loss 1.74731
wandb:       test_acc 0.568
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run whole-sweep-697 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gjotjdiv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001906-gjotjdiv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w52ht1ii with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001922-w52ht1ii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-698
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w52ht1ii
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 194.61it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:00, 199.51it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 201.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 195.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 177.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 167.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 173.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 175.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 177.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 180.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 181.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.534
wandb: best_valid_acc 0.522
wandb:  sub_train_acc 0.51846
wandb: sub_train_loss 1.75245
wandb:       test_acc 0.535
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run dazzling-sweep-698 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w52ht1ii
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001922-w52ht1ii/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pbkb5nlu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001938-pbkb5nlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-699
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pbkb5nlu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 197.28it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 189.83it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 188.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 190.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 188.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 186.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 182.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 183.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 186.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 185.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.326
wandb: best_valid_acc 0.322
wandb:  sub_train_acc 0.34934
wandb: sub_train_loss 1.77827
wandb:       test_acc 0.333
wandb:      valid_acc 0.322
wandb: 
wandb: üöÄ View run bright-sweep-699 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pbkb5nlu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001938-pbkb5nlu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h9l0h7ex with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_001959-h9l0h7ex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-700
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h9l0h7ex
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 164.17it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.75it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 165.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 169.30it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 169.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 172.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 174.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 175.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 175.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 171.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 169.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.416
wandb: best_valid_acc 0.428
wandb:  sub_train_acc 0.44535
wandb: sub_train_loss 1.77622
wandb:       test_acc 0.42
wandb:      valid_acc 0.428
wandb: 
wandb: üöÄ View run earthy-sweep-700 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h9l0h7ex
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_001959-h9l0h7ex/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h24vexbv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002020-h24vexbv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-701
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h24vexbv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.73it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 181.64it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 187.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 190.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 183.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 179.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 178.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 182.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 184.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 185.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.661
wandb: best_valid_acc 0.656
wandb:  sub_train_acc 0.64623
wandb: sub_train_loss 1.80061
wandb:       test_acc 0.663
wandb:      valid_acc 0.656
wandb: 
wandb: üöÄ View run hardy-sweep-701 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/h24vexbv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002020-h24vexbv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p0k0rgbw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002035-p0k0rgbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-702
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p0k0rgbw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.14it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:00, 167.68it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 125.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 134.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 133.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 136.23it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 138.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 139.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 139.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 144.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 153.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.63
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.62223
wandb: sub_train_loss 1.79863
wandb:       test_acc 0.631
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run gentle-sweep-702 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/p0k0rgbw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002035-p0k0rgbw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ensiqc49 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002051-ensiqc49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-703
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ensiqc49
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 193.92it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 182.48it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 179.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 175.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 177.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 176.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 173.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 170.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 170.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 171.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.735
wandb: best_valid_acc 0.734
wandb:  sub_train_acc 0.75222
wandb: sub_train_loss 1.79709
wandb:       test_acc 0.748
wandb:      valid_acc 0.732
wandb: 
wandb: üöÄ View run confused-sweep-703 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ensiqc49
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002051-ensiqc49/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qgxzx2ap with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002105-qgxzx2ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-704
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qgxzx2ap
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.49it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 170.01it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 167.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 167.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 167.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 166.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 168.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 171.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 173.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 178.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 180.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.687
wandb: best_valid_acc 0.674
wandb:  sub_train_acc 0.70975
wandb: sub_train_loss 1.80003
wandb:       test_acc 0.697
wandb:      valid_acc 0.672
wandb: 
wandb: üöÄ View run sleek-sweep-704 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/qgxzx2ap
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002105-qgxzx2ap/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gtpp9233 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002121-gtpp9233
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-705
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gtpp9233
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.64it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.10it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 148.57it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 147.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 147.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 146.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 143.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 144.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 145.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 145.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 142.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 142.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 142.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.258
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.20126
wandb: sub_train_loss 1.27743
wandb:       test_acc 0.207
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run lyric-sweep-705 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gtpp9233
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002121-gtpp9233/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0yvpryqs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002132-0yvpryqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-706
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0yvpryqs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.22it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 131.85it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 131.64it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 131.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 132.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 133.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 134.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 134.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 135.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 134.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 128.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 124.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 122.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 122.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.108
wandb: best_valid_acc 0.12
wandb:  sub_train_acc 0.137
wandb: sub_train_loss 1.20678
wandb:       test_acc 0.113
wandb:      valid_acc 0.12
wandb: 
wandb: üöÄ View run giddy-sweep-706 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/0yvpryqs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002132-0yvpryqs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 81j9ycqu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002146-81j9ycqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-707
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/81j9ycqu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.03it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 152.71it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 154.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.27it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 151.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 149.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 146.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 139.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 123.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 119.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 121.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 123.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 130.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.133
wandb: best_valid_acc 0.136
wandb:  sub_train_acc 0.0997
wandb: sub_train_loss 1.38249
wandb:       test_acc 0.076
wandb:      valid_acc 0.076
wandb: 
wandb: üöÄ View run trim-sweep-707 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/81j9ycqu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002146-81j9ycqu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nu2a27jz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002207-nu2a27jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-708
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nu2a27jz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.26it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.06it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 124.45it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 125.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 123.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 118.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 110.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:01, 90.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:01, 85.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 85.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 92.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 100.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 109.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 115.43it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 116.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 118.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.194
wandb: best_valid_acc 0.186
wandb:  sub_train_acc 0.20421
wandb: sub_train_loss 1.41547
wandb:       test_acc 0.196
wandb:      valid_acc 0.186
wandb: 
wandb: üöÄ View run divine-sweep-708 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nu2a27jz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002207-nu2a27jz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pqrs4yxk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002222-pqrs4yxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-709
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pqrs4yxk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.58it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.77it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 134.22it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 132.83it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 127.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 131.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 132.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 137.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 140.15it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 142.08it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 143.29it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 123.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 128.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.243
wandb: best_valid_acc 0.246
wandb:  sub_train_acc 0.25923
wandb: sub_train_loss 1.46831
wandb:       test_acc 0.248
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run morning-sweep-709 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/pqrs4yxk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002222-pqrs4yxk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fbe2gr80 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002238-fbe2gr80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-710
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fbe2gr80
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 108.63it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 114.91it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 115.91it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 116.75it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 115.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 114.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 111.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 111.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 108.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 102.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 90.97it/s]  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 93.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 94.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 92.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 88.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 89.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 89.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.338
wandb: best_valid_acc 0.342
wandb:  sub_train_acc 0.33973
wandb: sub_train_loss 1.46566
wandb:       test_acc 0.34
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run gallant-sweep-710 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fbe2gr80
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002238-fbe2gr80/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 63f1u755 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002254-63f1u755
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-711
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/63f1u755
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.59it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 137.15it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 129.09it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 116.93it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 106.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 103.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:01, 103.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 103.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 106.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 108.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 109.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 112.09it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 112.33it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 109.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 108.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 111.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 111.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.228
wandb:  sub_train_acc 0.25406
wandb: sub_train_loss 1.52642
wandb:       test_acc 0.21
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run woven-sweep-711 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/63f1u755
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002254-63f1u755/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: opdyuhbn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002309-opdyuhbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-712
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/opdyuhbn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 134.18it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 141.06it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 139.72it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 140.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 139.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 142.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 144.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 145.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 143.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 145.68it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 147.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 146.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 147.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.299
wandb: best_valid_acc 0.304
wandb:  sub_train_acc 0.3113
wandb: sub_train_loss 1.52153
wandb:       test_acc 0.306
wandb:      valid_acc 0.3
wandb: 
wandb: üöÄ View run youthful-sweep-712 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/opdyuhbn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002309-opdyuhbn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dai3az8v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002327-dai3az8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-713
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dai3az8v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.90it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.59it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 120.71it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 115.95it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 119.04it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 125.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 130.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 133.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 134.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 138.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 139.53it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 142.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 131.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.554
wandb: best_valid_acc 0.57
wandb:  sub_train_acc 0.51403
wandb: sub_train_loss 1.59254
wandb:       test_acc 0.554
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run grateful-sweep-713 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dai3az8v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002327-dai3az8v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wgs96ezh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002341-wgs96ezh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-714
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wgs96ezh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.81it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.31it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 150.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 145.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 140.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 132.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 126.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 128.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 132.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 133.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 132.26it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 131.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 132.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.452
wandb: best_valid_acc 0.46
wandb:  sub_train_acc 0.44424
wandb: sub_train_loss 1.56678
wandb:       test_acc 0.452
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run dainty-sweep-714 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wgs96ezh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002341-wgs96ezh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r13om4i7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002357-r13om4i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-715
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r13om4i7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.95it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 129.90it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 135.44it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 139.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 141.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 144.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 146.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 144.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 139.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 135.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 134.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 134.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 135.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.586
wandb: best_valid_acc 0.576
wandb:  sub_train_acc 0.57496
wandb: sub_train_loss 1.661
wandb:       test_acc 0.593
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run ethereal-sweep-715 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/r13om4i7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002357-r13om4i7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x5rpwl2c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002413-x5rpwl2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-716
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x5rpwl2c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.07it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.29it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 120.70it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 133.11it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 139.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 142.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 143.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 144.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 144.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 144.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 144.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 143.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 144.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.502
wandb: best_valid_acc 0.466
wandb:  sub_train_acc 0.49483
wandb: sub_train_loss 1.6323
wandb:       test_acc 0.502
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run stilted-sweep-716 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x5rpwl2c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002413-x5rpwl2c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nuvo9p05 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002427-nuvo9p05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-717
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nuvo9p05
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.22it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 133.78it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 136.41it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 136.08it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 134.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 132.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 132.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 130.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 131.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 135.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 138.13it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 140.01it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 142.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.459
wandb: best_valid_acc 0.454
wandb:  sub_train_acc 0.47267
wandb: sub_train_loss 1.66434
wandb:       test_acc 0.459
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run valiant-sweep-717 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/nuvo9p05
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002427-nuvo9p05/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: e1djzyf4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002443-e1djzyf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-718
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e1djzyf4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.24it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.35it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 141.98it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 138.52it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 134.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 137.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 142.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 144.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 142.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 136.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 121.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 128.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 132.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.663
wandb: best_valid_acc 0.638
wandb:  sub_train_acc 0.6418
wandb: sub_train_loss 1.677
wandb:       test_acc 0.663
wandb:      valid_acc 0.638
wandb: 
wandb: üöÄ View run jumping-sweep-718 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/e1djzyf4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002443-e1djzyf4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: crqkjfmu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002459-crqkjfmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-719
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/crqkjfmu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.39it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 135.48it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 129.60it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 130.82it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 133.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 134.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 134.27it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 130.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 128.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 120.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 123.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 128.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 124.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 126.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.701
wandb: best_valid_acc 0.68
wandb:  sub_train_acc 0.69978
wandb: sub_train_loss 1.66979
wandb:       test_acc 0.701
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run clean-sweep-719 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/crqkjfmu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002459-crqkjfmu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x78abax9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002513-x78abax9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-720
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x78abax9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.88it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 142.00it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 142.53it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 143.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 144.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 145.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 144.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 145.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 146.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 147.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 146.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 145.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 145.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.772
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.78287
wandb: sub_train_loss 1.65757
wandb:       test_acc 0.772
wandb:      valid_acc 0.762
wandb: 
wandb: üöÄ View run smooth-sweep-720 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x78abax9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002513-x78abax9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5rb7wbge with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002530-5rb7wbge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-721
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5rb7wbge
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñä         | 26/300 [00:00<00:01, 258.53it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 275.71it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:00, 287.78it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 291.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 295.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 299.01it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 298.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:00<00:00, 297.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:00<00:00, 304.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 297.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.207
wandb: best_valid_acc 0.216
wandb:  sub_train_acc 0.19941
wandb: sub_train_loss 1.85099
wandb:       test_acc 0.208
wandb:      valid_acc 0.216
wandb: 
wandb: üöÄ View run chocolate-sweep-721 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5rb7wbge
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002530-5rb7wbge/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mpbd5toe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002546-mpbd5toe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-722
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mpbd5toe
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 299.99it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 234.57it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 222.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:00, 226.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 231.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 243.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 254.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 260.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 262.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 269.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 255.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.21
wandb: best_valid_acc 0.242
wandb:  sub_train_acc 0.20679
wandb: sub_train_loss 1.85229
wandb:       test_acc 0.214
wandb:      valid_acc 0.24
wandb: 
wandb: üöÄ View run jumping-sweep-722 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mpbd5toe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002546-mpbd5toe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y4xxdmjc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002558-y4xxdmjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-723
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y4xxdmjc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 216.12it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 219.79it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 220.68it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 232.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 239.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 236.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 239.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 247.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 253.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 262.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 255.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 244.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.215
wandb: best_valid_acc 0.232
wandb:  sub_train_acc 0.21566
wandb: sub_train_loss 1.87672
wandb:       test_acc 0.224
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run bright-sweep-723 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y4xxdmjc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002558-y4xxdmjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xorpm0s3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002612-xorpm0s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-724
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xorpm0s3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 269.79it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 270.86it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 269.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 265.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 278.22it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 287.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 294.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:00<00:00, 296.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:00<00:00, 294.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 295.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 287.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.212
wandb: best_valid_acc 0.208
wandb:  sub_train_acc 0.20199
wandb: sub_train_loss 1.87595
wandb:       test_acc 0.212
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run hardy-sweep-724 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xorpm0s3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002612-xorpm0s3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4monobks with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002627-4monobks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-725
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4monobks
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 294.88it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:00, 299.96it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 296.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 281.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 263.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 262.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 268.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:00<00:00, 268.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:00<00:00, 265.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 277.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 276.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.292
wandb: best_valid_acc 0.282
wandb:  sub_train_acc 0.27917
wandb: sub_train_loss 1.88146
wandb:       test_acc 0.291
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run easy-sweep-725 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4monobks
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002627-4monobks/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5c37qimm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002639-5c37qimm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-726
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5c37qimm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 296.21it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:00, 298.76it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 290.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 282.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 297.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 306.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:00<00:00, 310.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 312.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:00<00:00, 313.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 305.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.301
wandb: best_valid_acc 0.31
wandb:  sub_train_acc 0.29616
wandb: sub_train_loss 1.88169
wandb:       test_acc 0.3
wandb:      valid_acc 0.31
wandb: 
wandb: üöÄ View run vivid-sweep-726 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5c37qimm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002639-5c37qimm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9c0q6b3t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002653-9c0q6b3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-727
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9c0q6b3t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 31/300 [00:00<00:00, 307.34it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:00, 279.59it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 276.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 272.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 267.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 266.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 264.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 264.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:00<00:00, 264.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 272.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 271.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.252
wandb: best_valid_acc 0.266
wandb:  sub_train_acc 0.25923
wandb: sub_train_loss 1.89044
wandb:       test_acc 0.253
wandb:      valid_acc 0.266
wandb: 
wandb: üöÄ View run sparkling-sweep-727 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/9c0q6b3t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002653-9c0q6b3t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uvz1cyh8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002709-uvz1cyh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-728
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uvz1cyh8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 295.89it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:00, 303.65it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 280.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 259.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 246.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 245.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 252.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 257.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:00<00:00, 271.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 283.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 270.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.266
wandb: best_valid_acc 0.284
wandb:  sub_train_acc 0.27179
wandb: sub_train_loss 1.88824
wandb:       test_acc 0.265
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run colorful-sweep-728 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/uvz1cyh8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002709-uvz1cyh8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z6wo0gcm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002724-z6wo0gcm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-729
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z6wo0gcm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.31it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 272.83it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 272.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 270.12it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 266.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 270.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 284.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:00<00:00, 285.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 292.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 296.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 284.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.44
wandb: best_valid_acc 0.452
wandb:  sub_train_acc 0.42319
wandb: sub_train_loss 1.89427
wandb:       test_acc 0.442
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run kind-sweep-729 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/z6wo0gcm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002724-z6wo0gcm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4tj5kezn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002739-4tj5kezn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-730
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4tj5kezn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 294.87it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 297.25it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 297.67it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 292.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 296.13it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:00<00:00, 297.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 299.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:00<00:00, 301.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:00<00:00, 306.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 302.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.441
wandb: best_valid_acc 0.448
wandb:  sub_train_acc 0.42393
wandb: sub_train_loss 1.89481
wandb:       test_acc 0.451
wandb:      valid_acc 0.448
wandb: 
wandb: üöÄ View run ruby-sweep-730 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4tj5kezn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002739-4tj5kezn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s1ynhewi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002756-s1ynhewi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-731
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s1ynhewi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 10%|‚ñà         | 30/300 [00:00<00:00, 293.47it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:00, 292.12it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:00, 289.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 290.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 288.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 298.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 302.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:00<00:00, 304.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:00<00:00, 309.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 302.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.489
wandb: best_valid_acc 0.494
wandb:  sub_train_acc 0.47932
wandb: sub_train_loss 1.90172
wandb:       test_acc 0.489
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run sandy-sweep-731 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s1ynhewi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002756-s1ynhewi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: anfaxf8h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002816-anfaxf8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-732
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/anfaxf8h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s] 11%|‚ñà         | 32/300 [00:00<00:00, 316.89it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:00, 315.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 308.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 303.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 304.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 305.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 306.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:00<00:00, 304.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:00<00:00, 303.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 305.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.509
wandb: best_valid_acc 0.478
wandb:  sub_train_acc 0.48486
wandb: sub_train_loss 1.90201
wandb:       test_acc 0.51
wandb:      valid_acc 0.476
wandb: 
wandb: üöÄ View run polished-sweep-732 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/anfaxf8h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002816-anfaxf8h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8a4ofi84 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002831-8a4ofi84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-733
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8a4ofi84
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 269.14it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 275.16it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 273.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 288.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 295.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 304.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 311.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:00<00:00, 312.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:00<00:00, 295.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 291.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.347
wandb: best_valid_acc 0.346
wandb:  sub_train_acc 0.36078
wandb: sub_train_loss 1.90766
wandb:       test_acc 0.357
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run absurd-sweep-733 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/8a4ofi84
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002831-8a4ofi84/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: reblbox3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002846-reblbox3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-734
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/reblbox3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 268.22it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 270.47it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:00, 267.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 272.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 283.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 290.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:00<00:00, 294.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:00<00:00, 299.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 302.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 302.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 291.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.391
wandb: best_valid_acc 0.396
wandb:  sub_train_acc 0.3678
wandb: sub_train_loss 1.90773
wandb:       test_acc 0.374
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run rosy-sweep-734 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/reblbox3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002846-reblbox3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dwjtoecl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002858-dwjtoecl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-735
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dwjtoecl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 266.78it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:00, 268.58it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:00, 259.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 249.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 252.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 270.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 280.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:00<00:00, 290.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:00<00:00, 298.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 302.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 282.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.669
wandb: best_valid_acc 0.642
wandb:  sub_train_acc 0.68648
wandb: sub_train_loss 1.90912
wandb:       test_acc 0.673
wandb:      valid_acc 0.642
wandb: 
wandb: üöÄ View run lunar-sweep-735 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/dwjtoecl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002858-dwjtoecl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y1t9asvo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002913-y1t9asvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-736
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y1t9asvo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  9%|‚ñâ         | 27/300 [00:00<00:01, 269.20it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:00, 274.52it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:00, 284.98it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 293.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 297.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 297.09it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:00<00:00, 293.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:00<00:00, 292.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:00<00:00, 287.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 286.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 288.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.615
wandb: best_valid_acc 0.626
wandb:  sub_train_acc 0.58493
wandb: sub_train_loss 1.9106
wandb:       test_acc 0.574
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run confused-sweep-736 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y1t9asvo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002913-y1t9asvo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5z9jcve7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002928-5z9jcve7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-737
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5z9jcve7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 208.87it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 208.68it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 205.19it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 201.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:00, 200.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 200.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 200.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 200.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 199.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 198.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 197.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 196.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 196.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 196.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 199.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.17
wandb: best_valid_acc 0.172
wandb:  sub_train_acc 0.17725
wandb: sub_train_loss 1.25335
wandb:       test_acc 0.17
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run wobbly-sweep-737 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/5z9jcve7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002928-5z9jcve7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ph24ygc3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_002949-ph24ygc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-738
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ph24ygc3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.03it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 172.40it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 183.42it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 184.41it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 185.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 187.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 189.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 190.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 190.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 188.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 188.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 190.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 188.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 189.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 192.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.18
wandb: best_valid_acc 0.194
wandb:  sub_train_acc 0.13294
wandb: sub_train_loss 1.31255
wandb:       test_acc 0.097
wandb:      valid_acc 0.092
wandb: 
wandb: üöÄ View run sparkling-sweep-738 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ph24ygc3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_002949-ph24ygc3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xyn346ou with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003001-xyn346ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-739
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xyn346ou
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 181.05it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 182.97it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 188.53it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 184.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 177.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 181.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 182.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 183.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 186.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 190.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 193.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 191.05it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 188.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 191.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 189.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 187.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.183
wandb: best_valid_acc 0.172
wandb:  sub_train_acc 0.16544
wandb: sub_train_loss 1.43303
wandb:       test_acc 0.124
wandb:      valid_acc 0.126
wandb: 
wandb: üöÄ View run dashing-sweep-739 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/xyn346ou
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003001-xyn346ou/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s48u11d8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003016-s48u11d8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-740
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s48u11d8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.26it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 193.07it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 192.24it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 193.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 193.15it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 192.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 192.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 193.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 192.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 193.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 194.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 194.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 194.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 193.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 190.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 192.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.288
wandb: best_valid_acc 0.278
wandb:  sub_train_acc 0.29727
wandb: sub_train_loss 1.42055
wandb:       test_acc 0.288
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run faithful-sweep-740 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/s48u11d8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003016-s48u11d8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x41buyew with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003028-x41buyew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-741
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x41buyew
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.76it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 185.86it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 194.94it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 192.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 189.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 185.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 188.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 189.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 190.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 189.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 192.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 195.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 198.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 199.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 193.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.294
wandb: best_valid_acc 0.288
wandb:  sub_train_acc 0.30908
wandb: sub_train_loss 1.48679
wandb:       test_acc 0.294
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run fanciful-sweep-741 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/x41buyew
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003028-x41buyew/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y8548pu5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003043-y8548pu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-742
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y8548pu5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.43it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 179.80it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 185.86it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 189.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 188.57it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 191.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 192.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 195.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 194.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 195.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 195.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 193.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 192.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 191.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 192.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 191.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.372
wandb: best_valid_acc 0.382
wandb:  sub_train_acc 0.37629
wandb: sub_train_loss 1.49061
wandb:       test_acc 0.374
wandb:      valid_acc 0.378
wandb: 
wandb: üöÄ View run flowing-sweep-742 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/y8548pu5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003043-y8548pu5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ysxamboh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003059-ysxamboh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-743
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ysxamboh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 171.73it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 186.05it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 177.80it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 178.32it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 179.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 179.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 181.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 175.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 176.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 173.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 171.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 168.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 169.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 168.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 171.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 174.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.375
wandb: best_valid_acc 0.354
wandb:  sub_train_acc 0.36189
wandb: sub_train_loss 1.53475
wandb:       test_acc 0.377
wandb:      valid_acc 0.354
wandb: 
wandb: üöÄ View run misty-sweep-743 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ysxamboh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003059-ysxamboh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m6dhqo0w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003114-m6dhqo0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-744
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m6dhqo0w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 195.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 197.48it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 172.77it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 181.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 185.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 190.90it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 195.19it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 197.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 198.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 193.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 191.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 192.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 188.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 188.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 189.93it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.269
wandb: best_valid_acc 0.276
wandb:  sub_train_acc 0.29764
wandb: sub_train_loss 1.53213
wandb:       test_acc 0.271
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run rose-sweep-744 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/m6dhqo0w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003114-m6dhqo0w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1k5ty4jn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003129-1k5ty4jn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-745
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1k5ty4jn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.26it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 149.90it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.85it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 150.41it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 158.74it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 164.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 171.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 181.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 185.94it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 187.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 188.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 188.10it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 183.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 178.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 181.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.362
wandb: best_valid_acc 0.36
wandb:  sub_train_acc 0.37075
wandb: sub_train_loss 1.6053
wandb:       test_acc 0.365
wandb:      valid_acc 0.36
wandb: 
wandb: üöÄ View run pleasant-sweep-745 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1k5ty4jn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003129-1k5ty4jn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wupcteoq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003141-wupcteoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-746
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wupcteoq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.73it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 105.68it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 109.27it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 119.86it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 118.98it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 123.68it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 116.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 108.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 111.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 130.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 144.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 152.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 158.92it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 166.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 171.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 173.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 177.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 182.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.518
wandb: best_valid_acc 0.504
wandb:  sub_train_acc 0.49003
wandb: sub_train_loss 1.58868
wandb:       test_acc 0.521
wandb:      valid_acc 0.504
wandb: 
wandb: üöÄ View run generous-sweep-746 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/wupcteoq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003141-wupcteoq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 88cryyi5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003154-88cryyi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-747
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/88cryyi5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.15it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 193.20it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 195.91it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 197.94it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 197.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 193.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 174.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 170.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 181.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 188.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 194.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 197.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 199.71it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 196.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.601
wandb: best_valid_acc 0.584
wandb:  sub_train_acc 0.58346
wandb: sub_train_loss 1.65382
wandb:       test_acc 0.604
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run vibrant-sweep-747 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/88cryyi5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003154-88cryyi5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bmwhsqtq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003210-bmwhsqtq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-748
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bmwhsqtq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.23it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.87it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 162.88it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 163.36it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 159.17it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 157.83it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 160.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 162.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 156.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 162.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 169.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 174.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 179.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 182.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 184.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 188.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.487
wandb: best_valid_acc 0.502
wandb:  sub_train_acc 0.49557
wandb: sub_train_loss 1.64985
wandb:       test_acc 0.487
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run worthy-sweep-748 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/bmwhsqtq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003210-bmwhsqtq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 000duavx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003226-000duavx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-749
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/000duavx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 179.80it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 188.92it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 194.16it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 191.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 193.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 195.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:00, 190.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 189.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 189.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 190.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 181.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 179.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 180.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 176.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 174.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.478
wandb: best_valid_acc 0.44
wandb:  sub_train_acc 0.47969
wandb: sub_train_loss 1.68241
wandb:       test_acc 0.478
wandb:      valid_acc 0.44
wandb: 
wandb: üöÄ View run fresh-sweep-749 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/000duavx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003226-000duavx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 43b3sp3x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003241-43b3sp3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-750
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/43b3sp3x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 159.62it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 157.01it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 155.92it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 162.56it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 167.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 170.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 173.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 177.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 174.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 168.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 171.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 171.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 172.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 176.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 178.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 179.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 172.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.573
wandb: best_valid_acc 0.57
wandb:  sub_train_acc 0.57607
wandb: sub_train_loss 1.65879
wandb:       test_acc 0.577
wandb:      valid_acc 0.57
wandb: 
wandb: üöÄ View run zesty-sweep-750 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/43b3sp3x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003241-43b3sp3x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l2f42h3p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003257-l2f42h3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-751
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l2f42h3p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.30it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 144.07it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 138.33it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 137.13it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 158.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 173.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 184.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 192.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 197.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 200.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 203.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 204.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 203.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 205.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 206.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.784
wandb: best_valid_acc 0.772
wandb:  sub_train_acc 0.79542
wandb: sub_train_loss 1.68326
wandb:       test_acc 0.788
wandb:      valid_acc 0.772
wandb: 
wandb: üöÄ View run graceful-sweep-751 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/l2f42h3p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003257-l2f42h3p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mtxmrc5p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003313-mtxmrc5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-752
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mtxmrc5p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.03it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 173.65it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 180.92it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 167.52it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 180.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 189.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 192.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 196.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 180.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 167.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 160.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 153.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 147.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 141.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 139.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 148.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.646
wandb: best_valid_acc 0.664
wandb:  sub_train_acc 0.67024
wandb: sub_train_loss 1.67023
wandb:       test_acc 0.648
wandb:      valid_acc 0.664
wandb: 
wandb: üöÄ View run young-sweep-752 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/mtxmrc5p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003313-mtxmrc5p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: crd2jsk9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003328-crd2jsk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-753
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/crd2jsk9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.25it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.66it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 132.72it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 130.21it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 128.67it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 127.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 131.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 133.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 135.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 135.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 135.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 137.03it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 137.15it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 137.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 138.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 139.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 139.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 139.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 139.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 135.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 133.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.169
wandb: best_valid_acc 0.164
wandb:  sub_train_acc 0.17134
wandb: sub_train_loss 0.64877
wandb:       test_acc 0.169
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run fast-sweep-753 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/crd2jsk9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003328-crd2jsk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 73eq04np with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003343-73eq04np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-754
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/73eq04np
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.33it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 136.37it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 136.54it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 139.97it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 139.70it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 140.72it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 142.31it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 145.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 145.93it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 147.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 142.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 137.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 136.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 134.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 133.47it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 131.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 124.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 126.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 129.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 131.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 135.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.233
wandb: best_valid_acc 0.248
wandb:  sub_train_acc 0.21529
wandb: sub_train_loss 0.48343
wandb:       test_acc 0.222
wandb:      valid_acc 0.222
wandb: 
wandb: üöÄ View run sunny-sweep-754 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/73eq04np
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003343-73eq04np/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gxeh12xw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003358-gxeh12xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-755
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gxeh12xw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.91it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.31it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.31it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 121.38it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 119.29it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 119.31it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 119.67it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 124.39it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 127.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 131.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 133.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 135.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 136.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 137.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 136.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 137.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 137.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 136.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 138.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 140.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 138.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.292
wandb: best_valid_acc 0.28
wandb:  sub_train_acc 0.28545
wandb: sub_train_loss 0.83076
wandb:       test_acc 0.294
wandb:      valid_acc 0.28
wandb: 
wandb: üöÄ View run young-sweep-755 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/gxeh12xw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003358-gxeh12xw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fup4kqwn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003414-fup4kqwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-756
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fup4kqwn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 130.78it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 137.33it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 137.89it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 137.92it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 136.67it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 135.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 135.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 131.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 126.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 125.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 124.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 126.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 127.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 128.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 126.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 126.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 126.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 127.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 128.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 128.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 127.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.241
wandb: best_valid_acc 0.236
wandb:  sub_train_acc 0.25148
wandb: sub_train_loss 0.831
wandb:       test_acc 0.242
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run exalted-sweep-756 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/fup4kqwn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003414-fup4kqwn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jt2q7jow with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003429-jt2q7jow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-757
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jt2q7jow
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.23it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.51it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 120.41it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 122.31it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 122.80it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 123.68it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 123.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 124.03it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 124.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 126.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 125.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 125.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 126.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 126.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 125.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 127.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 129.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 130.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 131.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 130.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 129.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 125.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 125.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.28
wandb: best_valid_acc 0.288
wandb:  sub_train_acc 0.31869
wandb: sub_train_loss 0.88873
wandb:       test_acc 0.283
wandb:      valid_acc 0.288
wandb: 
wandb: üöÄ View run balmy-sweep-757 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/jt2q7jow
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003429-jt2q7jow/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: up2dm2jp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003444-up2dm2jp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-758
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/up2dm2jp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.97it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 137.75it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 139.54it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 140.33it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 138.22it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 132.97it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 129.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 127.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 127.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 127.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 127.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 128.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 125.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 126.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 128.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 129.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 128.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 127.25it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 127.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 126.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 125.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.422
wandb: best_valid_acc 0.412
wandb:  sub_train_acc 0.39734
wandb: sub_train_loss 0.9237
wandb:       test_acc 0.422
wandb:      valid_acc 0.412
wandb: 
wandb: üöÄ View run glad-sweep-758 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/up2dm2jp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003444-up2dm2jp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w4p91stc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003500-w4p91stc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-759
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w4p91stc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.64it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.60it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 134.42it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 137.00it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 139.01it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 139.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 139.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 138.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 137.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 138.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 136.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 134.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 132.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 130.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 129.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 129.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 127.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 127.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 126.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 126.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 126.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.374
wandb: best_valid_acc 0.37
wandb:  sub_train_acc 0.39291
wandb: sub_train_loss 1.02595
wandb:       test_acc 0.373
wandb:      valid_acc 0.37
wandb: 
wandb: üöÄ View run stellar-sweep-759 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/w4p91stc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003500-w4p91stc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i18cm48b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.5
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003526-i18cm48b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-760
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i18cm48b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 139.02it/s]  9%|‚ñâ         | 28/300 [00:00<00:01, 138.49it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 138.73it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 139.20it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 138.91it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 139.21it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 139.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 139.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 137.90it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 137.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 137.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 135.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 132.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 129.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 131.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 130.09it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 128.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 129.33it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 131.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 130.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 129.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 133.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.372
wandb: best_valid_acc 0.396
wandb:  sub_train_acc 0.38146
wandb: sub_train_loss 1.03421
wandb:       test_acc 0.372
wandb:      valid_acc 0.396
wandb: 
wandb: üöÄ View run deep-sweep-760 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/i18cm48b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003526-i18cm48b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a6y89foy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003541-a6y89foy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-761
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a6y89foy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.66it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.00it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 148.31it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 145.43it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 142.70it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 133.41it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 120.96it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 122.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 125.42it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 129.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 132.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 136.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 138.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 140.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 141.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 141.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 143.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 141.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 139.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 135.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.592
wandb: best_valid_acc 0.59
wandb:  sub_train_acc 0.5288
wandb: sub_train_loss 1.11377
wandb:       test_acc 0.593
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run wobbly-sweep-761 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/a6y89foy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003541-a6y89foy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ajbhvk2s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.625
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003600-ajbhvk2s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-762
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ajbhvk2s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.78it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.76it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 129.18it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 125.14it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 117.84it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 119.48it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 121.54it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 122.79it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 122.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 126.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 128.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 129.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 129.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 130.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 132.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 134.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 134.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 135.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 136.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 138.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 136.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 129.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.614
wandb: best_valid_acc 0.598
wandb:  sub_train_acc 0.54764
wandb: sub_train_loss 1.10466
wandb:       test_acc 0.619
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run fiery-sweep-762 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/ajbhvk2s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003600-ajbhvk2s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4a0vu9au with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003617-4a0vu9au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-763
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4a0vu9au
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.56it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 129.51it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 129.08it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 128.38it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 127.55it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 125.90it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 125.50it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 126.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 126.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 128.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 130.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 130.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 130.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 128.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 129.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 130.40it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 129.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 127.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 123.21it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 123.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 123.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 124.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.643
wandb: best_valid_acc 0.628
wandb:  sub_train_acc 0.63146
wandb: sub_train_loss 1.28871
wandb:       test_acc 0.643
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run snowy-sweep-763 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/4a0vu9au
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003617-4a0vu9au/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f00lro4c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.75
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003638-f00lro4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-764
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f00lro4c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 114.38it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.14it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 120.85it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.72it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 128.54it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 128.42it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 131.04it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 134.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 134.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 131.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 125.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 120.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 119.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 121.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 121.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 119.38it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 119.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 121.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 121.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 117.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 115.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 114.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.671
wandb: best_valid_acc 0.646
wandb:  sub_train_acc 0.64586
wandb: sub_train_loss 1.2176
wandb:       test_acc 0.679
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run rosy-sweep-764 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/f00lro4c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003638-f00lro4c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 74huwxj1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003653-74huwxj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-765
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/74huwxj1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.83it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 142.65it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 142.35it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 142.90it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 141.75it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 143.79it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 143.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 141.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 140.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 140.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 140.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 140.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 140.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 139.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 139.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 138.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 136.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 131.79it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 121.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 109.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 131.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.725
wandb: best_valid_acc 0.7
wandb:  sub_train_acc 0.7031
wandb: sub_train_loss 1.28345
wandb:       test_acc 0.725
wandb:      valid_acc 0.7
wandb: 
wandb: üöÄ View run hopeful-sweep-765 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/74huwxj1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003653-74huwxj1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 10hl3ooi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.875
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003709-10hl3ooi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-766
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/10hl3ooi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.87it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 133.71it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 138.07it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 141.55it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 144.70it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 142.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 140.99it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 137.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 112.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 104.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 105.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 107.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 110.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 112.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 113.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 116.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 122.37it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 128.28it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 132.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 132.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 134.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 125.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.772
wandb: best_valid_acc 0.724
wandb:  sub_train_acc 0.73892
wandb: sub_train_loss 1.22512
wandb:       test_acc 0.775
wandb:      valid_acc 0.724
wandb: 
wandb: üöÄ View run feasible-sweep-766 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/10hl3ooi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003709-10hl3ooi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1nvyoami with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003725-1nvyoami
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-767
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1nvyoami
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.03it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 142.64it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 144.70it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 146.98it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.10it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.57it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 146.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 145.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 141.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 137.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 134.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 133.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 134.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 135.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 133.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 130.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 129.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 131.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 133.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 134.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 137.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.78
wandb: best_valid_acc 0.776
wandb:  sub_train_acc 0.79468
wandb: sub_train_loss 1.2588
wandb:       test_acc 0.78
wandb:      valid_acc 0.776
wandb: 
wandb: üöÄ View run polar-sweep-767 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/1nvyoami
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003725-1nvyoami/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vttvynua with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 1
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240829_003740-vttvynua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-768
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/sweeps/75qqj6bw
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vttvynua
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.79it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.04it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.02it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 126.47it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 126.73it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 128.32it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 128.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 128.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 126.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 124.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 124.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 125.72it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 127.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 129.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 128.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 128.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 128.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 128.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 129.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 130.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 130.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 132.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  best_test_acc 0.763
wandb: best_valid_acc 0.762
wandb:  sub_train_acc 0.78434
wandb: sub_train_loss 1.30744
wandb:       test_acc 0.767
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run vital-sweep-768 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected/runs/vttvynua
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_icassp_undirected
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240829_003740-vttvynua/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
